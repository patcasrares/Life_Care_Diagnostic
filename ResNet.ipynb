{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aaa021fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all imported\n"
     ]
    }
   ],
   "source": [
    "# Import the necessary libraries\n",
    "from PIL import Image\n",
    "from numpy import asarray\n",
    "import numpy as np\n",
    "import os\n",
    "import keras\n",
    "from keras.layers import Dense, Conv2D, BatchNormalization, Activation\n",
    "from keras.layers import AveragePooling2D, Input, Flatten\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.regularizers import l2\n",
    "from keras import backend as K\n",
    "from keras.models import Model\n",
    "from keras.datasets import cifar10\n",
    "import numpy as np\n",
    "import os\n",
    "from keras.utils import np_utils\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "# calculates f1 for 1:100 dataset with 95tp, 5fn, 55fp\n",
    "from sklearn.metrics import f1_score\n",
    "print('all imported')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "68181300",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 74  74  74]\n",
      "  [ 83  83  83]\n",
      "  [ 86  86  86]\n",
      "  ...\n",
      "  [108 108 108]\n",
      "  [107 107 107]\n",
      "  [102 102 102]]\n",
      "\n",
      " [[  8   8   8]\n",
      "  [  8   8   8]\n",
      "  [  7   7   7]\n",
      "  ...\n",
      "  [  9   9   9]\n",
      "  [ 14  14  14]\n",
      "  [ 25  25  25]]\n",
      "\n",
      " [[  8   8   8]\n",
      "  [  7   7   7]\n",
      "  [  7   7   7]\n",
      "  ...\n",
      "  [  9   9   9]\n",
      "  [ 15  15  15]\n",
      "  [ 27  27  27]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[  8   8   8]\n",
      "  [  7   7   7]\n",
      "  [  7   7   7]\n",
      "  ...\n",
      "  [128 128 128]\n",
      "  [ 87  87  87]\n",
      "  [ 84  84  84]]\n",
      "\n",
      " [[  8   8   8]\n",
      "  [  8   8   8]\n",
      "  [  7   7   7]\n",
      "  ...\n",
      "  [ 66  66  66]\n",
      "  [ 73  73  73]\n",
      "  [ 77  77  77]]\n",
      "\n",
      " [[ 87  87  87]\n",
      "  [ 70  70  70]\n",
      "  [ 61  61  61]\n",
      "  ...\n",
      "  [ 85  85  85]\n",
      "  [ 79  79  79]\n",
      "  [ 73  73  73]]]\n"
     ]
    }
   ],
   "source": [
    "def readImage(filePath):\n",
    "    img = Image.open(filePath)\n",
    "    \n",
    "    size=(30,40)\n",
    "    #resize image\n",
    "    out = img.resize(size)\n",
    "\n",
    "    # asarray() class is used to convert\n",
    "    # PIL images into NumPy arrays\n",
    "    numpydata = asarray(out)\n",
    "    numpydata = np.repeat(numpydata[:, :, np.newaxis], 3, axis=2)\n",
    "    # <class 'numpy.ndarray'>\n",
    "    #print(type(numpydata))\n",
    "\n",
    "    #  shape\n",
    "    #print(numpydata.shape)\n",
    "    return numpydata\n",
    "print(readImage('../../content/Benign/B_3141_1.RIGHT_CC.LJPEG.1_highpass.gif'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4fd11c2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['B_3091_1.LEFT_CC.LJPEG.1_highpass.gif', 'B_3091_1.LEFT_MLO.LJPEG.1_highpass.gif', 'B_3093_1.LEFT_CC.LJPEG.1_highpass.gif', 'B_3093_1.LEFT_MLO.LJPEG.1_highpass.gif', 'B_3094_1.LEFT_CC.LJPEG.1_highpass.gif']\n"
     ]
    }
   ],
   "source": [
    "listFiles = os.listdir('../../content/Benign/')\n",
    "print(listFiles[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f9b74ddd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[[  5,   5,   5],\n",
      "        [ 21,  21,  21],\n",
      "        [ 13,  13,  13],\n",
      "        ...,\n",
      "        [  7,   7,   7],\n",
      "        [  5,   5,   5],\n",
      "        [  2,   2,   2]],\n",
      "\n",
      "       [[ 23,  23,  23],\n",
      "        [ 14,  14,  14],\n",
      "        [  9,   9,   9],\n",
      "        ...,\n",
      "        [  1,   1,   1],\n",
      "        [  0,   0,   0],\n",
      "        [  0,   0,   0]],\n",
      "\n",
      "       [[ 23,  23,  23],\n",
      "        [ 14,  14,  14],\n",
      "        [  9,   9,   9],\n",
      "        ...,\n",
      "        [  0,   0,   0],\n",
      "        [  0,   0,   0],\n",
      "        [  0,   0,   0]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[ 29,  29,  29],\n",
      "        [ 17,  17,  17],\n",
      "        [ 10,  10,  10],\n",
      "        ...,\n",
      "        [  0,   0,   0],\n",
      "        [  0,   0,   0],\n",
      "        [  0,   0,   0]],\n",
      "\n",
      "       [[128, 128, 128],\n",
      "        [ 17,  17,  17],\n",
      "        [ 12,  12,  12],\n",
      "        ...,\n",
      "        [  0,   0,   0],\n",
      "        [  0,   0,   0],\n",
      "        [  0,   0,   0]],\n",
      "\n",
      "       [[128, 128, 128],\n",
      "        [128, 128, 128],\n",
      "        [ 14,  14,  14],\n",
      "        ...,\n",
      "        [  7,   7,   7],\n",
      "        [  6,   6,   6],\n",
      "        [  6,   6,   6]]], dtype=uint8), array([[[108, 108, 108],\n",
      "        [117, 117, 117],\n",
      "        [116, 116, 116],\n",
      "        ...,\n",
      "        [  1,   1,   1],\n",
      "        [  1,   1,   1],\n",
      "        [  1,   1,   1]],\n",
      "\n",
      "       [[112, 112, 112],\n",
      "        [108, 108, 108],\n",
      "        [115, 115, 115],\n",
      "        ...,\n",
      "        [  1,   1,   1],\n",
      "        [  1,   1,   1],\n",
      "        [  1,   1,   1]],\n",
      "\n",
      "       [[117, 117, 117],\n",
      "        [112, 112, 112],\n",
      "        [110, 110, 110],\n",
      "        ...,\n",
      "        [  1,   1,   1],\n",
      "        [  1,   1,   1],\n",
      "        [  1,   1,   1]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[ 25,  25,  25],\n",
      "        [ 17,  17,  17],\n",
      "        [ 10,  10,  10],\n",
      "        ...,\n",
      "        [  0,   0,   0],\n",
      "        [  0,   0,   0],\n",
      "        [  0,   0,   0]],\n",
      "\n",
      "       [[ 24,  24,  24],\n",
      "        [ 18,  18,  18],\n",
      "        [ 11,  11,  11],\n",
      "        ...,\n",
      "        [  0,   0,   0],\n",
      "        [  0,   0,   0],\n",
      "        [  0,   0,   0]],\n",
      "\n",
      "       [[128, 128, 128],\n",
      "        [ 19,  19,  19],\n",
      "        [ 19,  19,  19],\n",
      "        ...,\n",
      "        [  6,   6,   6],\n",
      "        [  6,   6,   6],\n",
      "        [  6,   6,   6]]], dtype=uint8), array([[[  1,   1,   1],\n",
      "        [  7,   7,   7],\n",
      "        [  4,   4,   4],\n",
      "        ...,\n",
      "        [  0,   0,   0],\n",
      "        [  0,   0,   0],\n",
      "        [  0,   0,   0]],\n",
      "\n",
      "       [[ 21,  21,  21],\n",
      "        [ 15,  15,  15],\n",
      "        [ 11,  11,  11],\n",
      "        ...,\n",
      "        [  4,   4,   4],\n",
      "        [  7,   7,   7],\n",
      "        [ 12,  12,  12]],\n",
      "\n",
      "       [[ 19,  19,  19],\n",
      "        [ 15,  15,  15],\n",
      "        [ 11,  11,  11],\n",
      "        ...,\n",
      "        [  4,   4,   4],\n",
      "        [  6,   6,   6],\n",
      "        [ 11,  11,  11]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[ 28,  28,  28],\n",
      "        [ 19,  19,  19],\n",
      "        [ 10,  10,  10],\n",
      "        ...,\n",
      "        [  0,   0,   0],\n",
      "        [  0,   0,   0],\n",
      "        [  1,   1,   1]],\n",
      "\n",
      "       [[ 22,  22,  22],\n",
      "        [ 14,  14,  14],\n",
      "        [ 10,  10,  10],\n",
      "        ...,\n",
      "        [  0,   0,   0],\n",
      "        [  0,   0,   0],\n",
      "        [  1,   1,   1]],\n",
      "\n",
      "       [[128, 128, 128],\n",
      "        [ 35,  35,  35],\n",
      "        [ 23,  23,  23],\n",
      "        ...,\n",
      "        [  0,   0,   0],\n",
      "        [  0,   0,   0],\n",
      "        [  0,   0,   0]]], dtype=uint8)]\n",
      "(40, 30, 3)\n"
     ]
    }
   ],
   "source": [
    "#load Benign\n",
    "listCancer = []\n",
    "listResults = []\n",
    "for elem in listFiles:\n",
    "    img = readImage('../../content/Benign/'+elem)\n",
    "    listCancer += [img]\n",
    "    listResults += [np.array([1])]\n",
    "print(listCancer[:3])\n",
    "print(img.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e7cf790e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['A_0002_1.LEFT_CC.LJPEG.1_highpass.gif', 'A_0002_1.LEFT_MLO.LJPEG.1_highpass.gif', 'A_0002_1.RIGHT_CC.LJPEG.1_highpass.gif', 'A_0002_1.RIGHT_MLO.LJPEG.1_highpass.gif', 'A_0003_1.LEFT_CC.LJPEG.1_highpass.gif']\n"
     ]
    }
   ],
   "source": [
    "listFiles = os.listdir('../../content/Normal/')\n",
    "print(listFiles[:5])\n",
    "for elem in listFiles:\n",
    "    img = readImage('../../content/Normal/'+elem)\n",
    "    listResults += [np.array([0])]\n",
    "    listCancer += [img]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0162b926",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['B_3006_1.LEFT_CC.LJPEG.1_highpass.gif', 'B_3006_1.LEFT_MLO.LJPEG.1_highpass.gif', 'B_3011_1.LEFT_CC.LJPEG.1_highpass.gif', 'B_3011_1.LEFT_MLO.LJPEG.1_highpass.gif', 'B_3011_1.RIGHT_CC.LJPEG.1_highpass.gif']\n"
     ]
    }
   ],
   "source": [
    "listFiles = os.listdir('../../content/Malign/')\n",
    "print(listFiles[:5])\n",
    "for elem in listFiles:\n",
    "    img = readImage('../../content/Malign/'+elem)\n",
    "    listResults += [np.array([2])]\n",
    "    listCancer += [img]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c6134bb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300\n"
     ]
    }
   ],
   "source": [
    "print(len(listCancer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e15204a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_test():\n",
    "    per = np.random.permutation(len(listCancer))\n",
    "    ln = int(len(listCancer) * 0.8)\n",
    "    x_train = []\n",
    "    y_train = []\n",
    "    x_test = []\n",
    "    y_test = []\n",
    "    positions = []\n",
    "    for i in range(ln):\n",
    "        positions += [per[i]]\n",
    "    for i in range(len(listCancer)):\n",
    "        if i in positions:\n",
    "            x_train += [listCancer[i]]\n",
    "            y_train += [listResults[i]]\n",
    "        else:\n",
    "            x_test += [listCancer[i]]\n",
    "            y_test += [listResults[i]]\n",
    "    \n",
    "    x_train = np.array(x_train)\n",
    "    y_train = np.array(y_train)\n",
    "\n",
    "    x_test = np.array(x_test)\n",
    "    y_test = np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7b91ed89",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data():\n",
    "    # Setting Training Hyperparameters\n",
    "    batch_size = 32 # original ResNet paper uses batch_size = 128 for training\n",
    "    epochs = 10\n",
    "    data_augmentation = True\n",
    "    num_classes = 10\n",
    "\n",
    "    # Data Preprocessing\n",
    "    subtract_pixel_mean = True\n",
    "    n = 3\n",
    "\n",
    "    # Select ResNet Version\n",
    "    version = 2\n",
    "\n",
    "    # Computed depth of\n",
    "    if version == 1:\n",
    "        depth = n * 6 + 2\n",
    "    elif version == 2:\n",
    "        depth = n * 9 + 2\n",
    "\n",
    "    # Model name, depth and version\n",
    "    model_type = 'ResNet % dv % d' % (depth, version)\n",
    "\n",
    "    # use the data\n",
    "    print(x_train[:3])\n",
    "    print(y_train[:3])\n",
    "    print(type(x_train[0]))\n",
    "    print(type(x_train))\n",
    "    print(type(y_train[0]))\n",
    "    print(type(y_train))\n",
    "\n",
    "    # Input image dimensions.\n",
    "    input_shape = x_train.shape[1:]\n",
    "    print(input_shape)\n",
    "\n",
    "    # Normalize data.\n",
    "    x_train = x_train.astype('float32') / 255\n",
    "    x_test = x_test.astype('float32') / 255\n",
    "\n",
    "    # If subtract pixel mean is enabled\n",
    "    if subtract_pixel_mean:\n",
    "        x_train_mean = np.mean(x_train, axis = 0)\n",
    "        x_train -= x_train_mean\n",
    "        x_test -= x_train_mean\n",
    "\n",
    "    # Print Training and Test Samples\n",
    "    print('x_train shape:', x_train.shape)\n",
    "    print(x_train.shape[0], 'train samples')\n",
    "    print(x_test.shape[0], 'test samples')\n",
    "    print('y_train shape:', y_train.shape)\n",
    "\n",
    "    # Convert class vectors to binary class matrices.\n",
    "    y_train = keras.utils.np_utils.to_categorical(y_train, num_classes)\n",
    "    y_test = keras.utils.np_utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e031e369",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting LR for different number of Epochs\n",
    "def lr_schedule(epoch):\n",
    "\tlr = 1e-3\n",
    "\tif epoch > 180:\n",
    "\t\tlr *= 0.5e-3\n",
    "\telif epoch > 160:\n",
    "\t\tlr *= 1e-3\n",
    "\telif epoch > 120:\n",
    "\t\tlr *= 1e-2\n",
    "\telif epoch > 80:\n",
    "\t\tlr *= 1e-1\n",
    "\tprint('Learning rate: ', lr)\n",
    "\treturn lr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2e7b97e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic ResNet Building Block\n",
    "def resnet_layer(inputs, conv_first = False,\n",
    "\t\t\t\tnum_filters = 16,\n",
    "\t\t\t\tkernel_size = 3,\n",
    "\t\t\t\tstrides = 1,\n",
    "\t\t\t\tactivation ='relu',\n",
    "\t\t\t\tbatch_normalization = True):\n",
    "\tconv = Conv2D(num_filters,\n",
    "\t\t\t\tkernel_size = kernel_size,\n",
    "\t\t\t\tstrides = strides,\n",
    "\t\t\t\tpadding ='same',\n",
    "\t\t\t\tkernel_initializer ='he_normal',\n",
    "\t\t\t\tkernel_regularizer = l2(1e-4))\n",
    "\n",
    "\tx = inputs\n",
    "\tif conv_first:\n",
    "\t\tx = conv(x)\n",
    "\t\tif batch_normalization:\n",
    "\t\t\tx = BatchNormalization()(x)\n",
    "\t\tif activation is not None:\n",
    "\t\t\tx = Activation(activation)(x)\n",
    "\telse:\n",
    "\t\tif batch_normalization:\n",
    "\t\t\tx = BatchNormalization()(x)\n",
    "\t\tif activation is not None:\n",
    "\t\t\tx = Activation(activation)(x)\n",
    "\t\tx = conv(x)\n",
    "\treturn x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9c3ccc68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ResNet V2 architecture\n",
    "def resnet_v2(input_shape, depth, num_classes = 10):\n",
    "\tif (depth - 2) % 9 != 0:\n",
    "\t\traise ValueError('depth should be 9n + 2 (eg 56 or 110 in [b])')\n",
    "\t# Start model definition.\n",
    "\tnum_filters_in = 16\n",
    "\tnum_res_blocks = int((depth - 2) / 9)\n",
    "\n",
    "\tinputs = Input(shape = input_shape)\n",
    "\t# v2 performs Conv2D with BN-ReLU on input before splitting into 2 paths\n",
    "\tx = resnet_layer(inputs = inputs,num_filters = num_filters_in,conv_first = True)\n",
    "\n",
    "\t# Instantiate the stack of residual units\n",
    "\tfor stage in range(3):\n",
    "\t\tfor res_block in range(num_res_blocks):\n",
    "\t\t\tactivation = 'relu'\n",
    "\t\t\tbatch_normalization = True\n",
    "\t\t\tstrides = 1\n",
    "\t\t\tif stage == 0:\n",
    "\t\t\t\tnum_filters_out = num_filters_in * 4\n",
    "\t\t\t\tif res_block == 0: # first layer and first stage\n",
    "\t\t\t\t\tactivation = None\n",
    "\t\t\t\t\tbatch_normalization = False\n",
    "\t\t\telse:\n",
    "\t\t\t\tnum_filters_out = num_filters_in * 2\n",
    "\t\t\t\tif res_block == 0: # first layer but not first stage\n",
    "\t\t\t\t\tstrides = 2 # downsample\n",
    "\n",
    "\t\t\t# bottleneck residual unit\n",
    "\t\t\ty = resnet_layer(inputs = x,\n",
    "\t\t\t\t\t\t\tnum_filters = num_filters_in,\n",
    "\t\t\t\t\t\t\tkernel_size = 1,\n",
    "\t\t\t\t\t\t\tstrides = strides,\n",
    "\t\t\t\t\t\t\tactivation = activation,\n",
    "\t\t\t\t\t\t\tbatch_normalization = batch_normalization)\n",
    "\t\t\ty = resnet_layer(inputs = y,\n",
    "\t\t\t\t\t\t\tnum_filters = num_filters_in,\n",
    "\t\t\t\t\t\t\tconv_first = False)\n",
    "\t\t\ty = resnet_layer(inputs = y,\n",
    "\t\t\t\t\t\t\tnum_filters = num_filters_out,\n",
    "\t\t\t\t\t\t\tkernel_size = 1,\n",
    "\t\t\t\t\t\t\tconv_first = False)\n",
    "\t\t\tif res_block == 0:\n",
    "\t\t\t\t# linear projection residual shortcut connection to match\n",
    "\t\t\t\t# changed dims\n",
    "\t\t\t\tx = resnet_layer(inputs = x,\n",
    "\t\t\t\t\t\t\t\tnum_filters = num_filters_out,\n",
    "\t\t\t\t\t\t\t\tkernel_size = 1,\n",
    "\t\t\t\t\t\t\t\tstrides = strides,\n",
    "\t\t\t\t\t\t\t\tactivation = None,\n",
    "\t\t\t\t\t\t\t\tbatch_normalization = False)\n",
    "\t\t\tx = keras.layers.add([x, y])\n",
    "\n",
    "\t\tnum_filters_in = num_filters_out\n",
    "\n",
    "\t# Add classifier on top.\n",
    "\t# v2 has BN-ReLU before Pooling\n",
    "\tx = BatchNormalization()(x)\n",
    "\tx = Activation('relu')(x)\n",
    "\tx = AveragePooling2D(pool_size = 8)(x)\n",
    "\ty = Flatten()(x)\n",
    "\toutputs = Dense(num_classes,\n",
    "\t\t\t\t\tactivation ='softmax',\n",
    "\t\t\t\t\tkernel_initializer ='he_normal')(y)\n",
    "\n",
    "\t# Instantiate model.\n",
    "\tmodel = Model(inputs = inputs, outputs = outputs)\n",
    "\treturn model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "71df1011",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train=[]\n",
    "y_train=[]\n",
    "accs=[]\n",
    "\n",
    "precisions = []\n",
    "recalls = []\n",
    "def main(pz):\n",
    "    \n",
    "    per = np.random.permutation(len(listCancer))\n",
    "    ln = int(len(listCancer) * 0.8)\n",
    "    x_train = []\n",
    "    y_train = []\n",
    "    x_test = []\n",
    "    y_test = []\n",
    "    positions = []\n",
    "    for i in range(ln):\n",
    "        positions += [per[i]]\n",
    "    for i in range(len(listCancer)):\n",
    "        if i in positions:\n",
    "            x_train += [listCancer[i]]\n",
    "            y_train += [listResults[i]]\n",
    "        else:\n",
    "            x_test += [listCancer[i]]\n",
    "            y_test += [listResults[i]]\n",
    "            \n",
    "    ln = len(x_test) // 2\n",
    "    \n",
    "    x_valid = x_test[ln:]\n",
    "    y_valid = y_test[ln:]\n",
    "    \n",
    "    x_test = x_test[:ln]\n",
    "    y_test = y_test[:ln]\n",
    "    \n",
    "    \n",
    "    x_train = np.array(x_train)\n",
    "    y_train = np.array(y_train)\n",
    "    \n",
    "\n",
    "    x_test = np.array(x_test)\n",
    "    y_test = np.array(y_test)\n",
    "    \n",
    "    x_valid = np.array(x_valid)\n",
    "    y_valid = np.array(y_valid)\n",
    "    \n",
    "    \n",
    "    batch_size = 32 # original ResNet paper uses batch_size = 128 for training\n",
    "    epochs = 10\n",
    "    data_augmentation = True\n",
    "    num_classes = 10\n",
    "\n",
    "    # Data Preprocessing\n",
    "    subtract_pixel_mean = True\n",
    "    n = 3\n",
    "\n",
    "    # Select ResNet Version\n",
    "    version = 2\n",
    "\n",
    "    # Computed depth of\n",
    "    if version == 1:\n",
    "        depth = n * 6 + 2\n",
    "    elif version == 2:\n",
    "        depth = n * 9 + 2\n",
    "\n",
    "    # Model name, depth and version\n",
    "    model_type = 'ResNet % dv % d' % (depth, version)\n",
    "\n",
    "    # use the data\n",
    "    print(x_train[:3])\n",
    "    print(y_train[:3])\n",
    "    print(type(x_train[0]))\n",
    "    print(type(x_train))\n",
    "    print(type(y_train[0]))\n",
    "    print(type(y_train))\n",
    "\n",
    "    # Input image dimensions.\n",
    "    input_shape = x_train.shape[1:]\n",
    "    print(input_shape)\n",
    "\n",
    "    # Normalize data.\n",
    "    x_train = x_train.astype('float32') / 255\n",
    "    x_test = x_test.astype('float32') / 255\n",
    "    x_valid = x_test.astype('float32') / 255\n",
    "\n",
    "    # If subtract pixel mean is enabled\n",
    "    if subtract_pixel_mean:\n",
    "        x_train_mean = np.mean(x_train, axis = 0)\n",
    "        x_train -= x_train_mean\n",
    "        x_test -= x_train_mean\n",
    "\n",
    "    # Print Training and Test Samples\n",
    "    print('x_train shape:', x_train.shape)\n",
    "    print(x_train.shape[0], 'train samples')\n",
    "    print(x_test.shape[0], 'test samples')\n",
    "    print('y_train shape:', y_train.shape)\n",
    "\n",
    "    # Convert class vectors to binary class matrices.\n",
    "    y_train = keras.utils.np_utils.to_categorical(y_train, num_classes)\n",
    "    y_test = keras.utils.np_utils.to_categorical(y_test, num_classes)\n",
    "    y_valid = keras.utils.np_utils.to_categorical(y_valid, num_classes)\n",
    "    \n",
    "    \n",
    "    model = resnet_v2(input_shape = input_shape, depth = depth)\n",
    "\n",
    "    model.compile(loss ='categorical_crossentropy',\n",
    "                optimizer = Adam(learning_rate = lr_schedule(0)),\n",
    "                metrics =['accuracy'])\n",
    "    model.summary()\n",
    "    print(model_type)\n",
    "\n",
    "    # Prepare model model saving directory.\n",
    "    save_dir = os.path.join(os.getcwd(), 'saved_models')\n",
    "    model_name = 'cifar10_% s_model.{epoch:03d}.h5' % model_type\n",
    "    if not os.path.isdir(save_dir):\n",
    "        os.makedirs(save_dir)\n",
    "    filepath = os.path.join(save_dir, model_name)\n",
    "\n",
    "    # Prepare callbacks for model saving and for learning rate adjustment.\n",
    "    checkpoint = ModelCheckpoint(filepath = filepath,\n",
    "                                monitor ='val_acc',\n",
    "                                verbose = 1,\n",
    "                                save_best_only = True)\n",
    "\n",
    "    lr_scheduler = LearningRateScheduler(lr_schedule)\n",
    "\n",
    "    lr_reducer = ReduceLROnPlateau(factor = np.sqrt(0.1),\n",
    "                                cooldown = 0,\n",
    "                                patience = 5,\n",
    "                                min_lr = 0.5e-6)\n",
    "\n",
    "    callbacks = [checkpoint, lr_reducer, lr_scheduler]\n",
    "\n",
    "    # Run training, with or without data augmentation.\n",
    "    if not data_augmentation:\n",
    "        print('Not using data augmentation.')\n",
    "        model.fit(x_train, y_train,\n",
    "                batch_size = batch_size,\n",
    "                epochs = epochs,\n",
    "                validation_data =(x_test, y_test),\n",
    "                shuffle = True,\n",
    "                callbacks = callbacks)\n",
    "    else:\n",
    "        print('Using real-time data augmentation.')\n",
    "        # This will do preprocessing and realtime data augmentation:\n",
    "        datagen = ImageDataGenerator(\n",
    "            # set input mean to 0 over the dataset\n",
    "            featurewise_center = False,\n",
    "            # set each sample mean to 0\n",
    "            samplewise_center = False,\n",
    "            # divide inputs by std of dataset\n",
    "            featurewise_std_normalization = False,\n",
    "            # divide each input by its std\n",
    "            samplewise_std_normalization = False,\n",
    "            # apply ZCA whitening\n",
    "            zca_whitening = False,\n",
    "            # epsilon for ZCA whitening\n",
    "            zca_epsilon = 1e-06,\n",
    "            # randomly rotate images in the range (deg 0 to 180)\n",
    "            rotation_range = 0,\n",
    "            # randomly shift images horizontally\n",
    "            width_shift_range = 0.1,\n",
    "            # randomly shift images vertically\n",
    "            height_shift_range = 0.1,\n",
    "            # set range for random shear\n",
    "            shear_range = 0.,\n",
    "            # set range for random zoom\n",
    "            zoom_range = 0.,\n",
    "            # set range for random channel shifts\n",
    "            channel_shift_range = 0.,\n",
    "            # set mode for filling points outside the input boundaries\n",
    "            fill_mode ='nearest',\n",
    "            # value used for fill_mode = \"constant\"\n",
    "            cval = 0.,\n",
    "            # randomly flip images\n",
    "            horizontal_flip = True,\n",
    "            # randomly flip images\n",
    "            vertical_flip = False,\n",
    "            # set rescaling factor (applied before any other transformation)\n",
    "            rescale = None,\n",
    "            # set function that will be applied on each input\n",
    "            preprocessing_function = None,\n",
    "            # image data format, either \"channels_first\" or \"channels_last\"\n",
    "            data_format = None,\n",
    "            # fraction of images reserved for validation (strictly between 0 and 1)\n",
    "            validation_split = 0.1)\n",
    "\n",
    "        # Compute quantities required for featurewise normalization\n",
    "        # (std, mean, and principal components if ZCA whitening is applied).\n",
    "        print('------------------')\n",
    "        print(x_train)\n",
    "        datagen.fit(x_train)\n",
    "\n",
    "        # Fit the model on the batches generated by datagen.flow().\n",
    "        model.fit_generator(datagen.flow(x_train, y_train, batch_size = batch_size),\n",
    "                            validation_data =(x_valid, y_valid),\n",
    "                            epochs = 100, verbose = 1, workers = 4,\n",
    "                            callbacks = callbacks)\n",
    "\n",
    "    # Score trained model.\n",
    "    scores = model.evaluate(x_test, y_test, verbose = 1)\n",
    "    print('Test loss:', scores[0])\n",
    "    print('Test accuracy:', scores[1])\n",
    "    ret = model.predict(x_test)\n",
    "    result = []\n",
    "    pred = []\n",
    "    for a,b in zip(ret, y_test):\n",
    "        pred+=[a.argmax(axis=-1)]\n",
    "        result+=[b.argmax(axis=-1)]\n",
    "    print(pred)\n",
    "    print(result)\n",
    "    precision = precision_score(result, pred, average='weighted')\n",
    "    recall = recall_score(result, pred, average='weighted')\n",
    "     # calculates f1 for 1:100 dataset with 95tp, 5fn, 55fp\n",
    "    fmeasure = f1_score(result, pred, average='weighted')\n",
    "    print('Precision: ', precision)\n",
    "    print('Recall: ', recall)\n",
    "    print('F1 Score: ', fmeasure)\n",
    "    #precisions += [precision]\n",
    "    #recalls += [recall]\n",
    "    #model.save('saved_models/resNetV'+pz+'.h5')\n",
    "    return [scores[1], precision, recall, fmeasure]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ee89ef05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[[  5   5   5]\n",
      "   [ 21  21  21]\n",
      "   [ 13  13  13]\n",
      "   ...\n",
      "   [  7   7   7]\n",
      "   [  5   5   5]\n",
      "   [  2   2   2]]\n",
      "\n",
      "  [[ 23  23  23]\n",
      "   [ 14  14  14]\n",
      "   [  9   9   9]\n",
      "   ...\n",
      "   [  1   1   1]\n",
      "   [  0   0   0]\n",
      "   [  0   0   0]]\n",
      "\n",
      "  [[ 23  23  23]\n",
      "   [ 14  14  14]\n",
      "   [  9   9   9]\n",
      "   ...\n",
      "   [  0   0   0]\n",
      "   [  0   0   0]\n",
      "   [  0   0   0]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[ 29  29  29]\n",
      "   [ 17  17  17]\n",
      "   [ 10  10  10]\n",
      "   ...\n",
      "   [  0   0   0]\n",
      "   [  0   0   0]\n",
      "   [  0   0   0]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [ 17  17  17]\n",
      "   [ 12  12  12]\n",
      "   ...\n",
      "   [  0   0   0]\n",
      "   [  0   0   0]\n",
      "   [  0   0   0]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [ 14  14  14]\n",
      "   ...\n",
      "   [  7   7   7]\n",
      "   [  6   6   6]\n",
      "   [  6   6   6]]]\n",
      "\n",
      "\n",
      " [[[108 108 108]\n",
      "   [117 117 117]\n",
      "   [116 116 116]\n",
      "   ...\n",
      "   [  1   1   1]\n",
      "   [  1   1   1]\n",
      "   [  1   1   1]]\n",
      "\n",
      "  [[112 112 112]\n",
      "   [108 108 108]\n",
      "   [115 115 115]\n",
      "   ...\n",
      "   [  1   1   1]\n",
      "   [  1   1   1]\n",
      "   [  1   1   1]]\n",
      "\n",
      "  [[117 117 117]\n",
      "   [112 112 112]\n",
      "   [110 110 110]\n",
      "   ...\n",
      "   [  1   1   1]\n",
      "   [  1   1   1]\n",
      "   [  1   1   1]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[ 25  25  25]\n",
      "   [ 17  17  17]\n",
      "   [ 10  10  10]\n",
      "   ...\n",
      "   [  0   0   0]\n",
      "   [  0   0   0]\n",
      "   [  0   0   0]]\n",
      "\n",
      "  [[ 24  24  24]\n",
      "   [ 18  18  18]\n",
      "   [ 11  11  11]\n",
      "   ...\n",
      "   [  0   0   0]\n",
      "   [  0   0   0]\n",
      "   [  0   0   0]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [ 19  19  19]\n",
      "   [ 19  19  19]\n",
      "   ...\n",
      "   [  6   6   6]\n",
      "   [  6   6   6]\n",
      "   [  6   6   6]]]\n",
      "\n",
      "\n",
      " [[[  1   1   1]\n",
      "   [  7   7   7]\n",
      "   [  4   4   4]\n",
      "   ...\n",
      "   [  0   0   0]\n",
      "   [  0   0   0]\n",
      "   [  0   0   0]]\n",
      "\n",
      "  [[ 21  21  21]\n",
      "   [ 15  15  15]\n",
      "   [ 11  11  11]\n",
      "   ...\n",
      "   [  4   4   4]\n",
      "   [  7   7   7]\n",
      "   [ 12  12  12]]\n",
      "\n",
      "  [[ 19  19  19]\n",
      "   [ 15  15  15]\n",
      "   [ 11  11  11]\n",
      "   ...\n",
      "   [  4   4   4]\n",
      "   [  6   6   6]\n",
      "   [ 11  11  11]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[ 28  28  28]\n",
      "   [ 19  19  19]\n",
      "   [ 10  10  10]\n",
      "   ...\n",
      "   [  0   0   0]\n",
      "   [  0   0   0]\n",
      "   [  1   1   1]]\n",
      "\n",
      "  [[ 22  22  22]\n",
      "   [ 14  14  14]\n",
      "   [ 10  10  10]\n",
      "   ...\n",
      "   [  0   0   0]\n",
      "   [  0   0   0]\n",
      "   [  1   1   1]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [ 35  35  35]\n",
      "   [ 23  23  23]\n",
      "   ...\n",
      "   [  0   0   0]\n",
      "   [  0   0   0]\n",
      "   [  0   0   0]]]]\n",
      "[[1]\n",
      " [1]\n",
      " [1]]\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "(40, 30, 3)\n",
      "x_train shape: (240, 40, 30, 3)\n",
      "240 train samples\n",
      "30 test samples\n",
      "y_train shape: (240, 1)\n",
      "Learning rate:  0.001\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 40, 30, 3)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 40, 30, 16)   448         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 40, 30, 16)   64          conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 40, 30, 16)   0           batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 40, 30, 16)   272         activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 40, 30, 16)   64          conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 40, 30, 16)   0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 40, 30, 16)   2320        activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 40, 30, 16)   64          conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 40, 30, 16)   0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 40, 30, 64)   1088        activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 40, 30, 64)   1088        activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "add (Add)                       (None, 40, 30, 64)   0           conv2d_4[0][0]                   \n",
      "                                                                 conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 40, 30, 64)   256         add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 40, 30, 64)   0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 40, 30, 16)   1040        activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 40, 30, 16)   64          conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 40, 30, 16)   0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 40, 30, 16)   2320        activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 40, 30, 16)   64          conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 40, 30, 16)   0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 40, 30, 64)   1088        activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 40, 30, 64)   0           add[0][0]                        \n",
      "                                                                 conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 40, 30, 64)   256         add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 40, 30, 64)   0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 40, 30, 16)   1040        activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 40, 30, 16)   64          conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 40, 30, 16)   0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 40, 30, 16)   2320        activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 40, 30, 16)   64          conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 40, 30, 16)   0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 40, 30, 64)   1088        activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 40, 30, 64)   0           add_1[0][0]                      \n",
      "                                                                 conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 40, 30, 64)   256         add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 40, 30, 64)   0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 20, 15, 64)   4160        activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 20, 15, 64)   256         conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 20, 15, 64)   0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 20, 15, 64)   36928       activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 20, 15, 64)   256         conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 20, 15, 64)   0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 20, 15, 128)  8320        add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 20, 15, 128)  8320        activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 20, 15, 128)  0           conv2d_14[0][0]                  \n",
      "                                                                 conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 20, 15, 128)  512         add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 20, 15, 128)  0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 20, 15, 64)   8256        activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 20, 15, 64)   256         conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 20, 15, 64)   0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 20, 15, 64)   36928       activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 20, 15, 64)   256         conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 20, 15, 64)   0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 20, 15, 128)  8320        activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 20, 15, 128)  0           add_3[0][0]                      \n",
      "                                                                 conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 20, 15, 128)  512         add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 20, 15, 128)  0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 20, 15, 64)   8256        activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 20, 15, 64)   256         conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 20, 15, 64)   0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 20, 15, 64)   36928       activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 20, 15, 64)   256         conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 20, 15, 64)   0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 20, 15, 128)  8320        activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 20, 15, 128)  0           add_4[0][0]                      \n",
      "                                                                 conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 20, 15, 128)  512         add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 20, 15, 128)  0           batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, 10, 8, 128)   16512       activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, 10, 8, 128)   512         conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 10, 8, 128)   0           batch_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, 10, 8, 128)   147584      activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, 10, 8, 128)   512         conv2d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 10, 8, 128)   0           batch_normalization_20[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)              (None, 10, 8, 256)   33024       add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, 10, 8, 256)   33024       activation_20[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 10, 8, 256)   0           conv2d_24[0][0]                  \n",
      "                                                                 conv2d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNo (None, 10, 8, 256)   1024        add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 10, 8, 256)   0           batch_normalization_21[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_25 (Conv2D)              (None, 10, 8, 128)   32896       activation_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNo (None, 10, 8, 128)   512         conv2d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 10, 8, 128)   0           batch_normalization_22[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_26 (Conv2D)              (None, 10, 8, 128)   147584      activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNo (None, 10, 8, 128)   512         conv2d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, 10, 8, 128)   0           batch_normalization_23[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_27 (Conv2D)              (None, 10, 8, 256)   33024       activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 10, 8, 256)   0           add_6[0][0]                      \n",
      "                                                                 conv2d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_24 (BatchNo (None, 10, 8, 256)   1024        add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, 10, 8, 256)   0           batch_normalization_24[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_28 (Conv2D)              (None, 10, 8, 128)   32896       activation_24[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_25 (BatchNo (None, 10, 8, 128)   512         conv2d_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, 10, 8, 128)   0           batch_normalization_25[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_29 (Conv2D)              (None, 10, 8, 128)   147584      activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_26 (BatchNo (None, 10, 8, 128)   512         conv2d_29[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, 10, 8, 128)   0           batch_normalization_26[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_30 (Conv2D)              (None, 10, 8, 256)   33024       activation_26[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, 10, 8, 256)   0           add_7[0][0]                      \n",
      "                                                                 conv2d_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_27 (BatchNo (None, 10, 8, 256)   1024        add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, 10, 8, 256)   0           batch_normalization_27[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d (AveragePooli (None, 1, 1, 256)    0           activation_27[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 256)          0           average_pooling2d[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 10)           2570        flatten[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 849,002\n",
      "Trainable params: 843,786\n",
      "Non-trainable params: 5,216\n",
      "__________________________________________________________________________________________________\n",
      "ResNet  29v  2\n",
      "Using real-time data augmentation.\n",
      "------------------\n",
      "[[[[-0.12633982 -0.12633982 -0.12633982]\n",
      "   [-0.06622542 -0.06622542 -0.06622542]\n",
      "   [-0.0895751  -0.0895751  -0.0895751 ]\n",
      "   ...\n",
      "   [-0.14098041 -0.14098041 -0.14098041]\n",
      "   [-0.15826795 -0.15826795 -0.15826795]\n",
      "   [-0.1768627  -0.1768627  -0.1768627 ]]\n",
      "\n",
      "  [[-0.05580062 -0.05580062 -0.05580062]\n",
      "   [-0.08037578 -0.08037578 -0.08037578]\n",
      "   [-0.09676458 -0.09676458 -0.09676458]\n",
      "   ...\n",
      "   [-0.13807188 -0.13807188 -0.13807188]\n",
      "   [-0.14377446 -0.14377446 -0.14377446]\n",
      "   [-0.15132348 -0.15132348 -0.15132348]]\n",
      "\n",
      "  [[-0.06285944 -0.06285944 -0.06285944]\n",
      "   [-0.08885613 -0.08885613 -0.08885613]\n",
      "   [-0.10367642 -0.10367642 -0.10367642]\n",
      "   ...\n",
      "   [-0.14397062 -0.14397062 -0.14397062]\n",
      "   [-0.15021242 -0.15021242 -0.15021242]\n",
      "   [-0.1572221  -0.1572221  -0.1572221 ]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[ 0.00348035  0.00348035  0.00348035]\n",
      "   [-0.03026134 -0.03026134 -0.03026134]\n",
      "   [-0.0401306  -0.0401306  -0.0401306 ]\n",
      "   ...\n",
      "   [-0.07449342 -0.07449342 -0.07449342]\n",
      "   [-0.08933003 -0.08933003 -0.08933003]\n",
      "   [-0.10140524 -0.10140524 -0.10140524]]\n",
      "\n",
      "  [[ 0.39305556  0.39305556  0.39305556]\n",
      "   [-0.03034302 -0.03034302 -0.03034302]\n",
      "   [-0.0359966  -0.0359966  -0.0359966 ]\n",
      "   ...\n",
      "   [-0.07333331 -0.07333331 -0.07333331]\n",
      "   [-0.08207513 -0.08207513 -0.08207513]\n",
      "   [-0.1088889  -0.1088889  -0.1088889 ]]\n",
      "\n",
      "  [[ 0.28091514  0.28091514  0.28091514]\n",
      "   [ 0.31934655  0.31934655  0.31934655]\n",
      "   [-0.11127441 -0.11127441 -0.11127441]\n",
      "   ...\n",
      "   [-0.12727122 -0.12727122 -0.12727122]\n",
      "   [-0.15238559 -0.15238559 -0.15238559]\n",
      "   [-0.18305545 -0.18305545 -0.18305545]]]\n",
      "\n",
      "\n",
      " [[[ 0.27758175  0.27758175  0.27758175]\n",
      "   [ 0.31024516  0.31024516  0.31024516]\n",
      "   [ 0.3143465   0.3143465   0.3143465 ]\n",
      "   ...\n",
      "   [-0.16450982 -0.16450982 -0.16450982]\n",
      "   [-0.17395422 -0.17395422 -0.17395422]\n",
      "   [-0.18078427 -0.18078427 -0.18078427]]\n",
      "\n",
      "  [[ 0.29321897  0.29321897  0.29321897]\n",
      "   [ 0.2882517   0.2882517   0.2882517 ]\n",
      "   [ 0.3189217   0.3189217   0.3189217 ]\n",
      "   ...\n",
      "   [-0.13807188 -0.13807188 -0.13807188]\n",
      "   [-0.1398529  -0.1398529  -0.1398529 ]\n",
      "   [-0.14740191 -0.14740191 -0.14740191]]\n",
      "\n",
      "  [[ 0.305768    0.305768    0.305768  ]\n",
      "   [ 0.2954576   0.2954576   0.2954576 ]\n",
      "   [ 0.29240203  0.29240203  0.29240203]\n",
      "   ...\n",
      "   [-0.14004906 -0.14004906 -0.14004906]\n",
      "   [-0.14629085 -0.14629085 -0.14629085]\n",
      "   [-0.15330054 -0.15330054 -0.15330054]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[-0.01220592 -0.01220592 -0.01220592]\n",
      "   [-0.03026134 -0.03026134 -0.03026134]\n",
      "   [-0.0401306  -0.0401306  -0.0401306 ]\n",
      "   ...\n",
      "   [-0.07449342 -0.07449342 -0.07449342]\n",
      "   [-0.08933003 -0.08933003 -0.08933003]\n",
      "   [-0.10140524 -0.10140524 -0.10140524]]\n",
      "\n",
      "  [[-0.01478762 -0.01478762 -0.01478762]\n",
      "   [-0.02642145 -0.02642145 -0.02642145]\n",
      "   [-0.03991817 -0.03991817 -0.03991817]\n",
      "   ...\n",
      "   [-0.07333331 -0.07333331 -0.07333331]\n",
      "   [-0.08207513 -0.08207513 -0.08207513]\n",
      "   [-0.1088889  -0.1088889  -0.1088889 ]]\n",
      "\n",
      "  [[ 0.28091514  0.28091514  0.28091514]\n",
      "   [-0.10810447 -0.10810447 -0.10810447]\n",
      "   [-0.09166656 -0.09166656 -0.09166656]\n",
      "   ...\n",
      "   [-0.13119279 -0.13119279 -0.13119279]\n",
      "   [-0.15238559 -0.15238559 -0.15238559]\n",
      "   [-0.18305545 -0.18305545 -0.18305545]]]\n",
      "\n",
      "\n",
      " [[[-0.1420261  -0.1420261  -0.1420261 ]\n",
      "   [-0.12112738 -0.12112738 -0.12112738]\n",
      "   [-0.12486921 -0.12486921 -0.12486921]\n",
      "   ...\n",
      "   [-0.16843139 -0.16843139 -0.16843139]\n",
      "   [-0.17787579 -0.17787579 -0.17787579]\n",
      "   [-0.18470584 -0.18470584 -0.18470584]]\n",
      "\n",
      "  [[-0.06364376 -0.06364376 -0.06364376]\n",
      "   [-0.07645421 -0.07645421 -0.07645421]\n",
      "   [-0.08892144 -0.08892144 -0.08892144]\n",
      "   ...\n",
      "   [-0.12630717 -0.12630717 -0.12630717]\n",
      "   [-0.11632349 -0.11632349 -0.11632349]\n",
      "   [-0.10426466 -0.10426466 -0.10426466]]\n",
      "\n",
      "  [[-0.07854571 -0.07854571 -0.07854571]\n",
      "   [-0.08493456 -0.08493456 -0.08493456]\n",
      "   [-0.09583329 -0.09583329 -0.09583329]\n",
      "   ...\n",
      "   [-0.12828435 -0.12828435 -0.12828435]\n",
      "   [-0.12668301 -0.12668301 -0.12668301]\n",
      "   [-0.11408485 -0.11408485 -0.11408485]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[-0.00044122 -0.00044122 -0.00044122]\n",
      "   [-0.0224182  -0.0224182  -0.0224182 ]\n",
      "   [-0.0401306  -0.0401306  -0.0401306 ]\n",
      "   ...\n",
      "   [-0.07449342 -0.07449342 -0.07449342]\n",
      "   [-0.08933003 -0.08933003 -0.08933003]\n",
      "   [-0.09748367 -0.09748367 -0.09748367]]\n",
      "\n",
      "  [[-0.02263076 -0.02263076 -0.02263076]\n",
      "   [-0.04210773 -0.04210773 -0.04210773]\n",
      "   [-0.04383974 -0.04383974 -0.04383974]\n",
      "   ...\n",
      "   [-0.07333331 -0.07333331 -0.07333331]\n",
      "   [-0.08207513 -0.08207513 -0.08207513]\n",
      "   [-0.10496733 -0.10496733 -0.10496733]]\n",
      "\n",
      "  [[ 0.28091514  0.28091514  0.28091514]\n",
      "   [-0.04535937 -0.04535937 -0.04535937]\n",
      "   [-0.07598028 -0.07598028 -0.07598028]\n",
      "   ...\n",
      "   [-0.1547222  -0.1547222  -0.1547222 ]\n",
      "   [-0.175915   -0.175915   -0.175915  ]\n",
      "   [-0.20658486 -0.20658486 -0.20658486]]]\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      " [[[ 0.34816998  0.34816998  0.34816998]\n",
      "   [ 0.33769614  0.33769614  0.33769614]\n",
      "   [ 0.35748374  0.35748374  0.35748374]\n",
      "   ...\n",
      "   [-0.15666668 -0.15666668 -0.15666668]\n",
      "   [-0.15826795 -0.15826795 -0.15826795]\n",
      "   [-0.15725486 -0.15725486 -0.15725486]]\n",
      "\n",
      "  [[ 0.3285131   0.3285131   0.3285131 ]\n",
      "   [ 0.34707522  0.34707522  0.34707522]\n",
      "   [ 0.3424511   0.3424511   0.3424511 ]\n",
      "   ...\n",
      "   [-0.13022874 -0.13022874 -0.13022874]\n",
      "   [-0.12416662 -0.12416662 -0.12416662]\n",
      "   [-0.1238725  -0.1238725  -0.1238725 ]]\n",
      "\n",
      "  [[ 0.30184644  0.30184644  0.30184644]\n",
      "   [ 0.35428113  0.35428113  0.35428113]\n",
      "   [ 0.34338242  0.34338242  0.34338242]\n",
      "   ...\n",
      "   [-0.13220592 -0.13220592 -0.13220592]\n",
      "   [-0.13060458 -0.13060458 -0.13060458]\n",
      "   [-0.12977113 -0.12977113 -0.12977113]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[-0.00436278 -0.00436278 -0.00436278]\n",
      "   [-0.03026134 -0.03026134 -0.03026134]\n",
      "   [-0.02052276 -0.02052276 -0.02052276]\n",
      "   ...\n",
      "   [-0.07449342 -0.07449342 -0.07449342]\n",
      "   [-0.06972218 -0.06972218 -0.06972218]\n",
      "   [-0.06611112 -0.06611112 -0.06611112]]\n",
      "\n",
      "  [[-0.00694449 -0.00694449 -0.00694449]\n",
      "   [-0.03426459 -0.03426459 -0.03426459]\n",
      "   [-0.0359966  -0.0359966  -0.0359966 ]\n",
      "   ...\n",
      "   [-0.07333331 -0.07333331 -0.07333331]\n",
      "   [-0.08207513 -0.08207513 -0.08207513]\n",
      "   [-0.06183008 -0.06183008 -0.06183008]]\n",
      "\n",
      "  [[-0.1935947  -0.1935947  -0.1935947 ]\n",
      "   [-0.11202604 -0.11202604 -0.11202604]\n",
      "   [-0.11519597 -0.11519597 -0.11519597]\n",
      "   ...\n",
      "   [-0.11942808 -0.11942808 -0.11942808]\n",
      "   [-0.13277775 -0.13277775 -0.13277775]\n",
      "   [-0.1516829  -0.1516829  -0.1516829 ]]]\n",
      "\n",
      "\n",
      " [[[-0.06751629 -0.06751629 -0.06751629]\n",
      "   [ 0.0200491   0.0200491   0.0200491 ]\n",
      "   [-0.10526137 -0.10526137 -0.10526137]\n",
      "   ...\n",
      "   [-0.12529413 -0.12529413 -0.12529413]\n",
      "   [-0.11905226 -0.11905226 -0.11905226]\n",
      "   [ 0.31725496  0.31725496  0.31725496]]\n",
      "\n",
      "  [[-0.06364376 -0.06364376 -0.06364376]\n",
      "   [-0.08429734 -0.08429734 -0.08429734]\n",
      "   [-0.09284301 -0.09284301 -0.09284301]\n",
      "   ...\n",
      "   [-0.1106209  -0.1106209  -0.1106209 ]\n",
      "   [-0.08887251 -0.08887251 -0.08887251]\n",
      "   [-0.08465681 -0.08465681 -0.08465681]]\n",
      "\n",
      "  [[-0.07070258 -0.07070258 -0.07070258]\n",
      "   [-0.0927777  -0.0927777  -0.0927777 ]\n",
      "   [-0.09975486 -0.09975486 -0.09975486]\n",
      "   ...\n",
      "   [-0.11651964 -0.11651964 -0.11651964]\n",
      "   [-0.09531046 -0.09531046 -0.09531046]\n",
      "   [-0.08663387 -0.08663387 -0.08663387]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[-0.06710789 -0.06710789 -0.06710789]\n",
      "   [-0.06163389 -0.06163389 -0.06163389]\n",
      "   [-0.04797374 -0.04797374 -0.04797374]\n",
      "   ...\n",
      "   [-0.04704244 -0.04704244 -0.04704244]\n",
      "   [-0.03834963 -0.03834963 -0.03834963]\n",
      "   [-0.02297387 -0.02297387 -0.02297387]]\n",
      "\n",
      "  [[-0.06184645 -0.06184645 -0.06184645]\n",
      "   [-0.06171557 -0.06171557 -0.06171557]\n",
      "   [-0.05168288 -0.05168288 -0.05168288]\n",
      "   ...\n",
      "   [-0.04588233 -0.04588233 -0.04588233]\n",
      "   [-0.03109474 -0.03109474 -0.03109474]\n",
      "   [-0.03045753 -0.03045753 -0.03045753]]\n",
      "\n",
      "  [[ 0.16718963  0.16718963  0.16718963]\n",
      "   [ 0.12718965  0.12718965  0.12718965]\n",
      "   [ 0.09264718  0.09264718  0.09264718]\n",
      "   ...\n",
      "   [-0.03315357 -0.03315357 -0.03315357]\n",
      "   [-0.03081696 -0.03081696 -0.03081696]\n",
      "   [-0.12031034 -0.12031034 -0.12031034]]]\n",
      "\n",
      "\n",
      " [[[ 0.29326802  0.29326802  0.29326802]\n",
      "   [ 0.3180883   0.3180883   0.3180883 ]\n",
      "   [ 0.29866022  0.29866022  0.29866022]\n",
      "   ...\n",
      "   [-0.16843139 -0.16843139 -0.16843139]\n",
      "   [-0.17787579 -0.17787579 -0.17787579]\n",
      "   [-0.18470584 -0.18470584 -0.18470584]]\n",
      "\n",
      "  [[ 0.32459152  0.32459152  0.32459152]\n",
      "   [ 0.3509968   0.3509968   0.3509968 ]\n",
      "   [ 0.2914707   0.2914707   0.2914707 ]\n",
      "   ...\n",
      "   [-0.14199345 -0.14199345 -0.14199345]\n",
      "   [-0.14377446 -0.14377446 -0.14377446]\n",
      "   [-0.15132348 -0.15132348 -0.15132348]]\n",
      "\n",
      "  [[ 0.2822386   0.2822386   0.2822386 ]\n",
      "   [ 0.2836929   0.2836929   0.2836929 ]\n",
      "   [ 0.27671576  0.27671576  0.27671576]\n",
      "   ...\n",
      "   [-0.14397062 -0.14397062 -0.14397062]\n",
      "   [-0.15021242 -0.15021242 -0.15021242]\n",
      "   [-0.1572221  -0.1572221  -0.1572221 ]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[ 0.01916663  0.01916663  0.01916663]\n",
      "   [-0.0224182  -0.0224182  -0.0224182 ]\n",
      "   [-0.03228747 -0.03228747 -0.03228747]\n",
      "   ...\n",
      "   [-0.07449342 -0.07449342 -0.07449342]\n",
      "   [-0.08933003 -0.08933003 -0.08933003]\n",
      "   [-0.10140524 -0.10140524 -0.10140524]]\n",
      "\n",
      "  [[ 0.0205065   0.0205065   0.0205065 ]\n",
      "   [-0.02249988 -0.02249988 -0.02249988]\n",
      "   [-0.03207504 -0.03207504 -0.03207504]\n",
      "   ...\n",
      "   [-0.07333331 -0.07333331 -0.07333331]\n",
      "   [-0.08207513 -0.08207513 -0.08207513]\n",
      "   [-0.1088889  -0.1088889  -0.1088889 ]]\n",
      "\n",
      "  [[-0.0916339  -0.0916339  -0.0916339 ]\n",
      "   [-0.10810447 -0.10810447 -0.10810447]\n",
      "   [-0.11127441 -0.11127441 -0.11127441]\n",
      "   ...\n",
      "   [-0.1547222  -0.1547222  -0.1547222 ]\n",
      "   [-0.175915   -0.175915   -0.175915  ]\n",
      "   [-0.20658486 -0.20658486 -0.20658486]]]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\patcas rares\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\keras\\engine\\training.py:1972: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 13s 1s/step - loss: 2.1606 - accuracy: 0.4750 - val_loss: 2.8952 - val_accuracy: 0.2000\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 2/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 700ms/step - loss: 1.3334 - accuracy: 0.6667 - val_loss: 2.6669 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 3/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 773ms/step - loss: 1.1759 - accuracy: 0.6958 - val_loss: 2.5575 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 4/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 737ms/step - loss: 1.1136 - accuracy: 0.7250 - val_loss: 2.6588 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 5/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 777ms/step - loss: 1.1363 - accuracy: 0.7375 - val_loss: 2.4833 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 6/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 9s 1s/step - loss: 1.1012 - accuracy: 0.7042 - val_loss: 2.6173 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 7/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 7s 921ms/step - loss: 1.0718 - accuracy: 0.7417 - val_loss: 3.1093 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 8/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 716ms/step - loss: 1.1092 - accuracy: 0.7250 - val_loss: 3.6205 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 9/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 8s 950ms/step - loss: 1.0605 - accuracy: 0.7458 - val_loss: 5.4795 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 10/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 7s 900ms/step - loss: 1.0643 - accuracy: 0.7417 - val_loss: 4.1120 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 11/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 8s 960ms/step - loss: 1.0824 - accuracy: 0.7250 - val_loss: 5.6897 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 12/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 7s 815ms/step - loss: 0.9845 - accuracy: 0.7833 - val_loss: 6.2341 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 13/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 711ms/step - loss: 1.0529 - accuracy: 0.7333 - val_loss: 5.9158 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 14/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 750ms/step - loss: 0.9938 - accuracy: 0.7458 - val_loss: 5.8433 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 15/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 773ms/step - loss: 0.9803 - accuracy: 0.7583 - val_loss: 7.0443 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 16/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 761ms/step - loss: 0.9704 - accuracy: 0.7458 - val_loss: 7.3281 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 17/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 862ms/step - loss: 0.9384 - accuracy: 0.7875 - val_loss: 8.2680 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 18/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 765ms/step - loss: 0.9223 - accuracy: 0.8125 - val_loss: 8.6899 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 19/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 720ms/step - loss: 0.9424 - accuracy: 0.7833 - val_loss: 10.3076 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 20/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 721ms/step - loss: 0.9135 - accuracy: 0.8125 - val_loss: 7.8906 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 21/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 715ms/step - loss: 0.9083 - accuracy: 0.8167 - val_loss: 8.1191 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 22/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 722ms/step - loss: 0.9190 - accuracy: 0.7917 - val_loss: 7.1579 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 23/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 729ms/step - loss: 0.8739 - accuracy: 0.8042 - val_loss: 8.4346 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 24/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 692ms/step - loss: 0.9035 - accuracy: 0.8250 - val_loss: 10.6870 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 25/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 727ms/step - loss: 0.8854 - accuracy: 0.8250 - val_loss: 10.3685 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 26/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 745ms/step - loss: 0.9669 - accuracy: 0.7667 - val_loss: 10.5626 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 27/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 5s 665ms/step - loss: 0.8848 - accuracy: 0.8375 - val_loss: 11.0390 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 28/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 5s 661ms/step - loss: 0.9227 - accuracy: 0.7875 - val_loss: 15.4174 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 29/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 5s 667ms/step - loss: 0.8970 - accuracy: 0.7958 - val_loss: 8.6380 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 30/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 5s 721ms/step - loss: 0.9038 - accuracy: 0.7750 - val_loss: 7.2079 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 31/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 5s 666ms/step - loss: 0.8338 - accuracy: 0.8167 - val_loss: 9.3163 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 32/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 5s 666ms/step - loss: 0.7922 - accuracy: 0.8625 - val_loss: 10.3073 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 33/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 5s 657ms/step - loss: 0.8150 - accuracy: 0.8333 - val_loss: 11.9812 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 34/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 5s 668ms/step - loss: 0.8248 - accuracy: 0.8208 - val_loss: 9.8939 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 35/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 5s 676ms/step - loss: 0.8168 - accuracy: 0.8167 - val_loss: 7.2367 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 36/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 689ms/step - loss: 0.8112 - accuracy: 0.8500 - val_loss: 4.5417 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 37/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 746ms/step - loss: 0.7692 - accuracy: 0.8667 - val_loss: 2.7580 - val_accuracy: 0.8000\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 38/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 790ms/step - loss: 0.7409 - accuracy: 0.8500 - val_loss: 17.4152 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 39/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 733ms/step - loss: 0.6966 - accuracy: 0.9167 - val_loss: 12.4191 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 40/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 791ms/step - loss: 0.7703 - accuracy: 0.8667 - val_loss: 13.3821 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 41/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 754ms/step - loss: 0.7139 - accuracy: 0.8833 - val_loss: 11.1332 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 42/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 797ms/step - loss: 0.7423 - accuracy: 0.8583 - val_loss: 11.0491 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 43/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 733ms/step - loss: 0.7913 - accuracy: 0.8208 - val_loss: 8.0488 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 44/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 787ms/step - loss: 0.8132 - accuracy: 0.8333 - val_loss: 10.4324 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 45/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 740ms/step - loss: 0.7471 - accuracy: 0.8542 - val_loss: 11.7491 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 46/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 756ms/step - loss: 0.7331 - accuracy: 0.8667 - val_loss: 14.7097 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 47/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 695ms/step - loss: 0.6978 - accuracy: 0.8833 - val_loss: 16.9911 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 48/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 7s 829ms/step - loss: 0.6877 - accuracy: 0.9000 - val_loss: 21.4124 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 49/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 740ms/step - loss: 0.6984 - accuracy: 0.8583 - val_loss: 12.0627 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 50/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 728ms/step - loss: 0.7014 - accuracy: 0.8792 - val_loss: 9.3410 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 51/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 766ms/step - loss: 0.6973 - accuracy: 0.8792 - val_loss: 9.3673 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 52/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 740ms/step - loss: 0.6799 - accuracy: 0.8917 - val_loss: 5.6317 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 53/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 748ms/step - loss: 0.6423 - accuracy: 0.9042 - val_loss: 10.2496 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 54/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 785ms/step - loss: 0.6655 - accuracy: 0.8708 - val_loss: 14.0952 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 55/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 792ms/step - loss: 0.6838 - accuracy: 0.8833 - val_loss: 14.6305 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 56/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 804ms/step - loss: 0.7170 - accuracy: 0.8625 - val_loss: 13.1809 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 57/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 7s 793ms/step - loss: 0.6793 - accuracy: 0.8708 - val_loss: 15.2405 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 58/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 774ms/step - loss: 0.7697 - accuracy: 0.8333 - val_loss: 14.6183 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 59/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 7s 815ms/step - loss: 0.6067 - accuracy: 0.9000 - val_loss: 19.4600 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 60/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 7s 779ms/step - loss: 0.5943 - accuracy: 0.9375 - val_loss: 21.0688 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 61/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 7s 804ms/step - loss: 0.6489 - accuracy: 0.9000 - val_loss: 23.3183 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 62/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 843ms/step - loss: 0.6811 - accuracy: 0.8708 - val_loss: 16.2282 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 63/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 7s 794ms/step - loss: 0.6187 - accuracy: 0.8958 - val_loss: 12.3586 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 64/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 7s 793ms/step - loss: 0.6924 - accuracy: 0.8708 - val_loss: 18.3348 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 65/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 7s 806ms/step - loss: 0.6676 - accuracy: 0.8667 - val_loss: 15.9398 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 66/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 7s 865ms/step - loss: 0.6942 - accuracy: 0.8625 - val_loss: 12.3557 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 67/100\n",
      "Learning rate:  0.001\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 7s 789ms/step - loss: 0.6834 - accuracy: 0.8625 - val_loss: 11.9517 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 68/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 7s 795ms/step - loss: 0.6792 - accuracy: 0.8542 - val_loss: 12.3414 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 69/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 7s 798ms/step - loss: 0.6214 - accuracy: 0.9000 - val_loss: 16.8427 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 70/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 7s 849ms/step - loss: 0.5883 - accuracy: 0.9083 - val_loss: 18.3523 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 71/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 7s 839ms/step - loss: 0.6014 - accuracy: 0.9083 - val_loss: 14.7044 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 72/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 7s 848ms/step - loss: 0.6023 - accuracy: 0.9000 - val_loss: 14.4246 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 73/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 7s 845ms/step - loss: 0.5617 - accuracy: 0.9458 - val_loss: 14.0721 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 74/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 7s 848ms/step - loss: 0.5783 - accuracy: 0.9167 - val_loss: 13.5062 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 75/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 7s 872ms/step - loss: 0.5594 - accuracy: 0.9250 - val_loss: 13.1941 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 76/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 7s 786ms/step - loss: 0.5766 - accuracy: 0.9000 - val_loss: 13.8404 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 77/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 7s 803ms/step - loss: 0.6114 - accuracy: 0.9000 - val_loss: 16.0219 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 78/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 774ms/step - loss: 0.5615 - accuracy: 0.9125 - val_loss: 18.3734 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 79/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 780ms/step - loss: 0.5824 - accuracy: 0.8958 - val_loss: 15.9777 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 80/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 783ms/step - loss: 0.6035 - accuracy: 0.9042 - val_loss: 15.9078 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 81/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 7s 811ms/step - loss: 0.5649 - accuracy: 0.9292 - val_loss: 12.5216 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 82/100\n",
      "Learning rate:  0.0001\n",
      "8/8 [==============================] - 6s 855ms/step - loss: 0.5042 - accuracy: 0.9500 - val_loss: 12.9145 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 83/100\n",
      "Learning rate:  0.0001\n",
      "8/8 [==============================] - 6s 776ms/step - loss: 0.5385 - accuracy: 0.9250 - val_loss: 13.4097 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 84/100\n",
      "Learning rate:  0.0001\n",
      "8/8 [==============================] - 6s 768ms/step - loss: 0.5693 - accuracy: 0.9292 - val_loss: 13.5064 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 85/100\n",
      "Learning rate:  0.0001\n",
      "8/8 [==============================] - 6s 814ms/step - loss: 0.4869 - accuracy: 0.9583 - val_loss: 13.6407 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 86/100\n",
      "Learning rate:  0.0001\n",
      "8/8 [==============================] - 6s 794ms/step - loss: 0.5541 - accuracy: 0.9292 - val_loss: 13.9014 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 87/100\n",
      "Learning rate:  0.0001\n",
      "8/8 [==============================] - 6s 771ms/step - loss: 0.5037 - accuracy: 0.9292 - val_loss: 13.7187 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 88/100\n",
      "Learning rate:  0.0001\n",
      "8/8 [==============================] - 6s 827ms/step - loss: 0.4981 - accuracy: 0.9417 - val_loss: 13.9638 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 89/100\n",
      "Learning rate:  0.0001\n",
      "8/8 [==============================] - 6s 780ms/step - loss: 0.4831 - accuracy: 0.9458 - val_loss: 14.2622 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 90/100\n",
      "Learning rate:  0.0001\n",
      "8/8 [==============================] - 6s 783ms/step - loss: 0.4719 - accuracy: 0.9625 - val_loss: 14.4583 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 91/100\n",
      "Learning rate:  0.0001\n",
      "8/8 [==============================] - 6s 779ms/step - loss: 0.4902 - accuracy: 0.9458 - val_loss: 14.8473 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 92/100\n",
      "Learning rate:  0.0001\n",
      "8/8 [==============================] - 7s 842ms/step - loss: 0.4873 - accuracy: 0.9458 - val_loss: 15.1042 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 93/100\n",
      "Learning rate:  0.0001\n",
      "8/8 [==============================] - 6s 804ms/step - loss: 0.4521 - accuracy: 0.9750 - val_loss: 15.0005 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 94/100\n",
      "Learning rate:  0.0001\n",
      "8/8 [==============================] - 7s 861ms/step - loss: 0.4734 - accuracy: 0.9542 - val_loss: 14.9957 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 95/100\n",
      "Learning rate:  0.0001\n",
      "8/8 [==============================] - 6s 724ms/step - loss: 0.4946 - accuracy: 0.9417 - val_loss: 14.8903 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 96/100\n",
      "Learning rate:  0.0001\n",
      "8/8 [==============================] - 6s 700ms/step - loss: 0.4530 - accuracy: 0.9708 - val_loss: 14.8940 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 97/100\n",
      "Learning rate:  0.0001\n",
      "8/8 [==============================] - 5s 703ms/step - loss: 0.4661 - accuracy: 0.9542 - val_loss: 15.0500 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 98/100\n",
      "Learning rate:  0.0001\n",
      "8/8 [==============================] - 6s 680ms/step - loss: 0.4525 - accuracy: 0.9667 - val_loss: 14.9819 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 99/100\n",
      "Learning rate:  0.0001\n",
      "8/8 [==============================] - 6s 749ms/step - loss: 0.4601 - accuracy: 0.9625 - val_loss: 14.7686 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 100/100\n",
      "Learning rate:  0.0001\n",
      "8/8 [==============================] - 6s 787ms/step - loss: 0.4891 - accuracy: 0.9417 - val_loss: 14.6023 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1/1 [==============================] - 1s 567ms/step - loss: 0.6706 - accuracy: 0.8333\n",
      "Test loss: 0.6706398725509644\n",
      "Test accuracy: 0.8333333134651184\n",
      "[1, 1, 1, 1, 2, 1, 0, 1, 1, 1, 2, 2, 1, 1, 1, 2, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Precision:  0.9692307692307692\n",
      "Recall:  0.8333333333333334\n",
      "F1 Score:  0.8872258064516129\n",
      "[[[[  5   5   5]\n",
      "   [ 21  21  21]\n",
      "   [ 13  13  13]\n",
      "   ...\n",
      "   [  7   7   7]\n",
      "   [  5   5   5]\n",
      "   [  2   2   2]]\n",
      "\n",
      "  [[ 23  23  23]\n",
      "   [ 14  14  14]\n",
      "   [  9   9   9]\n",
      "   ...\n",
      "   [  1   1   1]\n",
      "   [  0   0   0]\n",
      "   [  0   0   0]]\n",
      "\n",
      "  [[ 23  23  23]\n",
      "   [ 14  14  14]\n",
      "   [  9   9   9]\n",
      "   ...\n",
      "   [  0   0   0]\n",
      "   [  0   0   0]\n",
      "   [  0   0   0]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[ 29  29  29]\n",
      "   [ 17  17  17]\n",
      "   [ 10  10  10]\n",
      "   ...\n",
      "   [  0   0   0]\n",
      "   [  0   0   0]\n",
      "   [  0   0   0]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [ 17  17  17]\n",
      "   [ 12  12  12]\n",
      "   ...\n",
      "   [  0   0   0]\n",
      "   [  0   0   0]\n",
      "   [  0   0   0]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [ 14  14  14]\n",
      "   ...\n",
      "   [  7   7   7]\n",
      "   [  6   6   6]\n",
      "   [  6   6   6]]]\n",
      "\n",
      "\n",
      " [[[108 108 108]\n",
      "   [117 117 117]\n",
      "   [116 116 116]\n",
      "   ...\n",
      "   [  1   1   1]\n",
      "   [  1   1   1]\n",
      "   [  1   1   1]]\n",
      "\n",
      "  [[112 112 112]\n",
      "   [108 108 108]\n",
      "   [115 115 115]\n",
      "   ...\n",
      "   [  1   1   1]\n",
      "   [  1   1   1]\n",
      "   [  1   1   1]]\n",
      "\n",
      "  [[117 117 117]\n",
      "   [112 112 112]\n",
      "   [110 110 110]\n",
      "   ...\n",
      "   [  1   1   1]\n",
      "   [  1   1   1]\n",
      "   [  1   1   1]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[ 25  25  25]\n",
      "   [ 17  17  17]\n",
      "   [ 10  10  10]\n",
      "   ...\n",
      "   [  0   0   0]\n",
      "   [  0   0   0]\n",
      "   [  0   0   0]]\n",
      "\n",
      "  [[ 24  24  24]\n",
      "   [ 18  18  18]\n",
      "   [ 11  11  11]\n",
      "   ...\n",
      "   [  0   0   0]\n",
      "   [  0   0   0]\n",
      "   [  0   0   0]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [ 19  19  19]\n",
      "   [ 19  19  19]\n",
      "   ...\n",
      "   [  6   6   6]\n",
      "   [  6   6   6]\n",
      "   [  6   6   6]]]\n",
      "\n",
      "\n",
      " [[[  1   1   1]\n",
      "   [  7   7   7]\n",
      "   [  4   4   4]\n",
      "   ...\n",
      "   [  0   0   0]\n",
      "   [  0   0   0]\n",
      "   [  0   0   0]]\n",
      "\n",
      "  [[ 21  21  21]\n",
      "   [ 15  15  15]\n",
      "   [ 11  11  11]\n",
      "   ...\n",
      "   [  4   4   4]\n",
      "   [  7   7   7]\n",
      "   [ 12  12  12]]\n",
      "\n",
      "  [[ 19  19  19]\n",
      "   [ 15  15  15]\n",
      "   [ 11  11  11]\n",
      "   ...\n",
      "   [  4   4   4]\n",
      "   [  6   6   6]\n",
      "   [ 11  11  11]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[ 28  28  28]\n",
      "   [ 19  19  19]\n",
      "   [ 10  10  10]\n",
      "   ...\n",
      "   [  0   0   0]\n",
      "   [  0   0   0]\n",
      "   [  1   1   1]]\n",
      "\n",
      "  [[ 22  22  22]\n",
      "   [ 14  14  14]\n",
      "   [ 10  10  10]\n",
      "   ...\n",
      "   [  0   0   0]\n",
      "   [  0   0   0]\n",
      "   [  1   1   1]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [ 35  35  35]\n",
      "   [ 23  23  23]\n",
      "   ...\n",
      "   [  0   0   0]\n",
      "   [  0   0   0]\n",
      "   [  0   0   0]]]]\n",
      "[[1]\n",
      " [1]\n",
      " [1]]\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "(40, 30, 3)\n",
      "x_train shape: (240, 40, 30, 3)\n",
      "240 train samples\n",
      "30 test samples\n",
      "y_train shape: (240, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\patcas rares\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate:  0.001\n",
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, 40, 30, 3)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_31 (Conv2D)              (None, 40, 30, 16)   448         input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_28 (BatchNo (None, 40, 30, 16)   64          conv2d_31[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, 40, 30, 16)   0           batch_normalization_28[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_32 (Conv2D)              (None, 40, 30, 16)   272         activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_29 (BatchNo (None, 40, 30, 16)   64          conv2d_32[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (None, 40, 30, 16)   0           batch_normalization_29[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_33 (Conv2D)              (None, 40, 30, 16)   2320        activation_29[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_30 (BatchNo (None, 40, 30, 16)   64          conv2d_33[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, 40, 30, 16)   0           batch_normalization_30[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_35 (Conv2D)              (None, 40, 30, 64)   1088        activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_34 (Conv2D)              (None, 40, 30, 64)   1088        activation_30[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_9 (Add)                     (None, 40, 30, 64)   0           conv2d_35[0][0]                  \n",
      "                                                                 conv2d_34[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_31 (BatchNo (None, 40, 30, 64)   256         add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (None, 40, 30, 64)   0           batch_normalization_31[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_36 (Conv2D)              (None, 40, 30, 16)   1040        activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_32 (BatchNo (None, 40, 30, 16)   64          conv2d_36[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_32 (Activation)      (None, 40, 30, 16)   0           batch_normalization_32[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_37 (Conv2D)              (None, 40, 30, 16)   2320        activation_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_33 (BatchNo (None, 40, 30, 16)   64          conv2d_37[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, 40, 30, 16)   0           batch_normalization_33[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_38 (Conv2D)              (None, 40, 30, 64)   1088        activation_33[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_10 (Add)                    (None, 40, 30, 64)   0           add_9[0][0]                      \n",
      "                                                                 conv2d_38[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_34 (BatchNo (None, 40, 30, 64)   256         add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (None, 40, 30, 64)   0           batch_normalization_34[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_39 (Conv2D)              (None, 40, 30, 16)   1040        activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_35 (BatchNo (None, 40, 30, 16)   64          conv2d_39[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_35 (Activation)      (None, 40, 30, 16)   0           batch_normalization_35[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_40 (Conv2D)              (None, 40, 30, 16)   2320        activation_35[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_36 (BatchNo (None, 40, 30, 16)   64          conv2d_40[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_36 (Activation)      (None, 40, 30, 16)   0           batch_normalization_36[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_41 (Conv2D)              (None, 40, 30, 64)   1088        activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_11 (Add)                    (None, 40, 30, 64)   0           add_10[0][0]                     \n",
      "                                                                 conv2d_41[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_37 (BatchNo (None, 40, 30, 64)   256         add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_37 (Activation)      (None, 40, 30, 64)   0           batch_normalization_37[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_42 (Conv2D)              (None, 20, 15, 64)   4160        activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_38 (BatchNo (None, 20, 15, 64)   256         conv2d_42[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_38 (Activation)      (None, 20, 15, 64)   0           batch_normalization_38[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_43 (Conv2D)              (None, 20, 15, 64)   36928       activation_38[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_39 (BatchNo (None, 20, 15, 64)   256         conv2d_43[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_39 (Activation)      (None, 20, 15, 64)   0           batch_normalization_39[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_45 (Conv2D)              (None, 20, 15, 128)  8320        add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_44 (Conv2D)              (None, 20, 15, 128)  8320        activation_39[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_12 (Add)                    (None, 20, 15, 128)  0           conv2d_45[0][0]                  \n",
      "                                                                 conv2d_44[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_40 (BatchNo (None, 20, 15, 128)  512         add_12[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_40 (Activation)      (None, 20, 15, 128)  0           batch_normalization_40[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_46 (Conv2D)              (None, 20, 15, 64)   8256        activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_41 (BatchNo (None, 20, 15, 64)   256         conv2d_46[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_41 (Activation)      (None, 20, 15, 64)   0           batch_normalization_41[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_47 (Conv2D)              (None, 20, 15, 64)   36928       activation_41[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_42 (BatchNo (None, 20, 15, 64)   256         conv2d_47[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_42 (Activation)      (None, 20, 15, 64)   0           batch_normalization_42[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_48 (Conv2D)              (None, 20, 15, 128)  8320        activation_42[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_13 (Add)                    (None, 20, 15, 128)  0           add_12[0][0]                     \n",
      "                                                                 conv2d_48[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_43 (BatchNo (None, 20, 15, 128)  512         add_13[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_43 (Activation)      (None, 20, 15, 128)  0           batch_normalization_43[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_49 (Conv2D)              (None, 20, 15, 64)   8256        activation_43[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_44 (BatchNo (None, 20, 15, 64)   256         conv2d_49[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_44 (Activation)      (None, 20, 15, 64)   0           batch_normalization_44[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_50 (Conv2D)              (None, 20, 15, 64)   36928       activation_44[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_45 (BatchNo (None, 20, 15, 64)   256         conv2d_50[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_45 (Activation)      (None, 20, 15, 64)   0           batch_normalization_45[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_51 (Conv2D)              (None, 20, 15, 128)  8320        activation_45[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_14 (Add)                    (None, 20, 15, 128)  0           add_13[0][0]                     \n",
      "                                                                 conv2d_51[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_46 (BatchNo (None, 20, 15, 128)  512         add_14[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_46 (Activation)      (None, 20, 15, 128)  0           batch_normalization_46[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_52 (Conv2D)              (None, 10, 8, 128)   16512       activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_47 (BatchNo (None, 10, 8, 128)   512         conv2d_52[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_47 (Activation)      (None, 10, 8, 128)   0           batch_normalization_47[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_53 (Conv2D)              (None, 10, 8, 128)   147584      activation_47[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_48 (BatchNo (None, 10, 8, 128)   512         conv2d_53[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_48 (Activation)      (None, 10, 8, 128)   0           batch_normalization_48[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_55 (Conv2D)              (None, 10, 8, 256)   33024       add_14[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_54 (Conv2D)              (None, 10, 8, 256)   33024       activation_48[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_15 (Add)                    (None, 10, 8, 256)   0           conv2d_55[0][0]                  \n",
      "                                                                 conv2d_54[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_49 (BatchNo (None, 10, 8, 256)   1024        add_15[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_49 (Activation)      (None, 10, 8, 256)   0           batch_normalization_49[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_56 (Conv2D)              (None, 10, 8, 128)   32896       activation_49[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_50 (BatchNo (None, 10, 8, 128)   512         conv2d_56[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_50 (Activation)      (None, 10, 8, 128)   0           batch_normalization_50[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_57 (Conv2D)              (None, 10, 8, 128)   147584      activation_50[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_51 (BatchNo (None, 10, 8, 128)   512         conv2d_57[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_51 (Activation)      (None, 10, 8, 128)   0           batch_normalization_51[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_58 (Conv2D)              (None, 10, 8, 256)   33024       activation_51[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_16 (Add)                    (None, 10, 8, 256)   0           add_15[0][0]                     \n",
      "                                                                 conv2d_58[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_52 (BatchNo (None, 10, 8, 256)   1024        add_16[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_52 (Activation)      (None, 10, 8, 256)   0           batch_normalization_52[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_59 (Conv2D)              (None, 10, 8, 128)   32896       activation_52[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_53 (BatchNo (None, 10, 8, 128)   512         conv2d_59[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_53 (Activation)      (None, 10, 8, 128)   0           batch_normalization_53[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_60 (Conv2D)              (None, 10, 8, 128)   147584      activation_53[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_54 (BatchNo (None, 10, 8, 128)   512         conv2d_60[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_54 (Activation)      (None, 10, 8, 128)   0           batch_normalization_54[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_61 (Conv2D)              (None, 10, 8, 256)   33024       activation_54[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_17 (Add)                    (None, 10, 8, 256)   0           add_16[0][0]                     \n",
      "                                                                 conv2d_61[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_55 (BatchNo (None, 10, 8, 256)   1024        add_17[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_55 (Activation)      (None, 10, 8, 256)   0           batch_normalization_55[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_1 (AveragePoo (None, 1, 1, 256)    0           activation_55[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 256)          0           average_pooling2d_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 10)           2570        flatten_1[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 849,002\n",
      "Trainable params: 843,786\n",
      "Non-trainable params: 5,216\n",
      "__________________________________________________________________________________________________\n",
      "ResNet  29v  2\n",
      "Using real-time data augmentation.\n",
      "------------------\n",
      "[[[[-1.30849570e-01 -1.30849570e-01 -1.30849570e-01]\n",
      "   [-7.14868531e-02 -7.14868531e-02 -7.14868531e-02]\n",
      "   [-9.54410434e-02 -9.54410434e-02 -9.54410434e-02]\n",
      "   ...\n",
      "   [-1.57581717e-01 -1.57581717e-01 -1.57581717e-01]\n",
      "   [-1.70147091e-01 -1.70147091e-01 -1.70147091e-01]\n",
      "   [-1.88643754e-01 -1.88643754e-01 -1.88643754e-01]]\n",
      "\n",
      "  [[-4.97058257e-02 -4.97058257e-02 -4.97058257e-02]\n",
      "   [-7.42973089e-02 -7.42973089e-02 -7.42973089e-02]\n",
      "   [-9.00488943e-02 -9.00488943e-02 -9.00488943e-02]\n",
      "   ...\n",
      "   [-1.43709108e-01 -1.43709108e-01 -1.43709108e-01]\n",
      "   [-1.46013036e-01 -1.46013036e-01 -1.46013036e-01]\n",
      "   [-1.56977087e-01 -1.56977087e-01 -1.56977087e-01]]\n",
      "\n",
      "  [[-6.22058138e-02 -6.22058138e-02 -6.22058138e-02]\n",
      "   [-8.76306146e-02 -8.76306146e-02 -8.76306146e-02]\n",
      "   [-9.39868391e-02 -9.39868391e-02 -9.39868391e-02]\n",
      "   ...\n",
      "   [-1.51552275e-01 -1.51552275e-01 -1.51552275e-01]\n",
      "   [-1.54084966e-01 -1.54084966e-01 -1.54084966e-01]\n",
      "   [-1.58365920e-01 -1.58365920e-01 -1.58365920e-01]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[ 1.20097995e-02  1.20097995e-02  1.20097995e-02]\n",
      "   [-1.98364854e-02 -1.98364854e-02 -1.98364854e-02]\n",
      "   [-3.41338925e-02 -3.41338925e-02 -3.41338925e-02]\n",
      "   ...\n",
      "   [-7.21404999e-02 -7.21404999e-02 -7.21404999e-02]\n",
      "   [-8.14215466e-02 -8.14215466e-02 -8.14215466e-02]\n",
      "   [-9.80229229e-02 -9.80229229e-02 -9.80229229e-02]]\n",
      "\n",
      "  [[ 3.98758173e-01  3.98758173e-01  3.98758173e-01]\n",
      "   [-2.31697932e-02 -2.31697932e-02 -2.31697932e-02]\n",
      "   [-2.91175283e-02 -2.91175283e-02 -2.91175283e-02]\n",
      "   ...\n",
      "   [-7.12254569e-02 -7.12254569e-02 -7.12254569e-02]\n",
      "   [-7.99836144e-02 -7.99836144e-02 -7.99836144e-02]\n",
      "   [-1.05457552e-01 -1.05457552e-01 -1.05457552e-01]]\n",
      "\n",
      "  [[ 2.71536082e-01  2.71536082e-01  2.71536082e-01]\n",
      "   [ 3.09918463e-01  3.09918463e-01  3.09918463e-01]\n",
      "   [-1.22565240e-01 -1.22565240e-01 -1.22565240e-01]\n",
      "   ...\n",
      "   [-1.41682997e-01 -1.41682997e-01 -1.41682997e-01]\n",
      "   [-1.70767933e-01 -1.70767933e-01 -1.70767933e-01]\n",
      "   [-1.95081592e-01 -1.95081592e-01 -1.95081592e-01]]]\n",
      "\n",
      "\n",
      " [[[ 2.73072004e-01  2.73072004e-01  2.73072004e-01]\n",
      "   [ 3.04983735e-01  3.04983735e-01  3.04983735e-01]\n",
      "   [ 3.08480531e-01  3.08480531e-01  3.08480531e-01]\n",
      "   ...\n",
      "   [-1.81111127e-01 -1.81111127e-01 -1.81111127e-01]\n",
      "   [-1.85833365e-01 -1.85833365e-01 -1.85833365e-01]\n",
      "   [-1.92565322e-01 -1.92565322e-01 -1.92565322e-01]]\n",
      "\n",
      "  [[ 2.99313784e-01  2.99313784e-01  2.99313784e-01]\n",
      "   [ 2.94330150e-01  2.94330150e-01  2.94330150e-01]\n",
      "   [ 3.25637400e-01  3.25637400e-01  3.25637400e-01]\n",
      "   ...\n",
      "   [-1.43709108e-01 -1.43709108e-01 -1.43709108e-01]\n",
      "   [-1.42091468e-01 -1.42091468e-01 -1.42091468e-01]\n",
      "   [-1.53055519e-01 -1.53055519e-01 -1.53055519e-01]]\n",
      "\n",
      "  [[ 3.06421638e-01  3.06421638e-01  3.06421638e-01]\n",
      "   [ 2.96683133e-01  2.96683133e-01  2.96683133e-01]\n",
      "   [ 3.02091599e-01  3.02091599e-01  3.02091599e-01]\n",
      "   ...\n",
      "   [-1.47630706e-01 -1.47630706e-01 -1.47630706e-01]\n",
      "   [-1.50163397e-01 -1.50163397e-01 -1.50163397e-01]\n",
      "   [-1.54444352e-01 -1.54444352e-01 -1.54444352e-01]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[-3.67647409e-03 -3.67647409e-03 -3.67647409e-03]\n",
      "   [-1.98364854e-02 -1.98364854e-02 -1.98364854e-02]\n",
      "   [-3.41338925e-02 -3.41338925e-02 -3.41338925e-02]\n",
      "   ...\n",
      "   [-7.21404999e-02 -7.21404999e-02 -7.21404999e-02]\n",
      "   [-8.14215466e-02 -8.14215466e-02 -8.14215466e-02]\n",
      "   [-9.80229229e-02 -9.80229229e-02 -9.80229229e-02]]\n",
      "\n",
      "  [[-9.08497721e-03 -9.08497721e-03 -9.08497721e-03]\n",
      "   [-1.92482248e-02 -1.92482248e-02 -1.92482248e-02]\n",
      "   [-3.30390967e-02 -3.30390967e-02 -3.30390967e-02]\n",
      "   ...\n",
      "   [-7.12254569e-02 -7.12254569e-02 -7.12254569e-02]\n",
      "   [-7.99836144e-02 -7.99836144e-02 -7.99836144e-02]\n",
      "   [-1.05457552e-01 -1.05457552e-01 -1.05457552e-01]]\n",
      "\n",
      "  [[ 2.71536082e-01  2.71536082e-01  2.71536082e-01]\n",
      "   [-1.17532559e-01 -1.17532559e-01 -1.17532559e-01]\n",
      "   [-1.02957390e-01 -1.02957390e-01 -1.02957390e-01]\n",
      "   ...\n",
      "   [-1.45604566e-01 -1.45604566e-01 -1.45604566e-01]\n",
      "   [-1.70767933e-01 -1.70767933e-01 -1.70767933e-01]\n",
      "   [-1.95081592e-01 -1.95081592e-01 -1.95081592e-01]]]\n",
      "\n",
      "\n",
      " [[[-1.46535844e-01 -1.46535844e-01 -1.46535844e-01]\n",
      "   [-1.26388818e-01 -1.26388818e-01 -1.26388818e-01]\n",
      "   [-1.30735159e-01 -1.30735159e-01 -1.30735159e-01]\n",
      "   ...\n",
      "   [-1.85032696e-01 -1.85032696e-01 -1.85032696e-01]\n",
      "   [-1.89754933e-01 -1.89754933e-01 -1.89754933e-01]\n",
      "   [-1.96486890e-01 -1.96486890e-01 -1.96486890e-01]]\n",
      "\n",
      "  [[-5.75489625e-02 -5.75489625e-02 -5.75489625e-02]\n",
      "   [-7.03757405e-02 -7.03757405e-02 -7.03757405e-02]\n",
      "   [-8.22057575e-02 -8.22057575e-02 -8.22057575e-02]\n",
      "   ...\n",
      "   [-1.31944403e-01 -1.31944403e-01 -1.31944403e-01]\n",
      "   [-1.18562058e-01 -1.18562058e-01 -1.18562058e-01]\n",
      "   [-1.09918267e-01 -1.09918267e-01 -1.09918267e-01]]\n",
      "\n",
      "  [[-7.78920874e-02 -7.78920874e-02 -7.78920874e-02]\n",
      "   [-8.37090462e-02 -8.37090462e-02 -8.37090462e-02]\n",
      "   [-8.61437023e-02 -8.61437023e-02 -8.61437023e-02]\n",
      "   ...\n",
      "   [-1.35866001e-01 -1.35866001e-01 -1.35866001e-01]\n",
      "   [-1.30555555e-01 -1.30555555e-01 -1.30555555e-01]\n",
      "   [-1.15228668e-01 -1.15228668e-01 -1.15228668e-01]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[ 8.08823109e-03  8.08823109e-03  8.08823109e-03]\n",
      "   [-1.19933486e-02 -1.19933486e-02 -1.19933486e-02]\n",
      "   [-3.41338925e-02 -3.41338925e-02 -3.41338925e-02]\n",
      "   ...\n",
      "   [-7.21404999e-02 -7.21404999e-02 -7.21404999e-02]\n",
      "   [-8.14215466e-02 -8.14215466e-02 -8.14215466e-02]\n",
      "   [-9.41013545e-02 -9.41013545e-02 -9.41013545e-02]]\n",
      "\n",
      "  [[-1.69281140e-02 -1.69281140e-02 -1.69281140e-02]\n",
      "   [-3.49345021e-02 -3.49345021e-02 -3.49345021e-02]\n",
      "   [-3.69606651e-02 -3.69606651e-02 -3.69606651e-02]\n",
      "   ...\n",
      "   [-7.12254569e-02 -7.12254569e-02 -7.12254569e-02]\n",
      "   [-7.99836144e-02 -7.99836144e-02 -7.99836144e-02]\n",
      "   [-1.01535983e-01 -1.01535983e-01 -1.01535983e-01]]\n",
      "\n",
      "  [[ 2.71536082e-01  2.71536082e-01  2.71536082e-01]\n",
      "   [-5.47874570e-02 -5.47874570e-02 -5.47874570e-02]\n",
      "   [-8.72711167e-02 -8.72711167e-02 -8.72711167e-02]\n",
      "   ...\n",
      "   [-1.69133976e-01 -1.69133976e-01 -1.69133976e-01]\n",
      "   [-1.94297343e-01 -1.94297343e-01 -1.94297343e-01]\n",
      "   [-2.18611002e-01 -2.18611002e-01 -2.18611002e-01]]]\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      " [[[-8.37907419e-02 -8.37907419e-02 -8.37907419e-02]\n",
      "   [ 3.48121017e-01  3.48121017e-01  3.48121017e-01]\n",
      "   [-1.46421432e-01 -1.46421432e-01 -1.46421432e-01]\n",
      "   ...\n",
      "   [ 3.16928118e-01  3.16928118e-01  3.16928118e-01]\n",
      "   [ 3.12205881e-01  3.12205881e-01  3.12205881e-01]\n",
      "   [ 3.05473924e-01  3.05473924e-01  3.05473924e-01]]\n",
      "\n",
      "  [[-6.14705309e-02 -6.14705309e-02 -6.14705309e-02]\n",
      "   [-8.99835825e-02 -8.99835825e-02 -8.99835825e-02]\n",
      "   [-9.78920311e-02 -9.78920311e-02 -9.78920311e-02]\n",
      "   ...\n",
      "   [ 2.56290913e-01  2.56290913e-01  2.56290913e-01]\n",
      "   [ 3.04967344e-01  3.04967344e-01  3.04967344e-01]\n",
      "   [ 3.25375855e-01  3.25375855e-01  3.25375855e-01]]\n",
      "\n",
      "  [[-7.39705190e-02 -7.39705190e-02 -7.39705190e-02]\n",
      "   [-9.54737514e-02 -9.54737514e-02 -9.54737514e-02]\n",
      "   [-9.79084074e-02 -9.79084074e-02 -9.79084074e-02]\n",
      "   ...\n",
      "   [ 2.56290853e-01  2.56290853e-01  2.56290853e-01]\n",
      "   [ 2.77287602e-01  2.77287602e-01  2.77287602e-01]\n",
      "   [ 2.84771323e-01  2.84771323e-01  2.84771323e-01]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[-6.25000000e-02 -6.25000000e-02 -6.25000000e-02]\n",
      "   [-5.90521768e-02 -5.90521768e-02 -5.90521768e-02]\n",
      "   [-4.98201698e-02 -4.98201698e-02 -4.98201698e-02]\n",
      "   ...\n",
      "   [ 1.86683044e-01  1.86683044e-01  1.86683044e-01]\n",
      "   [-1.08333081e-02 -1.08333081e-02 -1.08333081e-02]\n",
      "   [ 1.96241364e-02  1.96241364e-02  1.96241364e-02]]\n",
      "\n",
      "  [[-6.00653701e-02 -6.00653701e-02 -6.00653701e-02]\n",
      "   [-6.23854846e-02 -6.23854846e-02 -6.23854846e-02]\n",
      "   [-5.26469424e-02 -5.26469424e-02 -5.26469424e-02]\n",
      "   ...\n",
      "   [-4.76960465e-02 -4.76960465e-02 -4.76960465e-02]\n",
      "   [-3.29247899e-02 -3.29247899e-02 -3.29247899e-02]\n",
      "   [ 8.26793909e-03  8.26793909e-03  8.26793909e-03]]\n",
      "\n",
      "  [[-1.87287480e-01 -1.87287480e-01 -1.87287480e-01]\n",
      "   [-1.64591387e-01 -1.64591387e-01 -1.64591387e-01]\n",
      "   [-1.57859355e-01 -1.57859355e-01 -1.57859355e-01]\n",
      "   ...\n",
      "   [-1.45604566e-01 -1.45604566e-01 -1.45604566e-01]\n",
      "   [-1.39395386e-01 -1.39395386e-01 -1.39395386e-01]\n",
      "   [-1.24493353e-01 -1.24493353e-01 -1.24493353e-01]]]\n",
      "\n",
      "\n",
      " [[[-4.06534895e-02 -4.06534895e-02 -4.06534895e-02]\n",
      "   [-6.36437163e-02 -6.36437163e-02 -6.36437163e-02]\n",
      "   [-7.58331940e-02 -7.58331940e-02 -7.58331940e-02]\n",
      "   ...\n",
      "   [-1.85032696e-01 -1.85032696e-01 -1.85032696e-01]\n",
      "   [-1.89754933e-01 -1.89754933e-01 -1.89754933e-01]\n",
      "   [-1.92565322e-01 -1.92565322e-01 -1.92565322e-01]]\n",
      "\n",
      "  [[-3.79411206e-02 -3.79411206e-02 -3.79411206e-02]\n",
      "   [-3.50816175e-02 -3.50816175e-02 -3.50816175e-02]\n",
      "   [-5.47547713e-02 -5.47547713e-02 -5.47547713e-02]\n",
      "   ...\n",
      "   [-1.47630677e-01 -1.47630677e-01 -1.47630677e-01]\n",
      "   [-1.46013036e-01 -1.46013036e-01 -1.46013036e-01]\n",
      "   [-1.53055519e-01 -1.53055519e-01 -1.53055519e-01]]\n",
      "\n",
      "  [[-6.22058138e-02 -6.22058138e-02 -6.22058138e-02]\n",
      "   [-3.66502181e-02 -3.66502181e-02 -3.66502181e-02]\n",
      "   [-5.86927161e-02 -5.86927161e-02 -5.86927161e-02]\n",
      "   ...\n",
      "   [-1.51552275e-01 -1.51552275e-01 -1.51552275e-01]\n",
      "   [-1.54084966e-01 -1.54084966e-01 -1.54084966e-01]\n",
      "   [-1.58365920e-01 -1.58365920e-01 -1.58365920e-01]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[ 2.76960805e-02  2.76960805e-02  2.76960805e-02]\n",
      "   [ 7.61449337e-03  7.61449337e-03  7.61449337e-03]\n",
      "   [-2.76134163e-03 -2.76134163e-03 -2.76134163e-03]\n",
      "   ...\n",
      "   [-7.21404999e-02 -7.21404999e-02 -7.21404999e-02]\n",
      "   [-8.14215466e-02 -8.14215466e-02 -8.14215466e-02]\n",
      "   [-9.80229229e-02 -9.80229229e-02 -9.80229229e-02]]\n",
      "\n",
      "  [[ 2.62091458e-02  2.62091458e-02  2.62091458e-02]\n",
      "   [ 3.59617174e-04  3.59617174e-04  3.59617174e-04]\n",
      "   [-9.50968266e-03 -9.50968266e-03 -9.50968266e-03]\n",
      "   ...\n",
      "   [-7.12254569e-02 -7.12254569e-02 -7.12254569e-02]\n",
      "   [-7.99836144e-02 -7.99836144e-02 -7.99836144e-02]\n",
      "   [-1.05457552e-01 -1.05457552e-01 -1.05457552e-01]]\n",
      "\n",
      "  [[-1.24542378e-01 -1.24542378e-01 -1.24542378e-01]\n",
      "   [-9.79247168e-02 -9.79247168e-02 -9.79247168e-02]\n",
      "   [-1.06878959e-01 -1.06878959e-01 -1.06878959e-01]\n",
      "   ...\n",
      "   [-1.69133976e-01 -1.69133976e-01 -1.69133976e-01]\n",
      "   [-1.94297343e-01 -1.94297343e-01 -1.94297343e-01]\n",
      "   [-2.18611002e-01 -2.18611002e-01 -2.18611002e-01]]]\n",
      "\n",
      "\n",
      " [[[ 2.88758278e-01  2.88758278e-01  2.88758278e-01]\n",
      "   [ 3.12826872e-01  3.12826872e-01  3.12826872e-01]\n",
      "   [ 2.92794257e-01  2.92794257e-01  2.92794257e-01]\n",
      "   ...\n",
      "   [-1.85032696e-01 -1.85032696e-01 -1.85032696e-01]\n",
      "   [-1.89754933e-01 -1.89754933e-01 -1.89754933e-01]\n",
      "   [-1.96486890e-01 -1.96486890e-01 -1.96486890e-01]]\n",
      "\n",
      "  [[ 3.30686331e-01  3.30686331e-01  3.30686331e-01]\n",
      "   [ 3.57075244e-01  3.57075244e-01  3.57075244e-01]\n",
      "   [ 2.98186421e-01  2.98186421e-01  2.98186421e-01]\n",
      "   ...\n",
      "   [-1.47630677e-01 -1.47630677e-01 -1.47630677e-01]\n",
      "   [-1.46013036e-01 -1.46013036e-01 -1.46013036e-01]\n",
      "   [-1.56977087e-01 -1.56977087e-01 -1.56977087e-01]]\n",
      "\n",
      "  [[ 2.82892227e-01  2.82892227e-01  2.82892227e-01]\n",
      "   [ 2.84918427e-01  2.84918427e-01  2.84918427e-01]\n",
      "   [ 2.86405325e-01  2.86405325e-01  2.86405325e-01]\n",
      "   ...\n",
      "   [-1.51552275e-01 -1.51552275e-01 -1.51552275e-01]\n",
      "   [-1.54084966e-01 -1.54084966e-01 -1.54084966e-01]\n",
      "   [-1.58365920e-01 -1.58365920e-01 -1.58365920e-01]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[ 2.76960805e-02  2.76960805e-02  2.76960805e-02]\n",
      "   [-1.19933486e-02 -1.19933486e-02 -1.19933486e-02]\n",
      "   [-2.62907557e-02 -2.62907557e-02 -2.62907557e-02]\n",
      "   ...\n",
      "   [-7.21404999e-02 -7.21404999e-02 -7.21404999e-02]\n",
      "   [-8.14215466e-02 -8.14215466e-02 -8.14215466e-02]\n",
      "   [-9.80229229e-02 -9.80229229e-02 -9.80229229e-02]]\n",
      "\n",
      "  [[ 2.62091458e-02  2.62091458e-02  2.62091458e-02]\n",
      "   [-1.53266564e-02 -1.53266564e-02 -1.53266564e-02]\n",
      "   [-2.51959600e-02 -2.51959600e-02 -2.51959600e-02]\n",
      "   ...\n",
      "   [-7.12254569e-02 -7.12254569e-02 -7.12254569e-02]\n",
      "   [-7.99836144e-02 -7.99836144e-02 -7.99836144e-02]\n",
      "   [-1.05457552e-01 -1.05457552e-01 -1.05457552e-01]]\n",
      "\n",
      "  [[-1.01012960e-01 -1.01012960e-01 -1.01012960e-01]\n",
      "   [-1.17532559e-01 -1.17532559e-01 -1.17532559e-01]\n",
      "   [-1.22565240e-01 -1.22565240e-01 -1.22565240e-01]\n",
      "   ...\n",
      "   [-1.69133976e-01 -1.69133976e-01 -1.69133976e-01]\n",
      "   [-1.94297343e-01 -1.94297343e-01 -1.94297343e-01]\n",
      "   [-2.18611002e-01 -2.18611002e-01 -2.18611002e-01]]]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\patcas rares\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\keras\\engine\\training.py:1972: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 12s 991ms/step - loss: 2.1159 - accuracy: 0.4875 - val_loss: 2.6769 - val_accuracy: 0.4333\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 2/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 7s 789ms/step - loss: 1.3873 - accuracy: 0.6292 - val_loss: 2.5402 - val_accuracy: 0.5667\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 3/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 7s 808ms/step - loss: 1.2339 - accuracy: 0.6875 - val_loss: 2.3353 - val_accuracy: 0.5667\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 4/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 7s 804ms/step - loss: 1.1620 - accuracy: 0.6833 - val_loss: 2.2378 - val_accuracy: 0.5667\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 5/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 711ms/step - loss: 1.1618 - accuracy: 0.7083 - val_loss: 2.4102 - val_accuracy: 0.5667\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 6/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 790ms/step - loss: 1.1098 - accuracy: 0.7125 - val_loss: 2.3833 - val_accuracy: 0.5667\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 7/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 7s 802ms/step - loss: 1.0896 - accuracy: 0.7292 - val_loss: 2.6367 - val_accuracy: 0.5667\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 8/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 671ms/step - loss: 1.0487 - accuracy: 0.7542 - val_loss: 2.7823 - val_accuracy: 0.5667\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 9/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 759ms/step - loss: 1.0442 - accuracy: 0.7292 - val_loss: 2.9651 - val_accuracy: 0.5667\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 10/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 745ms/step - loss: 1.0018 - accuracy: 0.7708 - val_loss: 2.9972 - val_accuracy: 0.5667\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 11/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 686ms/step - loss: 1.0722 - accuracy: 0.7333 - val_loss: 2.9172 - val_accuracy: 0.5667\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 12/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 5s 669ms/step - loss: 1.0243 - accuracy: 0.8042 - val_loss: 3.1051 - val_accuracy: 0.5667\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 13/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 781ms/step - loss: 0.9975 - accuracy: 0.7708 - val_loss: 3.7794 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 14/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 775ms/step - loss: 0.9835 - accuracy: 0.8125 - val_loss: 5.2039 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 15/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 697ms/step - loss: 0.9575 - accuracy: 0.8125 - val_loss: 3.4145 - val_accuracy: 0.5667\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 16/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 756ms/step - loss: 0.9592 - accuracy: 0.7708 - val_loss: 3.2502 - val_accuracy: 0.5667\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 17/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 7s 809ms/step - loss: 0.9626 - accuracy: 0.7708 - val_loss: 6.9029 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 18/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 7s 949ms/step - loss: 0.9409 - accuracy: 0.7667 - val_loss: 6.7038 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 19/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 7s 847ms/step - loss: 0.9233 - accuracy: 0.7875 - val_loss: 3.9012 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 20/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 756ms/step - loss: 0.8812 - accuracy: 0.8250 - val_loss: 3.0218 - val_accuracy: 0.5667\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 21/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 722ms/step - loss: 0.9355 - accuracy: 0.7833 - val_loss: 7.8602 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 22/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 7s 836ms/step - loss: 0.9007 - accuracy: 0.8292 - val_loss: 3.9483 - val_accuracy: 0.5667\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 23/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 701ms/step - loss: 0.8871 - accuracy: 0.8417 - val_loss: 3.1556 - val_accuracy: 0.5667\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 24/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 5s 647ms/step - loss: 0.8596 - accuracy: 0.8333 - val_loss: 3.2720 - val_accuracy: 0.5667\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 25/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 677ms/step - loss: 0.8290 - accuracy: 0.8417 - val_loss: 10.8199 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 26/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 773ms/step - loss: 0.8357 - accuracy: 0.8583 - val_loss: 11.2339 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 27/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 5s 672ms/step - loss: 0.8224 - accuracy: 0.8458 - val_loss: 9.3563 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 28/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 5s 648ms/step - loss: 0.8582 - accuracy: 0.8042 - val_loss: 3.5083 - val_accuracy: 0.5667\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 29/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 5s 672ms/step - loss: 0.8934 - accuracy: 0.8000 - val_loss: 6.8318 - val_accuracy: 0.5667\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 30/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 5s 632ms/step - loss: 0.8398 - accuracy: 0.8125 - val_loss: 7.7383 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 31/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 5s 655ms/step - loss: 0.8248 - accuracy: 0.8292 - val_loss: 1.8192 - val_accuracy: 0.5667\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 32/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 678ms/step - loss: 0.8502 - accuracy: 0.8000 - val_loss: 1.6100 - val_accuracy: 0.4333\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 33/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 5s 695ms/step - loss: 0.7812 - accuracy: 0.8833 - val_loss: 2.4979 - val_accuracy: 0.5667\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 34/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 5s 642ms/step - loss: 0.7950 - accuracy: 0.8375 - val_loss: 3.9401 - val_accuracy: 0.5667\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 728ms/step - loss: 0.8333 - accuracy: 0.8125 - val_loss: 8.6643 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 36/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 741ms/step - loss: 0.7483 - accuracy: 0.8583 - val_loss: 5.2074 - val_accuracy: 0.5667\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 37/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 667ms/step - loss: 0.8152 - accuracy: 0.8333 - val_loss: 4.1845 - val_accuracy: 0.5667\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 38/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 5s 648ms/step - loss: 0.7836 - accuracy: 0.8458 - val_loss: 16.0921 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 39/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 687ms/step - loss: 0.7024 - accuracy: 0.8917 - val_loss: 2.8385 - val_accuracy: 0.5333\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 40/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 681ms/step - loss: 0.6980 - accuracy: 0.8958 - val_loss: 19.1573 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 41/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 798ms/step - loss: 0.7088 - accuracy: 0.9042 - val_loss: 4.1709 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 42/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 757ms/step - loss: 0.7362 - accuracy: 0.8708 - val_loss: 10.6201 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 43/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 678ms/step - loss: 0.7264 - accuracy: 0.8917 - val_loss: 14.0870 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 44/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 695ms/step - loss: 0.6983 - accuracy: 0.8792 - val_loss: 14.0946 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 45/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 5s 674ms/step - loss: 0.7367 - accuracy: 0.8667 - val_loss: 15.6104 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 46/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 5s 666ms/step - loss: 0.7268 - accuracy: 0.8542 - val_loss: 12.9612 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 47/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 747ms/step - loss: 0.6833 - accuracy: 0.8917 - val_loss: 4.3475 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 48/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 5s 666ms/step - loss: 0.7695 - accuracy: 0.8542 - val_loss: 11.7841 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 49/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 674ms/step - loss: 0.7367 - accuracy: 0.8375 - val_loss: 14.1183 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 50/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 688ms/step - loss: 0.6631 - accuracy: 0.8875 - val_loss: 6.2945 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 51/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 5s 657ms/step - loss: 0.7294 - accuracy: 0.8542 - val_loss: 5.3670 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 52/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 7s 844ms/step - loss: 0.7715 - accuracy: 0.8417 - val_loss: 6.6573 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 53/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 7s 772ms/step - loss: 0.7018 - accuracy: 0.8625 - val_loss: 1.6311 - val_accuracy: 0.5667\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 54/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 7s 896ms/step - loss: 0.6902 - accuracy: 0.8667 - val_loss: 9.4417 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 55/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 7s 823ms/step - loss: 0.6898 - accuracy: 0.8667 - val_loss: 4.5635 - val_accuracy: 0.5667\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 56/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 756ms/step - loss: 0.6751 - accuracy: 0.8833 - val_loss: 3.7815 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 57/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 766ms/step - loss: 0.6834 - accuracy: 0.8833 - val_loss: 13.8108 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 58/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 744ms/step - loss: 0.6727 - accuracy: 0.8958 - val_loss: 15.1003 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 59/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 755ms/step - loss: 0.6125 - accuracy: 0.9208 - val_loss: 20.5400 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 60/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 760ms/step - loss: 0.6144 - accuracy: 0.9000 - val_loss: 18.8517 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 61/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 788ms/step - loss: 0.6157 - accuracy: 0.9000 - val_loss: 21.3546 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 62/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 753ms/step - loss: 0.5727 - accuracy: 0.9208 - val_loss: 21.7075 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 63/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 767ms/step - loss: 0.5833 - accuracy: 0.9000 - val_loss: 18.1417 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 64/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 752ms/step - loss: 0.5791 - accuracy: 0.9208 - val_loss: 7.4319 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 65/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 754ms/step - loss: 0.6058 - accuracy: 0.9167 - val_loss: 5.8857 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 66/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 771ms/step - loss: 0.6331 - accuracy: 0.8917 - val_loss: 22.4163 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 67/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 767ms/step - loss: 0.6189 - accuracy: 0.8833 - val_loss: 17.6214 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 68/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 765ms/step - loss: 0.6439 - accuracy: 0.8833 - val_loss: 17.5254 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 69/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 761ms/step - loss: 0.5722 - accuracy: 0.9375 - val_loss: 18.4348 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 70/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 762ms/step - loss: 0.5307 - accuracy: 0.9417 - val_loss: 16.7634 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 71/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 763ms/step - loss: 0.5694 - accuracy: 0.9375 - val_loss: 14.7132 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 72/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 748ms/step - loss: 0.7111 - accuracy: 0.8417 - val_loss: 11.4298 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 73/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 832ms/step - loss: 0.5843 - accuracy: 0.9125 - val_loss: 5.7424 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 74/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 788ms/step - loss: 0.5496 - accuracy: 0.9375 - val_loss: 13.9345 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 75/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 801ms/step - loss: 0.5463 - accuracy: 0.9292 - val_loss: 16.1235 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 76/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 774ms/step - loss: 0.5618 - accuracy: 0.9375 - val_loss: 9.8056 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 77/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 8s 959ms/step - loss: 0.6194 - accuracy: 0.8833 - val_loss: 14.6458 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 78/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 7s 806ms/step - loss: 0.6377 - accuracy: 0.8625 - val_loss: 15.1386 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 79/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 763ms/step - loss: 0.5817 - accuracy: 0.9083 - val_loss: 3.9121 - val_accuracy: 0.5667\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 80/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 678ms/step - loss: 0.5921 - accuracy: 0.9125 - val_loss: 26.1456 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 81/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 664ms/step - loss: 0.5779 - accuracy: 0.9125 - val_loss: 18.1520 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 82/100\n",
      "Learning rate:  0.0001\n",
      "8/8 [==============================] - 5s 641ms/step - loss: 0.5362 - accuracy: 0.9292 - val_loss: 17.2590 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 83/100\n",
      "Learning rate:  0.0001\n",
      "8/8 [==============================] - 5s 640ms/step - loss: 0.5161 - accuracy: 0.9458 - val_loss: 17.4196 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 84/100\n",
      "Learning rate:  0.0001\n",
      "8/8 [==============================] - 5s 705ms/step - loss: 0.5332 - accuracy: 0.9458 - val_loss: 17.6705 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 85/100\n",
      "Learning rate:  0.0001\n",
      "8/8 [==============================] - 6s 704ms/step - loss: 0.4690 - accuracy: 0.9750 - val_loss: 18.7781 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 86/100\n",
      "Learning rate:  0.0001\n",
      "8/8 [==============================] - 7s 905ms/step - loss: 0.4572 - accuracy: 0.9667 - val_loss: 19.4593 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 87/100\n",
      "Learning rate:  0.0001\n",
      "8/8 [==============================] - 7s 824ms/step - loss: 0.4577 - accuracy: 0.9625 - val_loss: 19.7381 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 88/100\n",
      "Learning rate:  0.0001\n",
      "8/8 [==============================] - 6s 762ms/step - loss: 0.4917 - accuracy: 0.9542 - val_loss: 19.8975 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 89/100\n",
      "Learning rate:  0.0001\n",
      "8/8 [==============================] - 7s 846ms/step - loss: 0.4702 - accuracy: 0.9542 - val_loss: 20.2037 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 90/100\n",
      "Learning rate:  0.0001\n",
      "8/8 [==============================] - 7s 822ms/step - loss: 0.4487 - accuracy: 0.9750 - val_loss: 20.1628 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 91/100\n",
      "Learning rate:  0.0001\n",
      "8/8 [==============================] - 6s 763ms/step - loss: 0.4588 - accuracy: 0.9750 - val_loss: 20.6406 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 92/100\n",
      "Learning rate:  0.0001\n",
      "8/8 [==============================] - 6s 784ms/step - loss: 0.4390 - accuracy: 0.9792 - val_loss: 20.8000 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 93/100\n",
      "Learning rate:  0.0001\n",
      "8/8 [==============================] - 6s 742ms/step - loss: 0.4406 - accuracy: 0.9792 - val_loss: 20.3674 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 94/100\n",
      "Learning rate:  0.0001\n",
      "8/8 [==============================] - 6s 758ms/step - loss: 0.4394 - accuracy: 0.9833 - val_loss: 19.9046 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 95/100\n",
      "Learning rate:  0.0001\n",
      "8/8 [==============================] - 6s 803ms/step - loss: 0.4441 - accuracy: 0.9833 - val_loss: 19.8358 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 96/100\n",
      "Learning rate:  0.0001\n",
      "8/8 [==============================] - 6s 822ms/step - loss: 0.4567 - accuracy: 0.9583 - val_loss: 19.9743 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 97/100\n",
      "Learning rate:  0.0001\n",
      "8/8 [==============================] - 6s 753ms/step - loss: 0.4571 - accuracy: 0.9708 - val_loss: 19.6489 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 98/100\n",
      "Learning rate:  0.0001\n",
      "8/8 [==============================] - 6s 769ms/step - loss: 0.4382 - accuracy: 0.9833 - val_loss: 19.0833 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 99/100\n",
      "Learning rate:  0.0001\n",
      "8/8 [==============================] - 6s 756ms/step - loss: 0.4164 - accuracy: 0.9833 - val_loss: 18.9598 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 100/100\n",
      "Learning rate:  0.0001\n",
      "8/8 [==============================] - 6s 761ms/step - loss: 0.4371 - accuracy: 0.9708 - val_loss: 19.6950 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 471ms/step - loss: 0.6708 - accuracy: 0.8333\n",
      "Test loss: 0.6707844138145447\n",
      "Test accuracy: 0.8333333134651184\n",
      "[1, 2, 1, 2, 1, 1, 1, 2, 1, 2, 2, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Precision:  1.0\n",
      "Recall:  0.8333333333333334\n",
      "F1 Score:  0.9032258064516128\n",
      "[[[[  5   5   5]\n",
      "   [ 21  21  21]\n",
      "   [ 13  13  13]\n",
      "   ...\n",
      "   [  7   7   7]\n",
      "   [  5   5   5]\n",
      "   [  2   2   2]]\n",
      "\n",
      "  [[ 23  23  23]\n",
      "   [ 14  14  14]\n",
      "   [  9   9   9]\n",
      "   ...\n",
      "   [  1   1   1]\n",
      "   [  0   0   0]\n",
      "   [  0   0   0]]\n",
      "\n",
      "  [[ 23  23  23]\n",
      "   [ 14  14  14]\n",
      "   [  9   9   9]\n",
      "   ...\n",
      "   [  0   0   0]\n",
      "   [  0   0   0]\n",
      "   [  0   0   0]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[ 29  29  29]\n",
      "   [ 17  17  17]\n",
      "   [ 10  10  10]\n",
      "   ...\n",
      "   [  0   0   0]\n",
      "   [  0   0   0]\n",
      "   [  0   0   0]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [ 17  17  17]\n",
      "   [ 12  12  12]\n",
      "   ...\n",
      "   [  0   0   0]\n",
      "   [  0   0   0]\n",
      "   [  0   0   0]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [ 14  14  14]\n",
      "   ...\n",
      "   [  7   7   7]\n",
      "   [  6   6   6]\n",
      "   [  6   6   6]]]\n",
      "\n",
      "\n",
      " [[[108 108 108]\n",
      "   [117 117 117]\n",
      "   [116 116 116]\n",
      "   ...\n",
      "   [  1   1   1]\n",
      "   [  1   1   1]\n",
      "   [  1   1   1]]\n",
      "\n",
      "  [[112 112 112]\n",
      "   [108 108 108]\n",
      "   [115 115 115]\n",
      "   ...\n",
      "   [  1   1   1]\n",
      "   [  1   1   1]\n",
      "   [  1   1   1]]\n",
      "\n",
      "  [[117 117 117]\n",
      "   [112 112 112]\n",
      "   [110 110 110]\n",
      "   ...\n",
      "   [  1   1   1]\n",
      "   [  1   1   1]\n",
      "   [  1   1   1]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[ 25  25  25]\n",
      "   [ 17  17  17]\n",
      "   [ 10  10  10]\n",
      "   ...\n",
      "   [  0   0   0]\n",
      "   [  0   0   0]\n",
      "   [  0   0   0]]\n",
      "\n",
      "  [[ 24  24  24]\n",
      "   [ 18  18  18]\n",
      "   [ 11  11  11]\n",
      "   ...\n",
      "   [  0   0   0]\n",
      "   [  0   0   0]\n",
      "   [  0   0   0]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [ 19  19  19]\n",
      "   [ 19  19  19]\n",
      "   ...\n",
      "   [  6   6   6]\n",
      "   [  6   6   6]\n",
      "   [  6   6   6]]]\n",
      "\n",
      "\n",
      " [[[  1   1   1]\n",
      "   [  7   7   7]\n",
      "   [  4   4   4]\n",
      "   ...\n",
      "   [  0   0   0]\n",
      "   [  0   0   0]\n",
      "   [  0   0   0]]\n",
      "\n",
      "  [[ 21  21  21]\n",
      "   [ 15  15  15]\n",
      "   [ 11  11  11]\n",
      "   ...\n",
      "   [  4   4   4]\n",
      "   [  7   7   7]\n",
      "   [ 12  12  12]]\n",
      "\n",
      "  [[ 19  19  19]\n",
      "   [ 15  15  15]\n",
      "   [ 11  11  11]\n",
      "   ...\n",
      "   [  4   4   4]\n",
      "   [  6   6   6]\n",
      "   [ 11  11  11]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[ 28  28  28]\n",
      "   [ 19  19  19]\n",
      "   [ 10  10  10]\n",
      "   ...\n",
      "   [  0   0   0]\n",
      "   [  0   0   0]\n",
      "   [  1   1   1]]\n",
      "\n",
      "  [[ 22  22  22]\n",
      "   [ 14  14  14]\n",
      "   [ 10  10  10]\n",
      "   ...\n",
      "   [  0   0   0]\n",
      "   [  0   0   0]\n",
      "   [  1   1   1]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [ 35  35  35]\n",
      "   [ 23  23  23]\n",
      "   ...\n",
      "   [  0   0   0]\n",
      "   [  0   0   0]\n",
      "   [  0   0   0]]]]\n",
      "[[1]\n",
      " [1]\n",
      " [1]]\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "(40, 30, 3)\n",
      "x_train shape: (240, 40, 30, 3)\n",
      "240 train samples\n",
      "30 test samples\n",
      "y_train shape: (240, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\patcas rares\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate:  0.001\n",
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            [(None, 40, 30, 3)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_62 (Conv2D)              (None, 40, 30, 16)   448         input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_56 (BatchNo (None, 40, 30, 16)   64          conv2d_62[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_56 (Activation)      (None, 40, 30, 16)   0           batch_normalization_56[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_63 (Conv2D)              (None, 40, 30, 16)   272         activation_56[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_57 (BatchNo (None, 40, 30, 16)   64          conv2d_63[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_57 (Activation)      (None, 40, 30, 16)   0           batch_normalization_57[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_64 (Conv2D)              (None, 40, 30, 16)   2320        activation_57[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_58 (BatchNo (None, 40, 30, 16)   64          conv2d_64[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_58 (Activation)      (None, 40, 30, 16)   0           batch_normalization_58[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_66 (Conv2D)              (None, 40, 30, 64)   1088        activation_56[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_65 (Conv2D)              (None, 40, 30, 64)   1088        activation_58[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_18 (Add)                    (None, 40, 30, 64)   0           conv2d_66[0][0]                  \n",
      "                                                                 conv2d_65[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_59 (BatchNo (None, 40, 30, 64)   256         add_18[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_59 (Activation)      (None, 40, 30, 64)   0           batch_normalization_59[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_67 (Conv2D)              (None, 40, 30, 16)   1040        activation_59[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_60 (BatchNo (None, 40, 30, 16)   64          conv2d_67[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_60 (Activation)      (None, 40, 30, 16)   0           batch_normalization_60[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_68 (Conv2D)              (None, 40, 30, 16)   2320        activation_60[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_61 (BatchNo (None, 40, 30, 16)   64          conv2d_68[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_61 (Activation)      (None, 40, 30, 16)   0           batch_normalization_61[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_69 (Conv2D)              (None, 40, 30, 64)   1088        activation_61[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_19 (Add)                    (None, 40, 30, 64)   0           add_18[0][0]                     \n",
      "                                                                 conv2d_69[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_62 (BatchNo (None, 40, 30, 64)   256         add_19[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_62 (Activation)      (None, 40, 30, 64)   0           batch_normalization_62[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_70 (Conv2D)              (None, 40, 30, 16)   1040        activation_62[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_63 (BatchNo (None, 40, 30, 16)   64          conv2d_70[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_63 (Activation)      (None, 40, 30, 16)   0           batch_normalization_63[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_71 (Conv2D)              (None, 40, 30, 16)   2320        activation_63[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_64 (BatchNo (None, 40, 30, 16)   64          conv2d_71[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_64 (Activation)      (None, 40, 30, 16)   0           batch_normalization_64[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_72 (Conv2D)              (None, 40, 30, 64)   1088        activation_64[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_20 (Add)                    (None, 40, 30, 64)   0           add_19[0][0]                     \n",
      "                                                                 conv2d_72[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_65 (BatchNo (None, 40, 30, 64)   256         add_20[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_65 (Activation)      (None, 40, 30, 64)   0           batch_normalization_65[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_73 (Conv2D)              (None, 20, 15, 64)   4160        activation_65[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_66 (BatchNo (None, 20, 15, 64)   256         conv2d_73[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_66 (Activation)      (None, 20, 15, 64)   0           batch_normalization_66[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_74 (Conv2D)              (None, 20, 15, 64)   36928       activation_66[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_67 (BatchNo (None, 20, 15, 64)   256         conv2d_74[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_67 (Activation)      (None, 20, 15, 64)   0           batch_normalization_67[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_76 (Conv2D)              (None, 20, 15, 128)  8320        add_20[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_75 (Conv2D)              (None, 20, 15, 128)  8320        activation_67[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_21 (Add)                    (None, 20, 15, 128)  0           conv2d_76[0][0]                  \n",
      "                                                                 conv2d_75[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_68 (BatchNo (None, 20, 15, 128)  512         add_21[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_68 (Activation)      (None, 20, 15, 128)  0           batch_normalization_68[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_77 (Conv2D)              (None, 20, 15, 64)   8256        activation_68[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_69 (BatchNo (None, 20, 15, 64)   256         conv2d_77[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_69 (Activation)      (None, 20, 15, 64)   0           batch_normalization_69[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_78 (Conv2D)              (None, 20, 15, 64)   36928       activation_69[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_70 (BatchNo (None, 20, 15, 64)   256         conv2d_78[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_70 (Activation)      (None, 20, 15, 64)   0           batch_normalization_70[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_79 (Conv2D)              (None, 20, 15, 128)  8320        activation_70[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_22 (Add)                    (None, 20, 15, 128)  0           add_21[0][0]                     \n",
      "                                                                 conv2d_79[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_71 (BatchNo (None, 20, 15, 128)  512         add_22[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_71 (Activation)      (None, 20, 15, 128)  0           batch_normalization_71[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_80 (Conv2D)              (None, 20, 15, 64)   8256        activation_71[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_72 (BatchNo (None, 20, 15, 64)   256         conv2d_80[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_72 (Activation)      (None, 20, 15, 64)   0           batch_normalization_72[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_81 (Conv2D)              (None, 20, 15, 64)   36928       activation_72[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_73 (BatchNo (None, 20, 15, 64)   256         conv2d_81[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_73 (Activation)      (None, 20, 15, 64)   0           batch_normalization_73[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_82 (Conv2D)              (None, 20, 15, 128)  8320        activation_73[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_23 (Add)                    (None, 20, 15, 128)  0           add_22[0][0]                     \n",
      "                                                                 conv2d_82[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_74 (BatchNo (None, 20, 15, 128)  512         add_23[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_74 (Activation)      (None, 20, 15, 128)  0           batch_normalization_74[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_83 (Conv2D)              (None, 10, 8, 128)   16512       activation_74[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_75 (BatchNo (None, 10, 8, 128)   512         conv2d_83[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_75 (Activation)      (None, 10, 8, 128)   0           batch_normalization_75[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_84 (Conv2D)              (None, 10, 8, 128)   147584      activation_75[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_76 (BatchNo (None, 10, 8, 128)   512         conv2d_84[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_76 (Activation)      (None, 10, 8, 128)   0           batch_normalization_76[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_86 (Conv2D)              (None, 10, 8, 256)   33024       add_23[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_85 (Conv2D)              (None, 10, 8, 256)   33024       activation_76[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_24 (Add)                    (None, 10, 8, 256)   0           conv2d_86[0][0]                  \n",
      "                                                                 conv2d_85[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_77 (BatchNo (None, 10, 8, 256)   1024        add_24[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_77 (Activation)      (None, 10, 8, 256)   0           batch_normalization_77[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_87 (Conv2D)              (None, 10, 8, 128)   32896       activation_77[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_78 (BatchNo (None, 10, 8, 128)   512         conv2d_87[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_78 (Activation)      (None, 10, 8, 128)   0           batch_normalization_78[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_88 (Conv2D)              (None, 10, 8, 128)   147584      activation_78[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_79 (BatchNo (None, 10, 8, 128)   512         conv2d_88[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_79 (Activation)      (None, 10, 8, 128)   0           batch_normalization_79[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_89 (Conv2D)              (None, 10, 8, 256)   33024       activation_79[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_25 (Add)                    (None, 10, 8, 256)   0           add_24[0][0]                     \n",
      "                                                                 conv2d_89[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_80 (BatchNo (None, 10, 8, 256)   1024        add_25[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_80 (Activation)      (None, 10, 8, 256)   0           batch_normalization_80[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_90 (Conv2D)              (None, 10, 8, 128)   32896       activation_80[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_81 (BatchNo (None, 10, 8, 128)   512         conv2d_90[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_81 (Activation)      (None, 10, 8, 128)   0           batch_normalization_81[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_91 (Conv2D)              (None, 10, 8, 128)   147584      activation_81[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_82 (BatchNo (None, 10, 8, 128)   512         conv2d_91[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_82 (Activation)      (None, 10, 8, 128)   0           batch_normalization_82[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_92 (Conv2D)              (None, 10, 8, 256)   33024       activation_82[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_26 (Add)                    (None, 10, 8, 256)   0           add_25[0][0]                     \n",
      "                                                                 conv2d_92[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_83 (BatchNo (None, 10, 8, 256)   1024        add_26[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_83 (Activation)      (None, 10, 8, 256)   0           batch_normalization_83[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_2 (AveragePoo (None, 1, 1, 256)    0           activation_83[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_2 (Flatten)             (None, 256)          0           average_pooling2d_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 10)           2570        flatten_2[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 849,002\n",
      "Trainable params: 843,786\n",
      "Non-trainable params: 5,216\n",
      "__________________________________________________________________________________________________\n",
      "ResNet  29v  2\n",
      "Using real-time data augmentation.\n",
      "------------------\n",
      "[[[[-0.119379   -0.119379   -0.119379  ]\n",
      "   [-0.06019595 -0.06019595 -0.06019595]\n",
      "   [-0.08467311 -0.08467311 -0.08467311]\n",
      "   ...\n",
      "   [-0.15588237 -0.15588237 -0.15588237]\n",
      "   [-0.16774508 -0.16774508 -0.16774508]\n",
      "   [-0.18707518 -0.18707518 -0.18707518]]\n",
      "\n",
      "  [[-0.04506531 -0.04506531 -0.04506531]\n",
      "   [-0.06666659 -0.06666659 -0.06666659]\n",
      "   [-0.0811927  -0.0811927  -0.0811927 ]\n",
      "   ...\n",
      "   [-0.14926465 -0.14926465 -0.14926465]\n",
      "   [-0.14830065 -0.14830065 -0.14830065]\n",
      "   [-0.16423197 -0.16423197 -0.16423197]]\n",
      "\n",
      "  [[-0.05509796 -0.05509796 -0.05509796]\n",
      "   [-0.07740186 -0.07740186 -0.07740186]\n",
      "   [-0.08468945 -0.08468945 -0.08468945]\n",
      "   ...\n",
      "   [-0.15767972 -0.15767972 -0.15767972]\n",
      "   [-0.15576798 -0.15576798 -0.15576798]\n",
      "   [-0.16879076 -0.16879076 -0.16879076]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[ 0.00091502  0.00091502  0.00091502]\n",
      "   [-0.02972209 -0.02972209 -0.02972209]\n",
      "   [-0.03491821 -0.03491821 -0.03491821]\n",
      "   ...\n",
      "   [-0.07640518 -0.07640518 -0.07640518]\n",
      "   [-0.08807185 -0.08807185 -0.08807185]\n",
      "   [-0.10738566 -0.10738566 -0.10738566]]\n",
      "\n",
      "  [[ 0.3923366   0.3923366   0.3923366 ]\n",
      "   [-0.02874169 -0.02874169 -0.02874169]\n",
      "   [-0.03274499 -0.03274499 -0.03274499]\n",
      "   ...\n",
      "   [-0.07913394 -0.07913394 -0.07913394]\n",
      "   [-0.08248362 -0.08248362 -0.08248362]\n",
      "   [-0.11109482 -0.11109482 -0.11109482]]\n",
      "\n",
      "  [[ 0.27472234  0.27472234  0.27472234]\n",
      "   [ 0.3183498   0.3183498   0.3183498 ]\n",
      "   [-0.11807181 -0.11807181 -0.11807181]\n",
      "   ...\n",
      "   [-0.13302284 -0.13302284 -0.13302284]\n",
      "   [-0.15503268 -0.15503268 -0.15503268]\n",
      "   [-0.18256527 -0.18256527 -0.18256527]]]\n",
      "\n",
      "\n",
      " [[[ 0.28454256  0.28454256  0.28454256]\n",
      "   [ 0.31627464  0.31627464  0.31627464]\n",
      "   [ 0.31924847  0.31924847  0.31924847]\n",
      "   ...\n",
      "   [-0.17941178 -0.17941178 -0.17941178]\n",
      "   [-0.18343136 -0.18343136 -0.18343136]\n",
      "   [-0.19099675 -0.19099675 -0.19099675]]\n",
      "\n",
      "  [[ 0.3039543   0.3039543   0.3039543 ]\n",
      "   [ 0.3019609   0.3019609   0.3019609 ]\n",
      "   [ 0.33449358  0.33449358  0.33449358]\n",
      "   ...\n",
      "   [-0.14926465 -0.14926465 -0.14926465]\n",
      "   [-0.14437908 -0.14437908 -0.14437908]\n",
      "   [-0.1603104  -0.1603104  -0.1603104 ]]\n",
      "\n",
      "  [[ 0.3135295   0.3135295   0.3135295 ]\n",
      "   [ 0.3069119   0.3069119   0.3069119 ]\n",
      "   [ 0.31138897  0.31138897  0.31138897]\n",
      "   ...\n",
      "   [-0.15375815 -0.15375815 -0.15375815]\n",
      "   [-0.15184641 -0.15184641 -0.15184641]\n",
      "   [-0.16486919 -0.16486919 -0.16486919]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[-0.01477125 -0.01477125 -0.01477125]\n",
      "   [-0.02972209 -0.02972209 -0.02972209]\n",
      "   [-0.03491821 -0.03491821 -0.03491821]\n",
      "   ...\n",
      "   [-0.07640518 -0.07640518 -0.07640518]\n",
      "   [-0.08807185 -0.08807185 -0.08807185]\n",
      "   [-0.10738566 -0.10738566 -0.10738566]]\n",
      "\n",
      "  [[-0.01550657 -0.01550657 -0.01550657]\n",
      "   [-0.02482012 -0.02482012 -0.02482012]\n",
      "   [-0.03666655 -0.03666655 -0.03666655]\n",
      "   ...\n",
      "   [-0.07913394 -0.07913394 -0.07913394]\n",
      "   [-0.08248362 -0.08248362 -0.08248362]\n",
      "   [-0.11109482 -0.11109482 -0.11109482]]\n",
      "\n",
      "  [[ 0.27472234  0.27472234  0.27472234]\n",
      "   [-0.1091012  -0.1091012  -0.1091012 ]\n",
      "   [-0.09846396 -0.09846396 -0.09846396]\n",
      "   ...\n",
      "   [-0.13694441 -0.13694441 -0.13694441]\n",
      "   [-0.15503268 -0.15503268 -0.15503268]\n",
      "   [-0.18256527 -0.18256527 -0.18256527]]]\n",
      "\n",
      "\n",
      " [[[-0.13506527 -0.13506527 -0.13506527]\n",
      "   [-0.11509791 -0.11509791 -0.11509791]\n",
      "   [-0.11996722 -0.11996722 -0.11996722]\n",
      "   ...\n",
      "   [-0.18333335 -0.18333335 -0.18333335]\n",
      "   [-0.18735293 -0.18735293 -0.18735293]\n",
      "   [-0.19491832 -0.19491832 -0.19491832]]\n",
      "\n",
      "  [[-0.05290844 -0.05290844 -0.05290844]\n",
      "   [-0.06274502 -0.06274502 -0.06274502]\n",
      "   [-0.07334957 -0.07334957 -0.07334957]\n",
      "   ...\n",
      "   [-0.13749994 -0.13749994 -0.13749994]\n",
      "   [-0.12084967 -0.12084967 -0.12084967]\n",
      "   [-0.11717315 -0.11717315 -0.11717315]]\n",
      "\n",
      "  [[-0.07078423 -0.07078423 -0.07078423]\n",
      "   [-0.07348029 -0.07348029 -0.07348029]\n",
      "   [-0.07684632 -0.07684632 -0.07684632]\n",
      "   ...\n",
      "   [-0.14199345 -0.14199345 -0.14199345]\n",
      "   [-0.13223857 -0.13223857 -0.13223857]\n",
      "   [-0.1256535  -0.1256535  -0.1256535 ]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[-0.00300655 -0.00300655 -0.00300655]\n",
      "   [-0.02187896 -0.02187896 -0.02187896]\n",
      "   [-0.03491821 -0.03491821 -0.03491821]\n",
      "   ...\n",
      "   [-0.07640518 -0.07640518 -0.07640518]\n",
      "   [-0.08807185 -0.08807185 -0.08807185]\n",
      "   [-0.10346409 -0.10346409 -0.10346409]]\n",
      "\n",
      "  [[-0.0233497  -0.0233497  -0.0233497 ]\n",
      "   [-0.0405064  -0.0405064  -0.0405064 ]\n",
      "   [-0.04058812 -0.04058812 -0.04058812]\n",
      "   ...\n",
      "   [-0.07913394 -0.07913394 -0.07913394]\n",
      "   [-0.08248362 -0.08248362 -0.08248362]\n",
      "   [-0.10717325 -0.10717325 -0.10717325]]\n",
      "\n",
      "  [[ 0.27472234  0.27472234  0.27472234]\n",
      "   [-0.0463561  -0.0463561  -0.0463561 ]\n",
      "   [-0.08277769 -0.08277769 -0.08277769]\n",
      "   ...\n",
      "   [-0.16047382 -0.16047382 -0.16047382]\n",
      "   [-0.17856209 -0.17856209 -0.17856209]\n",
      "   [-0.20609468 -0.20609468 -0.20609468]]]\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      " [[[-0.03702606 -0.03702606 -0.03702606]\n",
      "   [-0.03274497 -0.03274497 -0.03274497]\n",
      "   [-0.03761428 -0.03761428 -0.03761428]\n",
      "   ...\n",
      "   [-0.09705884 -0.09705884 -0.09705884]\n",
      "   [-0.08931371 -0.08931371 -0.08931371]\n",
      "   [-0.06158498 -0.06158498 -0.06158498]]\n",
      "\n",
      "  [[-0.00584961 -0.00584961 -0.00584961]\n",
      "   [-0.03529403 -0.03529403 -0.03529403]\n",
      "   [-0.04589859 -0.04589859 -0.04589859]\n",
      "   ...\n",
      "   [-0.13357837 -0.13357837 -0.13357837]\n",
      "   [-0.1169281  -0.1169281  -0.1169281 ]\n",
      "   [-0.12501629 -0.12501629 -0.12501629]]\n",
      "\n",
      "  [[-0.01588227 -0.01588227 -0.01588227]\n",
      "   [-0.04602931 -0.04602931 -0.04602931]\n",
      "   [-0.05331691 -0.05331691 -0.05331691]\n",
      "   ...\n",
      "   [-0.13807188 -0.13807188 -0.13807188]\n",
      "   [-0.128317   -0.128317   -0.128317  ]\n",
      "   [-0.13349664 -0.13349664 -0.13349664]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[ 0.04013071  0.04013071  0.04013071]\n",
      "   [ 0.01341516  0.01341516  0.01341516]\n",
      "   [ 0.00429748  0.00429748  0.00429748]\n",
      "   ...\n",
      "   [-0.06071891 -0.06071891 -0.06071891]\n",
      "   [-0.06454244 -0.06454244 -0.06454244]\n",
      "   [-0.0760131  -0.0760131  -0.0760131 ]]\n",
      "\n",
      "  [[ 0.08253265  0.08253265  0.08253265]\n",
      "   [ 0.0222387   0.0222387   0.0222387 ]\n",
      "   [ 0.0064707   0.0064707   0.0064707 ]\n",
      "   ...\n",
      "   [-0.07913394 -0.07913394 -0.07913394]\n",
      "   [-0.05503264 -0.05503264 -0.05503264]\n",
      "   [-0.0758007  -0.0758007  -0.0758007 ]]\n",
      "\n",
      "  [[-0.14488551 -0.14488551 -0.14488551]\n",
      "   [-0.13263062 -0.13263062 -0.13263062]\n",
      "   [-0.17297377 -0.17297377 -0.17297377]\n",
      "   ...\n",
      "   [-0.13302284 -0.13302284 -0.13302284]\n",
      "   [-0.1393464  -0.1393464  -0.1393464 ]\n",
      "   [-0.14727116 -0.14727116 -0.14727116]]]\n",
      "\n",
      "\n",
      " [[[-0.06055547 -0.06055547 -0.06055547]\n",
      "   [ 0.02607857  0.02607857  0.02607857]\n",
      "   [-0.10035938 -0.10035938 -0.10035938]\n",
      "   ...\n",
      "   [-0.1401961  -0.1401961  -0.1401961 ]\n",
      "   [-0.1285294  -0.1285294  -0.1285294 ]\n",
      "   [ 0.30704248  0.30704248  0.30704248]]\n",
      "\n",
      "  [[-0.05290844 -0.05290844 -0.05290844]\n",
      "   [-0.07058816 -0.07058816 -0.07058816]\n",
      "   [-0.07727113 -0.07727113 -0.07727113]\n",
      "   ...\n",
      "   [-0.12181367 -0.12181367 -0.12181367]\n",
      "   [-0.09339869 -0.09339869 -0.09339869]\n",
      "   [-0.0975653  -0.0975653  -0.0975653 ]]\n",
      "\n",
      "  [[-0.0629411  -0.0629411  -0.0629411 ]\n",
      "   [-0.08132343 -0.08132343 -0.08132343]\n",
      "   [-0.08076788 -0.08076788 -0.08076788]\n",
      "   ...\n",
      "   [-0.13022874 -0.13022874 -0.13022874]\n",
      "   [-0.10086602 -0.10086602 -0.10086602]\n",
      "   [-0.09820252 -0.09820252 -0.09820252]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[-0.06967321 -0.06967321 -0.06967321]\n",
      "   [-0.06109465 -0.06109465 -0.06109465]\n",
      "   [-0.04276134 -0.04276134 -0.04276134]\n",
      "   ...\n",
      "   [-0.0489542  -0.0489542  -0.0489542 ]\n",
      "   [-0.03709145 -0.03709145 -0.03709145]\n",
      "   [-0.02895428 -0.02895428 -0.02895428]]\n",
      "\n",
      "  [[-0.06256539 -0.06256539 -0.06256539]\n",
      "   [-0.06011424 -0.06011424 -0.06011424]\n",
      "   [-0.04843126 -0.04843126 -0.04843126]\n",
      "   ...\n",
      "   [-0.05168296 -0.05168296 -0.05168296]\n",
      "   [-0.03150323 -0.03150323 -0.03150323]\n",
      "   [-0.03266344 -0.03266344 -0.03266344]]\n",
      "\n",
      "  [[ 0.16099684  0.16099684  0.16099684]\n",
      "   [ 0.12619293  0.12619293  0.12619293]\n",
      "   [ 0.08584978  0.08584978  0.08584978]\n",
      "   ...\n",
      "   [-0.0389052  -0.0389052  -0.0389052 ]\n",
      "   [-0.03346404 -0.03346404 -0.03346404]\n",
      "   [-0.11982017 -0.11982017 -0.11982017]]]\n",
      "\n",
      "\n",
      " [[[-0.02918292 -0.02918292 -0.02918292]\n",
      "   [-0.05235281 -0.05235281 -0.05235281]\n",
      "   [-0.06506526 -0.06506526 -0.06506526]\n",
      "   ...\n",
      "   [-0.18333335 -0.18333335 -0.18333335]\n",
      "   [-0.18735293 -0.18735293 -0.18735293]\n",
      "   [-0.19099675 -0.19099675 -0.19099675]]\n",
      "\n",
      "  [[-0.0333006  -0.0333006  -0.0333006 ]\n",
      "   [-0.0274509  -0.0274509  -0.0274509 ]\n",
      "   [-0.04589859 -0.04589859 -0.04589859]\n",
      "   ...\n",
      "   [-0.15318622 -0.15318622 -0.15318622]\n",
      "   [-0.14830065 -0.14830065 -0.14830065]\n",
      "   [-0.1603104  -0.1603104  -0.1603104 ]]\n",
      "\n",
      "  [[-0.05509796 -0.05509796 -0.05509796]\n",
      "   [-0.02642146 -0.02642146 -0.02642146]\n",
      "   [-0.04939534 -0.04939534 -0.04939534]\n",
      "   ...\n",
      "   [-0.15767972 -0.15767972 -0.15767972]\n",
      "   [-0.15576798 -0.15576798 -0.15576798]\n",
      "   [-0.16879076 -0.16879076 -0.16879076]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[ 0.0166013   0.0166013   0.0166013 ]\n",
      "   [-0.00227112 -0.00227112 -0.00227112]\n",
      "   [-0.00354566 -0.00354566 -0.00354566]\n",
      "   ...\n",
      "   [-0.07640518 -0.07640518 -0.07640518]\n",
      "   [-0.08807185 -0.08807185 -0.08807185]\n",
      "   [-0.10738566 -0.10738566 -0.10738566]]\n",
      "\n",
      "  [[ 0.01978756  0.01978756  0.01978756]\n",
      "   [-0.00521228 -0.00521228 -0.00521228]\n",
      "   [-0.01313714 -0.01313714 -0.01313714]\n",
      "   ...\n",
      "   [-0.07913394 -0.07913394 -0.07913394]\n",
      "   [-0.08248362 -0.08248362 -0.08248362]\n",
      "   [-0.11109482 -0.11109482 -0.11109482]]\n",
      "\n",
      "  [[-0.12135611 -0.12135611 -0.12135611]\n",
      "   [-0.08949336 -0.08949336 -0.08949336]\n",
      "   [-0.10238553 -0.10238553 -0.10238553]\n",
      "   ...\n",
      "   [-0.16047382 -0.16047382 -0.16047382]\n",
      "   [-0.17856209 -0.17856209 -0.17856209]\n",
      "   [-0.20609468 -0.20609468 -0.20609468]]]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\patcas rares\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\keras\\engine\\training.py:1972: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 11s 853ms/step - loss: 1.9462 - accuracy: 0.4833 - val_loss: 2.3874 - val_accuracy: 0.2333\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 2/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 765ms/step - loss: 1.3042 - accuracy: 0.6500 - val_loss: 1.7928 - val_accuracy: 0.7667\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 3/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 710ms/step - loss: 1.1674 - accuracy: 0.6667 - val_loss: 2.1596 - val_accuracy: 0.7667\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 4/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 750ms/step - loss: 1.1130 - accuracy: 0.7292 - val_loss: 2.3136 - val_accuracy: 0.7667\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 5/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 720ms/step - loss: 1.0943 - accuracy: 0.7667 - val_loss: 1.8328 - val_accuracy: 0.7667\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 6/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 711ms/step - loss: 1.0655 - accuracy: 0.7375 - val_loss: 2.2091 - val_accuracy: 0.7667\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 7/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 703ms/step - loss: 1.0891 - accuracy: 0.7333 - val_loss: 2.1281 - val_accuracy: 0.7667\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 8/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 758ms/step - loss: 1.0628 - accuracy: 0.7667 - val_loss: 1.9787 - val_accuracy: 0.7667\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 9/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 714ms/step - loss: 1.0294 - accuracy: 0.7875 - val_loss: 1.9582 - val_accuracy: 0.7667\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 10/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 714ms/step - loss: 1.0305 - accuracy: 0.7542 - val_loss: 2.8246 - val_accuracy: 0.7667\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 11/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 705ms/step - loss: 0.9818 - accuracy: 0.7625 - val_loss: 3.2067 - val_accuracy: 0.7667\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 12/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 717ms/step - loss: 1.0158 - accuracy: 0.7292 - val_loss: 2.4606 - val_accuracy: 0.7667\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 13/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 711ms/step - loss: 0.9629 - accuracy: 0.7958 - val_loss: 2.0325 - val_accuracy: 0.7667\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 14/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 724ms/step - loss: 0.9989 - accuracy: 0.7750 - val_loss: 2.4441 - val_accuracy: 0.7667\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 15/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 718ms/step - loss: 0.9487 - accuracy: 0.7542 - val_loss: 1.6615 - val_accuracy: 0.7667\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 16/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 709ms/step - loss: 0.9161 - accuracy: 0.8125 - val_loss: 2.8740 - val_accuracy: 0.7667\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 17/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 719ms/step - loss: 1.0182 - accuracy: 0.7458 - val_loss: 5.0883 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 18/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 703ms/step - loss: 0.9747 - accuracy: 0.7875 - val_loss: 8.5536 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 19/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 711ms/step - loss: 0.9876 - accuracy: 0.7458 - val_loss: 7.4862 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 20/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 741ms/step - loss: 0.9683 - accuracy: 0.7833 - val_loss: 1.8258 - val_accuracy: 0.7667\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 21/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 697ms/step - loss: 0.9587 - accuracy: 0.7375 - val_loss: 9.2979 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 22/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 708ms/step - loss: 0.8833 - accuracy: 0.8208 - val_loss: 7.4614 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 23/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 776ms/step - loss: 0.8777 - accuracy: 0.8417 - val_loss: 5.9631 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 24/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 700ms/step - loss: 0.8360 - accuracy: 0.8417 - val_loss: 15.3280 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 25/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 730ms/step - loss: 0.8055 - accuracy: 0.8500 - val_loss: 14.0987 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 26/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 768ms/step - loss: 0.8765 - accuracy: 0.8000 - val_loss: 11.9728 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 27/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 717ms/step - loss: 0.8367 - accuracy: 0.8375 - val_loss: 13.4433 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 28/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 761ms/step - loss: 0.8445 - accuracy: 0.8333 - val_loss: 16.7298 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 29/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 756ms/step - loss: 0.8550 - accuracy: 0.8375 - val_loss: 15.7933 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 30/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 773ms/step - loss: 0.7636 - accuracy: 0.8625 - val_loss: 15.0659 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 31/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 779ms/step - loss: 0.8214 - accuracy: 0.8250 - val_loss: 17.3014 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 32/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 7s 807ms/step - loss: 0.7867 - accuracy: 0.8375 - val_loss: 9.3882 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 33/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 748ms/step - loss: 0.7997 - accuracy: 0.8583 - val_loss: 12.8735 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 34/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 716ms/step - loss: 0.8250 - accuracy: 0.8333 - val_loss: 16.6239 - val_accuracy: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 35/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 766ms/step - loss: 0.7649 - accuracy: 0.8542 - val_loss: 8.8305 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 36/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 762ms/step - loss: 0.8002 - accuracy: 0.8167 - val_loss: 13.8855 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 37/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 816ms/step - loss: 0.7557 - accuracy: 0.8583 - val_loss: 14.8447 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 38/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 741ms/step - loss: 0.7404 - accuracy: 0.8792 - val_loss: 15.4199 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 39/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 7s 863ms/step - loss: 0.7271 - accuracy: 0.8958 - val_loss: 16.9223 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 40/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 709ms/step - loss: 0.7351 - accuracy: 0.8667 - val_loss: 15.9851 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 41/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 770ms/step - loss: 0.7393 - accuracy: 0.8792 - val_loss: 10.8452 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 42/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 689ms/step - loss: 0.7422 - accuracy: 0.8667 - val_loss: 18.2969 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 43/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 5s 656ms/step - loss: 0.7173 - accuracy: 0.8625 - val_loss: 26.1897 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 44/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 5s 668ms/step - loss: 0.6828 - accuracy: 0.9083 - val_loss: 29.0530 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 45/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 5s 679ms/step - loss: 0.7263 - accuracy: 0.8542 - val_loss: 12.8174 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 46/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 768ms/step - loss: 0.6868 - accuracy: 0.8750 - val_loss: 9.7347 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 47/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 709ms/step - loss: 0.6353 - accuracy: 0.9167 - val_loss: 14.1375 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 48/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 712ms/step - loss: 0.6588 - accuracy: 0.9083 - val_loss: 9.2467 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 49/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 748ms/step - loss: 0.7460 - accuracy: 0.8792 - val_loss: 17.2743 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 50/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 805ms/step - loss: 0.7722 - accuracy: 0.8875 - val_loss: 15.6511 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 51/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 746ms/step - loss: 0.7050 - accuracy: 0.8667 - val_loss: 15.2347 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 52/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 764ms/step - loss: 0.6431 - accuracy: 0.8958 - val_loss: 17.4646 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 53/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 770ms/step - loss: 0.6220 - accuracy: 0.9208 - val_loss: 18.9493 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 54/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 710ms/step - loss: 0.5937 - accuracy: 0.9292 - val_loss: 23.8980 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 55/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 727ms/step - loss: 0.6200 - accuracy: 0.9167 - val_loss: 30.4242 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 56/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 731ms/step - loss: 0.6311 - accuracy: 0.9000 - val_loss: 24.3167 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 57/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 7s 851ms/step - loss: 0.5731 - accuracy: 0.9375 - val_loss: 20.5875 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 58/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 761ms/step - loss: 0.6086 - accuracy: 0.9208 - val_loss: 22.4311 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 59/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 739ms/step - loss: 0.5896 - accuracy: 0.9250 - val_loss: 24.4286 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 60/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 738ms/step - loss: 0.6200 - accuracy: 0.9042 - val_loss: 18.7893 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 61/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 772ms/step - loss: 0.5938 - accuracy: 0.9000 - val_loss: 16.9887 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 62/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 786ms/step - loss: 0.5577 - accuracy: 0.9458 - val_loss: 15.4209 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 63/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 758ms/step - loss: 0.5565 - accuracy: 0.9208 - val_loss: 17.5181 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 64/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 7s 864ms/step - loss: 0.5321 - accuracy: 0.9417 - val_loss: 21.7121 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 65/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 7s 807ms/step - loss: 0.5226 - accuracy: 0.9333 - val_loss: 23.3946 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 66/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 776ms/step - loss: 0.5957 - accuracy: 0.8958 - val_loss: 22.3310 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 67/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 779ms/step - loss: 0.7033 - accuracy: 0.8583 - val_loss: 26.4019 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 68/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 7s 828ms/step - loss: 0.5760 - accuracy: 0.9292 - val_loss: 15.2324 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 69/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 7s 821ms/step - loss: 0.6457 - accuracy: 0.8958 - val_loss: 11.7532 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 70/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 7s 802ms/step - loss: 0.5296 - accuracy: 0.9417 - val_loss: 18.5749 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 71/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 7s 900ms/step - loss: 0.5647 - accuracy: 0.9292 - val_loss: 21.7748 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 72/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 773ms/step - loss: 0.5717 - accuracy: 0.9208 - val_loss: 23.8616 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 73/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 768ms/step - loss: 0.5210 - accuracy: 0.9417 - val_loss: 24.3228 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 74/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 832ms/step - loss: 0.5527 - accuracy: 0.9083 - val_loss: 31.1887 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 75/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 769ms/step - loss: 0.5339 - accuracy: 0.9333 - val_loss: 28.5933 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 76/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 808ms/step - loss: 0.5091 - accuracy: 0.9458 - val_loss: 25.9219 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 77/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 747ms/step - loss: 0.4847 - accuracy: 0.9583 - val_loss: 28.2704 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 78/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 758ms/step - loss: 0.6547 - accuracy: 0.8667 - val_loss: 31.6200 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 79/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 758ms/step - loss: 0.6130 - accuracy: 0.9000 - val_loss: 28.0946 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 80/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 817ms/step - loss: 0.5186 - accuracy: 0.9458 - val_loss: 19.4759 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 81/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 738ms/step - loss: 0.5072 - accuracy: 0.9417 - val_loss: 19.3978 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 82/100\n",
      "Learning rate:  0.0001\n",
      "8/8 [==============================] - 6s 743ms/step - loss: 0.4944 - accuracy: 0.9583 - val_loss: 19.9280 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 83/100\n",
      "Learning rate:  0.0001\n",
      "8/8 [==============================] - 6s 766ms/step - loss: 0.4915 - accuracy: 0.9542 - val_loss: 21.0660 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 84/100\n",
      "Learning rate:  0.0001\n",
      "8/8 [==============================] - 6s 740ms/step - loss: 0.4763 - accuracy: 0.9542 - val_loss: 21.9928 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 85/100\n",
      "Learning rate:  0.0001\n",
      "8/8 [==============================] - 6s 743ms/step - loss: 0.4816 - accuracy: 0.9542 - val_loss: 22.8582 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 86/100\n",
      "Learning rate:  0.0001\n",
      "8/8 [==============================] - 7s 849ms/step - loss: 0.4429 - accuracy: 0.9792 - val_loss: 23.4177 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 87/100\n",
      "Learning rate:  0.0001\n",
      "8/8 [==============================] - 7s 827ms/step - loss: 0.4935 - accuracy: 0.9542 - val_loss: 23.9216 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 88/100\n",
      "Learning rate:  0.0001\n",
      "8/8 [==============================] - 6s 721ms/step - loss: 0.4572 - accuracy: 0.9792 - val_loss: 23.9358 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 89/100\n",
      "Learning rate:  0.0001\n",
      "8/8 [==============================] - 6s 773ms/step - loss: 0.4767 - accuracy: 0.9583 - val_loss: 24.0364 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 90/100\n",
      "Learning rate:  0.0001\n",
      "8/8 [==============================] - 6s 784ms/step - loss: 0.4274 - accuracy: 0.9792 - val_loss: 24.3931 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 91/100\n",
      "Learning rate:  0.0001\n",
      "8/8 [==============================] - 6s 827ms/step - loss: 0.4499 - accuracy: 0.9708 - val_loss: 25.1256 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 92/100\n",
      "Learning rate:  0.0001\n",
      "8/8 [==============================] - 5s 659ms/step - loss: 0.4388 - accuracy: 0.9792 - val_loss: 25.4596 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 93/100\n",
      "Learning rate:  0.0001\n",
      "8/8 [==============================] - 5s 672ms/step - loss: 0.4245 - accuracy: 0.9792 - val_loss: 25.4901 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 94/100\n",
      "Learning rate:  0.0001\n",
      "8/8 [==============================] - 6s 771ms/step - loss: 0.4128 - accuracy: 0.9917 - val_loss: 25.4010 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 95/100\n",
      "Learning rate:  0.0001\n",
      "8/8 [==============================] - 6s 674ms/step - loss: 0.4109 - accuracy: 0.9833 - val_loss: 25.6981 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 96/100\n",
      "Learning rate:  0.0001\n",
      "8/8 [==============================] - 6s 778ms/step - loss: 0.4313 - accuracy: 0.9667 - val_loss: 26.4578 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 97/100\n",
      "Learning rate:  0.0001\n",
      "8/8 [==============================] - 7s 848ms/step - loss: 0.4102 - accuracy: 0.9875 - val_loss: 26.6990 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 98/100\n",
      "Learning rate:  0.0001\n",
      "8/8 [==============================] - 7s 912ms/step - loss: 0.4146 - accuracy: 0.9792 - val_loss: 26.4521 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 99/100\n",
      "Learning rate:  0.0001\n",
      "8/8 [==============================] - 6s 684ms/step - loss: 0.4130 - accuracy: 0.9708 - val_loss: 26.3346 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 100/100\n",
      "Learning rate:  0.0001\n",
      "8/8 [==============================] - 5s 654ms/step - loss: 0.4237 - accuracy: 0.9833 - val_loss: 26.9008 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1/1 [==============================] - 0s 158ms/step - loss: 0.5366 - accuracy: 0.9333\n",
      "Test loss: 0.5366125106811523\n",
      "Test accuracy: 0.9333333373069763\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 2, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Precision:  1.0\n",
      "Recall:  0.9333333333333333\n",
      "F1 Score:  0.9650000000000001\n",
      "[[[[  5   5   5]\n",
      "   [ 21  21  21]\n",
      "   [ 13  13  13]\n",
      "   ...\n",
      "   [  7   7   7]\n",
      "   [  5   5   5]\n",
      "   [  2   2   2]]\n",
      "\n",
      "  [[ 23  23  23]\n",
      "   [ 14  14  14]\n",
      "   [  9   9   9]\n",
      "   ...\n",
      "   [  1   1   1]\n",
      "   [  0   0   0]\n",
      "   [  0   0   0]]\n",
      "\n",
      "  [[ 23  23  23]\n",
      "   [ 14  14  14]\n",
      "   [  9   9   9]\n",
      "   ...\n",
      "   [  0   0   0]\n",
      "   [  0   0   0]\n",
      "   [  0   0   0]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[ 29  29  29]\n",
      "   [ 17  17  17]\n",
      "   [ 10  10  10]\n",
      "   ...\n",
      "   [  0   0   0]\n",
      "   [  0   0   0]\n",
      "   [  0   0   0]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [ 17  17  17]\n",
      "   [ 12  12  12]\n",
      "   ...\n",
      "   [  0   0   0]\n",
      "   [  0   0   0]\n",
      "   [  0   0   0]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [ 14  14  14]\n",
      "   ...\n",
      "   [  7   7   7]\n",
      "   [  6   6   6]\n",
      "   [  6   6   6]]]\n",
      "\n",
      "\n",
      " [[[108 108 108]\n",
      "   [117 117 117]\n",
      "   [116 116 116]\n",
      "   ...\n",
      "   [  1   1   1]\n",
      "   [  1   1   1]\n",
      "   [  1   1   1]]\n",
      "\n",
      "  [[112 112 112]\n",
      "   [108 108 108]\n",
      "   [115 115 115]\n",
      "   ...\n",
      "   [  1   1   1]\n",
      "   [  1   1   1]\n",
      "   [  1   1   1]]\n",
      "\n",
      "  [[117 117 117]\n",
      "   [112 112 112]\n",
      "   [110 110 110]\n",
      "   ...\n",
      "   [  1   1   1]\n",
      "   [  1   1   1]\n",
      "   [  1   1   1]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[ 25  25  25]\n",
      "   [ 17  17  17]\n",
      "   [ 10  10  10]\n",
      "   ...\n",
      "   [  0   0   0]\n",
      "   [  0   0   0]\n",
      "   [  0   0   0]]\n",
      "\n",
      "  [[ 24  24  24]\n",
      "   [ 18  18  18]\n",
      "   [ 11  11  11]\n",
      "   ...\n",
      "   [  0   0   0]\n",
      "   [  0   0   0]\n",
      "   [  0   0   0]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [ 19  19  19]\n",
      "   [ 19  19  19]\n",
      "   ...\n",
      "   [  6   6   6]\n",
      "   [  6   6   6]\n",
      "   [  6   6   6]]]\n",
      "\n",
      "\n",
      " [[[  1   1   1]\n",
      "   [  7   7   7]\n",
      "   [  4   4   4]\n",
      "   ...\n",
      "   [  0   0   0]\n",
      "   [  0   0   0]\n",
      "   [  0   0   0]]\n",
      "\n",
      "  [[ 21  21  21]\n",
      "   [ 15  15  15]\n",
      "   [ 11  11  11]\n",
      "   ...\n",
      "   [  4   4   4]\n",
      "   [  7   7   7]\n",
      "   [ 12  12  12]]\n",
      "\n",
      "  [[ 19  19  19]\n",
      "   [ 15  15  15]\n",
      "   [ 11  11  11]\n",
      "   ...\n",
      "   [  4   4   4]\n",
      "   [  6   6   6]\n",
      "   [ 11  11  11]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[ 28  28  28]\n",
      "   [ 19  19  19]\n",
      "   [ 10  10  10]\n",
      "   ...\n",
      "   [  0   0   0]\n",
      "   [  0   0   0]\n",
      "   [  1   1   1]]\n",
      "\n",
      "  [[ 22  22  22]\n",
      "   [ 14  14  14]\n",
      "   [ 10  10  10]\n",
      "   ...\n",
      "   [  0   0   0]\n",
      "   [  0   0   0]\n",
      "   [  1   1   1]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [ 35  35  35]\n",
      "   [ 23  23  23]\n",
      "   ...\n",
      "   [  0   0   0]\n",
      "   [  0   0   0]\n",
      "   [  0   0   0]]]]\n",
      "[[1]\n",
      " [1]\n",
      " [1]]\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "(40, 30, 3)\n",
      "x_train shape: (240, 40, 30, 3)\n",
      "240 train samples\n",
      "30 test samples\n",
      "y_train shape: (240, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\patcas rares\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate:  0.001\n",
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_4 (InputLayer)            [(None, 40, 30, 3)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_93 (Conv2D)              (None, 40, 30, 16)   448         input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_84 (BatchNo (None, 40, 30, 16)   64          conv2d_93[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_84 (Activation)      (None, 40, 30, 16)   0           batch_normalization_84[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_94 (Conv2D)              (None, 40, 30, 16)   272         activation_84[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_85 (BatchNo (None, 40, 30, 16)   64          conv2d_94[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_85 (Activation)      (None, 40, 30, 16)   0           batch_normalization_85[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_95 (Conv2D)              (None, 40, 30, 16)   2320        activation_85[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_86 (BatchNo (None, 40, 30, 16)   64          conv2d_95[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_86 (Activation)      (None, 40, 30, 16)   0           batch_normalization_86[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_97 (Conv2D)              (None, 40, 30, 64)   1088        activation_84[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_96 (Conv2D)              (None, 40, 30, 64)   1088        activation_86[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_27 (Add)                    (None, 40, 30, 64)   0           conv2d_97[0][0]                  \n",
      "                                                                 conv2d_96[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_87 (BatchNo (None, 40, 30, 64)   256         add_27[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_87 (Activation)      (None, 40, 30, 64)   0           batch_normalization_87[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_98 (Conv2D)              (None, 40, 30, 16)   1040        activation_87[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_88 (BatchNo (None, 40, 30, 16)   64          conv2d_98[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_88 (Activation)      (None, 40, 30, 16)   0           batch_normalization_88[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_99 (Conv2D)              (None, 40, 30, 16)   2320        activation_88[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_89 (BatchNo (None, 40, 30, 16)   64          conv2d_99[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_89 (Activation)      (None, 40, 30, 16)   0           batch_normalization_89[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_100 (Conv2D)             (None, 40, 30, 64)   1088        activation_89[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_28 (Add)                    (None, 40, 30, 64)   0           add_27[0][0]                     \n",
      "                                                                 conv2d_100[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_90 (BatchNo (None, 40, 30, 64)   256         add_28[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_90 (Activation)      (None, 40, 30, 64)   0           batch_normalization_90[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_101 (Conv2D)             (None, 40, 30, 16)   1040        activation_90[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_91 (BatchNo (None, 40, 30, 16)   64          conv2d_101[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_91 (Activation)      (None, 40, 30, 16)   0           batch_normalization_91[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_102 (Conv2D)             (None, 40, 30, 16)   2320        activation_91[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_92 (BatchNo (None, 40, 30, 16)   64          conv2d_102[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_92 (Activation)      (None, 40, 30, 16)   0           batch_normalization_92[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_103 (Conv2D)             (None, 40, 30, 64)   1088        activation_92[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_29 (Add)                    (None, 40, 30, 64)   0           add_28[0][0]                     \n",
      "                                                                 conv2d_103[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_93 (BatchNo (None, 40, 30, 64)   256         add_29[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_93 (Activation)      (None, 40, 30, 64)   0           batch_normalization_93[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_104 (Conv2D)             (None, 20, 15, 64)   4160        activation_93[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_94 (BatchNo (None, 20, 15, 64)   256         conv2d_104[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_94 (Activation)      (None, 20, 15, 64)   0           batch_normalization_94[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_105 (Conv2D)             (None, 20, 15, 64)   36928       activation_94[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_95 (BatchNo (None, 20, 15, 64)   256         conv2d_105[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_95 (Activation)      (None, 20, 15, 64)   0           batch_normalization_95[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_107 (Conv2D)             (None, 20, 15, 128)  8320        add_29[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_106 (Conv2D)             (None, 20, 15, 128)  8320        activation_95[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_30 (Add)                    (None, 20, 15, 128)  0           conv2d_107[0][0]                 \n",
      "                                                                 conv2d_106[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_96 (BatchNo (None, 20, 15, 128)  512         add_30[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_96 (Activation)      (None, 20, 15, 128)  0           batch_normalization_96[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_108 (Conv2D)             (None, 20, 15, 64)   8256        activation_96[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_97 (BatchNo (None, 20, 15, 64)   256         conv2d_108[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_97 (Activation)      (None, 20, 15, 64)   0           batch_normalization_97[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_109 (Conv2D)             (None, 20, 15, 64)   36928       activation_97[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_98 (BatchNo (None, 20, 15, 64)   256         conv2d_109[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_98 (Activation)      (None, 20, 15, 64)   0           batch_normalization_98[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_110 (Conv2D)             (None, 20, 15, 128)  8320        activation_98[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_31 (Add)                    (None, 20, 15, 128)  0           add_30[0][0]                     \n",
      "                                                                 conv2d_110[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_99 (BatchNo (None, 20, 15, 128)  512         add_31[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_99 (Activation)      (None, 20, 15, 128)  0           batch_normalization_99[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_111 (Conv2D)             (None, 20, 15, 64)   8256        activation_99[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_100 (BatchN (None, 20, 15, 64)   256         conv2d_111[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_100 (Activation)     (None, 20, 15, 64)   0           batch_normalization_100[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_112 (Conv2D)             (None, 20, 15, 64)   36928       activation_100[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_101 (BatchN (None, 20, 15, 64)   256         conv2d_112[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_101 (Activation)     (None, 20, 15, 64)   0           batch_normalization_101[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_113 (Conv2D)             (None, 20, 15, 128)  8320        activation_101[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_32 (Add)                    (None, 20, 15, 128)  0           add_31[0][0]                     \n",
      "                                                                 conv2d_113[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_102 (BatchN (None, 20, 15, 128)  512         add_32[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_102 (Activation)     (None, 20, 15, 128)  0           batch_normalization_102[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_114 (Conv2D)             (None, 10, 8, 128)   16512       activation_102[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_103 (BatchN (None, 10, 8, 128)   512         conv2d_114[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_103 (Activation)     (None, 10, 8, 128)   0           batch_normalization_103[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_115 (Conv2D)             (None, 10, 8, 128)   147584      activation_103[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_104 (BatchN (None, 10, 8, 128)   512         conv2d_115[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_104 (Activation)     (None, 10, 8, 128)   0           batch_normalization_104[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_117 (Conv2D)             (None, 10, 8, 256)   33024       add_32[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_116 (Conv2D)             (None, 10, 8, 256)   33024       activation_104[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_33 (Add)                    (None, 10, 8, 256)   0           conv2d_117[0][0]                 \n",
      "                                                                 conv2d_116[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_105 (BatchN (None, 10, 8, 256)   1024        add_33[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_105 (Activation)     (None, 10, 8, 256)   0           batch_normalization_105[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_118 (Conv2D)             (None, 10, 8, 128)   32896       activation_105[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_106 (BatchN (None, 10, 8, 128)   512         conv2d_118[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_106 (Activation)     (None, 10, 8, 128)   0           batch_normalization_106[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_119 (Conv2D)             (None, 10, 8, 128)   147584      activation_106[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_107 (BatchN (None, 10, 8, 128)   512         conv2d_119[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_107 (Activation)     (None, 10, 8, 128)   0           batch_normalization_107[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_120 (Conv2D)             (None, 10, 8, 256)   33024       activation_107[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_34 (Add)                    (None, 10, 8, 256)   0           add_33[0][0]                     \n",
      "                                                                 conv2d_120[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_108 (BatchN (None, 10, 8, 256)   1024        add_34[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_108 (Activation)     (None, 10, 8, 256)   0           batch_normalization_108[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_121 (Conv2D)             (None, 10, 8, 128)   32896       activation_108[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_109 (BatchN (None, 10, 8, 128)   512         conv2d_121[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_109 (Activation)     (None, 10, 8, 128)   0           batch_normalization_109[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_122 (Conv2D)             (None, 10, 8, 128)   147584      activation_109[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_110 (BatchN (None, 10, 8, 128)   512         conv2d_122[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_110 (Activation)     (None, 10, 8, 128)   0           batch_normalization_110[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_123 (Conv2D)             (None, 10, 8, 256)   33024       activation_110[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_35 (Add)                    (None, 10, 8, 256)   0           add_34[0][0]                     \n",
      "                                                                 conv2d_123[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_111 (BatchN (None, 10, 8, 256)   1024        add_35[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_111 (Activation)     (None, 10, 8, 256)   0           batch_normalization_111[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_3 (AveragePoo (None, 1, 1, 256)    0           activation_111[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "flatten_3 (Flatten)             (None, 256)          0           average_pooling2d_3[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 10)           2570        flatten_3[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 849,002\n",
      "Trainable params: 843,786\n",
      "Non-trainable params: 5,216\n",
      "__________________________________________________________________________________________________\n",
      "ResNet  29v  2\n",
      "Using real-time data augmentation.\n",
      "------------------\n",
      "[[[[-0.12797378 -0.12797378 -0.12797378]\n",
      "   [-0.07181362 -0.07181362 -0.07181362]\n",
      "   [-0.09660119 -0.09660119 -0.09660119]\n",
      "   ...\n",
      "   [-0.15766343 -0.15766343 -0.15766343]\n",
      "   [-0.16872549 -0.16872549 -0.16872549]\n",
      "   [-0.18624182 -0.18624182 -0.18624182]]\n",
      "\n",
      "  [[-0.05382348 -0.05382348 -0.05382348]\n",
      "   [-0.07807182 -0.07807182 -0.07807182]\n",
      "   [-0.09416653 -0.09416653 -0.09416653]\n",
      "   ...\n",
      "   [-0.14070256 -0.14070256 -0.14070256]\n",
      "   [-0.14310457 -0.14310457 -0.14310457]\n",
      "   [-0.16245095 -0.16245095 -0.16245095]]\n",
      "\n",
      "  [[-0.06132347 -0.06132347 -0.06132347]\n",
      "   [-0.08362736 -0.08362736 -0.08362736]\n",
      "   [-0.09781037 -0.09781037 -0.09781037]\n",
      "   ...\n",
      "   [-0.15173201 -0.15173201 -0.15173201]\n",
      "   [-0.15665035 -0.15665035 -0.15665035]\n",
      "   [-0.16328427 -0.16328427 -0.16328427]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[-0.00287583 -0.00287583 -0.00287583]\n",
      "   [-0.03184628 -0.03184628 -0.03184628]\n",
      "   [-0.04276132 -0.04276132 -0.04276132]\n",
      "   ...\n",
      "   [-0.0740359  -0.0740359  -0.0740359 ]\n",
      "   [-0.0861601  -0.0861601  -0.0861601 ]\n",
      "   [-0.10428107 -0.10428107 -0.10428107]]\n",
      "\n",
      "  [[ 0.39039215  0.39039215  0.39039215]\n",
      "   [-0.02797373 -0.02797373 -0.02797373]\n",
      "   [-0.03426458 -0.03426458 -0.03426458]\n",
      "   ...\n",
      "   [-0.07967315 -0.07967315 -0.07967315]\n",
      "   [-0.08691172 -0.08691172 -0.08691172]\n",
      "   [-0.11282683 -0.11282683 -0.11282683]]\n",
      "\n",
      "  [[ 0.2790197   0.2790197   0.2790197 ]\n",
      "   [ 0.31733674  0.31733674  0.31733674]\n",
      "   [-0.11248353 -0.11248353 -0.11248353]\n",
      "   ...\n",
      "   [-0.13571893 -0.13571893 -0.13571893]\n",
      "   [-0.1560294  -0.1560294  -0.1560294 ]\n",
      "   [-0.18316986 -0.18316986 -0.18316986]]]\n",
      "\n",
      "\n",
      " [[[ 0.2759478   0.2759478   0.2759478 ]\n",
      "   [ 0.30465698  0.30465698  0.30465698]\n",
      "   [ 0.3073204   0.3073204   0.3073204 ]\n",
      "   ...\n",
      "   [-0.18119285 -0.18119285 -0.18119285]\n",
      "   [-0.18441176 -0.18441176 -0.18441176]\n",
      "   [-0.19016339 -0.19016339 -0.19016339]]\n",
      "\n",
      "  [[ 0.29519612  0.29519612  0.29519612]\n",
      "   [ 0.29055566  0.29055566  0.29055566]\n",
      "   [ 0.32151973  0.32151973  0.32151973]\n",
      "   ...\n",
      "   [-0.14070256 -0.14070256 -0.14070256]\n",
      "   [-0.139183   -0.139183   -0.139183  ]\n",
      "   [-0.15852939 -0.15852939 -0.15852939]]\n",
      "\n",
      "  [[ 0.30730397  0.30730397  0.30730397]\n",
      "   [ 0.30068636  0.30068636  0.30068636]\n",
      "   [ 0.29826808  0.29826808  0.29826808]\n",
      "   ...\n",
      "   [-0.14781044 -0.14781044 -0.14781044]\n",
      "   [-0.15272878 -0.15272878 -0.15272878]\n",
      "   [-0.1593627  -0.1593627  -0.1593627 ]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[-0.0185621  -0.0185621  -0.0185621 ]\n",
      "   [-0.03184628 -0.03184628 -0.03184628]\n",
      "   [-0.04276132 -0.04276132 -0.04276132]\n",
      "   ...\n",
      "   [-0.0740359  -0.0740359  -0.0740359 ]\n",
      "   [-0.0861601  -0.0861601  -0.0861601 ]\n",
      "   [-0.10428107 -0.10428107 -0.10428107]]\n",
      "\n",
      "  [[-0.01745101 -0.01745101 -0.01745101]\n",
      "   [-0.02405217 -0.02405217 -0.02405217]\n",
      "   [-0.03818614 -0.03818614 -0.03818614]\n",
      "   ...\n",
      "   [-0.07967315 -0.07967315 -0.07967315]\n",
      "   [-0.08691172 -0.08691172 -0.08691172]\n",
      "   [-0.11282683 -0.11282683 -0.11282683]]\n",
      "\n",
      "  [[ 0.2790197   0.2790197   0.2790197 ]\n",
      "   [-0.11011428 -0.11011428 -0.11011428]\n",
      "   [-0.09287568 -0.09287568 -0.09287568]\n",
      "   ...\n",
      "   [-0.1396405  -0.1396405  -0.1396405 ]\n",
      "   [-0.1560294  -0.1560294  -0.1560294 ]\n",
      "   [-0.18316986 -0.18316986 -0.18316986]]]\n",
      "\n",
      "\n",
      " [[[-0.14366005 -0.14366005 -0.14366005]\n",
      "   [-0.12671559 -0.12671559 -0.12671559]\n",
      "   [-0.1318953  -0.1318953  -0.1318953 ]\n",
      "   ...\n",
      "   [-0.18511441 -0.18511441 -0.18511441]\n",
      "   [-0.18833333 -0.18833333 -0.18833333]\n",
      "   [-0.19408496 -0.19408496 -0.19408496]]\n",
      "\n",
      "  [[-0.06166662 -0.06166662 -0.06166662]\n",
      "   [-0.07415025 -0.07415025 -0.07415025]\n",
      "   [-0.0863234  -0.0863234  -0.0863234 ]\n",
      "   ...\n",
      "   [-0.12893786 -0.12893786 -0.12893786]\n",
      "   [-0.11565359 -0.11565359 -0.11565359]\n",
      "   [-0.11539213 -0.11539213 -0.11539213]]\n",
      "\n",
      "  [[-0.07700974 -0.07700974 -0.07700974]\n",
      "   [-0.07970579 -0.07970579 -0.07970579]\n",
      "   [-0.08996724 -0.08996724 -0.08996724]\n",
      "   ...\n",
      "   [-0.13604574 -0.13604574 -0.13604574]\n",
      "   [-0.13312094 -0.13312094 -0.13312094]\n",
      "   [-0.12014702 -0.12014702 -0.12014702]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[-0.0067974  -0.0067974  -0.0067974 ]\n",
      "   [-0.02400315 -0.02400315 -0.02400315]\n",
      "   [-0.04276132 -0.04276132 -0.04276132]\n",
      "   ...\n",
      "   [-0.0740359  -0.0740359  -0.0740359 ]\n",
      "   [-0.0861601  -0.0861601  -0.0861601 ]\n",
      "   [-0.1003595  -0.1003595  -0.1003595 ]]\n",
      "\n",
      "  [[-0.02529415 -0.02529415 -0.02529415]\n",
      "   [-0.03973844 -0.03973844 -0.03973844]\n",
      "   [-0.04210771 -0.04210771 -0.04210771]\n",
      "   ...\n",
      "   [-0.07967315 -0.07967315 -0.07967315]\n",
      "   [-0.08691172 -0.08691172 -0.08691172]\n",
      "   [-0.10890526 -0.10890526 -0.10890526]]\n",
      "\n",
      "  [[ 0.2790197   0.2790197   0.2790197 ]\n",
      "   [-0.04736918 -0.04736918 -0.04736918]\n",
      "   [-0.07718941 -0.07718941 -0.07718941]\n",
      "   ...\n",
      "   [-0.1631699  -0.1631699  -0.1631699 ]\n",
      "   [-0.17955881 -0.17955881 -0.17955881]\n",
      "   [-0.20669927 -0.20669927 -0.20669927]]]\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      " [[[-0.08091495 -0.08091495 -0.08091495]\n",
      "   [ 0.34779423  0.34779423  0.34779423]\n",
      "   [-0.14758158 -0.14758158 -0.14758158]\n",
      "   ...\n",
      "   [ 0.3168464   0.3168464   0.3168464 ]\n",
      "   [ 0.31362748  0.31362748  0.31362748]\n",
      "   [ 0.30787587  0.30787587  0.30787587]]\n",
      "\n",
      "  [[-0.06558818 -0.06558818 -0.06558818]\n",
      "   [-0.09375809 -0.09375809 -0.09375809]\n",
      "   [-0.10200967 -0.10200967 -0.10200967]\n",
      "   ...\n",
      "   [ 0.25929743  0.25929743  0.25929743]\n",
      "   [ 0.3078758   0.3078758   0.3078758 ]\n",
      "   [ 0.319902    0.319902    0.319902  ]]\n",
      "\n",
      "  [[-0.07308818 -0.07308818 -0.07308818]\n",
      "   [-0.09147049 -0.09147049 -0.09147049]\n",
      "   [-0.10173194 -0.10173194 -0.10173194]\n",
      "   ...\n",
      "   [ 0.25611115  0.25611115  0.25611115]\n",
      "   [ 0.27472222  0.27472222  0.27472222]\n",
      "   [ 0.279853    0.279853    0.279853  ]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[-0.07738563 -0.07738563 -0.07738563]\n",
      "   [-0.07106198 -0.07106198 -0.07106198]\n",
      "   [-0.0584476  -0.0584476  -0.0584476 ]\n",
      "   ...\n",
      "   [ 0.18478765  0.18478765  0.18478765]\n",
      "   [-0.01557186 -0.01557186 -0.01557186]\n",
      "   [ 0.01336599  0.01336599  0.01336599]]\n",
      "\n",
      "  [[-0.06843141 -0.06843141 -0.06843141]\n",
      "   [-0.06718943 -0.06718943 -0.06718943]\n",
      "   [-0.05779399 -0.05779399 -0.05779399]\n",
      "   ...\n",
      "   [-0.05614374 -0.05614374 -0.05614374]\n",
      "   [-0.0398529  -0.0398529  -0.0398529 ]\n",
      "   [ 0.00089866  0.00089866  0.00089866]]\n",
      "\n",
      "  [[-0.17980385 -0.17980385 -0.17980385]\n",
      "   [-0.15717311 -0.15717311 -0.15717311]\n",
      "   [-0.14777765 -0.14777765 -0.14777765]\n",
      "   ...\n",
      "   [-0.1396405  -0.1396405  -0.1396405 ]\n",
      "   [-0.12465686 -0.12465686 -0.12465686]\n",
      "   [-0.11258162 -0.11258162 -0.11258162]]]\n",
      "\n",
      "\n",
      " [[[-0.0377777  -0.0377777  -0.0377777 ]\n",
      "   [-0.06397048 -0.06397048 -0.06397048]\n",
      "   [-0.07699334 -0.07699334 -0.07699334]\n",
      "   ...\n",
      "   [-0.18511441 -0.18511441 -0.18511441]\n",
      "   [-0.18833333 -0.18833333 -0.18833333]\n",
      "   [-0.19016339 -0.19016339 -0.19016339]]\n",
      "\n",
      "  [[-0.04205877 -0.04205877 -0.04205877]\n",
      "   [-0.03885613 -0.03885613 -0.03885613]\n",
      "   [-0.05887241 -0.05887241 -0.05887241]\n",
      "   ...\n",
      "   [-0.14462413 -0.14462413 -0.14462413]\n",
      "   [-0.14310457 -0.14310457 -0.14310457]\n",
      "   [-0.15852939 -0.15852939 -0.15852939]]\n",
      "\n",
      "  [[-0.06132347 -0.06132347 -0.06132347]\n",
      "   [-0.03264696 -0.03264696 -0.03264696]\n",
      "   [-0.06251625 -0.06251625 -0.06251625]\n",
      "   ...\n",
      "   [-0.15173201 -0.15173201 -0.15173201]\n",
      "   [-0.15665035 -0.15665035 -0.15665035]\n",
      "   [-0.16328427 -0.16328427 -0.16328427]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[ 0.01281045  0.01281045  0.01281045]\n",
      "   [-0.00439531 -0.00439531 -0.00439531]\n",
      "   [-0.01138877 -0.01138877 -0.01138877]\n",
      "   ...\n",
      "   [-0.0740359  -0.0740359  -0.0740359 ]\n",
      "   [-0.0861601  -0.0861601  -0.0861601 ]\n",
      "   [-0.10428107 -0.10428107 -0.10428107]]\n",
      "\n",
      "  [[ 0.01784311  0.01784311  0.01784311]\n",
      "   [-0.00444432 -0.00444432 -0.00444432]\n",
      "   [-0.01465673 -0.01465673 -0.01465673]\n",
      "   ...\n",
      "   [-0.07967315 -0.07967315 -0.07967315]\n",
      "   [-0.08691172 -0.08691172 -0.08691172]\n",
      "   [-0.11282683 -0.11282683 -0.11282683]]\n",
      "\n",
      "  [[-0.11705875 -0.11705875 -0.11705875]\n",
      "   [-0.09050644 -0.09050644 -0.09050644]\n",
      "   [-0.09679725 -0.09679725 -0.09679725]\n",
      "   ...\n",
      "   [-0.1631699  -0.1631699  -0.1631699 ]\n",
      "   [-0.17955881 -0.17955881 -0.17955881]\n",
      "   [-0.20669927 -0.20669927 -0.20669927]]]\n",
      "\n",
      "\n",
      " [[[ 0.29163408  0.29163408  0.29163408]\n",
      "   [ 0.31250012  0.31250012  0.31250012]\n",
      "   [ 0.2916341   0.2916341   0.2916341 ]\n",
      "   ...\n",
      "   [-0.18511441 -0.18511441 -0.18511441]\n",
      "   [-0.18833333 -0.18833333 -0.18833333]\n",
      "   [-0.19408496 -0.19408496 -0.19408496]]\n",
      "\n",
      "  [[ 0.32656866  0.32656866  0.32656866]\n",
      "   [ 0.35330075  0.35330075  0.35330075]\n",
      "   [ 0.29406875  0.29406875  0.29406875]\n",
      "   ...\n",
      "   [-0.14462413 -0.14462413 -0.14462413]\n",
      "   [-0.14310457 -0.14310457 -0.14310457]\n",
      "   [-0.16245095 -0.16245095 -0.16245095]]\n",
      "\n",
      "  [[ 0.28377455  0.28377455  0.28377455]\n",
      "   [ 0.28892165  0.28892165  0.28892165]\n",
      "   [ 0.2825818   0.2825818   0.2825818 ]\n",
      "   ...\n",
      "   [-0.15173201 -0.15173201 -0.15173201]\n",
      "   [-0.15665035 -0.15665035 -0.15665035]\n",
      "   [-0.16328427 -0.16328427 -0.16328427]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[ 0.01281045  0.01281045  0.01281045]\n",
      "   [-0.02400315 -0.02400315 -0.02400315]\n",
      "   [-0.03491819 -0.03491819 -0.03491819]\n",
      "   ...\n",
      "   [-0.0740359  -0.0740359  -0.0740359 ]\n",
      "   [-0.0861601  -0.0861601  -0.0861601 ]\n",
      "   [-0.10428107 -0.10428107 -0.10428107]]\n",
      "\n",
      "  [[ 0.01784311  0.01784311  0.01784311]\n",
      "   [-0.0201306  -0.0201306  -0.0201306 ]\n",
      "   [-0.03034301 -0.03034301 -0.03034301]\n",
      "   ...\n",
      "   [-0.07967315 -0.07967315 -0.07967315]\n",
      "   [-0.08691172 -0.08691172 -0.08691172]\n",
      "   [-0.11282683 -0.11282683 -0.11282683]]\n",
      "\n",
      "  [[-0.09352933 -0.09352933 -0.09352933]\n",
      "   [-0.11011428 -0.11011428 -0.11011428]\n",
      "   [-0.11248353 -0.11248353 -0.11248353]\n",
      "   ...\n",
      "   [-0.1631699  -0.1631699  -0.1631699 ]\n",
      "   [-0.17955881 -0.17955881 -0.17955881]\n",
      "   [-0.20669927 -0.20669927 -0.20669927]]]]\n",
      "Epoch 1/100\n",
      "Learning rate:  0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\patcas rares\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\keras\\engine\\training.py:1972: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 11s 763ms/step - loss: 2.4000 - accuracy: 0.4125 - val_loss: 2.7979 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 2/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 678ms/step - loss: 1.4412 - accuracy: 0.6667 - val_loss: 2.5438 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 3/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 715ms/step - loss: 1.1919 - accuracy: 0.6833 - val_loss: 2.5925 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 4/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 5s 617ms/step - loss: 1.1321 - accuracy: 0.7458 - val_loss: 2.7518 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 5/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 5s 617ms/step - loss: 1.1400 - accuracy: 0.7167 - val_loss: 2.4173 - val_accuracy: 0.7000\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 6/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 784ms/step - loss: 1.1051 - accuracy: 0.7458 - val_loss: 2.7038 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 7/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 5s 646ms/step - loss: 1.0829 - accuracy: 0.7417 - val_loss: 3.5695 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 8/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 5s 656ms/step - loss: 1.0363 - accuracy: 0.7292 - val_loss: 2.6876 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 9/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 5s 672ms/step - loss: 1.0625 - accuracy: 0.7583 - val_loss: 2.0940 - val_accuracy: 0.7000\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 10/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 777ms/step - loss: 1.0221 - accuracy: 0.7792 - val_loss: 5.0472 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 11/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 801ms/step - loss: 1.0284 - accuracy: 0.7583 - val_loss: 5.7320 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 12/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 782ms/step - loss: 1.0237 - accuracy: 0.7542 - val_loss: 2.0275 - val_accuracy: 0.7000\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 13/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 818ms/step - loss: 0.9770 - accuracy: 0.8083 - val_loss: 4.5928 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 14/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 727ms/step - loss: 0.9943 - accuracy: 0.7958 - val_loss: 4.9590 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 15/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 820ms/step - loss: 1.0053 - accuracy: 0.7875 - val_loss: 5.4823 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 16/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 663ms/step - loss: 0.9147 - accuracy: 0.8042 - val_loss: 5.7384 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 17/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 5s 679ms/step - loss: 0.9398 - accuracy: 0.7583 - val_loss: 5.9256 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 18/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 5s 664ms/step - loss: 0.8966 - accuracy: 0.8125 - val_loss: 5.8969 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 19/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 5s 659ms/step - loss: 0.9517 - accuracy: 0.7875 - val_loss: 6.4050 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 20/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 684ms/step - loss: 0.9179 - accuracy: 0.8083 - val_loss: 7.3361 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 21/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 5s 672ms/step - loss: 0.8937 - accuracy: 0.8625 - val_loss: 8.0814 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 22/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 5s 658ms/step - loss: 0.8824 - accuracy: 0.7792 - val_loss: 9.0002 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 23/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 5s 666ms/step - loss: 0.8832 - accuracy: 0.8042 - val_loss: 9.3392 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 24/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 672ms/step - loss: 0.8992 - accuracy: 0.7750 - val_loss: 10.5037 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 25/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 5s 659ms/step - loss: 0.8915 - accuracy: 0.8125 - val_loss: 9.9461 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 26/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 5s 667ms/step - loss: 0.8372 - accuracy: 0.8333 - val_loss: 11.0538 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 27/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 5s 656ms/step - loss: 0.8399 - accuracy: 0.8167 - val_loss: 13.1282 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 28/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 5s 665ms/step - loss: 0.8819 - accuracy: 0.8000 - val_loss: 13.1484 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 29/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 678ms/step - loss: 0.7866 - accuracy: 0.8500 - val_loss: 13.6136 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 30/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 5s 657ms/step - loss: 0.7953 - accuracy: 0.8500 - val_loss: 14.5813 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 31/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 5s 670ms/step - loss: 0.7583 - accuracy: 0.8625 - val_loss: 15.5582 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 32/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 5s 727ms/step - loss: 0.8560 - accuracy: 0.8125 - val_loss: 15.6620 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 33/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 5s 705ms/step - loss: 0.8268 - accuracy: 0.8125 - val_loss: 11.5151 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 34/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 5s 674ms/step - loss: 0.7871 - accuracy: 0.8292 - val_loss: 12.2509 - val_accuracy: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 35/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 5s 667ms/step - loss: 0.7551 - accuracy: 0.8500 - val_loss: 15.4557 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 36/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 5s 659ms/step - loss: 0.7874 - accuracy: 0.8375 - val_loss: 16.8421 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 37/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 5s 657ms/step - loss: 0.8027 - accuracy: 0.8375 - val_loss: 12.7408 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 38/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 5s 660ms/step - loss: 0.7681 - accuracy: 0.8625 - val_loss: 13.3012 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 39/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 5s 719ms/step - loss: 0.7967 - accuracy: 0.8167 - val_loss: 9.4915 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 40/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 5s 660ms/step - loss: 0.7510 - accuracy: 0.8625 - val_loss: 10.3171 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 41/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 5s 662ms/step - loss: 0.7213 - accuracy: 0.8625 - val_loss: 10.8760 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 42/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 5s 666ms/step - loss: 0.7093 - accuracy: 0.9000 - val_loss: 13.8411 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 43/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 5s 708ms/step - loss: 0.7262 - accuracy: 0.8792 - val_loss: 13.9026 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 44/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 5s 676ms/step - loss: 0.6930 - accuracy: 0.8708 - val_loss: 13.6513 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 45/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 5s 671ms/step - loss: 0.7206 - accuracy: 0.8708 - val_loss: 16.7172 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 46/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 5s 671ms/step - loss: 0.7056 - accuracy: 0.8750 - val_loss: 16.9072 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 47/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 5s 656ms/step - loss: 0.6924 - accuracy: 0.8625 - val_loss: 19.9995 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 48/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 5s 660ms/step - loss: 0.7645 - accuracy: 0.8208 - val_loss: 15.5567 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 49/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 673ms/step - loss: 0.6948 - accuracy: 0.8583 - val_loss: 14.3562 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 50/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 5s 673ms/step - loss: 0.6618 - accuracy: 0.9042 - val_loss: 14.6639 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 51/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 5s 707ms/step - loss: 0.6371 - accuracy: 0.8917 - val_loss: 15.3377 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 52/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 5s 661ms/step - loss: 0.6298 - accuracy: 0.9292 - val_loss: 17.2081 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 53/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 5s 710ms/step - loss: 0.6078 - accuracy: 0.9167 - val_loss: 15.1480 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 54/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 5s 672ms/step - loss: 0.6336 - accuracy: 0.9000 - val_loss: 19.0186 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 55/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 5s 659ms/step - loss: 0.6644 - accuracy: 0.8708 - val_loss: 17.6218 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 56/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 689ms/step - loss: 0.6568 - accuracy: 0.8958 - val_loss: 19.4204 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 57/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 676ms/step - loss: 0.6741 - accuracy: 0.8875 - val_loss: 14.1015 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 58/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 5s 668ms/step - loss: 0.6694 - accuracy: 0.8667 - val_loss: 11.8713 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 59/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 692ms/step - loss: 0.6730 - accuracy: 0.8667 - val_loss: 11.2679 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 60/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 693ms/step - loss: 0.6158 - accuracy: 0.9208 - val_loss: 12.0406 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 61/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 5s 661ms/step - loss: 0.5980 - accuracy: 0.9042 - val_loss: 11.4627 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 62/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 690ms/step - loss: 0.6266 - accuracy: 0.9083 - val_loss: 13.3919 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 63/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 7s 862ms/step - loss: 0.6125 - accuracy: 0.8875 - val_loss: 14.1260 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 64/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 7s 845ms/step - loss: 0.6444 - accuracy: 0.8583 - val_loss: 14.6233 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 65/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 7s 810ms/step - loss: 0.5978 - accuracy: 0.9042 - val_loss: 15.6827 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 66/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 5s 603ms/step - loss: 0.5842 - accuracy: 0.9083 - val_loss: 15.8279 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 67/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 849ms/step - loss: 0.5564 - accuracy: 0.9083 - val_loss: 18.2779 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 68/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 5s 608ms/step - loss: 0.5420 - accuracy: 0.9417 - val_loss: 20.0834 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 69/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 760ms/step - loss: 0.5253 - accuracy: 0.9292 - val_loss: 21.5079 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 70/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 720ms/step - loss: 0.5770 - accuracy: 0.8958 - val_loss: 15.4381 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 71/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 7s 854ms/step - loss: 0.5690 - accuracy: 0.9250 - val_loss: 14.0894 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 72/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 742ms/step - loss: 0.5625 - accuracy: 0.9042 - val_loss: 17.3624 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 73/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 5s 623ms/step - loss: 0.5241 - accuracy: 0.9208 - val_loss: 19.3413 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 74/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 5s 621ms/step - loss: 0.5785 - accuracy: 0.9125 - val_loss: 12.8115 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 75/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 5s 617ms/step - loss: 0.5584 - accuracy: 0.9083 - val_loss: 11.0029 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 76/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 5s 648ms/step - loss: 0.5074 - accuracy: 0.9542 - val_loss: 12.9163 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 77/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 7s 798ms/step - loss: 0.4985 - accuracy: 0.9542 - val_loss: 16.3598 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 78/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 9s 1s/step - loss: 0.5095 - accuracy: 0.9375 - val_loss: 17.4458 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 79/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 7s 837ms/step - loss: 0.4584 - accuracy: 0.9583 - val_loss: 16.8576 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 80/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 7s 810ms/step - loss: 0.4934 - accuracy: 0.9375 - val_loss: 18.4690 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 81/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 7s 948ms/step - loss: 0.5450 - accuracy: 0.9167 - val_loss: 16.6151 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 82/100\n",
      "Learning rate:  0.0001\n",
      "8/8 [==============================] - 6s 681ms/step - loss: 0.4607 - accuracy: 0.9542 - val_loss: 16.3590 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 83/100\n",
      "Learning rate:  0.0001\n",
      "8/8 [==============================] - 6s 748ms/step - loss: 0.4613 - accuracy: 0.9625 - val_loss: 16.7253 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 84/100\n",
      "Learning rate:  0.0001\n",
      "8/8 [==============================] - 6s 829ms/step - loss: 0.4538 - accuracy: 0.9708 - val_loss: 17.5887 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 85/100\n",
      "Learning rate:  0.0001\n",
      "8/8 [==============================] - 6s 782ms/step - loss: 0.4420 - accuracy: 0.9792 - val_loss: 17.6986 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 86/100\n",
      "Learning rate:  0.0001\n",
      "8/8 [==============================] - 7s 824ms/step - loss: 0.4778 - accuracy: 0.9375 - val_loss: 17.7343 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 87/100\n",
      "Learning rate:  0.0001\n",
      "8/8 [==============================] - 6s 764ms/step - loss: 0.4708 - accuracy: 0.9667 - val_loss: 17.5623 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 88/100\n",
      "Learning rate:  0.0001\n",
      "8/8 [==============================] - 7s 913ms/step - loss: 0.4301 - accuracy: 0.9708 - val_loss: 16.8366 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 89/100\n",
      "Learning rate:  0.0001\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.4571 - accuracy: 0.9542 - val_loss: 16.6061 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 90/100\n",
      "Learning rate:  0.0001\n",
      "8/8 [==============================] - 6s 667ms/step - loss: 0.4280 - accuracy: 0.9708 - val_loss: 17.0816 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 91/100\n",
      "Learning rate:  0.0001\n",
      "8/8 [==============================] - 5s 663ms/step - loss: 0.4236 - accuracy: 0.9708 - val_loss: 17.5843 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 92/100\n",
      "Learning rate:  0.0001\n",
      "8/8 [==============================] - 5s 667ms/step - loss: 0.4692 - accuracy: 0.9500 - val_loss: 17.7904 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 93/100\n",
      "Learning rate:  0.0001\n",
      "8/8 [==============================] - 5s 662ms/step - loss: 0.4326 - accuracy: 0.9708 - val_loss: 18.0243 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 94/100\n",
      "Learning rate:  0.0001\n",
      "8/8 [==============================] - 6s 676ms/step - loss: 0.4088 - accuracy: 0.9875 - val_loss: 17.7982 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 95/100\n",
      "Learning rate:  0.0001\n",
      "8/8 [==============================] - 5s 708ms/step - loss: 0.4147 - accuracy: 0.9750 - val_loss: 17.5513 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 96/100\n",
      "Learning rate:  0.0001\n",
      "8/8 [==============================] - 5s 658ms/step - loss: 0.4416 - accuracy: 0.9708 - val_loss: 17.8301 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 97/100\n",
      "Learning rate:  0.0001\n",
      "8/8 [==============================] - 5s 654ms/step - loss: 0.4248 - accuracy: 0.9708 - val_loss: 18.0016 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 98/100\n",
      "Learning rate:  0.0001\n",
      "8/8 [==============================] - 5s 660ms/step - loss: 0.4068 - accuracy: 0.9792 - val_loss: 17.5271 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 99/100\n",
      "Learning rate:  0.0001\n",
      "8/8 [==============================] - 6s 742ms/step - loss: 0.4130 - accuracy: 0.9708 - val_loss: 17.0440 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 100/100\n",
      "Learning rate:  0.0001\n",
      "8/8 [==============================] - 5s 658ms/step - loss: 0.4057 - accuracy: 0.9750 - val_loss: 16.8499 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.6021 - accuracy: 0.9000\n",
      "Test loss: 0.6020776629447937\n",
      "Test accuracy: 0.8999999761581421\n",
      "[1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]\n",
      "Precision:  1.0\n",
      "Recall:  0.9\n",
      "F1 Score:  0.9465116279069767\n",
      "[[[[  5   5   5]\n",
      "   [ 21  21  21]\n",
      "   [ 13  13  13]\n",
      "   ...\n",
      "   [  7   7   7]\n",
      "   [  5   5   5]\n",
      "   [  2   2   2]]\n",
      "\n",
      "  [[ 23  23  23]\n",
      "   [ 14  14  14]\n",
      "   [  9   9   9]\n",
      "   ...\n",
      "   [  1   1   1]\n",
      "   [  0   0   0]\n",
      "   [  0   0   0]]\n",
      "\n",
      "  [[ 23  23  23]\n",
      "   [ 14  14  14]\n",
      "   [  9   9   9]\n",
      "   ...\n",
      "   [  0   0   0]\n",
      "   [  0   0   0]\n",
      "   [  0   0   0]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[ 29  29  29]\n",
      "   [ 17  17  17]\n",
      "   [ 10  10  10]\n",
      "   ...\n",
      "   [  0   0   0]\n",
      "   [  0   0   0]\n",
      "   [  0   0   0]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [ 17  17  17]\n",
      "   [ 12  12  12]\n",
      "   ...\n",
      "   [  0   0   0]\n",
      "   [  0   0   0]\n",
      "   [  0   0   0]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [ 14  14  14]\n",
      "   ...\n",
      "   [  7   7   7]\n",
      "   [  6   6   6]\n",
      "   [  6   6   6]]]\n",
      "\n",
      "\n",
      " [[[108 108 108]\n",
      "   [117 117 117]\n",
      "   [116 116 116]\n",
      "   ...\n",
      "   [  1   1   1]\n",
      "   [  1   1   1]\n",
      "   [  1   1   1]]\n",
      "\n",
      "  [[112 112 112]\n",
      "   [108 108 108]\n",
      "   [115 115 115]\n",
      "   ...\n",
      "   [  1   1   1]\n",
      "   [  1   1   1]\n",
      "   [  1   1   1]]\n",
      "\n",
      "  [[117 117 117]\n",
      "   [112 112 112]\n",
      "   [110 110 110]\n",
      "   ...\n",
      "   [  1   1   1]\n",
      "   [  1   1   1]\n",
      "   [  1   1   1]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[ 25  25  25]\n",
      "   [ 17  17  17]\n",
      "   [ 10  10  10]\n",
      "   ...\n",
      "   [  0   0   0]\n",
      "   [  0   0   0]\n",
      "   [  0   0   0]]\n",
      "\n",
      "  [[ 24  24  24]\n",
      "   [ 18  18  18]\n",
      "   [ 11  11  11]\n",
      "   ...\n",
      "   [  0   0   0]\n",
      "   [  0   0   0]\n",
      "   [  0   0   0]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [ 19  19  19]\n",
      "   [ 19  19  19]\n",
      "   ...\n",
      "   [  6   6   6]\n",
      "   [  6   6   6]\n",
      "   [  6   6   6]]]\n",
      "\n",
      "\n",
      " [[[  1   1   1]\n",
      "   [  7   7   7]\n",
      "   [  4   4   4]\n",
      "   ...\n",
      "   [  0   0   0]\n",
      "   [  0   0   0]\n",
      "   [  0   0   0]]\n",
      "\n",
      "  [[ 21  21  21]\n",
      "   [ 15  15  15]\n",
      "   [ 11  11  11]\n",
      "   ...\n",
      "   [  4   4   4]\n",
      "   [  7   7   7]\n",
      "   [ 12  12  12]]\n",
      "\n",
      "  [[ 19  19  19]\n",
      "   [ 15  15  15]\n",
      "   [ 11  11  11]\n",
      "   ...\n",
      "   [  4   4   4]\n",
      "   [  6   6   6]\n",
      "   [ 11  11  11]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[ 28  28  28]\n",
      "   [ 19  19  19]\n",
      "   [ 10  10  10]\n",
      "   ...\n",
      "   [  0   0   0]\n",
      "   [  0   0   0]\n",
      "   [  1   1   1]]\n",
      "\n",
      "  [[ 22  22  22]\n",
      "   [ 14  14  14]\n",
      "   [ 10  10  10]\n",
      "   ...\n",
      "   [  0   0   0]\n",
      "   [  0   0   0]\n",
      "   [  1   1   1]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [ 35  35  35]\n",
      "   [ 23  23  23]\n",
      "   ...\n",
      "   [  0   0   0]\n",
      "   [  0   0   0]\n",
      "   [  0   0   0]]]]\n",
      "[[1]\n",
      " [1]\n",
      " [1]]\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "(40, 30, 3)\n",
      "x_train shape: (240, 40, 30, 3)\n",
      "240 train samples\n",
      "30 test samples\n",
      "y_train shape: (240, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\patcas rares\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate:  0.001\n",
      "Model: \"model_4\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_5 (InputLayer)            [(None, 40, 30, 3)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_124 (Conv2D)             (None, 40, 30, 16)   448         input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_112 (BatchN (None, 40, 30, 16)   64          conv2d_124[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_112 (Activation)     (None, 40, 30, 16)   0           batch_normalization_112[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_125 (Conv2D)             (None, 40, 30, 16)   272         activation_112[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_113 (BatchN (None, 40, 30, 16)   64          conv2d_125[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_113 (Activation)     (None, 40, 30, 16)   0           batch_normalization_113[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_126 (Conv2D)             (None, 40, 30, 16)   2320        activation_113[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_114 (BatchN (None, 40, 30, 16)   64          conv2d_126[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_114 (Activation)     (None, 40, 30, 16)   0           batch_normalization_114[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_128 (Conv2D)             (None, 40, 30, 64)   1088        activation_112[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_127 (Conv2D)             (None, 40, 30, 64)   1088        activation_114[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_36 (Add)                    (None, 40, 30, 64)   0           conv2d_128[0][0]                 \n",
      "                                                                 conv2d_127[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_115 (BatchN (None, 40, 30, 64)   256         add_36[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_115 (Activation)     (None, 40, 30, 64)   0           batch_normalization_115[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_129 (Conv2D)             (None, 40, 30, 16)   1040        activation_115[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_116 (BatchN (None, 40, 30, 16)   64          conv2d_129[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_116 (Activation)     (None, 40, 30, 16)   0           batch_normalization_116[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_130 (Conv2D)             (None, 40, 30, 16)   2320        activation_116[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_117 (BatchN (None, 40, 30, 16)   64          conv2d_130[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_117 (Activation)     (None, 40, 30, 16)   0           batch_normalization_117[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_131 (Conv2D)             (None, 40, 30, 64)   1088        activation_117[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_37 (Add)                    (None, 40, 30, 64)   0           add_36[0][0]                     \n",
      "                                                                 conv2d_131[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_118 (BatchN (None, 40, 30, 64)   256         add_37[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_118 (Activation)     (None, 40, 30, 64)   0           batch_normalization_118[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_132 (Conv2D)             (None, 40, 30, 16)   1040        activation_118[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_119 (BatchN (None, 40, 30, 16)   64          conv2d_132[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_119 (Activation)     (None, 40, 30, 16)   0           batch_normalization_119[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_133 (Conv2D)             (None, 40, 30, 16)   2320        activation_119[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_120 (BatchN (None, 40, 30, 16)   64          conv2d_133[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_120 (Activation)     (None, 40, 30, 16)   0           batch_normalization_120[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_134 (Conv2D)             (None, 40, 30, 64)   1088        activation_120[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_38 (Add)                    (None, 40, 30, 64)   0           add_37[0][0]                     \n",
      "                                                                 conv2d_134[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_121 (BatchN (None, 40, 30, 64)   256         add_38[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_121 (Activation)     (None, 40, 30, 64)   0           batch_normalization_121[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_135 (Conv2D)             (None, 20, 15, 64)   4160        activation_121[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_122 (BatchN (None, 20, 15, 64)   256         conv2d_135[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_122 (Activation)     (None, 20, 15, 64)   0           batch_normalization_122[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_136 (Conv2D)             (None, 20, 15, 64)   36928       activation_122[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_123 (BatchN (None, 20, 15, 64)   256         conv2d_136[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_123 (Activation)     (None, 20, 15, 64)   0           batch_normalization_123[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_138 (Conv2D)             (None, 20, 15, 128)  8320        add_38[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_137 (Conv2D)             (None, 20, 15, 128)  8320        activation_123[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_39 (Add)                    (None, 20, 15, 128)  0           conv2d_138[0][0]                 \n",
      "                                                                 conv2d_137[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_124 (BatchN (None, 20, 15, 128)  512         add_39[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_124 (Activation)     (None, 20, 15, 128)  0           batch_normalization_124[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_139 (Conv2D)             (None, 20, 15, 64)   8256        activation_124[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_125 (BatchN (None, 20, 15, 64)   256         conv2d_139[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_125 (Activation)     (None, 20, 15, 64)   0           batch_normalization_125[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_140 (Conv2D)             (None, 20, 15, 64)   36928       activation_125[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_126 (BatchN (None, 20, 15, 64)   256         conv2d_140[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_126 (Activation)     (None, 20, 15, 64)   0           batch_normalization_126[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_141 (Conv2D)             (None, 20, 15, 128)  8320        activation_126[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_40 (Add)                    (None, 20, 15, 128)  0           add_39[0][0]                     \n",
      "                                                                 conv2d_141[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_127 (BatchN (None, 20, 15, 128)  512         add_40[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_127 (Activation)     (None, 20, 15, 128)  0           batch_normalization_127[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_142 (Conv2D)             (None, 20, 15, 64)   8256        activation_127[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_128 (BatchN (None, 20, 15, 64)   256         conv2d_142[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_128 (Activation)     (None, 20, 15, 64)   0           batch_normalization_128[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_143 (Conv2D)             (None, 20, 15, 64)   36928       activation_128[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_129 (BatchN (None, 20, 15, 64)   256         conv2d_143[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_129 (Activation)     (None, 20, 15, 64)   0           batch_normalization_129[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_144 (Conv2D)             (None, 20, 15, 128)  8320        activation_129[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_41 (Add)                    (None, 20, 15, 128)  0           add_40[0][0]                     \n",
      "                                                                 conv2d_144[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_130 (BatchN (None, 20, 15, 128)  512         add_41[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_130 (Activation)     (None, 20, 15, 128)  0           batch_normalization_130[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_145 (Conv2D)             (None, 10, 8, 128)   16512       activation_130[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_131 (BatchN (None, 10, 8, 128)   512         conv2d_145[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_131 (Activation)     (None, 10, 8, 128)   0           batch_normalization_131[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_146 (Conv2D)             (None, 10, 8, 128)   147584      activation_131[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_132 (BatchN (None, 10, 8, 128)   512         conv2d_146[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_132 (Activation)     (None, 10, 8, 128)   0           batch_normalization_132[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_148 (Conv2D)             (None, 10, 8, 256)   33024       add_41[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_147 (Conv2D)             (None, 10, 8, 256)   33024       activation_132[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_42 (Add)                    (None, 10, 8, 256)   0           conv2d_148[0][0]                 \n",
      "                                                                 conv2d_147[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_133 (BatchN (None, 10, 8, 256)   1024        add_42[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_133 (Activation)     (None, 10, 8, 256)   0           batch_normalization_133[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_149 (Conv2D)             (None, 10, 8, 128)   32896       activation_133[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_134 (BatchN (None, 10, 8, 128)   512         conv2d_149[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_134 (Activation)     (None, 10, 8, 128)   0           batch_normalization_134[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_150 (Conv2D)             (None, 10, 8, 128)   147584      activation_134[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_135 (BatchN (None, 10, 8, 128)   512         conv2d_150[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_135 (Activation)     (None, 10, 8, 128)   0           batch_normalization_135[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_151 (Conv2D)             (None, 10, 8, 256)   33024       activation_135[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_43 (Add)                    (None, 10, 8, 256)   0           add_42[0][0]                     \n",
      "                                                                 conv2d_151[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_136 (BatchN (None, 10, 8, 256)   1024        add_43[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_136 (Activation)     (None, 10, 8, 256)   0           batch_normalization_136[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_152 (Conv2D)             (None, 10, 8, 128)   32896       activation_136[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_137 (BatchN (None, 10, 8, 128)   512         conv2d_152[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_137 (Activation)     (None, 10, 8, 128)   0           batch_normalization_137[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_153 (Conv2D)             (None, 10, 8, 128)   147584      activation_137[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_138 (BatchN (None, 10, 8, 128)   512         conv2d_153[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_138 (Activation)     (None, 10, 8, 128)   0           batch_normalization_138[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_154 (Conv2D)             (None, 10, 8, 256)   33024       activation_138[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_44 (Add)                    (None, 10, 8, 256)   0           add_43[0][0]                     \n",
      "                                                                 conv2d_154[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_139 (BatchN (None, 10, 8, 256)   1024        add_44[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_139 (Activation)     (None, 10, 8, 256)   0           batch_normalization_139[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_4 (AveragePoo (None, 1, 1, 256)    0           activation_139[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "flatten_4 (Flatten)             (None, 256)          0           average_pooling2d_4[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 10)           2570        flatten_4[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 849,002\n",
      "Trainable params: 843,786\n",
      "Non-trainable params: 5,216\n",
      "__________________________________________________________________________________________________\n",
      "ResNet  29v  2\n",
      "Using real-time data augmentation.\n",
      "------------------\n",
      "[[[[-0.1136601  -0.1136601  -0.1136601 ]\n",
      "   [-0.05588228 -0.05588228 -0.05588228]\n",
      "   [-0.0781862  -0.0781862  -0.0781862 ]\n",
      "   ...\n",
      "   [-0.15612748 -0.15612748 -0.15612748]\n",
      "   [-0.1716503  -0.1716503  -0.1716503 ]\n",
      "   [-0.18673201 -0.18673201 -0.18673201]]\n",
      "\n",
      "  [[-0.03851306 -0.03851306 -0.03851306]\n",
      "   [-0.06264699 -0.06264699 -0.06264699]\n",
      "   [-0.07998353 -0.07998353 -0.07998353]\n",
      "   ...\n",
      "   [-0.14627448 -0.14627448 -0.14627448]\n",
      "   [-0.15452616 -0.15452616 -0.15452616]\n",
      "   [-0.16279407 -0.16279407 -0.16279407]]\n",
      "\n",
      "  [[-0.04622547 -0.04622547 -0.04622547]\n",
      "   [-0.07233649 -0.07233649 -0.07233649]\n",
      "   [-0.08499993 -0.08499993 -0.08499993]\n",
      "   ...\n",
      "   [-0.15511438 -0.15511438 -0.15511438]\n",
      "   [-0.16521242 -0.16521242 -0.16521242]\n",
      "   [-0.16852933 -0.16852933 -0.16852933]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[ 0.00455882  0.00455882  0.00455882]\n",
      "   [-0.02856197 -0.02856197 -0.02856197]\n",
      "   [-0.03790838 -0.03790838 -0.03790838]\n",
      "   ...\n",
      "   [-0.07279409 -0.07279409 -0.07279409]\n",
      "   [-0.08496729 -0.08496729 -0.08496729]\n",
      "   [-0.10674839 -0.10674839 -0.10674839]]\n",
      "\n",
      "  [[ 0.39745098  0.39745098  0.39745098]\n",
      "   [-0.02570248 -0.02570248 -0.02570248]\n",
      "   [-0.02849663 -0.02849663 -0.02849663]\n",
      "   ...\n",
      "   [-0.06975487 -0.06975487 -0.06975487]\n",
      "   [-0.07596402 -0.07596402 -0.07596402]\n",
      "   [-0.11075167 -0.11075167 -0.11075167]]\n",
      "\n",
      "  [[ 0.28215694  0.28215694  0.28215694]\n",
      "   [ 0.31718966  0.31718966  0.31718966]\n",
      "   [-0.11207506 -0.11207506 -0.11207506]\n",
      "   ...\n",
      "   [-0.1244771  -0.1244771  -0.1244771 ]\n",
      "   [-0.14967315 -0.14967315 -0.14967315]\n",
      "   [-0.177124   -0.177124   -0.177124  ]]]\n",
      "\n",
      "\n",
      " [[[ 0.29026148  0.29026148  0.29026148]\n",
      "   [ 0.3205883   0.3205883   0.3205883 ]\n",
      "   [ 0.3257354   0.3257354   0.3257354 ]\n",
      "   ...\n",
      "   [-0.1796569  -0.1796569  -0.1796569 ]\n",
      "   [-0.18733658 -0.18733658 -0.18733658]\n",
      "   [-0.19065358 -0.19065358 -0.19065358]]\n",
      "\n",
      "  [[ 0.31050655  0.31050655  0.31050655]\n",
      "   [ 0.30598047  0.30598047  0.30598047]\n",
      "   [ 0.33570275  0.33570275  0.33570275]\n",
      "   ...\n",
      "   [-0.14627448 -0.14627448 -0.14627448]\n",
      "   [-0.15060459 -0.15060459 -0.15060459]\n",
      "   [-0.1588725  -0.1588725  -0.1588725 ]]\n",
      "\n",
      "  [[ 0.322402    0.322402    0.322402  ]\n",
      "   [ 0.31197724  0.31197724  0.31197724]\n",
      "   [ 0.3110785   0.3110785   0.3110785 ]\n",
      "   ...\n",
      "   [-0.15119281 -0.15119281 -0.15119281]\n",
      "   [-0.16129085 -0.16129085 -0.16129085]\n",
      "   [-0.16460776 -0.16460776 -0.16460776]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[-0.01112746 -0.01112746 -0.01112746]\n",
      "   [-0.02856197 -0.02856197 -0.02856197]\n",
      "   [-0.03790838 -0.03790838 -0.03790838]\n",
      "   ...\n",
      "   [-0.07279409 -0.07279409 -0.07279409]\n",
      "   [-0.08496729 -0.08496729 -0.08496729]\n",
      "   [-0.10674839 -0.10674839 -0.10674839]]\n",
      "\n",
      "  [[-0.01039217 -0.01039217 -0.01039217]\n",
      "   [-0.02178092 -0.02178092 -0.02178092]\n",
      "   [-0.0324182  -0.0324182  -0.0324182 ]\n",
      "   ...\n",
      "   [-0.06975487 -0.06975487 -0.06975487]\n",
      "   [-0.07596402 -0.07596402 -0.07596402]\n",
      "   [-0.11075167 -0.11075167 -0.11075167]]\n",
      "\n",
      "  [[ 0.28215694  0.28215694  0.28215694]\n",
      "   [-0.11026134 -0.11026134 -0.11026134]\n",
      "   [-0.09246721 -0.09246721 -0.09246721]\n",
      "   ...\n",
      "   [-0.12839867 -0.12839867 -0.12839867]\n",
      "   [-0.14967315 -0.14967315 -0.14967315]\n",
      "   [-0.177124   -0.177124   -0.177124  ]]]\n",
      "\n",
      "\n",
      " [[[-0.12934637 -0.12934637 -0.12934637]\n",
      "   [-0.11078425 -0.11078425 -0.11078425]\n",
      "   [-0.11348031 -0.11348031 -0.11348031]\n",
      "   ...\n",
      "   [-0.18357846 -0.18357846 -0.18357846]\n",
      "   [-0.19125815 -0.19125815 -0.19125815]\n",
      "   [-0.19457515 -0.19457515 -0.19457515]]\n",
      "\n",
      "  [[-0.04635619 -0.04635619 -0.04635619]\n",
      "   [-0.05872541 -0.05872541 -0.05872541]\n",
      "   [-0.0721404  -0.0721404  -0.0721404 ]\n",
      "   ...\n",
      "   [-0.13450977 -0.13450977 -0.13450977]\n",
      "   [-0.12707518 -0.12707518 -0.12707518]\n",
      "   [-0.11573525 -0.11573525 -0.11573525]]\n",
      "\n",
      "  [[-0.06191174 -0.06191174 -0.06191174]\n",
      "   [-0.06841493 -0.06841493 -0.06841493]\n",
      "   [-0.0771568  -0.0771568  -0.0771568 ]\n",
      "   ...\n",
      "   [-0.13942811 -0.13942811 -0.13942811]\n",
      "   [-0.14168301 -0.14168301 -0.14168301]\n",
      "   [-0.12539208 -0.12539208 -0.12539208]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[ 0.00063725  0.00063725  0.00063725]\n",
      "   [-0.02071884 -0.02071884 -0.02071884]\n",
      "   [-0.03790838 -0.03790838 -0.03790838]\n",
      "   ...\n",
      "   [-0.07279409 -0.07279409 -0.07279409]\n",
      "   [-0.08496729 -0.08496729 -0.08496729]\n",
      "   [-0.10282683 -0.10282683 -0.10282683]]\n",
      "\n",
      "  [[-0.0182353  -0.0182353  -0.0182353 ]\n",
      "   [-0.03746719 -0.03746719 -0.03746719]\n",
      "   [-0.03633976 -0.03633976 -0.03633976]\n",
      "   ...\n",
      "   [-0.06975487 -0.06975487 -0.06975487]\n",
      "   [-0.07596402 -0.07596402 -0.07596402]\n",
      "   [-0.1068301  -0.1068301  -0.1068301 ]]\n",
      "\n",
      "  [[ 0.28215694  0.28215694  0.28215694]\n",
      "   [-0.04751624 -0.04751624 -0.04751624]\n",
      "   [-0.07678094 -0.07678094 -0.07678094]\n",
      "   ...\n",
      "   [-0.15192808 -0.15192808 -0.15192808]\n",
      "   [-0.17320256 -0.17320256 -0.17320256]\n",
      "   [-0.2006534  -0.2006534  -0.2006534 ]]]\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      " [[[-0.05483656 -0.05483656 -0.05483656]\n",
      "   [ 0.03039223  0.03039223  0.03039223]\n",
      "   [-0.09387247 -0.09387247 -0.09387247]\n",
      "   ...\n",
      "   [-0.14044121 -0.14044121 -0.14044121]\n",
      "   [-0.13243462 -0.13243462 -0.13243462]\n",
      "   [ 0.30738568  0.30738568  0.30738568]]\n",
      "\n",
      "  [[-0.04635619 -0.04635619 -0.04635619]\n",
      "   [-0.06656855 -0.06656855 -0.06656855]\n",
      "   [-0.07606196 -0.07606196 -0.07606196]\n",
      "   ...\n",
      "   [-0.1188235  -0.1188235  -0.1188235 ]\n",
      "   [-0.0996242  -0.0996242  -0.0996242 ]\n",
      "   [-0.0961274  -0.0961274  -0.0961274 ]]\n",
      "\n",
      "  [[-0.0540686  -0.0540686  -0.0540686 ]\n",
      "   [-0.07625806 -0.07625806 -0.07625806]\n",
      "   [-0.08107837 -0.08107837 -0.08107837]\n",
      "   ...\n",
      "   [-0.1276634  -0.1276634  -0.1276634 ]\n",
      "   [-0.11031047 -0.11031047 -0.11031047]\n",
      "   [-0.09794109 -0.09794109 -0.09794109]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[-0.06602941 -0.06602941 -0.06602941]\n",
      "   [-0.05993452 -0.05993452 -0.05993452]\n",
      "   [-0.04575152 -0.04575152 -0.04575152]\n",
      "   ...\n",
      "   [-0.04534311 -0.04534311 -0.04534311]\n",
      "   [-0.03398689 -0.03398689 -0.03398689]\n",
      "   [-0.02831702 -0.02831702 -0.02831702]]\n",
      "\n",
      "  [[-0.05745099 -0.05745099 -0.05745099]\n",
      "   [-0.05707503 -0.05707503 -0.05707503]\n",
      "   [-0.0441829  -0.0441829  -0.0441829 ]\n",
      "   ...\n",
      "   [-0.04230389 -0.04230389 -0.04230389]\n",
      "   [-0.02498363 -0.02498363 -0.02498363]\n",
      "   [-0.03232029 -0.03232029 -0.03232029]]\n",
      "\n",
      "  [[ 0.16843143  0.16843143  0.16843143]\n",
      "   [ 0.12503278  0.12503278  0.12503278]\n",
      "   [ 0.09184653  0.09184653  0.09184653]\n",
      "   ...\n",
      "   [-0.03035945 -0.03035945 -0.03035945]\n",
      "   [-0.02810451 -0.02810451 -0.02810451]\n",
      "   [-0.11437889 -0.11437889 -0.11437889]]]\n",
      "\n",
      "\n",
      " [[[-0.06660127 -0.06660127 -0.06660127]\n",
      "   [ 0.3637256   0.3637256   0.3637256 ]\n",
      "   [-0.12916659 -0.12916659 -0.12916659]\n",
      "   ...\n",
      "   [ 0.31838235  0.31838235  0.31838235]\n",
      "   [ 0.31070268  0.31070268  0.31070268]\n",
      "   [ 0.30738568  0.30738568  0.30738568]]\n",
      "\n",
      "  [[-0.05027776 -0.05027776 -0.05027776]\n",
      "   [-0.07833326 -0.07833326 -0.07833326]\n",
      "   [-0.08782668 -0.08782668 -0.08782668]\n",
      "   ...\n",
      "   [ 0.25372553  0.25372553  0.25372553]\n",
      "   [ 0.29645425  0.29645425  0.29645425]\n",
      "   [ 0.31955886  0.31955886  0.31955886]]\n",
      "\n",
      "  [[-0.05799017 -0.05799017 -0.05799017]\n",
      "   [-0.08017963 -0.08017963 -0.08017963]\n",
      "   [-0.0889215  -0.0889215  -0.0889215 ]\n",
      "   ...\n",
      "   [ 0.25272876  0.25272876  0.25272876]\n",
      "   [ 0.26616013  0.26616013  0.26616013]\n",
      "   [ 0.27460793  0.27460793  0.27460793]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[-0.06995098 -0.06995098 -0.06995098]\n",
      "   [-0.06777766 -0.06777766 -0.06777766]\n",
      "   [-0.05359466 -0.05359466 -0.05359466]\n",
      "   ...\n",
      "   [ 0.18602946  0.18602946  0.18602946]\n",
      "   [-0.01437905 -0.01437905 -0.01437905]\n",
      "   [ 0.01089866  0.01089866  0.01089866]]\n",
      "\n",
      "  [[-0.06137256 -0.06137256 -0.06137256]\n",
      "   [-0.06491818 -0.06491818 -0.06491818]\n",
      "   [-0.05202604 -0.05202604 -0.05202604]\n",
      "   ...\n",
      "   [-0.04622546 -0.04622546 -0.04622546]\n",
      "   [-0.02890519 -0.02890519 -0.02890519]\n",
      "   [ 0.00297382  0.00297382  0.00297382]]\n",
      "\n",
      "  [[-0.17666662 -0.17666662 -0.17666662]\n",
      "   [-0.15732017 -0.15732017 -0.15732017]\n",
      "   [-0.14736918 -0.14736918 -0.14736918]\n",
      "   ...\n",
      "   [-0.12839867 -0.12839867 -0.12839867]\n",
      "   [-0.1183006  -0.1183006  -0.1183006 ]\n",
      "   [-0.10653576 -0.10653576 -0.10653576]]]\n",
      "\n",
      "\n",
      " [[[ 0.30594775  0.30594775  0.30594775]\n",
      "   [ 0.32843143  0.32843143  0.32843143]\n",
      "   [ 0.31004912  0.31004912  0.31004912]\n",
      "   ...\n",
      "   [-0.18357846 -0.18357846 -0.18357846]\n",
      "   [-0.19125815 -0.19125815 -0.19125815]\n",
      "   [-0.19457515 -0.19457515 -0.19457515]]\n",
      "\n",
      "  [[ 0.3418791   0.3418791   0.3418791 ]\n",
      "   [ 0.36872557  0.36872557  0.36872557]\n",
      "   [ 0.30825177  0.30825177  0.30825177]\n",
      "   ...\n",
      "   [-0.15019605 -0.15019605 -0.15019605]\n",
      "   [-0.15452616 -0.15452616 -0.15452616]\n",
      "   [-0.16279407 -0.16279407 -0.16279407]]\n",
      "\n",
      "  [[ 0.2988726   0.2988726   0.2988726 ]\n",
      "   [ 0.30021253  0.30021253  0.30021253]\n",
      "   [ 0.29539222  0.29539222  0.29539222]\n",
      "   ...\n",
      "   [-0.15511438 -0.15511438 -0.15511438]\n",
      "   [-0.16521242 -0.16521242 -0.16521242]\n",
      "   [-0.16852933 -0.16852933 -0.16852933]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[ 0.0202451   0.0202451   0.0202451 ]\n",
      "   [-0.02071884 -0.02071884 -0.02071884]\n",
      "   [-0.03006524 -0.03006524 -0.03006524]\n",
      "   ...\n",
      "   [-0.07279409 -0.07279409 -0.07279409]\n",
      "   [-0.08496729 -0.08496729 -0.08496729]\n",
      "   [-0.10674839 -0.10674839 -0.10674839]]\n",
      "\n",
      "  [[ 0.02490196  0.02490196  0.02490196]\n",
      "   [-0.01785935 -0.01785935 -0.01785935]\n",
      "   [-0.02457506 -0.02457506 -0.02457506]\n",
      "   ...\n",
      "   [-0.06975487 -0.06975487 -0.06975487]\n",
      "   [-0.07596402 -0.07596402 -0.07596402]\n",
      "   [-0.11075167 -0.11075167 -0.11075167]]\n",
      "\n",
      "  [[-0.0903921  -0.0903921  -0.0903921 ]\n",
      "   [-0.11026134 -0.11026134 -0.11026134]\n",
      "   [-0.11207506 -0.11207506 -0.11207506]\n",
      "   ...\n",
      "   [-0.15192808 -0.15192808 -0.15192808]\n",
      "   [-0.17320256 -0.17320256 -0.17320256]\n",
      "   [-0.2006534  -0.2006534  -0.2006534 ]]]]\n",
      "Epoch 1/100\n",
      "Learning rate:  0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\patcas rares\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\keras\\engine\\training.py:1972: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 11s 788ms/step - loss: 2.1080 - accuracy: 0.5000 - val_loss: 2.6607 - val_accuracy: 0.3000\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 2/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 687ms/step - loss: 1.3530 - accuracy: 0.6708 - val_loss: 2.5621 - val_accuracy: 0.3000\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 3/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 685ms/step - loss: 1.1913 - accuracy: 0.7000 - val_loss: 2.7005 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 4/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 740ms/step - loss: 1.1491 - accuracy: 0.7167 - val_loss: 3.3968 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 5/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 786ms/step - loss: 1.0958 - accuracy: 0.7167 - val_loss: 3.8371 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 6/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 798ms/step - loss: 1.1060 - accuracy: 0.7375 - val_loss: 5.0475 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 7/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 708ms/step - loss: 1.0642 - accuracy: 0.7583 - val_loss: 4.8907 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 8/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 732ms/step - loss: 1.0528 - accuracy: 0.7417 - val_loss: 5.0758 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 9/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 782ms/step - loss: 1.0298 - accuracy: 0.7667 - val_loss: 6.2540 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 10/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 721ms/step - loss: 1.0137 - accuracy: 0.7750 - val_loss: 7.2827 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 11/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 780ms/step - loss: 0.9880 - accuracy: 0.8042 - val_loss: 9.2220 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 12/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 724ms/step - loss: 0.9832 - accuracy: 0.7458 - val_loss: 8.2511 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 13/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 728ms/step - loss: 0.9416 - accuracy: 0.8000 - val_loss: 10.8379 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 14/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 712ms/step - loss: 0.9995 - accuracy: 0.8000 - val_loss: 12.1409 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 15/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 716ms/step - loss: 0.9704 - accuracy: 0.7542 - val_loss: 9.9853 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 16/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 786ms/step - loss: 0.9664 - accuracy: 0.7708 - val_loss: 10.6865 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 17/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 705ms/step - loss: 0.9176 - accuracy: 0.8250 - val_loss: 14.8709 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 18/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 772ms/step - loss: 0.9545 - accuracy: 0.7708 - val_loss: 18.9349 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 19/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 803ms/step - loss: 0.9246 - accuracy: 0.8167 - val_loss: 20.1341 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 20/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 738ms/step - loss: 0.8952 - accuracy: 0.8125 - val_loss: 17.8484 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 21/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 726ms/step - loss: 0.8995 - accuracy: 0.8333 - val_loss: 16.3901 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 22/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 7s 908ms/step - loss: 0.9332 - accuracy: 0.7875 - val_loss: 19.1581 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 23/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 709ms/step - loss: 0.8790 - accuracy: 0.7833 - val_loss: 14.9772 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 24/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 7s 821ms/step - loss: 0.8502 - accuracy: 0.8083 - val_loss: 19.3791 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 25/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 803ms/step - loss: 0.8521 - accuracy: 0.8458 - val_loss: 18.9903 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 26/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 722ms/step - loss: 0.8603 - accuracy: 0.8125 - val_loss: 17.7870 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 27/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 728ms/step - loss: 0.8402 - accuracy: 0.8417 - val_loss: 19.7441 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 28/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 715ms/step - loss: 0.8873 - accuracy: 0.7958 - val_loss: 19.1734 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 29/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 713ms/step - loss: 0.8408 - accuracy: 0.8125 - val_loss: 16.5698 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 30/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 751ms/step - loss: 0.8820 - accuracy: 0.8125 - val_loss: 15.7022 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 31/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 721ms/step - loss: 0.8306 - accuracy: 0.8333 - val_loss: 17.9997 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 32/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 706ms/step - loss: 0.7600 - accuracy: 0.8875 - val_loss: 15.0076 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 33/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 722ms/step - loss: 0.7770 - accuracy: 0.8333 - val_loss: 22.3980 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 34/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 724ms/step - loss: 0.7351 - accuracy: 0.8708 - val_loss: 25.3071 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 35/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 715ms/step - loss: 0.7541 - accuracy: 0.8833 - val_loss: 29.2697 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 36/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 716ms/step - loss: 0.7496 - accuracy: 0.8625 - val_loss: 25.0983 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 37/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 719ms/step - loss: 0.7936 - accuracy: 0.8375 - val_loss: 19.4833 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 38/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 709ms/step - loss: 0.7483 - accuracy: 0.8625 - val_loss: 20.3684 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 39/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 709ms/step - loss: 0.8014 - accuracy: 0.8375 - val_loss: 16.0930 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 40/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 734ms/step - loss: 0.7554 - accuracy: 0.8625 - val_loss: 18.3090 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 41/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 740ms/step - loss: 0.7056 - accuracy: 0.8708 - val_loss: 17.6448 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 42/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 768ms/step - loss: 0.7362 - accuracy: 0.8833 - val_loss: 19.2683 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 43/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 715ms/step - loss: 0.6912 - accuracy: 0.9042 - val_loss: 21.4002 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 44/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 716ms/step - loss: 0.7027 - accuracy: 0.8792 - val_loss: 19.1435 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 45/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 717ms/step - loss: 0.6748 - accuracy: 0.8917 - val_loss: 22.7910 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 46/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 710ms/step - loss: 0.6562 - accuracy: 0.9083 - val_loss: 16.7131 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 47/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 722ms/step - loss: 0.6906 - accuracy: 0.8917 - val_loss: 14.2652 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 48/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 716ms/step - loss: 0.6411 - accuracy: 0.9042 - val_loss: 17.5255 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 49/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 710ms/step - loss: 0.6411 - accuracy: 0.9000 - val_loss: 30.0154 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 50/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 737ms/step - loss: 0.6609 - accuracy: 0.9000 - val_loss: 21.9934 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 51/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 718ms/step - loss: 0.6684 - accuracy: 0.8583 - val_loss: 25.2062 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 52/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 724ms/step - loss: 0.7039 - accuracy: 0.8667 - val_loss: 21.4251 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 53/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 7s 843ms/step - loss: 0.6427 - accuracy: 0.8917 - val_loss: 19.0241 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 54/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 788ms/step - loss: 0.6430 - accuracy: 0.9000 - val_loss: 19.5627 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 55/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 5s 707ms/step - loss: 0.7022 - accuracy: 0.8792 - val_loss: 17.2892 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 56/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 675ms/step - loss: 0.6471 - accuracy: 0.8792 - val_loss: 17.7472 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 57/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 5s 635ms/step - loss: 0.6603 - accuracy: 0.8958 - val_loss: 18.3428 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 58/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 5s 606ms/step - loss: 0.5852 - accuracy: 0.9167 - val_loss: 18.4444 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 59/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 5s 698ms/step - loss: 0.6626 - accuracy: 0.8917 - val_loss: 19.1915 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 60/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 5s 680ms/step - loss: 0.5993 - accuracy: 0.9167 - val_loss: 18.5334 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 61/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 5s 638ms/step - loss: 0.5936 - accuracy: 0.9042 - val_loss: 23.8759 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 62/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 5s 628ms/step - loss: 0.5584 - accuracy: 0.9208 - val_loss: 23.0917 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 63/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 5s 675ms/step - loss: 0.6084 - accuracy: 0.9125 - val_loss: 29.9925 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 64/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 675ms/step - loss: 0.5753 - accuracy: 0.8958 - val_loss: 30.9002 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 65/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 7s 897ms/step - loss: 0.5946 - accuracy: 0.9208 - val_loss: 23.4552 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 66/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 731ms/step - loss: 0.5648 - accuracy: 0.9125 - val_loss: 21.2138 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 67/100\n",
      "Learning rate:  0.001\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 6s 790ms/step - loss: 0.5530 - accuracy: 0.9333 - val_loss: 21.6240 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 68/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 745ms/step - loss: 0.5150 - accuracy: 0.9500 - val_loss: 24.7176 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 69/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 767ms/step - loss: 0.5149 - accuracy: 0.9417 - val_loss: 26.9282 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 70/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 734ms/step - loss: 0.5592 - accuracy: 0.9250 - val_loss: 31.1229 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 71/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 760ms/step - loss: 0.5366 - accuracy: 0.9292 - val_loss: 18.2307 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 72/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 723ms/step - loss: 0.5670 - accuracy: 0.9375 - val_loss: 21.0685 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 73/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 724ms/step - loss: 0.4979 - accuracy: 0.9375 - val_loss: 24.7916 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 74/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 713ms/step - loss: 0.5773 - accuracy: 0.9083 - val_loss: 23.3394 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 75/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 734ms/step - loss: 0.5249 - accuracy: 0.9083 - val_loss: 18.1838 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 76/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 718ms/step - loss: 0.5647 - accuracy: 0.9292 - val_loss: 17.0872 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 77/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 712ms/step - loss: 0.5828 - accuracy: 0.9167 - val_loss: 20.0007 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 78/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 766ms/step - loss: 0.5365 - accuracy: 0.9292 - val_loss: 25.2612 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 79/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 720ms/step - loss: 0.5101 - accuracy: 0.9333 - val_loss: 26.8322 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 80/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 718ms/step - loss: 0.5165 - accuracy: 0.9292 - val_loss: 26.3086 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 81/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 716ms/step - loss: 0.5250 - accuracy: 0.9208 - val_loss: 32.7900 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 82/100\n",
      "Learning rate:  0.0001\n",
      "8/8 [==============================] - 6s 701ms/step - loss: 0.5307 - accuracy: 0.9083 - val_loss: 29.9749 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 83/100\n",
      "Learning rate:  0.0001\n",
      "8/8 [==============================] - 6s 720ms/step - loss: 0.4607 - accuracy: 0.9667 - val_loss: 27.5042 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 84/100\n",
      "Learning rate:  0.0001\n",
      "8/8 [==============================] - 6s 773ms/step - loss: 0.4602 - accuracy: 0.9625 - val_loss: 25.7716 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 85/100\n",
      "Learning rate:  0.0001\n",
      "8/8 [==============================] - 6s 707ms/step - loss: 0.4455 - accuracy: 0.9792 - val_loss: 24.2826 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 86/100\n",
      "Learning rate:  0.0001\n",
      "8/8 [==============================] - 6s 741ms/step - loss: 0.4452 - accuracy: 0.9667 - val_loss: 24.3158 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 87/100\n",
      "Learning rate:  0.0001\n",
      "8/8 [==============================] - 6s 727ms/step - loss: 0.4282 - accuracy: 0.9792 - val_loss: 25.0614 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 88/100\n",
      "Learning rate:  0.0001\n",
      "8/8 [==============================] - 6s 715ms/step - loss: 0.4291 - accuracy: 0.9875 - val_loss: 24.9653 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 89/100\n",
      "Learning rate:  0.0001\n",
      "8/8 [==============================] - 6s 710ms/step - loss: 0.4534 - accuracy: 0.9708 - val_loss: 24.4844 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 90/100\n",
      "Learning rate:  0.0001\n",
      "8/8 [==============================] - 6s 727ms/step - loss: 0.4270 - accuracy: 0.9792 - val_loss: 24.7567 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 91/100\n",
      "Learning rate:  0.0001\n",
      "8/8 [==============================] - 6s 718ms/step - loss: 0.4220 - accuracy: 0.9750 - val_loss: 25.2686 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 92/100\n",
      "Learning rate:  0.0001\n",
      "8/8 [==============================] - 6s 777ms/step - loss: 0.4208 - accuracy: 0.9875 - val_loss: 24.7701 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 93/100\n",
      "Learning rate:  0.0001\n",
      "8/8 [==============================] - 6s 858ms/step - loss: 0.4553 - accuracy: 0.9750 - val_loss: 23.4364 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 94/100\n",
      "Learning rate:  0.0001\n",
      "8/8 [==============================] - 6s 775ms/step - loss: 0.4297 - accuracy: 0.9833 - val_loss: 22.8452 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 95/100\n",
      "Learning rate:  0.0001\n",
      "8/8 [==============================] - 7s 874ms/step - loss: 0.4095 - accuracy: 0.9833 - val_loss: 22.9859 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 96/100\n",
      "Learning rate:  0.0001\n",
      "8/8 [==============================] - 6s 711ms/step - loss: 0.4199 - accuracy: 0.9833 - val_loss: 23.9497 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 97/100\n",
      "Learning rate:  0.0001\n",
      "8/8 [==============================] - 6s 730ms/step - loss: 0.4153 - accuracy: 0.9792 - val_loss: 24.7281 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 98/100\n",
      "Learning rate:  0.0001\n",
      "8/8 [==============================] - 6s 713ms/step - loss: 0.4168 - accuracy: 0.9833 - val_loss: 24.8080 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 99/100\n",
      "Learning rate:  0.0001\n",
      "8/8 [==============================] - 6s 709ms/step - loss: 0.4378 - accuracy: 0.9625 - val_loss: 23.5862 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 100/100\n",
      "Learning rate:  0.0001\n",
      "8/8 [==============================] - 6s 715ms/step - loss: 0.4006 - accuracy: 0.9917 - val_loss: 22.4180 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.9084 - accuracy: 0.8667\n",
      "Test loss: 0.9084187746047974\n",
      "Test accuracy: 0.8666666746139526\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000001C1AC05FC10> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "[2, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 2, 2, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Precision:  1.0\n",
      "Recall:  0.8666666666666667\n",
      "F1 Score:  0.9263157894736842\n",
      "[[[[  5   5   5]\n",
      "   [ 21  21  21]\n",
      "   [ 13  13  13]\n",
      "   ...\n",
      "   [  7   7   7]\n",
      "   [  5   5   5]\n",
      "   [  2   2   2]]\n",
      "\n",
      "  [[ 23  23  23]\n",
      "   [ 14  14  14]\n",
      "   [  9   9   9]\n",
      "   ...\n",
      "   [  1   1   1]\n",
      "   [  0   0   0]\n",
      "   [  0   0   0]]\n",
      "\n",
      "  [[ 23  23  23]\n",
      "   [ 14  14  14]\n",
      "   [  9   9   9]\n",
      "   ...\n",
      "   [  0   0   0]\n",
      "   [  0   0   0]\n",
      "   [  0   0   0]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[ 29  29  29]\n",
      "   [ 17  17  17]\n",
      "   [ 10  10  10]\n",
      "   ...\n",
      "   [  0   0   0]\n",
      "   [  0   0   0]\n",
      "   [  0   0   0]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [ 17  17  17]\n",
      "   [ 12  12  12]\n",
      "   ...\n",
      "   [  0   0   0]\n",
      "   [  0   0   0]\n",
      "   [  0   0   0]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [ 14  14  14]\n",
      "   ...\n",
      "   [  7   7   7]\n",
      "   [  6   6   6]\n",
      "   [  6   6   6]]]\n",
      "\n",
      "\n",
      " [[[108 108 108]\n",
      "   [117 117 117]\n",
      "   [116 116 116]\n",
      "   ...\n",
      "   [  1   1   1]\n",
      "   [  1   1   1]\n",
      "   [  1   1   1]]\n",
      "\n",
      "  [[112 112 112]\n",
      "   [108 108 108]\n",
      "   [115 115 115]\n",
      "   ...\n",
      "   [  1   1   1]\n",
      "   [  1   1   1]\n",
      "   [  1   1   1]]\n",
      "\n",
      "  [[117 117 117]\n",
      "   [112 112 112]\n",
      "   [110 110 110]\n",
      "   ...\n",
      "   [  1   1   1]\n",
      "   [  1   1   1]\n",
      "   [  1   1   1]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[ 25  25  25]\n",
      "   [ 17  17  17]\n",
      "   [ 10  10  10]\n",
      "   ...\n",
      "   [  0   0   0]\n",
      "   [  0   0   0]\n",
      "   [  0   0   0]]\n",
      "\n",
      "  [[ 24  24  24]\n",
      "   [ 18  18  18]\n",
      "   [ 11  11  11]\n",
      "   ...\n",
      "   [  0   0   0]\n",
      "   [  0   0   0]\n",
      "   [  0   0   0]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [ 19  19  19]\n",
      "   [ 19  19  19]\n",
      "   ...\n",
      "   [  6   6   6]\n",
      "   [  6   6   6]\n",
      "   [  6   6   6]]]\n",
      "\n",
      "\n",
      " [[[  1   1   1]\n",
      "   [  7   7   7]\n",
      "   [  4   4   4]\n",
      "   ...\n",
      "   [  0   0   0]\n",
      "   [  0   0   0]\n",
      "   [  0   0   0]]\n",
      "\n",
      "  [[ 21  21  21]\n",
      "   [ 15  15  15]\n",
      "   [ 11  11  11]\n",
      "   ...\n",
      "   [  4   4   4]\n",
      "   [  7   7   7]\n",
      "   [ 12  12  12]]\n",
      "\n",
      "  [[ 19  19  19]\n",
      "   [ 15  15  15]\n",
      "   [ 11  11  11]\n",
      "   ...\n",
      "   [  4   4   4]\n",
      "   [  6   6   6]\n",
      "   [ 11  11  11]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[ 28  28  28]\n",
      "   [ 19  19  19]\n",
      "   [ 10  10  10]\n",
      "   ...\n",
      "   [  0   0   0]\n",
      "   [  0   0   0]\n",
      "   [  1   1   1]]\n",
      "\n",
      "  [[ 22  22  22]\n",
      "   [ 14  14  14]\n",
      "   [ 10  10  10]\n",
      "   ...\n",
      "   [  0   0   0]\n",
      "   [  0   0   0]\n",
      "   [  1   1   1]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [ 35  35  35]\n",
      "   [ 23  23  23]\n",
      "   ...\n",
      "   [  0   0   0]\n",
      "   [  0   0   0]\n",
      "   [  0   0   0]]]]\n",
      "[[1]\n",
      " [1]\n",
      " [1]]\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "(40, 30, 3)\n",
      "x_train shape: (240, 40, 30, 3)\n",
      "240 train samples\n",
      "30 test samples\n",
      "y_train shape: (240, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\patcas rares\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate:  0.001\n",
      "Model: \"model_5\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_6 (InputLayer)            [(None, 40, 30, 3)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_155 (Conv2D)             (None, 40, 30, 16)   448         input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_140 (BatchN (None, 40, 30, 16)   64          conv2d_155[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_140 (Activation)     (None, 40, 30, 16)   0           batch_normalization_140[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_156 (Conv2D)             (None, 40, 30, 16)   272         activation_140[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_141 (BatchN (None, 40, 30, 16)   64          conv2d_156[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_141 (Activation)     (None, 40, 30, 16)   0           batch_normalization_141[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_157 (Conv2D)             (None, 40, 30, 16)   2320        activation_141[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_142 (BatchN (None, 40, 30, 16)   64          conv2d_157[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_142 (Activation)     (None, 40, 30, 16)   0           batch_normalization_142[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_159 (Conv2D)             (None, 40, 30, 64)   1088        activation_140[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_158 (Conv2D)             (None, 40, 30, 64)   1088        activation_142[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_45 (Add)                    (None, 40, 30, 64)   0           conv2d_159[0][0]                 \n",
      "                                                                 conv2d_158[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_143 (BatchN (None, 40, 30, 64)   256         add_45[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_143 (Activation)     (None, 40, 30, 64)   0           batch_normalization_143[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_160 (Conv2D)             (None, 40, 30, 16)   1040        activation_143[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_144 (BatchN (None, 40, 30, 16)   64          conv2d_160[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_144 (Activation)     (None, 40, 30, 16)   0           batch_normalization_144[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_161 (Conv2D)             (None, 40, 30, 16)   2320        activation_144[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_145 (BatchN (None, 40, 30, 16)   64          conv2d_161[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_145 (Activation)     (None, 40, 30, 16)   0           batch_normalization_145[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_162 (Conv2D)             (None, 40, 30, 64)   1088        activation_145[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_46 (Add)                    (None, 40, 30, 64)   0           add_45[0][0]                     \n",
      "                                                                 conv2d_162[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_146 (BatchN (None, 40, 30, 64)   256         add_46[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_146 (Activation)     (None, 40, 30, 64)   0           batch_normalization_146[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_163 (Conv2D)             (None, 40, 30, 16)   1040        activation_146[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_147 (BatchN (None, 40, 30, 16)   64          conv2d_163[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_147 (Activation)     (None, 40, 30, 16)   0           batch_normalization_147[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_164 (Conv2D)             (None, 40, 30, 16)   2320        activation_147[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_148 (BatchN (None, 40, 30, 16)   64          conv2d_164[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_148 (Activation)     (None, 40, 30, 16)   0           batch_normalization_148[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_165 (Conv2D)             (None, 40, 30, 64)   1088        activation_148[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_47 (Add)                    (None, 40, 30, 64)   0           add_46[0][0]                     \n",
      "                                                                 conv2d_165[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_149 (BatchN (None, 40, 30, 64)   256         add_47[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_149 (Activation)     (None, 40, 30, 64)   0           batch_normalization_149[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_166 (Conv2D)             (None, 20, 15, 64)   4160        activation_149[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_150 (BatchN (None, 20, 15, 64)   256         conv2d_166[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_150 (Activation)     (None, 20, 15, 64)   0           batch_normalization_150[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_167 (Conv2D)             (None, 20, 15, 64)   36928       activation_150[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_151 (BatchN (None, 20, 15, 64)   256         conv2d_167[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_151 (Activation)     (None, 20, 15, 64)   0           batch_normalization_151[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_169 (Conv2D)             (None, 20, 15, 128)  8320        add_47[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_168 (Conv2D)             (None, 20, 15, 128)  8320        activation_151[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_48 (Add)                    (None, 20, 15, 128)  0           conv2d_169[0][0]                 \n",
      "                                                                 conv2d_168[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_152 (BatchN (None, 20, 15, 128)  512         add_48[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_152 (Activation)     (None, 20, 15, 128)  0           batch_normalization_152[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_170 (Conv2D)             (None, 20, 15, 64)   8256        activation_152[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_153 (BatchN (None, 20, 15, 64)   256         conv2d_170[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_153 (Activation)     (None, 20, 15, 64)   0           batch_normalization_153[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_171 (Conv2D)             (None, 20, 15, 64)   36928       activation_153[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_154 (BatchN (None, 20, 15, 64)   256         conv2d_171[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_154 (Activation)     (None, 20, 15, 64)   0           batch_normalization_154[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_172 (Conv2D)             (None, 20, 15, 128)  8320        activation_154[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_49 (Add)                    (None, 20, 15, 128)  0           add_48[0][0]                     \n",
      "                                                                 conv2d_172[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_155 (BatchN (None, 20, 15, 128)  512         add_49[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_155 (Activation)     (None, 20, 15, 128)  0           batch_normalization_155[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_173 (Conv2D)             (None, 20, 15, 64)   8256        activation_155[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_156 (BatchN (None, 20, 15, 64)   256         conv2d_173[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_156 (Activation)     (None, 20, 15, 64)   0           batch_normalization_156[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_174 (Conv2D)             (None, 20, 15, 64)   36928       activation_156[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_157 (BatchN (None, 20, 15, 64)   256         conv2d_174[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_157 (Activation)     (None, 20, 15, 64)   0           batch_normalization_157[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_175 (Conv2D)             (None, 20, 15, 128)  8320        activation_157[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_50 (Add)                    (None, 20, 15, 128)  0           add_49[0][0]                     \n",
      "                                                                 conv2d_175[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_158 (BatchN (None, 20, 15, 128)  512         add_50[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_158 (Activation)     (None, 20, 15, 128)  0           batch_normalization_158[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_176 (Conv2D)             (None, 10, 8, 128)   16512       activation_158[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_159 (BatchN (None, 10, 8, 128)   512         conv2d_176[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_159 (Activation)     (None, 10, 8, 128)   0           batch_normalization_159[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_177 (Conv2D)             (None, 10, 8, 128)   147584      activation_159[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_160 (BatchN (None, 10, 8, 128)   512         conv2d_177[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_160 (Activation)     (None, 10, 8, 128)   0           batch_normalization_160[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_179 (Conv2D)             (None, 10, 8, 256)   33024       add_50[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_178 (Conv2D)             (None, 10, 8, 256)   33024       activation_160[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_51 (Add)                    (None, 10, 8, 256)   0           conv2d_179[0][0]                 \n",
      "                                                                 conv2d_178[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_161 (BatchN (None, 10, 8, 256)   1024        add_51[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_161 (Activation)     (None, 10, 8, 256)   0           batch_normalization_161[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_180 (Conv2D)             (None, 10, 8, 128)   32896       activation_161[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_162 (BatchN (None, 10, 8, 128)   512         conv2d_180[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_162 (Activation)     (None, 10, 8, 128)   0           batch_normalization_162[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_181 (Conv2D)             (None, 10, 8, 128)   147584      activation_162[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_163 (BatchN (None, 10, 8, 128)   512         conv2d_181[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_163 (Activation)     (None, 10, 8, 128)   0           batch_normalization_163[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_182 (Conv2D)             (None, 10, 8, 256)   33024       activation_163[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_52 (Add)                    (None, 10, 8, 256)   0           add_51[0][0]                     \n",
      "                                                                 conv2d_182[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_164 (BatchN (None, 10, 8, 256)   1024        add_52[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_164 (Activation)     (None, 10, 8, 256)   0           batch_normalization_164[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_183 (Conv2D)             (None, 10, 8, 128)   32896       activation_164[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_165 (BatchN (None, 10, 8, 128)   512         conv2d_183[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_165 (Activation)     (None, 10, 8, 128)   0           batch_normalization_165[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_184 (Conv2D)             (None, 10, 8, 128)   147584      activation_165[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_166 (BatchN (None, 10, 8, 128)   512         conv2d_184[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_166 (Activation)     (None, 10, 8, 128)   0           batch_normalization_166[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_185 (Conv2D)             (None, 10, 8, 256)   33024       activation_166[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_53 (Add)                    (None, 10, 8, 256)   0           add_52[0][0]                     \n",
      "                                                                 conv2d_185[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_167 (BatchN (None, 10, 8, 256)   1024        add_53[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_167 (Activation)     (None, 10, 8, 256)   0           batch_normalization_167[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_5 (AveragePoo (None, 1, 1, 256)    0           activation_167[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "flatten_5 (Flatten)             (None, 256)          0           average_pooling2d_5[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 10)           2570        flatten_5[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 849,002\n",
      "Trainable params: 843,786\n",
      "Non-trainable params: 5,216\n",
      "__________________________________________________________________________________________________\n",
      "ResNet  29v  2\n",
      "Using real-time data augmentation.\n",
      "------------------\n",
      "[[[[-0.12176463 -0.12176463 -0.12176463]\n",
      "   [-0.06348031 -0.06348031 -0.06348031]\n",
      "   [-0.08478749 -0.08478749 -0.08478749]\n",
      "   ...\n",
      "   [-0.15683009 -0.15683009 -0.15683009]\n",
      "   [-0.17401959 -0.17401959 -0.17401959]\n",
      "   [-0.19696078 -0.19696078 -0.19696078]]\n",
      "\n",
      "  [[-0.04478753 -0.04478753 -0.04478753]\n",
      "   [-0.06535938 -0.06535938 -0.06535938]\n",
      "   [-0.08334956 -0.08334956 -0.08334956]\n",
      "   ...\n",
      "   [-0.14683    -0.14683    -0.14683   ]\n",
      "   [-0.15482026 -0.15482026 -0.15482026]\n",
      "   [-0.16473852 -0.16473852 -0.16473852]]\n",
      "\n",
      "  [[-0.05222217 -0.05222217 -0.05222217]\n",
      "   [-0.07669929 -0.07669929 -0.07669929]\n",
      "   [-0.08488555 -0.08488555 -0.08488555]\n",
      "   ...\n",
      "   [-0.15826796 -0.15826796 -0.15826796]\n",
      "   [-0.1657353  -0.1657353  -0.1657353 ]\n",
      "   [-0.16986918 -0.16986918 -0.16986918]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[ 0.0101634   0.0101634   0.0101634 ]\n",
      "   [-0.02612737 -0.02612737 -0.02612737]\n",
      "   [-0.03464043 -0.03464043 -0.03464043]\n",
      "   ...\n",
      "   [-0.07857838 -0.07857838 -0.07857838]\n",
      "   [-0.08531042 -0.08531042 -0.08531042]\n",
      "   [-0.10913403 -0.10913403 -0.10913403]]\n",
      "\n",
      "  [[ 0.40034318  0.40034318  0.40034318]\n",
      "   [-0.02552278 -0.02552278 -0.02552278]\n",
      "   [-0.0301633  -0.0301633  -0.0301633 ]\n",
      "   ...\n",
      "   [-0.07908491 -0.07908491 -0.07908491]\n",
      "   [-0.08341499 -0.08341499 -0.08341499]\n",
      "   [-0.11655233 -0.11655233 -0.11655233]]\n",
      "\n",
      "  [[ 0.28504908  0.28504908  0.28504908]\n",
      "   [ 0.3215524   0.3215524   0.3215524 ]\n",
      "   [-0.115245   -0.115245   -0.115245  ]\n",
      "   ...\n",
      "   [-0.13374177 -0.13374177 -0.13374177]\n",
      "   [-0.15856203 -0.15856203 -0.15856203]\n",
      "   [-0.18869269 -0.18869269 -0.18869269]]]\n",
      "\n",
      "\n",
      " [[[ 0.28215694  0.28215694  0.28215694]\n",
      "   [ 0.31299028  0.31299028  0.31299028]\n",
      "   [ 0.3191341   0.3191341   0.3191341 ]\n",
      "   ...\n",
      "   [-0.1803595  -0.1803595  -0.1803595 ]\n",
      "   [-0.18970586 -0.18970586 -0.18970586]\n",
      "   [-0.20088235 -0.20088235 -0.20088235]]\n",
      "\n",
      "  [[ 0.30423206  0.30423206  0.30423206]\n",
      "   [ 0.30326807  0.30326807  0.30326807]\n",
      "   [ 0.33233672  0.33233672  0.33233672]\n",
      "   ...\n",
      "   [-0.14683    -0.14683    -0.14683   ]\n",
      "   [-0.1508987  -0.1508987  -0.1508987 ]\n",
      "   [-0.16081695 -0.16081695 -0.16081695]]\n",
      "\n",
      "  [[ 0.3164053   0.3164053   0.3164053 ]\n",
      "   [ 0.30761445  0.30761445  0.30761445]\n",
      "   [ 0.31119287  0.31119287  0.31119287]\n",
      "   ...\n",
      "   [-0.15434639 -0.15434639 -0.15434639]\n",
      "   [-0.16181374 -0.16181374 -0.16181374]\n",
      "   [-0.16594762 -0.16594762 -0.16594762]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[-0.00552288 -0.00552288 -0.00552288]\n",
      "   [-0.02612737 -0.02612737 -0.02612737]\n",
      "   [-0.03464043 -0.03464043 -0.03464043]\n",
      "   ...\n",
      "   [-0.07857838 -0.07857838 -0.07857838]\n",
      "   [-0.08531042 -0.08531042 -0.08531042]\n",
      "   [-0.10913403 -0.10913403 -0.10913403]]\n",
      "\n",
      "  [[-0.0075     -0.0075     -0.0075    ]\n",
      "   [-0.02160121 -0.02160121 -0.02160121]\n",
      "   [-0.03408487 -0.03408487 -0.03408487]\n",
      "   ...\n",
      "   [-0.07908491 -0.07908491 -0.07908491]\n",
      "   [-0.08341499 -0.08341499 -0.08341499]\n",
      "   [-0.11655233 -0.11655233 -0.11655233]]\n",
      "\n",
      "  [[ 0.28504908  0.28504908  0.28504908]\n",
      "   [-0.10589861 -0.10589861 -0.10589861]\n",
      "   [-0.09563715 -0.09563715 -0.09563715]\n",
      "   ...\n",
      "   [-0.13766333 -0.13766333 -0.13766333]\n",
      "   [-0.15856203 -0.15856203 -0.15856203]\n",
      "   [-0.18869269 -0.18869269 -0.18869269]]]\n",
      "\n",
      "\n",
      " [[[-0.1374509  -0.1374509  -0.1374509 ]\n",
      "   [-0.11838228 -0.11838228 -0.11838228]\n",
      "   [-0.1200816  -0.1200816  -0.1200816 ]\n",
      "   ...\n",
      "   [-0.18428107 -0.18428107 -0.18428107]\n",
      "   [-0.19362743 -0.19362743 -0.19362743]\n",
      "   [-0.20480391 -0.20480391 -0.20480391]]\n",
      "\n",
      "  [[-0.05263067 -0.05263067 -0.05263067]\n",
      "   [-0.06143782 -0.06143782 -0.06143782]\n",
      "   [-0.07550642 -0.07550642 -0.07550642]\n",
      "   ...\n",
      "   [-0.1350653  -0.1350653  -0.1350653 ]\n",
      "   [-0.12736928 -0.12736928 -0.12736928]\n",
      "   [-0.1176797  -0.1176797  -0.1176797 ]]\n",
      "\n",
      "  [[-0.06790844 -0.06790844 -0.06790844]\n",
      "   [-0.07277772 -0.07277772 -0.07277772]\n",
      "   [-0.07704242 -0.07704242 -0.07704242]\n",
      "   ...\n",
      "   [-0.14258169 -0.14258169 -0.14258169]\n",
      "   [-0.1422059  -0.1422059  -0.1422059 ]\n",
      "   [-0.12673193 -0.12673193 -0.12673193]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[ 0.00624183  0.00624183  0.00624183]\n",
      "   [-0.01828423 -0.01828423 -0.01828423]\n",
      "   [-0.03464043 -0.03464043 -0.03464043]\n",
      "   ...\n",
      "   [-0.07857838 -0.07857838 -0.07857838]\n",
      "   [-0.08531042 -0.08531042 -0.08531042]\n",
      "   [-0.10521246 -0.10521246 -0.10521246]]\n",
      "\n",
      "  [[-0.01534314 -0.01534314 -0.01534314]\n",
      "   [-0.03728748 -0.03728748 -0.03728748]\n",
      "   [-0.03800644 -0.03800644 -0.03800644]\n",
      "   ...\n",
      "   [-0.07908491 -0.07908491 -0.07908491]\n",
      "   [-0.08341499 -0.08341499 -0.08341499]\n",
      "   [-0.11263076 -0.11263076 -0.11263076]]\n",
      "\n",
      "  [[ 0.28504908  0.28504908  0.28504908]\n",
      "   [-0.04315351 -0.04315351 -0.04315351]\n",
      "   [-0.07995088 -0.07995088 -0.07995088]\n",
      "   ...\n",
      "   [-0.16119274 -0.16119274 -0.16119274]\n",
      "   [-0.18209144 -0.18209144 -0.18209144]\n",
      "   [-0.2122221  -0.2122221  -0.2122221 ]]]\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      " [[[-0.0629411  -0.0629411  -0.0629411 ]\n",
      "   [ 0.0227942   0.0227942   0.0227942 ]\n",
      "   [-0.10047376 -0.10047376 -0.10047376]\n",
      "   ...\n",
      "   [-0.14114381 -0.14114381 -0.14114381]\n",
      "   [-0.1348039  -0.1348039  -0.1348039 ]\n",
      "   [ 0.2971569   0.2971569   0.2971569 ]]\n",
      "\n",
      "  [[-0.05263067 -0.05263067 -0.05263067]\n",
      "   [-0.06928095 -0.06928095 -0.06928095]\n",
      "   [-0.07942799 -0.07942799 -0.07942799]\n",
      "   ...\n",
      "   [-0.11937903 -0.11937903 -0.11937903]\n",
      "   [-0.09991831 -0.09991831 -0.09991831]\n",
      "   [-0.09807185 -0.09807185 -0.09807185]]\n",
      "\n",
      "  [[-0.06006531 -0.06006531 -0.06006531]\n",
      "   [-0.08062086 -0.08062086 -0.08062086]\n",
      "   [-0.08096398 -0.08096398 -0.08096398]\n",
      "   ...\n",
      "   [-0.13081698 -0.13081698 -0.13081698]\n",
      "   [-0.11083335 -0.11083335 -0.11083335]\n",
      "   [-0.09928095 -0.09928095 -0.09928095]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[-0.06042484 -0.06042484 -0.06042484]\n",
      "   [-0.05749992 -0.05749992 -0.05749992]\n",
      "   [-0.04248356 -0.04248356 -0.04248356]\n",
      "   ...\n",
      "   [-0.0511274  -0.0511274  -0.0511274 ]\n",
      "   [-0.03433003 -0.03433003 -0.03433003]\n",
      "   [-0.03070265 -0.03070265 -0.03070265]]\n",
      "\n",
      "  [[-0.05455882 -0.05455882 -0.05455882]\n",
      "   [-0.05689533 -0.05689533 -0.05689533]\n",
      "   [-0.04584957 -0.04584957 -0.04584957]\n",
      "   ...\n",
      "   [-0.05163393 -0.05163393 -0.05163393]\n",
      "   [-0.0324346  -0.0324346  -0.0324346 ]\n",
      "   [-0.03812096 -0.03812096 -0.03812096]]\n",
      "\n",
      "  [[ 0.17132358  0.17132358  0.17132358]\n",
      "   [ 0.12939551  0.12939551  0.12939551]\n",
      "   [ 0.08867659  0.08867659  0.08867659]\n",
      "   ...\n",
      "   [-0.03962412 -0.03962412 -0.03962412]\n",
      "   [-0.0369934  -0.0369934  -0.0369934 ]\n",
      "   [-0.1259476  -0.1259476  -0.1259476 ]]]\n",
      "\n",
      "\n",
      " [[[-0.0747058  -0.0747058  -0.0747058 ]\n",
      "   [ 0.35612756  0.35612756  0.35612756]\n",
      "   [-0.13576788 -0.13576788 -0.13576788]\n",
      "   ...\n",
      "   [ 0.31767976  0.31767976  0.31767976]\n",
      "   [ 0.3083334   0.3083334   0.3083334 ]\n",
      "   [ 0.2971569   0.2971569   0.2971569 ]]\n",
      "\n",
      "  [[-0.05655224 -0.05655224 -0.05655224]\n",
      "   [-0.08104566 -0.08104566 -0.08104566]\n",
      "   [-0.0911927  -0.0911927  -0.0911927 ]\n",
      "   ...\n",
      "   [ 0.25317     0.25317     0.25317   ]\n",
      "   [ 0.29616013  0.29616013  0.29616013]\n",
      "   [ 0.31761444  0.31761444  0.31761444]]\n",
      "\n",
      "  [[-0.06398688 -0.06398688 -0.06398688]\n",
      "   [-0.08454242 -0.08454242 -0.08454242]\n",
      "   [-0.08880712 -0.08880712 -0.08880712]\n",
      "   ...\n",
      "   [ 0.24957518  0.24957518  0.24957518]\n",
      "   [ 0.26563725  0.26563725  0.26563725]\n",
      "   [ 0.27326807  0.27326807  0.27326807]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[-0.0643464  -0.0643464  -0.0643464 ]\n",
      "   [-0.06534306 -0.06534306 -0.06534306]\n",
      "   [-0.0503267  -0.0503267  -0.0503267 ]\n",
      "   ...\n",
      "   [ 0.18024516  0.18024516  0.18024516]\n",
      "   [-0.01472218 -0.01472218 -0.01472218]\n",
      "   [ 0.00851303  0.00851303  0.00851303]]\n",
      "\n",
      "  [[-0.05848039 -0.05848039 -0.05848039]\n",
      "   [-0.06473847 -0.06473847 -0.06473847]\n",
      "   [-0.05369271 -0.05369271 -0.05369271]\n",
      "   ...\n",
      "   [-0.0555555  -0.0555555  -0.0555555 ]\n",
      "   [-0.03635617 -0.03635617 -0.03635617]\n",
      "   [-0.00282684 -0.00282684 -0.00282684]]\n",
      "\n",
      "  [[-0.17377447 -0.17377447 -0.17377447]\n",
      "   [-0.15295744 -0.15295744 -0.15295744]\n",
      "   [-0.15053912 -0.15053912 -0.15053912]\n",
      "   ...\n",
      "   [-0.13766333 -0.13766333 -0.13766333]\n",
      "   [-0.12718949 -0.12718949 -0.12718949]\n",
      "   [-0.11810445 -0.11810445 -0.11810445]]]\n",
      "\n",
      "\n",
      " [[[-0.03156855 -0.03156855 -0.03156855]\n",
      "   [-0.05563717 -0.05563717 -0.05563717]\n",
      "   [-0.06517964 -0.06517964 -0.06517964]\n",
      "   ...\n",
      "   [-0.18428107 -0.18428107 -0.18428107]\n",
      "   [-0.19362743 -0.19362743 -0.19362743]\n",
      "   [-0.20088235 -0.20088235 -0.20088235]]\n",
      "\n",
      "  [[-0.03302283 -0.03302283 -0.03302283]\n",
      "   [-0.0261437  -0.0261437  -0.0261437 ]\n",
      "   [-0.04805544 -0.04805544 -0.04805544]\n",
      "   ...\n",
      "   [-0.15075158 -0.15075158 -0.15075158]\n",
      "   [-0.15482026 -0.15482026 -0.15482026]\n",
      "   [-0.16081695 -0.16081695 -0.16081695]]\n",
      "\n",
      "  [[-0.05222217 -0.05222217 -0.05222217]\n",
      "   [-0.02571889 -0.02571889 -0.02571889]\n",
      "   [-0.04959143 -0.04959143 -0.04959143]\n",
      "   ...\n",
      "   [-0.15826796 -0.15826796 -0.15826796]\n",
      "   [-0.1657353  -0.1657353  -0.1657353 ]\n",
      "   [-0.16986918 -0.16986918 -0.16986918]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[ 0.02584968  0.02584968  0.02584968]\n",
      "   [ 0.00132361  0.00132361  0.00132361]\n",
      "   [-0.00326788 -0.00326788 -0.00326788]\n",
      "   ...\n",
      "   [-0.07857838 -0.07857838 -0.07857838]\n",
      "   [-0.08531042 -0.08531042 -0.08531042]\n",
      "   [-0.10913403 -0.10913403 -0.10913403]]\n",
      "\n",
      "  [[ 0.02779412  0.02779412  0.02779412]\n",
      "   [-0.00199337 -0.00199337 -0.00199337]\n",
      "   [-0.01055545 -0.01055545 -0.01055545]\n",
      "   ...\n",
      "   [-0.07908491 -0.07908491 -0.07908491]\n",
      "   [-0.08341499 -0.08341499 -0.08341499]\n",
      "   [-0.11655233 -0.11655233 -0.11655233]]\n",
      "\n",
      "  [[-0.11102936 -0.11102936 -0.11102936]\n",
      "   [-0.08629077 -0.08629077 -0.08629077]\n",
      "   [-0.09955872 -0.09955872 -0.09955872]\n",
      "   ...\n",
      "   [-0.16119274 -0.16119274 -0.16119274]\n",
      "   [-0.18209144 -0.18209144 -0.18209144]\n",
      "   [-0.2122221  -0.2122221  -0.2122221 ]]]]\n",
      "Epoch 1/100\n",
      "Learning rate:  0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\patcas rares\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\keras\\engine\\training.py:1972: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 11s 834ms/step - loss: 2.3610 - accuracy: 0.4208 - val_loss: 4.0334 - val_accuracy: 0.0667\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 2/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 706ms/step - loss: 1.3200 - accuracy: 0.7042 - val_loss: 2.4527 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 3/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 757ms/step - loss: 1.2035 - accuracy: 0.7292 - val_loss: 2.5474 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 4/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 781ms/step - loss: 1.1764 - accuracy: 0.7333 - val_loss: 2.8896 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 5/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 732ms/step - loss: 1.0848 - accuracy: 0.7583 - val_loss: 3.3240 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 6/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 708ms/step - loss: 1.0658 - accuracy: 0.7708 - val_loss: 3.5039 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 7/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 726ms/step - loss: 1.0777 - accuracy: 0.7333 - val_loss: 4.0949 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 8/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 725ms/step - loss: 1.0852 - accuracy: 0.7250 - val_loss: 4.3804 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 9/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 787ms/step - loss: 1.0724 - accuracy: 0.7542 - val_loss: 4.6625 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 10/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 713ms/step - loss: 1.0267 - accuracy: 0.8083 - val_loss: 6.7425 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 11/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 7s 917ms/step - loss: 1.0534 - accuracy: 0.7583 - val_loss: 6.1459 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 12/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 745ms/step - loss: 0.9847 - accuracy: 0.7875 - val_loss: 8.0612 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 13/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 7s 866ms/step - loss: 0.9502 - accuracy: 0.8208 - val_loss: 8.0899 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 14/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 717ms/step - loss: 0.9660 - accuracy: 0.7833 - val_loss: 4.4770 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 15/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 721ms/step - loss: 0.9710 - accuracy: 0.8125 - val_loss: 5.2306 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 16/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 714ms/step - loss: 0.9947 - accuracy: 0.7792 - val_loss: 10.8812 - val_accuracy: 0.0667\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 17/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 735ms/step - loss: 0.9301 - accuracy: 0.8375 - val_loss: 3.3512 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 18/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 716ms/step - loss: 0.9233 - accuracy: 0.8042 - val_loss: 1.0356 - val_accuracy: 0.9333\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 19/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 707ms/step - loss: 0.9113 - accuracy: 0.8000 - val_loss: 9.2019 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 20/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 712ms/step - loss: 0.9437 - accuracy: 0.8208 - val_loss: 7.5152 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 21/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 719ms/step - loss: 0.8595 - accuracy: 0.8458 - val_loss: 6.0992 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 22/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 712ms/step - loss: 0.8811 - accuracy: 0.8208 - val_loss: 8.1957 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 23/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 708ms/step - loss: 0.8771 - accuracy: 0.8167 - val_loss: 7.6620 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 24/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 764ms/step - loss: 0.8762 - accuracy: 0.8000 - val_loss: 10.1073 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 25/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 716ms/step - loss: 0.8206 - accuracy: 0.8542 - val_loss: 10.3740 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 26/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 717ms/step - loss: 0.7766 - accuracy: 0.8875 - val_loss: 18.2803 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 27/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 709ms/step - loss: 0.8372 - accuracy: 0.8333 - val_loss: 14.2641 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 28/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 737ms/step - loss: 0.9124 - accuracy: 0.8042 - val_loss: 14.6829 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 29/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 803ms/step - loss: 0.8275 - accuracy: 0.8542 - val_loss: 8.8285 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 30/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 7s 825ms/step - loss: 0.7993 - accuracy: 0.8708 - val_loss: 10.4634 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 31/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 792ms/step - loss: 0.8706 - accuracy: 0.7917 - val_loss: 12.5590 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 32/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 725ms/step - loss: 0.8421 - accuracy: 0.8417 - val_loss: 17.1414 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 33/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 708ms/step - loss: 0.8090 - accuracy: 0.8500 - val_loss: 11.2511 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 34/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 718ms/step - loss: 0.7592 - accuracy: 0.8583 - val_loss: 13.6476 - val_accuracy: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 35/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 718ms/step - loss: 0.7954 - accuracy: 0.8333 - val_loss: 15.3519 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 36/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 710ms/step - loss: 0.7388 - accuracy: 0.8625 - val_loss: 12.0815 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 37/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 704ms/step - loss: 0.7819 - accuracy: 0.8500 - val_loss: 16.0374 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 38/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 776ms/step - loss: 0.7302 - accuracy: 0.8833 - val_loss: 17.2687 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 39/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 730ms/step - loss: 0.6889 - accuracy: 0.8958 - val_loss: 13.4970 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 40/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 769ms/step - loss: 0.7420 - accuracy: 0.8792 - val_loss: 17.1060 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 41/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 804ms/step - loss: 0.7459 - accuracy: 0.8583 - val_loss: 12.3455 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 42/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 799ms/step - loss: 0.6811 - accuracy: 0.8708 - val_loss: 15.8997 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 43/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 749ms/step - loss: 0.6920 - accuracy: 0.8958 - val_loss: 24.4336 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 44/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 708ms/step - loss: 0.6860 - accuracy: 0.8917 - val_loss: 19.1932 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 45/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 715ms/step - loss: 0.7035 - accuracy: 0.8875 - val_loss: 11.0840 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 46/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 729ms/step - loss: 0.7063 - accuracy: 0.8750 - val_loss: 19.5819 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 47/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 706ms/step - loss: 0.7254 - accuracy: 0.8958 - val_loss: 25.2728 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 48/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 7s 825ms/step - loss: 0.6942 - accuracy: 0.8792 - val_loss: 19.8252 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 49/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 716ms/step - loss: 0.7298 - accuracy: 0.8833 - val_loss: 22.9095 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 50/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 717ms/step - loss: 0.6762 - accuracy: 0.8792 - val_loss: 12.2768 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 51/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 686ms/step - loss: 0.7255 - accuracy: 0.8625 - val_loss: 22.6152 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 52/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 5s 619ms/step - loss: 0.6168 - accuracy: 0.8958 - val_loss: 27.3499 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 53/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 5s 606ms/step - loss: 0.6076 - accuracy: 0.9292 - val_loss: 13.1118 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 54/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 5s 648ms/step - loss: 0.6359 - accuracy: 0.8958 - val_loss: 18.0326 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 55/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 5s 598ms/step - loss: 0.6081 - accuracy: 0.9375 - val_loss: 22.9858 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 56/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 5s 645ms/step - loss: 0.7537 - accuracy: 0.8375 - val_loss: 24.5751 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 57/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 5s 608ms/step - loss: 0.6140 - accuracy: 0.9167 - val_loss: 23.1832 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 58/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 5s 604ms/step - loss: 0.6427 - accuracy: 0.9000 - val_loss: 26.5256 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 59/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 5s 643ms/step - loss: 0.6067 - accuracy: 0.9083 - val_loss: 28.2018 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 60/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 5s 608ms/step - loss: 0.5951 - accuracy: 0.9042 - val_loss: 22.9206 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 61/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 760ms/step - loss: 0.5947 - accuracy: 0.8875 - val_loss: 31.8020 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 62/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 5s 623ms/step - loss: 0.6621 - accuracy: 0.8667 - val_loss: 33.9362 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 63/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 5s 626ms/step - loss: 0.5890 - accuracy: 0.9125 - val_loss: 33.4607 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 64/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 5s 611ms/step - loss: 0.6501 - accuracy: 0.9000 - val_loss: 24.9669 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 65/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 686ms/step - loss: 0.6093 - accuracy: 0.9208 - val_loss: 23.6451 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 66/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 7s 860ms/step - loss: 0.6344 - accuracy: 0.9125 - val_loss: 24.1420 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 67/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 7s 798ms/step - loss: 0.5509 - accuracy: 0.9208 - val_loss: 15.2595 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 68/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.5831 - accuracy: 0.9000 - val_loss: 16.9137 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 69/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 8s 945ms/step - loss: 0.5795 - accuracy: 0.9125 - val_loss: 15.9284 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 70/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 8s 942ms/step - loss: 0.5521 - accuracy: 0.9083 - val_loss: 18.6656 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 71/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 7s 853ms/step - loss: 0.6289 - accuracy: 0.8875 - val_loss: 20.0095 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 72/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 7s 789ms/step - loss: 0.6486 - accuracy: 0.8708 - val_loss: 14.5935 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 73/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 737ms/step - loss: 0.5497 - accuracy: 0.9292 - val_loss: 13.1773 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 74/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 683ms/step - loss: 0.5543 - accuracy: 0.9292 - val_loss: 15.8149 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 75/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 690ms/step - loss: 0.5291 - accuracy: 0.9500 - val_loss: 20.8780 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 76/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 807ms/step - loss: 0.5372 - accuracy: 0.9375 - val_loss: 25.5860 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 77/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 789ms/step - loss: 0.6011 - accuracy: 0.9042 - val_loss: 23.4144 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 78/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 7s 901ms/step - loss: 0.5502 - accuracy: 0.9250 - val_loss: 22.8960 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 79/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 7s 852ms/step - loss: 0.5432 - accuracy: 0.9417 - val_loss: 28.7071 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 80/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 7s 821ms/step - loss: 0.4845 - accuracy: 0.9500 - val_loss: 32.0117 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 81/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 7s 810ms/step - loss: 0.5102 - accuracy: 0.9417 - val_loss: 11.6419 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 82/100\n",
      "Learning rate:  0.0001\n",
      "8/8 [==============================] - 7s 842ms/step - loss: 0.5096 - accuracy: 0.9417 - val_loss: 13.8234 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 83/100\n",
      "Learning rate:  0.0001\n",
      "8/8 [==============================] - 7s 857ms/step - loss: 0.5219 - accuracy: 0.9333 - val_loss: 16.8070 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 84/100\n",
      "Learning rate:  0.0001\n",
      "8/8 [==============================] - 7s 829ms/step - loss: 0.4743 - accuracy: 0.9542 - val_loss: 18.2425 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 85/100\n",
      "Learning rate:  0.0001\n",
      "8/8 [==============================] - 6s 774ms/step - loss: 0.4747 - accuracy: 0.9583 - val_loss: 18.7769 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 86/100\n",
      "Learning rate:  0.0001\n",
      "8/8 [==============================] - 6s 776ms/step - loss: 0.4933 - accuracy: 0.9333 - val_loss: 19.1615 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 87/100\n",
      "Learning rate:  0.0001\n",
      "8/8 [==============================] - 6s 786ms/step - loss: 0.4630 - accuracy: 0.9625 - val_loss: 19.4583 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 88/100\n",
      "Learning rate:  0.0001\n",
      "8/8 [==============================] - 7s 815ms/step - loss: 0.4485 - accuracy: 0.9625 - val_loss: 20.3760 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 89/100\n",
      "Learning rate:  0.0001\n",
      "8/8 [==============================] - 6s 749ms/step - loss: 0.4378 - accuracy: 0.9708 - val_loss: 19.9201 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 90/100\n",
      "Learning rate:  0.0001\n",
      "8/8 [==============================] - 6s 716ms/step - loss: 0.4660 - accuracy: 0.9542 - val_loss: 19.0552 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 91/100\n",
      "Learning rate:  0.0001\n",
      "8/8 [==============================] - 6s 749ms/step - loss: 0.4518 - accuracy: 0.9750 - val_loss: 19.2095 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 92/100\n",
      "Learning rate:  0.0001\n",
      "8/8 [==============================] - 6s 765ms/step - loss: 0.4130 - accuracy: 0.9958 - val_loss: 19.8123 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 93/100\n",
      "Learning rate:  0.0001\n",
      "8/8 [==============================] - 6s 740ms/step - loss: 0.4526 - accuracy: 0.9542 - val_loss: 20.3020 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 94/100\n",
      "Learning rate:  0.0001\n",
      "8/8 [==============================] - 6s 720ms/step - loss: 0.4275 - accuracy: 0.9792 - val_loss: 20.5753 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 95/100\n",
      "Learning rate:  0.0001\n",
      "8/8 [==============================] - 6s 714ms/step - loss: 0.4206 - accuracy: 0.9875 - val_loss: 20.4888 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 96/100\n",
      "Learning rate:  0.0001\n",
      "8/8 [==============================] - 6s 707ms/step - loss: 0.4349 - accuracy: 0.9708 - val_loss: 20.6156 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 97/100\n",
      "Learning rate:  0.0001\n",
      "8/8 [==============================] - 6s 738ms/step - loss: 0.4384 - accuracy: 0.9708 - val_loss: 20.7975 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 98/100\n",
      "Learning rate:  0.0001\n",
      "8/8 [==============================] - 6s 729ms/step - loss: 0.4422 - accuracy: 0.9667 - val_loss: 20.5908 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 99/100\n",
      "Learning rate:  0.0001\n",
      "8/8 [==============================] - 6s 719ms/step - loss: 0.4338 - accuracy: 0.9667 - val_loss: 20.3084 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 100/100\n",
      "Learning rate:  0.0001\n",
      "8/8 [==============================] - 6s 709ms/step - loss: 0.4122 - accuracy: 0.9792 - val_loss: 21.2625 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1/1 [==============================] - 0s 161ms/step - loss: 0.5295 - accuracy: 0.9000\n",
      "Test loss: 0.5295130014419556\n",
      "Test accuracy: 0.8999999761581421\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000001C1ABCC7310> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "[1, 2, 1, 1, 1, 1, 2, 1, 1, 2, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Precision:  1.0\n",
      "Recall:  0.9\n",
      "F1 Score:  0.9444444444444445\n",
      "[[[[  5   5   5]\n",
      "   [ 21  21  21]\n",
      "   [ 13  13  13]\n",
      "   ...\n",
      "   [  7   7   7]\n",
      "   [  5   5   5]\n",
      "   [  2   2   2]]\n",
      "\n",
      "  [[ 23  23  23]\n",
      "   [ 14  14  14]\n",
      "   [  9   9   9]\n",
      "   ...\n",
      "   [  1   1   1]\n",
      "   [  0   0   0]\n",
      "   [  0   0   0]]\n",
      "\n",
      "  [[ 23  23  23]\n",
      "   [ 14  14  14]\n",
      "   [  9   9   9]\n",
      "   ...\n",
      "   [  0   0   0]\n",
      "   [  0   0   0]\n",
      "   [  0   0   0]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[ 29  29  29]\n",
      "   [ 17  17  17]\n",
      "   [ 10  10  10]\n",
      "   ...\n",
      "   [  0   0   0]\n",
      "   [  0   0   0]\n",
      "   [  0   0   0]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [ 17  17  17]\n",
      "   [ 12  12  12]\n",
      "   ...\n",
      "   [  0   0   0]\n",
      "   [  0   0   0]\n",
      "   [  0   0   0]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [ 14  14  14]\n",
      "   ...\n",
      "   [  7   7   7]\n",
      "   [  6   6   6]\n",
      "   [  6   6   6]]]\n",
      "\n",
      "\n",
      " [[[108 108 108]\n",
      "   [117 117 117]\n",
      "   [116 116 116]\n",
      "   ...\n",
      "   [  1   1   1]\n",
      "   [  1   1   1]\n",
      "   [  1   1   1]]\n",
      "\n",
      "  [[112 112 112]\n",
      "   [108 108 108]\n",
      "   [115 115 115]\n",
      "   ...\n",
      "   [  1   1   1]\n",
      "   [  1   1   1]\n",
      "   [  1   1   1]]\n",
      "\n",
      "  [[117 117 117]\n",
      "   [112 112 112]\n",
      "   [110 110 110]\n",
      "   ...\n",
      "   [  1   1   1]\n",
      "   [  1   1   1]\n",
      "   [  1   1   1]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[ 25  25  25]\n",
      "   [ 17  17  17]\n",
      "   [ 10  10  10]\n",
      "   ...\n",
      "   [  0   0   0]\n",
      "   [  0   0   0]\n",
      "   [  0   0   0]]\n",
      "\n",
      "  [[ 24  24  24]\n",
      "   [ 18  18  18]\n",
      "   [ 11  11  11]\n",
      "   ...\n",
      "   [  0   0   0]\n",
      "   [  0   0   0]\n",
      "   [  0   0   0]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [ 19  19  19]\n",
      "   [ 19  19  19]\n",
      "   ...\n",
      "   [  6   6   6]\n",
      "   [  6   6   6]\n",
      "   [  6   6   6]]]\n",
      "\n",
      "\n",
      " [[[  1   1   1]\n",
      "   [  7   7   7]\n",
      "   [  4   4   4]\n",
      "   ...\n",
      "   [  0   0   0]\n",
      "   [  0   0   0]\n",
      "   [  0   0   0]]\n",
      "\n",
      "  [[ 21  21  21]\n",
      "   [ 15  15  15]\n",
      "   [ 11  11  11]\n",
      "   ...\n",
      "   [  4   4   4]\n",
      "   [  7   7   7]\n",
      "   [ 12  12  12]]\n",
      "\n",
      "  [[ 19  19  19]\n",
      "   [ 15  15  15]\n",
      "   [ 11  11  11]\n",
      "   ...\n",
      "   [  4   4   4]\n",
      "   [  6   6   6]\n",
      "   [ 11  11  11]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[ 28  28  28]\n",
      "   [ 19  19  19]\n",
      "   [ 10  10  10]\n",
      "   ...\n",
      "   [  0   0   0]\n",
      "   [  0   0   0]\n",
      "   [  1   1   1]]\n",
      "\n",
      "  [[ 22  22  22]\n",
      "   [ 14  14  14]\n",
      "   [ 10  10  10]\n",
      "   ...\n",
      "   [  0   0   0]\n",
      "   [  0   0   0]\n",
      "   [  1   1   1]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [ 35  35  35]\n",
      "   [ 23  23  23]\n",
      "   ...\n",
      "   [  0   0   0]\n",
      "   [  0   0   0]\n",
      "   [  0   0   0]]]]\n",
      "[[1]\n",
      " [1]\n",
      " [1]]\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "(40, 30, 3)\n",
      "x_train shape: (240, 40, 30, 3)\n",
      "240 train samples\n",
      "30 test samples\n",
      "y_train shape: (240, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\patcas rares\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate:  0.001\n",
      "Model: \"model_6\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_7 (InputLayer)            [(None, 40, 30, 3)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_186 (Conv2D)             (None, 40, 30, 16)   448         input_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_168 (BatchN (None, 40, 30, 16)   64          conv2d_186[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_168 (Activation)     (None, 40, 30, 16)   0           batch_normalization_168[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_187 (Conv2D)             (None, 40, 30, 16)   272         activation_168[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_169 (BatchN (None, 40, 30, 16)   64          conv2d_187[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_169 (Activation)     (None, 40, 30, 16)   0           batch_normalization_169[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_188 (Conv2D)             (None, 40, 30, 16)   2320        activation_169[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_170 (BatchN (None, 40, 30, 16)   64          conv2d_188[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_170 (Activation)     (None, 40, 30, 16)   0           batch_normalization_170[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_190 (Conv2D)             (None, 40, 30, 64)   1088        activation_168[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_189 (Conv2D)             (None, 40, 30, 64)   1088        activation_170[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_54 (Add)                    (None, 40, 30, 64)   0           conv2d_190[0][0]                 \n",
      "                                                                 conv2d_189[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_171 (BatchN (None, 40, 30, 64)   256         add_54[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_171 (Activation)     (None, 40, 30, 64)   0           batch_normalization_171[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_191 (Conv2D)             (None, 40, 30, 16)   1040        activation_171[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_172 (BatchN (None, 40, 30, 16)   64          conv2d_191[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_172 (Activation)     (None, 40, 30, 16)   0           batch_normalization_172[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_192 (Conv2D)             (None, 40, 30, 16)   2320        activation_172[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_173 (BatchN (None, 40, 30, 16)   64          conv2d_192[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_173 (Activation)     (None, 40, 30, 16)   0           batch_normalization_173[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_193 (Conv2D)             (None, 40, 30, 64)   1088        activation_173[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_55 (Add)                    (None, 40, 30, 64)   0           add_54[0][0]                     \n",
      "                                                                 conv2d_193[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_174 (BatchN (None, 40, 30, 64)   256         add_55[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_174 (Activation)     (None, 40, 30, 64)   0           batch_normalization_174[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_194 (Conv2D)             (None, 40, 30, 16)   1040        activation_174[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_175 (BatchN (None, 40, 30, 16)   64          conv2d_194[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_175 (Activation)     (None, 40, 30, 16)   0           batch_normalization_175[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_195 (Conv2D)             (None, 40, 30, 16)   2320        activation_175[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_176 (BatchN (None, 40, 30, 16)   64          conv2d_195[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_176 (Activation)     (None, 40, 30, 16)   0           batch_normalization_176[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_196 (Conv2D)             (None, 40, 30, 64)   1088        activation_176[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_56 (Add)                    (None, 40, 30, 64)   0           add_55[0][0]                     \n",
      "                                                                 conv2d_196[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_177 (BatchN (None, 40, 30, 64)   256         add_56[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_177 (Activation)     (None, 40, 30, 64)   0           batch_normalization_177[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_197 (Conv2D)             (None, 20, 15, 64)   4160        activation_177[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_178 (BatchN (None, 20, 15, 64)   256         conv2d_197[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_178 (Activation)     (None, 20, 15, 64)   0           batch_normalization_178[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_198 (Conv2D)             (None, 20, 15, 64)   36928       activation_178[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_179 (BatchN (None, 20, 15, 64)   256         conv2d_198[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_179 (Activation)     (None, 20, 15, 64)   0           batch_normalization_179[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_200 (Conv2D)             (None, 20, 15, 128)  8320        add_56[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_199 (Conv2D)             (None, 20, 15, 128)  8320        activation_179[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_57 (Add)                    (None, 20, 15, 128)  0           conv2d_200[0][0]                 \n",
      "                                                                 conv2d_199[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_180 (BatchN (None, 20, 15, 128)  512         add_57[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_180 (Activation)     (None, 20, 15, 128)  0           batch_normalization_180[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_201 (Conv2D)             (None, 20, 15, 64)   8256        activation_180[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_181 (BatchN (None, 20, 15, 64)   256         conv2d_201[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_181 (Activation)     (None, 20, 15, 64)   0           batch_normalization_181[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_202 (Conv2D)             (None, 20, 15, 64)   36928       activation_181[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_182 (BatchN (None, 20, 15, 64)   256         conv2d_202[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_182 (Activation)     (None, 20, 15, 64)   0           batch_normalization_182[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_203 (Conv2D)             (None, 20, 15, 128)  8320        activation_182[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_58 (Add)                    (None, 20, 15, 128)  0           add_57[0][0]                     \n",
      "                                                                 conv2d_203[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_183 (BatchN (None, 20, 15, 128)  512         add_58[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_183 (Activation)     (None, 20, 15, 128)  0           batch_normalization_183[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_204 (Conv2D)             (None, 20, 15, 64)   8256        activation_183[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_184 (BatchN (None, 20, 15, 64)   256         conv2d_204[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_184 (Activation)     (None, 20, 15, 64)   0           batch_normalization_184[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_205 (Conv2D)             (None, 20, 15, 64)   36928       activation_184[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_185 (BatchN (None, 20, 15, 64)   256         conv2d_205[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_185 (Activation)     (None, 20, 15, 64)   0           batch_normalization_185[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_206 (Conv2D)             (None, 20, 15, 128)  8320        activation_185[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_59 (Add)                    (None, 20, 15, 128)  0           add_58[0][0]                     \n",
      "                                                                 conv2d_206[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_186 (BatchN (None, 20, 15, 128)  512         add_59[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_186 (Activation)     (None, 20, 15, 128)  0           batch_normalization_186[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_207 (Conv2D)             (None, 10, 8, 128)   16512       activation_186[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_187 (BatchN (None, 10, 8, 128)   512         conv2d_207[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_187 (Activation)     (None, 10, 8, 128)   0           batch_normalization_187[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_208 (Conv2D)             (None, 10, 8, 128)   147584      activation_187[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_188 (BatchN (None, 10, 8, 128)   512         conv2d_208[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_188 (Activation)     (None, 10, 8, 128)   0           batch_normalization_188[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_210 (Conv2D)             (None, 10, 8, 256)   33024       add_59[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_209 (Conv2D)             (None, 10, 8, 256)   33024       activation_188[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_60 (Add)                    (None, 10, 8, 256)   0           conv2d_210[0][0]                 \n",
      "                                                                 conv2d_209[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_189 (BatchN (None, 10, 8, 256)   1024        add_60[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_189 (Activation)     (None, 10, 8, 256)   0           batch_normalization_189[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_211 (Conv2D)             (None, 10, 8, 128)   32896       activation_189[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_190 (BatchN (None, 10, 8, 128)   512         conv2d_211[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_190 (Activation)     (None, 10, 8, 128)   0           batch_normalization_190[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_212 (Conv2D)             (None, 10, 8, 128)   147584      activation_190[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_191 (BatchN (None, 10, 8, 128)   512         conv2d_212[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_191 (Activation)     (None, 10, 8, 128)   0           batch_normalization_191[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_213 (Conv2D)             (None, 10, 8, 256)   33024       activation_191[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_61 (Add)                    (None, 10, 8, 256)   0           add_60[0][0]                     \n",
      "                                                                 conv2d_213[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_192 (BatchN (None, 10, 8, 256)   1024        add_61[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_192 (Activation)     (None, 10, 8, 256)   0           batch_normalization_192[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_214 (Conv2D)             (None, 10, 8, 128)   32896       activation_192[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_193 (BatchN (None, 10, 8, 128)   512         conv2d_214[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_193 (Activation)     (None, 10, 8, 128)   0           batch_normalization_193[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_215 (Conv2D)             (None, 10, 8, 128)   147584      activation_193[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_194 (BatchN (None, 10, 8, 128)   512         conv2d_215[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_194 (Activation)     (None, 10, 8, 128)   0           batch_normalization_194[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_216 (Conv2D)             (None, 10, 8, 256)   33024       activation_194[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_62 (Add)                    (None, 10, 8, 256)   0           add_61[0][0]                     \n",
      "                                                                 conv2d_216[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_195 (BatchN (None, 10, 8, 256)   1024        add_62[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_195 (Activation)     (None, 10, 8, 256)   0           batch_normalization_195[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_6 (AveragePoo (None, 1, 1, 256)    0           activation_195[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "flatten_6 (Flatten)             (None, 256)          0           average_pooling2d_6[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 10)           2570        flatten_6[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 849,002\n",
      "Trainable params: 843,786\n",
      "Non-trainable params: 5,216\n",
      "__________________________________________________________________________________________________\n",
      "ResNet  29v  2\n",
      "Using real-time data augmentation.\n",
      "------------------\n",
      "[[[[-1.19771197e-01 -1.19771197e-01 -1.19771197e-01]\n",
      "   [-5.97711876e-02 -5.97711876e-02 -5.97711876e-02]\n",
      "   [-8.36436898e-02 -8.36436898e-02 -8.36436898e-02]\n",
      "   ...\n",
      "   [-1.69199362e-01 -1.69199362e-01 -1.69199362e-01]\n",
      "   [-1.78660125e-01 -1.78660125e-01 -1.78660125e-01]\n",
      "   [-2.00000003e-01 -2.00000003e-01 -2.00000003e-01]]\n",
      "\n",
      "  [[-4.51796874e-02 -4.51796874e-02 -4.51796874e-02]\n",
      "   [-7.06862211e-02 -7.06862211e-02 -7.06862211e-02]\n",
      "   [-8.91502202e-02 -8.91502202e-02 -8.91502202e-02]\n",
      "   ...\n",
      "   [-1.50620848e-01 -1.50620848e-01 -1.50620848e-01]\n",
      "   [-1.54019594e-01 -1.54019594e-01 -1.54019594e-01]\n",
      "   [-1.68823466e-01 -1.68823466e-01 -1.68823466e-01]]\n",
      "\n",
      "  [[-5.14215305e-02 -5.14215305e-02 -5.14215305e-02]\n",
      "   [-7.72875249e-02 -7.72875249e-02 -7.72875249e-02]\n",
      "   [-8.95097405e-02 -8.95097405e-02 -8.95097405e-02]\n",
      "   ...\n",
      "   [-1.62728727e-01 -1.62728727e-01 -1.62728727e-01]\n",
      "   [-1.65980399e-01 -1.65980399e-01 -1.65980399e-01]\n",
      "   [-1.68594688e-01 -1.68594688e-01 -1.68594688e-01]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[ 6.24181330e-03  6.24181330e-03  6.24181330e-03]\n",
      "   [-2.50815824e-02 -2.50815824e-02 -2.50815824e-02]\n",
      "   [-3.79900597e-02 -3.79900597e-02 -3.79900597e-02]\n",
      "   ...\n",
      "   [-7.50326365e-02 -7.50326365e-02 -7.50326365e-02]\n",
      "   [-9.19444114e-02 -9.19444114e-02 -9.19444114e-02]\n",
      "   [-1.07467368e-01 -1.07467368e-01 -1.07467368e-01]]\n",
      "\n",
      "  [[ 3.99084985e-01  3.99084985e-01  3.99084985e-01]\n",
      "   [-2.41338536e-02 -2.41338536e-02 -2.41338536e-02]\n",
      "   [-3.19116227e-02 -3.19116227e-02 -3.19116227e-02]\n",
      "   ...\n",
      "   [-7.78921023e-02 -7.78921023e-02 -7.78921023e-02]\n",
      "   [-8.52777287e-02 -8.52777287e-02 -8.52777287e-02]\n",
      "   [-1.13529451e-01 -1.13529451e-01 -1.13529451e-01]]\n",
      "\n",
      "  [[ 2.84951061e-01  2.84951061e-01  2.84951061e-01]\n",
      "   [ 3.22026193e-01  3.22026193e-01  3.22026193e-01]\n",
      "   [-1.11111030e-01 -1.11111030e-01 -1.11111030e-01]\n",
      "   ...\n",
      "   [-1.34346366e-01 -1.34346366e-01 -1.34346366e-01]\n",
      "   [-1.59150302e-01 -1.59150302e-01 -1.59150302e-01]\n",
      "   [-1.87695965e-01 -1.87695965e-01 -1.87695965e-01]]]\n",
      "\n",
      "\n",
      " [[[ 2.84150362e-01  2.84150362e-01  2.84150362e-01]\n",
      "   [ 3.16699386e-01  3.16699386e-01  3.16699386e-01]\n",
      "   [ 3.20277870e-01  3.20277870e-01  3.20277870e-01]\n",
      "   ...\n",
      "   [-1.92728773e-01 -1.92728773e-01 -1.92728773e-01]\n",
      "   [-1.94346398e-01 -1.94346398e-01 -1.94346398e-01]\n",
      "   [-2.03921571e-01 -2.03921571e-01 -2.03921571e-01]]\n",
      "\n",
      "  [[ 3.03839922e-01  3.03839922e-01  3.03839922e-01]\n",
      "   [ 2.97941238e-01  2.97941238e-01  2.97941238e-01]\n",
      "   [ 3.26536059e-01  3.26536059e-01  3.26536059e-01]\n",
      "   ...\n",
      "   [-1.50620848e-01 -1.50620848e-01 -1.50620848e-01]\n",
      "   [-1.50098026e-01 -1.50098026e-01 -1.50098026e-01]\n",
      "   [-1.64901897e-01 -1.64901897e-01 -1.64901897e-01]]\n",
      "\n",
      "  [[ 3.17205906e-01  3.17205906e-01  3.17205906e-01]\n",
      "   [ 3.07026207e-01  3.07026207e-01  3.07026207e-01]\n",
      "   [ 3.06568682e-01  3.06568682e-01  3.06568682e-01]\n",
      "   ...\n",
      "   [-1.58807158e-01 -1.58807158e-01 -1.58807158e-01]\n",
      "   [-1.62058830e-01 -1.62058830e-01 -1.62058830e-01]\n",
      "   [-1.64673120e-01 -1.64673120e-01 -1.64673120e-01]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[-9.44446027e-03 -9.44446027e-03 -9.44446027e-03]\n",
      "   [-2.50815824e-02 -2.50815824e-02 -2.50815824e-02]\n",
      "   [-3.79900597e-02 -3.79900597e-02 -3.79900597e-02]\n",
      "   ...\n",
      "   [-7.50326365e-02 -7.50326365e-02 -7.50326365e-02]\n",
      "   [-9.19444114e-02 -9.19444114e-02 -9.19444114e-02]\n",
      "   [-1.07467368e-01 -1.07467368e-01 -1.07467368e-01]]\n",
      "\n",
      "  [[-8.75819474e-03 -8.75819474e-03 -8.75819474e-03]\n",
      "   [-2.02122852e-02 -2.02122852e-02 -2.02122852e-02]\n",
      "   [-3.58331911e-02 -3.58331911e-02 -3.58331911e-02]\n",
      "   ...\n",
      "   [-7.78921023e-02 -7.78921023e-02 -7.78921023e-02]\n",
      "   [-8.52777287e-02 -8.52777287e-02 -8.52777287e-02]\n",
      "   [-1.13529451e-01 -1.13529451e-01 -1.13529451e-01]]\n",
      "\n",
      "  [[ 2.84951061e-01  2.84951061e-01  2.84951061e-01]\n",
      "   [-1.05424799e-01 -1.05424799e-01 -1.05424799e-01]\n",
      "   [-9.15031806e-02 -9.15031806e-02 -9.15031806e-02]\n",
      "   ...\n",
      "   [-1.38267934e-01 -1.38267934e-01 -1.38267934e-01]\n",
      "   [-1.59150302e-01 -1.59150302e-01 -1.59150302e-01]\n",
      "   [-1.87695965e-01 -1.87695965e-01 -1.87695965e-01]]]\n",
      "\n",
      "\n",
      " [[[-1.35457471e-01 -1.35457471e-01 -1.35457471e-01]\n",
      "   [-1.14673153e-01 -1.14673153e-01 -1.14673153e-01]\n",
      "   [-1.18937805e-01 -1.18937805e-01 -1.18937805e-01]\n",
      "   ...\n",
      "   [-1.96650341e-01 -1.96650341e-01 -1.96650341e-01]\n",
      "   [-1.98267967e-01 -1.98267967e-01 -1.98267967e-01]\n",
      "   [-2.07843140e-01 -2.07843140e-01 -2.07843140e-01]]\n",
      "\n",
      "  [[-5.30228242e-02 -5.30228242e-02 -5.30228242e-02]\n",
      "   [-6.67646527e-02 -6.67646527e-02 -6.67646527e-02]\n",
      "   [-8.13070834e-02 -8.13070834e-02 -8.13070834e-02]\n",
      "   ...\n",
      "   [-1.38856143e-01 -1.38856143e-01 -1.38856143e-01]\n",
      "   [-1.26568615e-01 -1.26568615e-01 -1.26568615e-01]\n",
      "   [-1.21764645e-01 -1.21764645e-01 -1.21764645e-01]]\n",
      "\n",
      "  [[-6.71078041e-02 -6.71078041e-02 -6.71078041e-02]\n",
      "   [-7.33659565e-02 -7.33659565e-02 -7.33659565e-02]\n",
      "   [-8.16666037e-02 -8.16666037e-02 -8.16666037e-02]\n",
      "   ...\n",
      "   [-1.47042453e-01 -1.47042453e-01 -1.47042453e-01]\n",
      "   [-1.42450988e-01 -1.42450988e-01 -1.42450988e-01]\n",
      "   [-1.25457436e-01 -1.25457436e-01 -1.25457436e-01]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[ 2.32024491e-03  2.32024491e-03  2.32024491e-03]\n",
      "   [-1.72384456e-02 -1.72384456e-02 -1.72384456e-02]\n",
      "   [-3.79900597e-02 -3.79900597e-02 -3.79900597e-02]\n",
      "   ...\n",
      "   [-7.50326365e-02 -7.50326365e-02 -7.50326365e-02]\n",
      "   [-9.19444114e-02 -9.19444114e-02 -9.19444114e-02]\n",
      "   [-1.03545800e-01 -1.03545800e-01 -1.03545800e-01]]\n",
      "\n",
      "  [[-1.66013315e-02 -1.66013315e-02 -1.66013315e-02]\n",
      "   [-3.58985625e-02 -3.58985625e-02 -3.58985625e-02]\n",
      "   [-3.97547595e-02 -3.97547595e-02 -3.97547595e-02]\n",
      "   ...\n",
      "   [-7.78921023e-02 -7.78921023e-02 -7.78921023e-02]\n",
      "   [-8.52777287e-02 -8.52777287e-02 -8.52777287e-02]\n",
      "   [-1.09607883e-01 -1.09607883e-01 -1.09607883e-01]]\n",
      "\n",
      "  [[ 2.84951061e-01  2.84951061e-01  2.84951061e-01]\n",
      "   [-4.26796973e-02 -4.26796973e-02 -4.26796973e-02]\n",
      "   [-7.58169070e-02 -7.58169070e-02 -7.58169070e-02]\n",
      "   ...\n",
      "   [-1.61797345e-01 -1.61797345e-01 -1.61797345e-01]\n",
      "   [-1.82679713e-01 -1.82679713e-01 -1.82679713e-01]\n",
      "   [-2.11225376e-01 -2.11225376e-01 -2.11225376e-01]]]\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      " [[[-3.74182537e-02 -3.74182537e-02 -3.74182537e-02]\n",
      "   [-3.23202088e-02 -3.23202088e-02 -3.23202088e-02]\n",
      "   [-3.65848616e-02 -3.65848616e-02 -3.65848616e-02]\n",
      "   ...\n",
      "   [-1.10375829e-01 -1.10375829e-01 -1.10375829e-01]\n",
      "   [-1.00228749e-01 -1.00228749e-01 -1.00228749e-01]\n",
      "   [-7.45097995e-02 -7.45097995e-02 -7.45097995e-02]]\n",
      "\n",
      "  [[-5.96399605e-03 -5.96399605e-03 -5.96399605e-03]\n",
      "   [-3.93136665e-02 -3.93136665e-02 -3.93136665e-02]\n",
      "   [-5.38560972e-02 -5.38560972e-02 -5.38560972e-02]\n",
      "   ...\n",
      "   [-1.34934574e-01 -1.34934574e-01 -1.34934574e-01]\n",
      "   [-1.22647047e-01 -1.22647047e-01 -1.22647047e-01]\n",
      "   [-1.29607782e-01 -1.29607782e-01 -1.29607782e-01]]\n",
      "\n",
      "  [[-1.22058392e-02 -1.22058392e-02 -1.22058392e-02]\n",
      "   [-4.59149703e-02 -4.59149703e-02 -4.59149703e-02]\n",
      "   [-5.81371933e-02 -5.81371933e-02 -5.81371933e-02]\n",
      "   ...\n",
      "   [-1.43120885e-01 -1.43120885e-01 -1.43120885e-01]\n",
      "   [-1.38529420e-01 -1.38529420e-01 -1.38529420e-01]\n",
      "   [-1.33300573e-01 -1.33300573e-01 -1.33300573e-01]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[ 4.54575047e-02  4.54575047e-02  4.54575047e-02]\n",
      "   [ 1.80556700e-02  1.80556700e-02  1.80556700e-02]\n",
      "   [ 1.22562796e-03  1.22562796e-03  1.22562796e-03]\n",
      "   ...\n",
      "   [-5.93463629e-02 -5.93463629e-02 -5.93463629e-02]\n",
      "   [-6.84150010e-02 -6.84150010e-02 -6.84150010e-02]\n",
      "   [-7.60948211e-02 -7.60948211e-02 -7.60948211e-02]]\n",
      "\n",
      "  [[ 8.92810225e-02  8.92810225e-02  8.92810225e-02]\n",
      "   [ 2.68465355e-02  2.68465355e-02  2.68465355e-02]\n",
      "   [ 7.30406493e-03  7.30406493e-03  7.30406493e-03]\n",
      "   ...\n",
      "   [-7.78921023e-02 -7.78921023e-02 -7.78921023e-02]\n",
      "   [-5.78267500e-02 -5.78267500e-02 -5.78267500e-02]\n",
      "   [-7.82353282e-02 -7.82353282e-02 -7.82353282e-02]]\n",
      "\n",
      "  [[-1.34656817e-01 -1.34656817e-01 -1.34656817e-01]\n",
      "   [-1.28954217e-01 -1.28954217e-01 -1.28954217e-01]\n",
      "   [-1.66012987e-01 -1.66012987e-01 -1.66012987e-01]\n",
      "   ...\n",
      "   [-1.34346366e-01 -1.34346366e-01 -1.34346366e-01]\n",
      "   [-1.43464029e-01 -1.43464029e-01 -1.43464029e-01]\n",
      "   [-1.52401850e-01 -1.52401850e-01 -1.52401850e-01]]]\n",
      "\n",
      "\n",
      " [[[ 3.54738593e-01  3.54738593e-01  3.54738593e-01]\n",
      "   [ 3.44150364e-01  3.44150364e-01  3.44150364e-01]\n",
      "   [ 3.63415122e-01  3.63415122e-01  3.63415122e-01]\n",
      "   ...\n",
      "   [-1.84885636e-01 -1.84885636e-01 -1.84885636e-01]\n",
      "   [-1.78660125e-01 -1.78660125e-01 -1.78660125e-01]\n",
      "   [-1.80392161e-01 -1.80392161e-01 -1.80392161e-01]]\n",
      "\n",
      "  [[ 3.39134037e-01  3.39134037e-01  3.39134037e-01]\n",
      "   [ 3.56764764e-01  3.56764764e-01  3.56764764e-01]\n",
      "   [ 3.50065470e-01  3.50065470e-01  3.50065470e-01]\n",
      "   ...\n",
      "   [-1.42777711e-01 -1.42777711e-01 -1.42777711e-01]\n",
      "   [-1.34411752e-01 -1.34411752e-01 -1.34411752e-01]\n",
      "   [-1.41372487e-01 -1.41372487e-01 -1.41372487e-01]]\n",
      "\n",
      "  [[ 3.13284338e-01  3.13284338e-01  3.13284338e-01]\n",
      "   [ 3.65849733e-01  3.65849733e-01  3.65849733e-01]\n",
      "   [ 3.57549071e-01  3.57549071e-01  3.57549071e-01]\n",
      "   ...\n",
      "   [-1.50964022e-01 -1.50964022e-01 -1.50964022e-01]\n",
      "   [-1.46372557e-01 -1.46372557e-01 -1.46372557e-01]\n",
      "   [-1.41143709e-01 -1.41143709e-01 -1.41143709e-01]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[-1.60132349e-03 -1.60132349e-03 -1.60132349e-03]\n",
      "   [-2.50815824e-02 -2.50815824e-02 -2.50815824e-02]\n",
      "   [-1.83822177e-02 -1.83822177e-02 -1.83822177e-02]\n",
      "   ...\n",
      "   [-7.50326365e-02 -7.50326365e-02 -7.50326365e-02]\n",
      "   [-7.23365694e-02 -7.23365694e-02 -7.23365694e-02]\n",
      "   [-7.21732527e-02 -7.21732527e-02 -7.21732527e-02]]\n",
      "\n",
      "  [[-9.15057957e-04 -9.15057957e-04 -9.15057957e-04]\n",
      "   [-2.80554220e-02 -2.80554220e-02 -2.80554220e-02]\n",
      "   [-3.19116227e-02 -3.19116227e-02 -3.19116227e-02]\n",
      "   ...\n",
      "   [-7.78921023e-02 -7.78921023e-02 -7.78921023e-02]\n",
      "   [-8.52777287e-02 -8.52777287e-02 -8.52777287e-02]\n",
      "   [-6.64706230e-02 -6.64706230e-02 -6.64706230e-02]]\n",
      "\n",
      "  [[-1.89558774e-01 -1.89558774e-01 -1.89558774e-01]\n",
      "   [-1.09346367e-01 -1.09346367e-01 -1.09346367e-01]\n",
      "   [-1.15032598e-01 -1.15032598e-01 -1.15032598e-01]\n",
      "   ...\n",
      "   [-1.26503229e-01 -1.26503229e-01 -1.26503229e-01]\n",
      "   [-1.39542460e-01 -1.39542460e-01 -1.39542460e-01]\n",
      "   [-1.56323418e-01 -1.56323418e-01 -1.56323418e-01]]]\n",
      "\n",
      "\n",
      " [[[-7.27123693e-02 -7.27123693e-02 -7.27123693e-02]\n",
      "   [ 3.59836698e-01  3.59836698e-01  3.59836698e-01]\n",
      "   [-1.34624079e-01 -1.34624079e-01 -1.34624079e-01]\n",
      "   ...\n",
      "   [ 3.05310488e-01  3.05310488e-01  3.05310488e-01]\n",
      "   [ 3.03692847e-01  3.03692847e-01  3.03692847e-01]\n",
      "   [ 2.94117689e-01  2.94117689e-01  2.94117689e-01]]\n",
      "\n",
      "  [[-5.69443926e-02 -5.69443926e-02 -5.69443926e-02]\n",
      "   [-8.63724947e-02 -8.63724947e-02 -8.63724947e-02]\n",
      "   [-9.69933569e-02 -9.69933569e-02 -9.69933569e-02]\n",
      "   ...\n",
      "   [ 2.49379158e-01  2.49379158e-01  2.49379158e-01]\n",
      "   [ 2.96960801e-01  2.96960801e-01  2.96960801e-01]\n",
      "   [ 3.13529491e-01  3.13529491e-01  3.13529491e-01]]\n",
      "\n",
      "  [[-6.31862357e-02 -6.31862357e-02 -6.31862357e-02]\n",
      "   [-8.51306617e-02 -8.51306617e-02 -8.51306617e-02]\n",
      "   [-9.34313089e-02 -9.34313089e-02 -9.34313089e-02]\n",
      "   ...\n",
      "   [ 2.45114416e-01  2.45114416e-01  2.45114416e-01]\n",
      "   [ 2.65392154e-01  2.65392154e-01  2.65392154e-01]\n",
      "   [ 2.74542570e-01  2.74542570e-01  2.74542570e-01]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[-6.82679862e-02 -6.82679862e-02 -6.82679862e-02]\n",
      "   [-6.42972738e-02 -6.42972738e-02 -6.42972738e-02]\n",
      "   [-5.36763370e-02 -5.36763370e-02 -5.36763370e-02]\n",
      "   ...\n",
      "   [ 1.83790907e-01  1.83790907e-01  1.83790907e-01]\n",
      "   [-2.13561729e-02 -2.13561729e-02 -2.13561729e-02]\n",
      "   [ 1.01796910e-02  1.01796910e-02  1.01796910e-02]]\n",
      "\n",
      "  [[-5.97385876e-02 -5.97385876e-02 -5.97385876e-02]\n",
      "   [-6.33495450e-02 -6.33495450e-02 -6.33495450e-02]\n",
      "   [-5.54410368e-02 -5.54410368e-02 -5.54410368e-02]\n",
      "   ...\n",
      "   [-5.43626919e-02 -5.43626919e-02 -5.43626919e-02]\n",
      "   [-3.82189043e-02 -3.82189043e-02 -3.82189043e-02]\n",
      "   [ 1.96039677e-04  1.96039677e-04  1.96039677e-04]]\n",
      "\n",
      "  [[-1.73872501e-01 -1.73872501e-01 -1.73872501e-01]\n",
      "   [-1.52483627e-01 -1.52483627e-01 -1.52483627e-01]\n",
      "   [-1.46405146e-01 -1.46405146e-01 -1.46405146e-01]\n",
      "   ...\n",
      "   [-1.38267934e-01 -1.38267934e-01 -1.38267934e-01]\n",
      "   [-1.27777755e-01 -1.27777755e-01 -1.27777755e-01]\n",
      "   [-1.17107727e-01 -1.17107727e-01 -1.17107727e-01]]]]\n",
      "Epoch 1/100\n",
      "Learning rate:  0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\patcas rares\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\keras\\engine\\training.py:1972: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 12s 863ms/step - loss: 2.0357 - accuracy: 0.4833 - val_loss: 2.5801 - val_accuracy: 0.5667\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 2/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 759ms/step - loss: 1.3574 - accuracy: 0.7125 - val_loss: 2.5404 - val_accuracy: 0.5667\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 3/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 738ms/step - loss: 1.1692 - accuracy: 0.7333 - val_loss: 2.5435 - val_accuracy: 0.4333\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 4/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 725ms/step - loss: 1.1263 - accuracy: 0.7458 - val_loss: 2.4449 - val_accuracy: 0.4333\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 5/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 722ms/step - loss: 1.1028 - accuracy: 0.7333 - val_loss: 2.2587 - val_accuracy: 0.4333\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 6/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 734ms/step - loss: 1.0866 - accuracy: 0.7542 - val_loss: 2.6246 - val_accuracy: 0.4333\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 7/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 7s 816ms/step - loss: 1.0976 - accuracy: 0.7375 - val_loss: 2.6712 - val_accuracy: 0.4333\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 8/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 7s 798ms/step - loss: 1.0402 - accuracy: 0.7917 - val_loss: 4.5054 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 9/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 774ms/step - loss: 1.0434 - accuracy: 0.7333 - val_loss: 2.8987 - val_accuracy: 0.4333\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 10/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 729ms/step - loss: 1.0261 - accuracy: 0.7542 - val_loss: 3.1416 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 11/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 763ms/step - loss: 0.9951 - accuracy: 0.7625 - val_loss: 7.4020 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 12/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 785ms/step - loss: 1.0117 - accuracy: 0.7875 - val_loss: 9.0125 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 13/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 781ms/step - loss: 0.9647 - accuracy: 0.8208 - val_loss: 8.6084 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 14/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 785ms/step - loss: 0.9532 - accuracy: 0.7917 - val_loss: 13.5808 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 15/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 770ms/step - loss: 1.0091 - accuracy: 0.7792 - val_loss: 13.8794 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 16/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 766ms/step - loss: 0.9042 - accuracy: 0.8333 - val_loss: 11.2692 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 17/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 776ms/step - loss: 0.9019 - accuracy: 0.8167 - val_loss: 14.4488 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 18/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 676ms/step - loss: 0.9292 - accuracy: 0.8000 - val_loss: 9.0196 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 19/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 758ms/step - loss: 0.9449 - accuracy: 0.7875 - val_loss: 5.1301 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 20/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 773ms/step - loss: 0.9319 - accuracy: 0.8042 - val_loss: 6.9569 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 21/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 725ms/step - loss: 0.9796 - accuracy: 0.7833 - val_loss: 10.4069 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 22/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 713ms/step - loss: 0.8668 - accuracy: 0.8125 - val_loss: 11.8755 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 23/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 728ms/step - loss: 0.9234 - accuracy: 0.8125 - val_loss: 16.5142 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 24/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 735ms/step - loss: 0.9021 - accuracy: 0.8000 - val_loss: 17.8954 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 25/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 720ms/step - loss: 0.8921 - accuracy: 0.8125 - val_loss: 16.3982 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 26/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 784ms/step - loss: 0.8788 - accuracy: 0.7917 - val_loss: 15.0728 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 27/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 714ms/step - loss: 0.8977 - accuracy: 0.7958 - val_loss: 11.1740 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 28/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 726ms/step - loss: 0.8360 - accuracy: 0.8417 - val_loss: 7.1271 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 29/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 745ms/step - loss: 0.8332 - accuracy: 0.8250 - val_loss: 9.2556 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 30/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 712ms/step - loss: 0.7925 - accuracy: 0.8708 - val_loss: 12.2074 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 31/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 708ms/step - loss: 0.8186 - accuracy: 0.8458 - val_loss: 14.1723 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 32/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 728ms/step - loss: 0.8004 - accuracy: 0.8500 - val_loss: 22.8803 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 33/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 715ms/step - loss: 0.7838 - accuracy: 0.8458 - val_loss: 22.1459 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 34/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 718ms/step - loss: 0.7934 - accuracy: 0.8500 - val_loss: 17.8586 - val_accuracy: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 35/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 748ms/step - loss: 0.7920 - accuracy: 0.8333 - val_loss: 15.8117 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 36/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 723ms/step - loss: 0.8185 - accuracy: 0.8375 - val_loss: 13.1697 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 37/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 706ms/step - loss: 0.7278 - accuracy: 0.8875 - val_loss: 11.8865 - val_accuracy: 0.5667\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 38/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 729ms/step - loss: 0.7802 - accuracy: 0.8333 - val_loss: 11.2108 - val_accuracy: 0.5667\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 39/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 787ms/step - loss: 0.7888 - accuracy: 0.8792 - val_loss: 17.3243 - val_accuracy: 0.5667\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 40/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 740ms/step - loss: 0.7667 - accuracy: 0.8292 - val_loss: 17.3876 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 41/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 7s 824ms/step - loss: 0.7555 - accuracy: 0.8750 - val_loss: 23.3578 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 42/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 771ms/step - loss: 0.7815 - accuracy: 0.8542 - val_loss: 16.7983 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 43/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 766ms/step - loss: 0.7252 - accuracy: 0.8583 - val_loss: 16.0082 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 44/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 740ms/step - loss: 0.6721 - accuracy: 0.9083 - val_loss: 18.6855 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 45/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 713ms/step - loss: 0.6864 - accuracy: 0.8833 - val_loss: 25.2910 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 46/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 736ms/step - loss: 0.7056 - accuracy: 0.8833 - val_loss: 23.7117 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 47/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 730ms/step - loss: 0.6798 - accuracy: 0.8958 - val_loss: 21.4623 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 48/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 715ms/step - loss: 0.6795 - accuracy: 0.8875 - val_loss: 19.4367 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 49/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 738ms/step - loss: 0.6836 - accuracy: 0.8792 - val_loss: 26.3785 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 50/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 724ms/step - loss: 0.6798 - accuracy: 0.9042 - val_loss: 25.6885 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 51/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 769ms/step - loss: 0.7119 - accuracy: 0.8833 - val_loss: 20.0588 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 52/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 7s 899ms/step - loss: 0.6942 - accuracy: 0.8875 - val_loss: 16.9596 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 53/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 843ms/step - loss: 0.6661 - accuracy: 0.8917 - val_loss: 13.3435 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 54/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 787ms/step - loss: 0.6164 - accuracy: 0.9292 - val_loss: 15.7329 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 55/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 719ms/step - loss: 0.6477 - accuracy: 0.9125 - val_loss: 15.1964 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 56/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 717ms/step - loss: 0.6146 - accuracy: 0.8958 - val_loss: 13.3307 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 57/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 748ms/step - loss: 0.6368 - accuracy: 0.8958 - val_loss: 11.2879 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 58/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 728ms/step - loss: 0.5662 - accuracy: 0.9458 - val_loss: 14.8923 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 59/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 720ms/step - loss: 0.5660 - accuracy: 0.9292 - val_loss: 19.5966 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 60/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 790ms/step - loss: 0.5808 - accuracy: 0.9417 - val_loss: 14.1407 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 61/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 7s 815ms/step - loss: 0.6261 - accuracy: 0.8917 - val_loss: 2.7419 - val_accuracy: 0.4333\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 62/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 7s 895ms/step - loss: 0.6313 - accuracy: 0.8750 - val_loss: 5.5579 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 63/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 740ms/step - loss: 0.6834 - accuracy: 0.8792 - val_loss: 8.2475 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 64/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 754ms/step - loss: 0.5865 - accuracy: 0.9167 - val_loss: 14.2204 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 65/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 5s 631ms/step - loss: 0.6317 - accuracy: 0.9083 - val_loss: 16.2082 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 66/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 5s 648ms/step - loss: 0.5820 - accuracy: 0.9292 - val_loss: 22.0526 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 67/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 5s 619ms/step - loss: 0.5929 - accuracy: 0.9083 - val_loss: 13.2717 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 68/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 5s 615ms/step - loss: 0.5519 - accuracy: 0.9375 - val_loss: 11.7707 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 69/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 5s 624ms/step - loss: 0.5746 - accuracy: 0.9125 - val_loss: 10.1453 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 70/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 7s 872ms/step - loss: 0.5717 - accuracy: 0.9167 - val_loss: 14.5018 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 71/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 715ms/step - loss: 0.6348 - accuracy: 0.8917 - val_loss: 13.3733 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 72/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 720ms/step - loss: 0.6048 - accuracy: 0.9000 - val_loss: 14.3190 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 73/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 767ms/step - loss: 0.5790 - accuracy: 0.9167 - val_loss: 15.9503 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 74/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 733ms/step - loss: 0.5355 - accuracy: 0.9167 - val_loss: 15.6439 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 75/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 720ms/step - loss: 0.5379 - accuracy: 0.9250 - val_loss: 15.2072 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 76/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 772ms/step - loss: 0.5779 - accuracy: 0.9125 - val_loss: 19.5249 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 77/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 789ms/step - loss: 0.5268 - accuracy: 0.9292 - val_loss: 21.9515 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 78/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 776ms/step - loss: 0.5433 - accuracy: 0.9333 - val_loss: 17.6764 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 79/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 731ms/step - loss: 0.5343 - accuracy: 0.9292 - val_loss: 15.6585 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 80/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 777ms/step - loss: 0.4901 - accuracy: 0.9542 - val_loss: 20.3774 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 81/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 713ms/step - loss: 0.5284 - accuracy: 0.9417 - val_loss: 12.0904 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 82/100\n",
      "Learning rate:  0.0001\n",
      "8/8 [==============================] - 6s 718ms/step - loss: 0.5293 - accuracy: 0.9375 - val_loss: 11.8746 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 83/100\n",
      "Learning rate:  0.0001\n",
      "8/8 [==============================] - 6s 710ms/step - loss: 0.4656 - accuracy: 0.9625 - val_loss: 11.8708 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 84/100\n",
      "Learning rate:  0.0001\n",
      "8/8 [==============================] - 6s 739ms/step - loss: 0.4692 - accuracy: 0.9500 - val_loss: 11.9773 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 85/100\n",
      "Learning rate:  0.0001\n",
      "8/8 [==============================] - 6s 715ms/step - loss: 0.4923 - accuracy: 0.9417 - val_loss: 12.0166 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 86/100\n",
      "Learning rate:  0.0001\n",
      "8/8 [==============================] - 6s 768ms/step - loss: 0.4538 - accuracy: 0.9667 - val_loss: 11.9945 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 87/100\n",
      "Learning rate:  0.0001\n",
      "8/8 [==============================] - 6s 729ms/step - loss: 0.4613 - accuracy: 0.9542 - val_loss: 11.8469 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 88/100\n",
      "Learning rate:  0.0001\n",
      "8/8 [==============================] - 6s 718ms/step - loss: 0.4676 - accuracy: 0.9500 - val_loss: 11.2338 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 89/100\n",
      "Learning rate:  0.0001\n",
      "8/8 [==============================] - 6s 708ms/step - loss: 0.4415 - accuracy: 0.9708 - val_loss: 11.0118 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 90/100\n",
      "Learning rate:  0.0001\n",
      "8/8 [==============================] - 7s 878ms/step - loss: 0.4930 - accuracy: 0.9458 - val_loss: 11.0249 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 91/100\n",
      "Learning rate:  0.0001\n",
      "8/8 [==============================] - 6s 796ms/step - loss: 0.4603 - accuracy: 0.9583 - val_loss: 10.9113 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 92/100\n",
      "Learning rate:  0.0001\n",
      "8/8 [==============================] - 7s 855ms/step - loss: 0.4370 - accuracy: 0.9750 - val_loss: 11.2034 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 93/100\n",
      "Learning rate:  0.0001\n",
      "8/8 [==============================] - 6s 716ms/step - loss: 0.4820 - accuracy: 0.9542 - val_loss: 11.2551 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 94/100\n",
      "Learning rate:  0.0001\n",
      "8/8 [==============================] - 6s 781ms/step - loss: 0.4465 - accuracy: 0.9667 - val_loss: 11.3862 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 95/100\n",
      "Learning rate:  0.0001\n",
      "8/8 [==============================] - 7s 792ms/step - loss: 0.4435 - accuracy: 0.9708 - val_loss: 11.3358 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 96/100\n",
      "Learning rate:  0.0001\n",
      "8/8 [==============================] - 5s 634ms/step - loss: 0.4454 - accuracy: 0.9667 - val_loss: 11.3502 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 97/100\n",
      "Learning rate:  0.0001\n",
      "8/8 [==============================] - 5s 697ms/step - loss: 0.4382 - accuracy: 0.9708 - val_loss: 11.2257 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 98/100\n",
      "Learning rate:  0.0001\n",
      "8/8 [==============================] - 6s 685ms/step - loss: 0.4168 - accuracy: 0.9917 - val_loss: 10.9318 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 99/100\n",
      "Learning rate:  0.0001\n",
      "8/8 [==============================] - 6s 694ms/step - loss: 0.4377 - accuracy: 0.9667 - val_loss: 10.9547 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 100/100\n",
      "Learning rate:  0.0001\n",
      "8/8 [==============================] - 5s 651ms/step - loss: 0.4532 - accuracy: 0.9708 - val_loss: 11.1508 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1/1 [==============================] - 0s 157ms/step - loss: 1.1364 - accuracy: 0.7333\n",
      "Test loss: 1.1363641023635864\n",
      "Test accuracy: 0.7333333492279053\n",
      "[2, 1, 1, 2, 1, 1, 1, 2, 1, 2, 1, 1, 1, 1, 2, 1, 2, 2, 1, 1, 2, 1, 1, 1, 1, 0, 0, 0, 0, 0]\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]\n",
      "Precision:  1.0\n",
      "Recall:  0.7333333333333333\n",
      "F1 Score:  0.8412698412698413\n",
      "[[[[  5   5   5]\n",
      "   [ 21  21  21]\n",
      "   [ 13  13  13]\n",
      "   ...\n",
      "   [  7   7   7]\n",
      "   [  5   5   5]\n",
      "   [  2   2   2]]\n",
      "\n",
      "  [[ 23  23  23]\n",
      "   [ 14  14  14]\n",
      "   [  9   9   9]\n",
      "   ...\n",
      "   [  1   1   1]\n",
      "   [  0   0   0]\n",
      "   [  0   0   0]]\n",
      "\n",
      "  [[ 23  23  23]\n",
      "   [ 14  14  14]\n",
      "   [  9   9   9]\n",
      "   ...\n",
      "   [  0   0   0]\n",
      "   [  0   0   0]\n",
      "   [  0   0   0]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[ 29  29  29]\n",
      "   [ 17  17  17]\n",
      "   [ 10  10  10]\n",
      "   ...\n",
      "   [  0   0   0]\n",
      "   [  0   0   0]\n",
      "   [  0   0   0]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [ 17  17  17]\n",
      "   [ 12  12  12]\n",
      "   ...\n",
      "   [  0   0   0]\n",
      "   [  0   0   0]\n",
      "   [  0   0   0]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [ 14  14  14]\n",
      "   ...\n",
      "   [  7   7   7]\n",
      "   [  6   6   6]\n",
      "   [  6   6   6]]]\n",
      "\n",
      "\n",
      " [[[108 108 108]\n",
      "   [117 117 117]\n",
      "   [116 116 116]\n",
      "   ...\n",
      "   [  1   1   1]\n",
      "   [  1   1   1]\n",
      "   [  1   1   1]]\n",
      "\n",
      "  [[112 112 112]\n",
      "   [108 108 108]\n",
      "   [115 115 115]\n",
      "   ...\n",
      "   [  1   1   1]\n",
      "   [  1   1   1]\n",
      "   [  1   1   1]]\n",
      "\n",
      "  [[117 117 117]\n",
      "   [112 112 112]\n",
      "   [110 110 110]\n",
      "   ...\n",
      "   [  1   1   1]\n",
      "   [  1   1   1]\n",
      "   [  1   1   1]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[ 25  25  25]\n",
      "   [ 17  17  17]\n",
      "   [ 10  10  10]\n",
      "   ...\n",
      "   [  0   0   0]\n",
      "   [  0   0   0]\n",
      "   [  0   0   0]]\n",
      "\n",
      "  [[ 24  24  24]\n",
      "   [ 18  18  18]\n",
      "   [ 11  11  11]\n",
      "   ...\n",
      "   [  0   0   0]\n",
      "   [  0   0   0]\n",
      "   [  0   0   0]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [ 19  19  19]\n",
      "   [ 19  19  19]\n",
      "   ...\n",
      "   [  6   6   6]\n",
      "   [  6   6   6]\n",
      "   [  6   6   6]]]\n",
      "\n",
      "\n",
      " [[[102 102 102]\n",
      "   [ 99  99  99]\n",
      "   [100 100 100]\n",
      "   ...\n",
      "   [  0   0   0]\n",
      "   [  0   0   0]\n",
      "   [  0   0   0]]\n",
      "\n",
      "  [[111 111 111]\n",
      "   [110 110 110]\n",
      "   [110 110 110]\n",
      "   ...\n",
      "   [  2   2   2]\n",
      "   [  3   3   3]\n",
      "   [  4   4   4]]\n",
      "\n",
      "  [[104 104 104]\n",
      "   [103 103 103]\n",
      "   [101 101 101]\n",
      "   ...\n",
      "   [  2   2   2]\n",
      "   [  2   2   2]\n",
      "   [  4   4   4]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[ 21  21  21]\n",
      "   [ 11  11  11]\n",
      "   [  7   7   7]\n",
      "   ...\n",
      "   [  0   0   0]\n",
      "   [  0   0   0]\n",
      "   [  0   0   0]]\n",
      "\n",
      "  [[ 20  20  20]\n",
      "   [ 11  11  11]\n",
      "   [  6   6   6]\n",
      "   ...\n",
      "   [  0   0   0]\n",
      "   [  0   0   0]\n",
      "   [  0   0   0]]\n",
      "\n",
      "  [[  5   5   5]\n",
      "   [  0   0   0]\n",
      "   [  0   0   0]\n",
      "   ...\n",
      "   [  0   0   0]\n",
      "   [  0   0   0]\n",
      "   [  0   0   0]]]]\n",
      "[[1]\n",
      " [1]\n",
      " [1]]\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "(40, 30, 3)\n",
      "x_train shape: (240, 40, 30, 3)\n",
      "240 train samples\n",
      "30 test samples\n",
      "y_train shape: (240, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\patcas rares\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate:  0.001\n",
      "Model: \"model_7\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_8 (InputLayer)            [(None, 40, 30, 3)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_217 (Conv2D)             (None, 40, 30, 16)   448         input_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_196 (BatchN (None, 40, 30, 16)   64          conv2d_217[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_196 (Activation)     (None, 40, 30, 16)   0           batch_normalization_196[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_218 (Conv2D)             (None, 40, 30, 16)   272         activation_196[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_197 (BatchN (None, 40, 30, 16)   64          conv2d_218[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_197 (Activation)     (None, 40, 30, 16)   0           batch_normalization_197[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_219 (Conv2D)             (None, 40, 30, 16)   2320        activation_197[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_198 (BatchN (None, 40, 30, 16)   64          conv2d_219[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_198 (Activation)     (None, 40, 30, 16)   0           batch_normalization_198[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_221 (Conv2D)             (None, 40, 30, 64)   1088        activation_196[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_220 (Conv2D)             (None, 40, 30, 64)   1088        activation_198[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_63 (Add)                    (None, 40, 30, 64)   0           conv2d_221[0][0]                 \n",
      "                                                                 conv2d_220[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_199 (BatchN (None, 40, 30, 64)   256         add_63[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_199 (Activation)     (None, 40, 30, 64)   0           batch_normalization_199[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_222 (Conv2D)             (None, 40, 30, 16)   1040        activation_199[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_200 (BatchN (None, 40, 30, 16)   64          conv2d_222[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_200 (Activation)     (None, 40, 30, 16)   0           batch_normalization_200[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_223 (Conv2D)             (None, 40, 30, 16)   2320        activation_200[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_201 (BatchN (None, 40, 30, 16)   64          conv2d_223[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_201 (Activation)     (None, 40, 30, 16)   0           batch_normalization_201[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_224 (Conv2D)             (None, 40, 30, 64)   1088        activation_201[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_64 (Add)                    (None, 40, 30, 64)   0           add_63[0][0]                     \n",
      "                                                                 conv2d_224[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_202 (BatchN (None, 40, 30, 64)   256         add_64[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_202 (Activation)     (None, 40, 30, 64)   0           batch_normalization_202[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_225 (Conv2D)             (None, 40, 30, 16)   1040        activation_202[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_203 (BatchN (None, 40, 30, 16)   64          conv2d_225[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_203 (Activation)     (None, 40, 30, 16)   0           batch_normalization_203[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_226 (Conv2D)             (None, 40, 30, 16)   2320        activation_203[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_204 (BatchN (None, 40, 30, 16)   64          conv2d_226[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_204 (Activation)     (None, 40, 30, 16)   0           batch_normalization_204[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_227 (Conv2D)             (None, 40, 30, 64)   1088        activation_204[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_65 (Add)                    (None, 40, 30, 64)   0           add_64[0][0]                     \n",
      "                                                                 conv2d_227[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_205 (BatchN (None, 40, 30, 64)   256         add_65[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_205 (Activation)     (None, 40, 30, 64)   0           batch_normalization_205[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_228 (Conv2D)             (None, 20, 15, 64)   4160        activation_205[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_206 (BatchN (None, 20, 15, 64)   256         conv2d_228[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_206 (Activation)     (None, 20, 15, 64)   0           batch_normalization_206[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_229 (Conv2D)             (None, 20, 15, 64)   36928       activation_206[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_207 (BatchN (None, 20, 15, 64)   256         conv2d_229[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_207 (Activation)     (None, 20, 15, 64)   0           batch_normalization_207[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_231 (Conv2D)             (None, 20, 15, 128)  8320        add_65[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_230 (Conv2D)             (None, 20, 15, 128)  8320        activation_207[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_66 (Add)                    (None, 20, 15, 128)  0           conv2d_231[0][0]                 \n",
      "                                                                 conv2d_230[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_208 (BatchN (None, 20, 15, 128)  512         add_66[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_208 (Activation)     (None, 20, 15, 128)  0           batch_normalization_208[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_232 (Conv2D)             (None, 20, 15, 64)   8256        activation_208[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_209 (BatchN (None, 20, 15, 64)   256         conv2d_232[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_209 (Activation)     (None, 20, 15, 64)   0           batch_normalization_209[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_233 (Conv2D)             (None, 20, 15, 64)   36928       activation_209[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_210 (BatchN (None, 20, 15, 64)   256         conv2d_233[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_210 (Activation)     (None, 20, 15, 64)   0           batch_normalization_210[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_234 (Conv2D)             (None, 20, 15, 128)  8320        activation_210[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_67 (Add)                    (None, 20, 15, 128)  0           add_66[0][0]                     \n",
      "                                                                 conv2d_234[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_211 (BatchN (None, 20, 15, 128)  512         add_67[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_211 (Activation)     (None, 20, 15, 128)  0           batch_normalization_211[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_235 (Conv2D)             (None, 20, 15, 64)   8256        activation_211[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_212 (BatchN (None, 20, 15, 64)   256         conv2d_235[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_212 (Activation)     (None, 20, 15, 64)   0           batch_normalization_212[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_236 (Conv2D)             (None, 20, 15, 64)   36928       activation_212[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_213 (BatchN (None, 20, 15, 64)   256         conv2d_236[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_213 (Activation)     (None, 20, 15, 64)   0           batch_normalization_213[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_237 (Conv2D)             (None, 20, 15, 128)  8320        activation_213[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_68 (Add)                    (None, 20, 15, 128)  0           add_67[0][0]                     \n",
      "                                                                 conv2d_237[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_214 (BatchN (None, 20, 15, 128)  512         add_68[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_214 (Activation)     (None, 20, 15, 128)  0           batch_normalization_214[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_238 (Conv2D)             (None, 10, 8, 128)   16512       activation_214[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_215 (BatchN (None, 10, 8, 128)   512         conv2d_238[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_215 (Activation)     (None, 10, 8, 128)   0           batch_normalization_215[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_239 (Conv2D)             (None, 10, 8, 128)   147584      activation_215[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_216 (BatchN (None, 10, 8, 128)   512         conv2d_239[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_216 (Activation)     (None, 10, 8, 128)   0           batch_normalization_216[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_241 (Conv2D)             (None, 10, 8, 256)   33024       add_68[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_240 (Conv2D)             (None, 10, 8, 256)   33024       activation_216[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_69 (Add)                    (None, 10, 8, 256)   0           conv2d_241[0][0]                 \n",
      "                                                                 conv2d_240[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_217 (BatchN (None, 10, 8, 256)   1024        add_69[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_217 (Activation)     (None, 10, 8, 256)   0           batch_normalization_217[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_242 (Conv2D)             (None, 10, 8, 128)   32896       activation_217[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_218 (BatchN (None, 10, 8, 128)   512         conv2d_242[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_218 (Activation)     (None, 10, 8, 128)   0           batch_normalization_218[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_243 (Conv2D)             (None, 10, 8, 128)   147584      activation_218[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_219 (BatchN (None, 10, 8, 128)   512         conv2d_243[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_219 (Activation)     (None, 10, 8, 128)   0           batch_normalization_219[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_244 (Conv2D)             (None, 10, 8, 256)   33024       activation_219[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_70 (Add)                    (None, 10, 8, 256)   0           add_69[0][0]                     \n",
      "                                                                 conv2d_244[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_220 (BatchN (None, 10, 8, 256)   1024        add_70[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_220 (Activation)     (None, 10, 8, 256)   0           batch_normalization_220[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_245 (Conv2D)             (None, 10, 8, 128)   32896       activation_220[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_221 (BatchN (None, 10, 8, 128)   512         conv2d_245[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_221 (Activation)     (None, 10, 8, 128)   0           batch_normalization_221[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_246 (Conv2D)             (None, 10, 8, 128)   147584      activation_221[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_222 (BatchN (None, 10, 8, 128)   512         conv2d_246[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_222 (Activation)     (None, 10, 8, 128)   0           batch_normalization_222[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_247 (Conv2D)             (None, 10, 8, 256)   33024       activation_222[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_71 (Add)                    (None, 10, 8, 256)   0           add_70[0][0]                     \n",
      "                                                                 conv2d_247[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_223 (BatchN (None, 10, 8, 256)   1024        add_71[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_223 (Activation)     (None, 10, 8, 256)   0           batch_normalization_223[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_7 (AveragePoo (None, 1, 1, 256)    0           activation_223[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "flatten_7 (Flatten)             (None, 256)          0           average_pooling2d_7[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 10)           2570        flatten_7[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 849,002\n",
      "Trainable params: 843,786\n",
      "Non-trainable params: 5,216\n",
      "__________________________________________________________________________________________________\n",
      "ResNet  29v  2\n",
      "Using real-time data augmentation.\n",
      "------------------\n",
      "[[[[-0.12129079 -0.12129079 -0.12129079]\n",
      "   [-0.06661757 -0.06661757 -0.06661757]\n",
      "   [-0.08705871 -0.08705871 -0.08705871]\n",
      "   ...\n",
      "   [-0.16681378 -0.16681378 -0.16681378]\n",
      "   [-0.17975493 -0.17975493 -0.17975493]\n",
      "   [-0.20153597 -0.20153597 -0.20153597]]\n",
      "\n",
      "  [[-0.04143787 -0.04143787 -0.04143787]\n",
      "   [-0.06929728 -0.06929728 -0.06929728]\n",
      "   [-0.08622535 -0.08622535 -0.08622535]\n",
      "   ...\n",
      "   [-0.15037577 -0.15037577 -0.15037577]\n",
      "   [-0.15544121 -0.15544121 -0.15544121]\n",
      "   [-0.17040849 -0.17040849 -0.17040849]]\n",
      "\n",
      "  [[-0.05488554 -0.05488554 -0.05488554]\n",
      "   [-0.07647049 -0.07647049 -0.07647049]\n",
      "   [-0.08733651 -0.08733651 -0.08733651]\n",
      "   ...\n",
      "   [-0.15900326 -0.15900326 -0.15900326]\n",
      "   [-0.15735297 -0.15735297 -0.15735297]\n",
      "   [-0.16818623 -0.16818623 -0.16818623]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[ 0.00740194  0.00740194  0.00740194]\n",
      "   [-0.02483651 -0.02483651 -0.02483651]\n",
      "   [-0.03375809 -0.03375809 -0.03375809]\n",
      "   ...\n",
      "   [-0.07418298 -0.07418298 -0.07418298]\n",
      "   [-0.08897056 -0.08897056 -0.08897056]\n",
      "   [-0.11042488 -0.11042488 -0.11042488]]\n",
      "\n",
      "  [[ 0.39805558  0.39805558  0.39805558]\n",
      "   [-0.02472211 -0.02472211 -0.02472211]\n",
      "   [-0.03124173 -0.03124173 -0.03124173]\n",
      "   ...\n",
      "   [-0.07545745 -0.07545745 -0.07545745]\n",
      "   [-0.08388887 -0.08388887 -0.08388887]\n",
      "   [-0.1144935  -0.1144935  -0.1144935 ]]\n",
      "\n",
      "  [[ 0.28361118  0.28361118  0.28361118]\n",
      "   [ 0.31862754  0.31862754  0.31862754]\n",
      "   [-0.11418292 -0.11418292 -0.11418292]\n",
      "   ...\n",
      "   [-0.1361764  -0.1361764  -0.1361764 ]\n",
      "   [-0.16599667 -0.16599667 -0.16599667]\n",
      "   [-0.1904574  -0.1904574  -0.1904574 ]]]\n",
      "\n",
      "\n",
      " [[[ 0.2826308   0.2826308   0.2826308 ]\n",
      "   [ 0.30985302  0.30985302  0.30985302]\n",
      "   [ 0.31686288  0.31686288  0.31686288]\n",
      "   ...\n",
      "   [-0.19034319 -0.19034319 -0.19034319]\n",
      "   [-0.1954412  -0.1954412  -0.1954412 ]\n",
      "   [-0.20545754 -0.20545754 -0.20545754]]\n",
      "\n",
      "  [[ 0.30758172  0.30758172  0.30758172]\n",
      "   [ 0.29933017  0.29933017  0.29933017]\n",
      "   [ 0.32946092  0.32946092  0.32946092]\n",
      "   ...\n",
      "   [-0.15037577 -0.15037577 -0.15037577]\n",
      "   [-0.15151964 -0.15151964 -0.15151964]\n",
      "   [-0.16648692 -0.16648692 -0.16648692]]\n",
      "\n",
      "  [[ 0.31374192  0.31374192  0.31374192]\n",
      "   [ 0.30784324  0.30784324  0.30784324]\n",
      "   [ 0.30874193  0.30874193  0.30874193]\n",
      "   ...\n",
      "   [-0.15508169 -0.15508169 -0.15508169]\n",
      "   [-0.1534314  -0.1534314  -0.1534314 ]\n",
      "   [-0.16426466 -0.16426466 -0.16426466]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[-0.00828433 -0.00828433 -0.00828433]\n",
      "   [-0.02483651 -0.02483651 -0.02483651]\n",
      "   [-0.03375809 -0.03375809 -0.03375809]\n",
      "   ...\n",
      "   [-0.07418298 -0.07418298 -0.07418298]\n",
      "   [-0.08897056 -0.08897056 -0.08897056]\n",
      "   [-0.11042488 -0.11042488 -0.11042488]]\n",
      "\n",
      "  [[-0.00978758 -0.00978758 -0.00978758]\n",
      "   [-0.02080054 -0.02080054 -0.02080054]\n",
      "   [-0.03516329 -0.03516329 -0.03516329]\n",
      "   ...\n",
      "   [-0.07545745 -0.07545745 -0.07545745]\n",
      "   [-0.08388887 -0.08388887 -0.08388887]\n",
      "   [-0.1144935  -0.1144935  -0.1144935 ]]\n",
      "\n",
      "  [[ 0.28361118  0.28361118  0.28361118]\n",
      "   [-0.10882346 -0.10882346 -0.10882346]\n",
      "   [-0.09457507 -0.09457507 -0.09457507]\n",
      "   ...\n",
      "   [-0.14009798 -0.14009798 -0.14009798]\n",
      "   [-0.16599667 -0.16599667 -0.16599667]\n",
      "   [-0.1904574  -0.1904574  -0.1904574 ]]]\n",
      "\n",
      "\n",
      " [[[ 0.2591014   0.2591014   0.2591014 ]\n",
      "   [ 0.23926479  0.23926479  0.23926479]\n",
      "   [ 0.2541178   0.2541178   0.2541178 ]\n",
      "   ...\n",
      "   [-0.19426475 -0.19426475 -0.19426475]\n",
      "   [-0.19936277 -0.19936277 -0.19936277]\n",
      "   [-0.2093791  -0.2093791  -0.2093791 ]]\n",
      "\n",
      "  [[ 0.30366015  0.30366015  0.30366015]\n",
      "   [ 0.3071733   0.3071733   0.3071733 ]\n",
      "   [ 0.30985308  0.30985308  0.30985308]\n",
      "   ...\n",
      "   [-0.1464542  -0.1464542  -0.1464542 ]\n",
      "   [-0.1436765  -0.1436765  -0.1436765 ]\n",
      "   [-0.15472221 -0.15472221 -0.15472221]]\n",
      "\n",
      "  [[ 0.26276153  0.26276153  0.26276153]\n",
      "   [ 0.27254912  0.27254912  0.27254912]\n",
      "   [ 0.2734478   0.2734478   0.2734478 ]\n",
      "   ...\n",
      "   [-0.15116012 -0.15116012 -0.15116012]\n",
      "   [-0.14950983 -0.14950983 -0.14950983]\n",
      "   [-0.15249996 -0.15249996 -0.15249996]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[-0.0239706  -0.0239706  -0.0239706 ]\n",
      "   [-0.04836592 -0.04836592 -0.04836592]\n",
      "   [-0.04552279 -0.04552279 -0.04552279]\n",
      "   ...\n",
      "   [-0.07418298 -0.07418298 -0.07418298]\n",
      "   [-0.08897056 -0.08897056 -0.08897056]\n",
      "   [-0.11042488 -0.11042488 -0.11042488]]\n",
      "\n",
      "  [[-0.02547386 -0.02547386 -0.02547386]\n",
      "   [-0.04825152 -0.04825152 -0.04825152]\n",
      "   [-0.05477114 -0.05477114 -0.05477114]\n",
      "   ...\n",
      "   [-0.07545745 -0.07545745 -0.07545745]\n",
      "   [-0.08388887 -0.08388887 -0.08388887]\n",
      "   [-0.1144935  -0.1144935  -0.1144935 ]]\n",
      "\n",
      "  [[-0.19874178 -0.19874178 -0.19874178]\n",
      "   [-0.18333326 -0.18333326 -0.18333326]\n",
      "   [-0.16908488 -0.16908488 -0.16908488]\n",
      "   ...\n",
      "   [-0.16362739 -0.16362739 -0.16362739]\n",
      "   [-0.18952608 -0.18952608 -0.18952608]\n",
      "   [-0.21398681 -0.21398681 -0.21398681]]]\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      " [[[-0.06246725 -0.06246725 -0.06246725]\n",
      "   [ 0.01965694  0.01965694  0.01965694]\n",
      "   [-0.10274498 -0.10274498 -0.10274498]\n",
      "   ...\n",
      "   [-0.1511275  -0.1511275  -0.1511275 ]\n",
      "   [-0.14053924 -0.14053924 -0.14053924]\n",
      "   [ 0.2925817   0.2925817   0.2925817 ]]\n",
      "\n",
      "  [[-0.04928101 -0.04928101 -0.04928101]\n",
      "   [-0.07321885 -0.07321885 -0.07321885]\n",
      "   [-0.08230378 -0.08230378 -0.08230378]\n",
      "   ...\n",
      "   [-0.12292479 -0.12292479 -0.12292479]\n",
      "   [-0.10053925 -0.10053925 -0.10053925]\n",
      "   [-0.10374182 -0.10374182 -0.10374182]]\n",
      "\n",
      "  [[-0.06272868 -0.06272868 -0.06272868]\n",
      "   [-0.08039206 -0.08039206 -0.08039206]\n",
      "   [-0.08341494 -0.08341494 -0.08341494]\n",
      "   ...\n",
      "   [-0.13155228 -0.13155228 -0.13155228]\n",
      "   [-0.10245101 -0.10245101 -0.10245101]\n",
      "   [-0.09759799 -0.09759799 -0.09759799]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[-0.06318629 -0.06318629 -0.06318629]\n",
      "   [-0.05620906 -0.05620906 -0.05620906]\n",
      "   [-0.04160122 -0.04160122 -0.04160122]\n",
      "   ...\n",
      "   [-0.046732   -0.046732   -0.046732  ]\n",
      "   [-0.03799017 -0.03799017 -0.03799017]\n",
      "   [-0.0319935  -0.0319935  -0.0319935 ]]\n",
      "\n",
      "  [[-0.05684641 -0.05684641 -0.05684641]\n",
      "   [-0.05609466 -0.05609466 -0.05609466]\n",
      "   [-0.046928   -0.046928   -0.046928  ]\n",
      "   ...\n",
      "   [-0.04800647 -0.04800647 -0.04800647]\n",
      "   [-0.03290847 -0.03290847 -0.03290847]\n",
      "   [-0.03606213 -0.03606213 -0.03606213]]\n",
      "\n",
      "  [[ 0.16988568  0.16988568  0.16988568]\n",
      "   [ 0.12647067  0.12647067  0.12647067]\n",
      "   [ 0.08973867  0.08973867  0.08973867]\n",
      "   ...\n",
      "   [-0.04205876 -0.04205876 -0.04205876]\n",
      "   [-0.04442804 -0.04442804 -0.04442804]\n",
      "   [-0.12771231 -0.12771231 -0.12771231]]]\n",
      "\n",
      "\n",
      " [[[-0.07423196 -0.07423196 -0.07423196]\n",
      "   [ 0.3529903   0.3529903   0.3529903 ]\n",
      "   [-0.1380391  -0.1380391  -0.1380391 ]\n",
      "   ...\n",
      "   [ 0.30769604  0.30769604  0.30769604]\n",
      "   [ 0.30259806  0.30259806  0.30259806]\n",
      "   [ 0.2925817   0.2925817   0.2925817 ]]\n",
      "\n",
      "  [[-0.05320258 -0.05320258 -0.05320258]\n",
      "   [-0.08498356 -0.08498356 -0.08498356]\n",
      "   [-0.09406849 -0.09406849 -0.09406849]\n",
      "   ...\n",
      "   [ 0.24962424  0.24962424  0.24962424]\n",
      "   [ 0.2955392   0.2955392   0.2955392 ]\n",
      "   [ 0.31194445  0.31194445  0.31194445]]\n",
      "\n",
      "  [[-0.06665025 -0.06665025 -0.06665025]\n",
      "   [-0.08431363 -0.08431363 -0.08431363]\n",
      "   [-0.09125808 -0.09125808 -0.09125808]\n",
      "   ...\n",
      "   [ 0.24883988  0.24883988  0.24883988]\n",
      "   [ 0.2740196   0.2740196   0.2740196 ]\n",
      "   [ 0.27495104  0.27495104  0.27495104]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[-0.06710786 -0.06710786 -0.06710786]\n",
      "   [-0.0640522  -0.0640522  -0.0640522 ]\n",
      "   [-0.04944436 -0.04944436 -0.04944436]\n",
      "   ...\n",
      "   [ 0.18464056  0.18464056  0.18464056]\n",
      "   [-0.01838233 -0.01838233 -0.01838233]\n",
      "   [ 0.00722218  0.00722218  0.00722218]]\n",
      "\n",
      "  [[-0.06076797 -0.06076797 -0.06076797]\n",
      "   [-0.0639378  -0.0639378  -0.0639378 ]\n",
      "   [-0.05477114 -0.05477114 -0.05477114]\n",
      "   ...\n",
      "   [-0.05192804 -0.05192804 -0.05192804]\n",
      "   [-0.03683004 -0.03683004 -0.03683004]\n",
      "   [-0.00076801 -0.00076801 -0.00076801]]\n",
      "\n",
      "  [[-0.17521237 -0.17521237 -0.17521237]\n",
      "   [-0.15588228 -0.15588228 -0.15588228]\n",
      "   [-0.14947703 -0.14947703 -0.14947703]\n",
      "   ...\n",
      "   [-0.14009798 -0.14009798 -0.14009798]\n",
      "   [-0.13462412 -0.13462412 -0.13462412]\n",
      "   [-0.11986917 -0.11986917 -0.11986917]]]\n",
      "\n",
      "\n",
      " [[[-0.03109471 -0.03109471 -0.03109471]\n",
      "   [-0.05877443 -0.05877443 -0.05877443]\n",
      "   [-0.06745086 -0.06745086 -0.06745086]\n",
      "   ...\n",
      "   [-0.19426475 -0.19426475 -0.19426475]\n",
      "   [-0.19936277 -0.19936277 -0.19936277]\n",
      "   [-0.20545754 -0.20545754 -0.20545754]]\n",
      "\n",
      "  [[-0.02967317 -0.02967317 -0.02967317]\n",
      "   [-0.0300816  -0.0300816  -0.0300816 ]\n",
      "   [-0.05093123 -0.05093123 -0.05093123]\n",
      "   ...\n",
      "   [-0.15429734 -0.15429734 -0.15429734]\n",
      "   [-0.15544121 -0.15544121 -0.15544121]\n",
      "   [-0.16648692 -0.16648692 -0.16648692]]\n",
      "\n",
      "  [[-0.05488554 -0.05488554 -0.05488554]\n",
      "   [-0.0254901  -0.0254901  -0.0254901 ]\n",
      "   [-0.05204239 -0.05204239 -0.05204239]\n",
      "   ...\n",
      "   [-0.15900326 -0.15900326 -0.15900326]\n",
      "   [-0.15735297 -0.15735297 -0.15735297]\n",
      "   [-0.16818623 -0.16818623 -0.16818623]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[ 0.02308822  0.02308822  0.02308822]\n",
      "   [ 0.00261447  0.00261447  0.00261447]\n",
      "   [-0.00238553 -0.00238553 -0.00238553]\n",
      "   ...\n",
      "   [-0.07418298 -0.07418298 -0.07418298]\n",
      "   [-0.08897056 -0.08897056 -0.08897056]\n",
      "   [-0.11042488 -0.11042488 -0.11042488]]\n",
      "\n",
      "  [[ 0.02550654  0.02550654  0.02550654]\n",
      "   [-0.0011927  -0.0011927  -0.0011927 ]\n",
      "   [-0.01163388 -0.01163388 -0.01163388]\n",
      "   ...\n",
      "   [-0.07545745 -0.07545745 -0.07545745]\n",
      "   [-0.08388887 -0.08388887 -0.08388887]\n",
      "   [-0.1144935  -0.1144935  -0.1144935 ]]\n",
      "\n",
      "  [[-0.11246727 -0.11246727 -0.11246727]\n",
      "   [-0.08921561 -0.08921561 -0.08921561]\n",
      "   [-0.09849664 -0.09849664 -0.09849664]\n",
      "   ...\n",
      "   [-0.16362739 -0.16362739 -0.16362739]\n",
      "   [-0.18952608 -0.18952608 -0.18952608]\n",
      "   [-0.21398681 -0.21398681 -0.21398681]]]]\n",
      "Epoch 1/100\n",
      "Learning rate:  0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\patcas rares\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\keras\\engine\\training.py:1972: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 12s 890ms/step - loss: 2.3456 - accuracy: 0.4125 - val_loss: 2.8733 - val_accuracy: 0.2333\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 2/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 681ms/step - loss: 1.3889 - accuracy: 0.6417 - val_loss: 2.5960 - val_accuracy: 0.7667\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 3/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 697ms/step - loss: 1.2160 - accuracy: 0.7042 - val_loss: 2.2840 - val_accuracy: 0.7667\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 4/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 756ms/step - loss: 1.1566 - accuracy: 0.7167 - val_loss: 2.1742 - val_accuracy: 0.7667\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 5/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 5s 643ms/step - loss: 1.1434 - accuracy: 0.6917 - val_loss: 2.2449 - val_accuracy: 0.7667\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 6/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 740ms/step - loss: 1.1041 - accuracy: 0.7333 - val_loss: 2.1760 - val_accuracy: 0.7667\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 7/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 695ms/step - loss: 1.0621 - accuracy: 0.7250 - val_loss: 2.0661 - val_accuracy: 0.7667\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 8/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 788ms/step - loss: 1.0882 - accuracy: 0.7208 - val_loss: 1.9392 - val_accuracy: 0.7667\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 9/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 5s 609ms/step - loss: 1.0476 - accuracy: 0.7625 - val_loss: 2.0315 - val_accuracy: 0.7667\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 10/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 804ms/step - loss: 1.0802 - accuracy: 0.7167 - val_loss: 1.8798 - val_accuracy: 0.7667\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 11/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 779ms/step - loss: 1.0307 - accuracy: 0.7500 - val_loss: 1.4885 - val_accuracy: 0.7667\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 12/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 5s 628ms/step - loss: 0.9948 - accuracy: 0.7500 - val_loss: 1.4728 - val_accuracy: 0.7667\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 13/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 5s 674ms/step - loss: 0.9744 - accuracy: 0.8000 - val_loss: 1.9116 - val_accuracy: 0.7667\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 14/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 5s 651ms/step - loss: 1.0030 - accuracy: 0.7583 - val_loss: 2.0530 - val_accuracy: 0.7667\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 15/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 5s 667ms/step - loss: 0.9573 - accuracy: 0.7833 - val_loss: 2.1060 - val_accuracy: 0.7667\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 16/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 5s 662ms/step - loss: 0.9681 - accuracy: 0.7792 - val_loss: 2.0554 - val_accuracy: 0.7667\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 17/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 719ms/step - loss: 0.9604 - accuracy: 0.7708 - val_loss: 3.8952 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 18/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 737ms/step - loss: 0.9629 - accuracy: 0.7583 - val_loss: 4.5605 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 19/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 5s 611ms/step - loss: 0.9032 - accuracy: 0.8167 - val_loss: 2.3274 - val_accuracy: 0.7667\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 20/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 739ms/step - loss: 0.9291 - accuracy: 0.7917 - val_loss: 2.2892 - val_accuracy: 0.7667\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 21/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 768ms/step - loss: 0.9307 - accuracy: 0.7542 - val_loss: 6.4416 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 22/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 826ms/step - loss: 0.8905 - accuracy: 0.8333 - val_loss: 9.8743 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 23/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 5s 683ms/step - loss: 0.8639 - accuracy: 0.8375 - val_loss: 13.3318 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 24/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 5s 663ms/step - loss: 0.9224 - accuracy: 0.7792 - val_loss: 2.3890 - val_accuracy: 0.7667\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 25/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 668ms/step - loss: 0.8830 - accuracy: 0.8083 - val_loss: 6.9499 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 26/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 5s 636ms/step - loss: 0.8679 - accuracy: 0.8417 - val_loss: 7.6189 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 27/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 5s 658ms/step - loss: 0.8741 - accuracy: 0.7958 - val_loss: 11.6596 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 28/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 5s 625ms/step - loss: 0.8413 - accuracy: 0.8333 - val_loss: 4.5348 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 29/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 5s 662ms/step - loss: 0.8431 - accuracy: 0.8000 - val_loss: 10.5959 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 30/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 5s 621ms/step - loss: 0.8385 - accuracy: 0.8125 - val_loss: 5.1595 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 31/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 5s 627ms/step - loss: 0.8405 - accuracy: 0.8500 - val_loss: 2.7584 - val_accuracy: 0.7667\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 32/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 5s 603ms/step - loss: 0.8126 - accuracy: 0.8417 - val_loss: 9.7194 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 33/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 5s 608ms/step - loss: 0.8434 - accuracy: 0.8125 - val_loss: 9.0352 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 34/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 5s 605ms/step - loss: 0.8507 - accuracy: 0.7708 - val_loss: 11.1518 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 5s 623ms/step - loss: 0.7905 - accuracy: 0.8500 - val_loss: 16.1346 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 36/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 5s 605ms/step - loss: 0.7885 - accuracy: 0.8417 - val_loss: 11.4693 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 37/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 5s 607ms/step - loss: 0.8486 - accuracy: 0.8083 - val_loss: 11.5310 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 38/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 779ms/step - loss: 0.7861 - accuracy: 0.8292 - val_loss: 10.5636 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 39/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 791ms/step - loss: 0.7891 - accuracy: 0.8208 - val_loss: 7.5412 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 40/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 737ms/step - loss: 0.7659 - accuracy: 0.8333 - val_loss: 18.1347 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 41/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 767ms/step - loss: 0.8190 - accuracy: 0.8375 - val_loss: 18.5416 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 42/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 767ms/step - loss: 0.7333 - accuracy: 0.8708 - val_loss: 15.6714 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 43/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 8s 978ms/step - loss: 0.7112 - accuracy: 0.8792 - val_loss: 16.8784 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 44/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 8s 972ms/step - loss: 0.6995 - accuracy: 0.8792 - val_loss: 18.3095 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 45/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 7s 865ms/step - loss: 0.6901 - accuracy: 0.8958 - val_loss: 13.2731 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 46/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 7s 799ms/step - loss: 0.7569 - accuracy: 0.8375 - val_loss: 14.6027 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 47/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 730ms/step - loss: 0.7231 - accuracy: 0.8583 - val_loss: 15.1654 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 48/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 729ms/step - loss: 0.6979 - accuracy: 0.8833 - val_loss: 12.5693 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 49/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 5s 668ms/step - loss: 0.7177 - accuracy: 0.8625 - val_loss: 16.3740 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 50/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 701ms/step - loss: 0.6716 - accuracy: 0.8792 - val_loss: 17.6915 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 51/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 700ms/step - loss: 0.6442 - accuracy: 0.9000 - val_loss: 19.9245 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 52/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 5s 666ms/step - loss: 0.6538 - accuracy: 0.9042 - val_loss: 17.6068 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 53/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 730ms/step - loss: 0.6771 - accuracy: 0.8792 - val_loss: 19.9712 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 54/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 7s 767ms/step - loss: 0.6431 - accuracy: 0.9000 - val_loss: 19.7651 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 55/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 5s 629ms/step - loss: 0.6892 - accuracy: 0.8625 - val_loss: 10.5420 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 56/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 781ms/step - loss: 0.6106 - accuracy: 0.9167 - val_loss: 8.9235 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 57/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 777ms/step - loss: 0.6509 - accuracy: 0.9042 - val_loss: 13.9432 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 58/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 777ms/step - loss: 0.6200 - accuracy: 0.9083 - val_loss: 13.2474 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 59/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 851ms/step - loss: 0.6840 - accuracy: 0.8750 - val_loss: 14.2266 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 60/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 692ms/step - loss: 0.6370 - accuracy: 0.8750 - val_loss: 12.5844 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 61/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 5s 670ms/step - loss: 0.6111 - accuracy: 0.9042 - val_loss: 16.0952 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 62/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 5s 668ms/step - loss: 0.6516 - accuracy: 0.8750 - val_loss: 20.8098 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 63/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 697ms/step - loss: 0.6798 - accuracy: 0.8708 - val_loss: 32.7216 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 64/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 707ms/step - loss: 0.6431 - accuracy: 0.8917 - val_loss: 37.7124 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 65/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 703ms/step - loss: 0.5802 - accuracy: 0.9125 - val_loss: 38.3960 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 66/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 5s 671ms/step - loss: 0.6034 - accuracy: 0.8917 - val_loss: 27.5377 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 67/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 684ms/step - loss: 0.5787 - accuracy: 0.9125 - val_loss: 19.6857 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 68/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 682ms/step - loss: 0.5658 - accuracy: 0.9167 - val_loss: 18.0378 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 69/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 5s 665ms/step - loss: 0.5845 - accuracy: 0.9208 - val_loss: 21.3117 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 70/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 685ms/step - loss: 0.5997 - accuracy: 0.8875 - val_loss: 17.6051 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 71/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 690ms/step - loss: 0.5931 - accuracy: 0.8875 - val_loss: 22.0678 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 72/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 683ms/step - loss: 0.6466 - accuracy: 0.8917 - val_loss: 12.3495 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 73/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 673ms/step - loss: 0.5601 - accuracy: 0.9250 - val_loss: 12.4198 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 74/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 5s 666ms/step - loss: 0.5131 - accuracy: 0.9500 - val_loss: 11.5390 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 75/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 5s 668ms/step - loss: 0.5611 - accuracy: 0.9333 - val_loss: 17.9958 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 76/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 685ms/step - loss: 0.5453 - accuracy: 0.9375 - val_loss: 14.8127 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 77/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 5s 670ms/step - loss: 0.4902 - accuracy: 0.9667 - val_loss: 19.9783 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 78/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 5s 672ms/step - loss: 0.5124 - accuracy: 0.9250 - val_loss: 20.7916 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 79/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 738ms/step - loss: 0.5379 - accuracy: 0.9333 - val_loss: 20.5234 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 80/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 784ms/step - loss: 0.5566 - accuracy: 0.9208 - val_loss: 9.6228 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 81/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 5s 676ms/step - loss: 0.5627 - accuracy: 0.9125 - val_loss: 11.3275 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 82/100\n",
      "Learning rate:  0.0001\n",
      "8/8 [==============================] - 5s 670ms/step - loss: 0.5974 - accuracy: 0.9083 - val_loss: 11.8602 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 83/100\n",
      "Learning rate:  0.0001\n",
      "8/8 [==============================] - 6s 803ms/step - loss: 0.4903 - accuracy: 0.9667 - val_loss: 12.4451 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 84/100\n",
      "Learning rate:  0.0001\n",
      "8/8 [==============================] - 6s 674ms/step - loss: 0.4691 - accuracy: 0.9583 - val_loss: 13.4777 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 85/100\n",
      "Learning rate:  0.0001\n",
      "8/8 [==============================] - 6s 711ms/step - loss: 0.4568 - accuracy: 0.9708 - val_loss: 14.4385 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 86/100\n",
      "Learning rate:  0.0001\n",
      "8/8 [==============================] - 5s 669ms/step - loss: 0.4627 - accuracy: 0.9542 - val_loss: 14.8307 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 87/100\n",
      "Learning rate:  0.0001\n",
      "8/8 [==============================] - 5s 612ms/step - loss: 0.4973 - accuracy: 0.9458 - val_loss: 15.4249 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 88/100\n",
      "Learning rate:  0.0001\n",
      "8/8 [==============================] - 5s 647ms/step - loss: 0.4442 - accuracy: 0.9833 - val_loss: 16.1241 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 89/100\n",
      "Learning rate:  0.0001\n",
      "8/8 [==============================] - 5s 667ms/step - loss: 0.4564 - accuracy: 0.9708 - val_loss: 16.2790 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 90/100\n",
      "Learning rate:  0.0001\n",
      "8/8 [==============================] - 5s 629ms/step - loss: 0.4532 - accuracy: 0.9667 - val_loss: 16.4808 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 91/100\n",
      "Learning rate:  0.0001\n",
      "8/8 [==============================] - 5s 616ms/step - loss: 0.4451 - accuracy: 0.9792 - val_loss: 16.7982 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 92/100\n",
      "Learning rate:  0.0001\n",
      "8/8 [==============================] - 5s 607ms/step - loss: 0.4518 - accuracy: 0.9625 - val_loss: 17.3246 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 93/100\n",
      "Learning rate:  0.0001\n",
      "8/8 [==============================] - 5s 638ms/step - loss: 0.4524 - accuracy: 0.9542 - val_loss: 17.7309 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 94/100\n",
      "Learning rate:  0.0001\n",
      "8/8 [==============================] - 5s 675ms/step - loss: 0.4561 - accuracy: 0.9708 - val_loss: 18.3602 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 95/100\n",
      "Learning rate:  0.0001\n",
      "8/8 [==============================] - 5s 608ms/step - loss: 0.4772 - accuracy: 0.9542 - val_loss: 18.7752 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 96/100\n",
      "Learning rate:  0.0001\n",
      "8/8 [==============================] - 5s 625ms/step - loss: 0.4086 - accuracy: 0.9875 - val_loss: 18.8687 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 97/100\n",
      "Learning rate:  0.0001\n",
      "8/8 [==============================] - 5s 649ms/step - loss: 0.4399 - accuracy: 0.9750 - val_loss: 18.6170 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 98/100\n",
      "Learning rate:  0.0001\n",
      "8/8 [==============================] - 5s 676ms/step - loss: 0.4491 - accuracy: 0.9667 - val_loss: 18.3776 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 99/100\n",
      "Learning rate:  0.0001\n",
      "8/8 [==============================] - 5s 607ms/step - loss: 0.4663 - accuracy: 0.9583 - val_loss: 18.2482 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 100/100\n",
      "Learning rate:  0.0001\n",
      "8/8 [==============================] - 5s 639ms/step - loss: 0.4276 - accuracy: 0.9708 - val_loss: 17.9012 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 197ms/step - loss: 0.7177 - accuracy: 0.9000\n",
      "Test loss: 0.717656135559082\n",
      "Test accuracy: 0.8999999761581421\n",
      "[1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Precision:  1.0\n",
      "Recall:  0.9\n",
      "F1 Score:  0.9457142857142856\n",
      "[[[[108 108 108]\n",
      "   [117 117 117]\n",
      "   [116 116 116]\n",
      "   ...\n",
      "   [  1   1   1]\n",
      "   [  1   1   1]\n",
      "   [  1   1   1]]\n",
      "\n",
      "  [[112 112 112]\n",
      "   [108 108 108]\n",
      "   [115 115 115]\n",
      "   ...\n",
      "   [  1   1   1]\n",
      "   [  1   1   1]\n",
      "   [  1   1   1]]\n",
      "\n",
      "  [[117 117 117]\n",
      "   [112 112 112]\n",
      "   [110 110 110]\n",
      "   ...\n",
      "   [  1   1   1]\n",
      "   [  1   1   1]\n",
      "   [  1   1   1]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[ 25  25  25]\n",
      "   [ 17  17  17]\n",
      "   [ 10  10  10]\n",
      "   ...\n",
      "   [  0   0   0]\n",
      "   [  0   0   0]\n",
      "   [  0   0   0]]\n",
      "\n",
      "  [[ 24  24  24]\n",
      "   [ 18  18  18]\n",
      "   [ 11  11  11]\n",
      "   ...\n",
      "   [  0   0   0]\n",
      "   [  0   0   0]\n",
      "   [  0   0   0]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [ 19  19  19]\n",
      "   [ 19  19  19]\n",
      "   ...\n",
      "   [  6   6   6]\n",
      "   [  6   6   6]\n",
      "   [  6   6   6]]]\n",
      "\n",
      "\n",
      " [[[102 102 102]\n",
      "   [ 99  99  99]\n",
      "   [100 100 100]\n",
      "   ...\n",
      "   [  0   0   0]\n",
      "   [  0   0   0]\n",
      "   [  0   0   0]]\n",
      "\n",
      "  [[111 111 111]\n",
      "   [110 110 110]\n",
      "   [110 110 110]\n",
      "   ...\n",
      "   [  2   2   2]\n",
      "   [  3   3   3]\n",
      "   [  4   4   4]]\n",
      "\n",
      "  [[104 104 104]\n",
      "   [103 103 103]\n",
      "   [101 101 101]\n",
      "   ...\n",
      "   [  2   2   2]\n",
      "   [  2   2   2]\n",
      "   [  4   4   4]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[ 21  21  21]\n",
      "   [ 11  11  11]\n",
      "   [  7   7   7]\n",
      "   ...\n",
      "   [  0   0   0]\n",
      "   [  0   0   0]\n",
      "   [  0   0   0]]\n",
      "\n",
      "  [[ 20  20  20]\n",
      "   [ 11  11  11]\n",
      "   [  6   6   6]\n",
      "   ...\n",
      "   [  0   0   0]\n",
      "   [  0   0   0]\n",
      "   [  0   0   0]]\n",
      "\n",
      "  [[  5   5   5]\n",
      "   [  0   0   0]\n",
      "   [  0   0   0]\n",
      "   ...\n",
      "   [  0   0   0]\n",
      "   [  0   0   0]\n",
      "   [  0   0   0]]]\n",
      "\n",
      "\n",
      " [[[  9   9   9]\n",
      "   [ 18  18  18]\n",
      "   [ 15  15  15]\n",
      "   ...\n",
      "   [ 11  11  11]\n",
      "   [ 19  19  19]\n",
      "   [ 10  10  10]]\n",
      "\n",
      "  [[ 22  22  22]\n",
      "   [ 13  13  13]\n",
      "   [  9   9   9]\n",
      "   ...\n",
      "   [  1   1   1]\n",
      "   [  1   1   1]\n",
      "   [  2   2   2]]\n",
      "\n",
      "  [[ 23  23  23]\n",
      "   [ 13  13  13]\n",
      "   [  9   9   9]\n",
      "   ...\n",
      "   [  1   1   1]\n",
      "   [  1   1   1]\n",
      "   [  1   1   1]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[ 86  86  86]\n",
      "   [ 71  71  71]\n",
      "   [ 48  48  48]\n",
      "   ...\n",
      "   [  0   0   0]\n",
      "   [  0   0   0]\n",
      "   [  0   0   0]]\n",
      "\n",
      "  [[ 74  74  74]\n",
      "   [ 26  26  26]\n",
      "   [ 12  12  12]\n",
      "   ...\n",
      "   [  0   0   0]\n",
      "   [  0   0   0]\n",
      "   [  0   0   0]]\n",
      "\n",
      "  [[ 29  29  29]\n",
      "   [ 10  10  10]\n",
      "   [  9   9   9]\n",
      "   ...\n",
      "   [  0   0   0]\n",
      "   [  0   0   0]\n",
      "   [  0   0   0]]]]\n",
      "[[1]\n",
      " [1]\n",
      " [1]]\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "(40, 30, 3)\n",
      "x_train shape: (240, 40, 30, 3)\n",
      "240 train samples\n",
      "30 test samples\n",
      "y_train shape: (240, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\patcas rares\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate:  0.001\n",
      "Model: \"model_8\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_9 (InputLayer)            [(None, 40, 30, 3)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_248 (Conv2D)             (None, 40, 30, 16)   448         input_9[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_224 (BatchN (None, 40, 30, 16)   64          conv2d_248[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_224 (Activation)     (None, 40, 30, 16)   0           batch_normalization_224[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_249 (Conv2D)             (None, 40, 30, 16)   272         activation_224[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_225 (BatchN (None, 40, 30, 16)   64          conv2d_249[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_225 (Activation)     (None, 40, 30, 16)   0           batch_normalization_225[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_250 (Conv2D)             (None, 40, 30, 16)   2320        activation_225[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_226 (BatchN (None, 40, 30, 16)   64          conv2d_250[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_226 (Activation)     (None, 40, 30, 16)   0           batch_normalization_226[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_252 (Conv2D)             (None, 40, 30, 64)   1088        activation_224[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_251 (Conv2D)             (None, 40, 30, 64)   1088        activation_226[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_72 (Add)                    (None, 40, 30, 64)   0           conv2d_252[0][0]                 \n",
      "                                                                 conv2d_251[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_227 (BatchN (None, 40, 30, 64)   256         add_72[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_227 (Activation)     (None, 40, 30, 64)   0           batch_normalization_227[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_253 (Conv2D)             (None, 40, 30, 16)   1040        activation_227[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_228 (BatchN (None, 40, 30, 16)   64          conv2d_253[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_228 (Activation)     (None, 40, 30, 16)   0           batch_normalization_228[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_254 (Conv2D)             (None, 40, 30, 16)   2320        activation_228[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_229 (BatchN (None, 40, 30, 16)   64          conv2d_254[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_229 (Activation)     (None, 40, 30, 16)   0           batch_normalization_229[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_255 (Conv2D)             (None, 40, 30, 64)   1088        activation_229[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_73 (Add)                    (None, 40, 30, 64)   0           add_72[0][0]                     \n",
      "                                                                 conv2d_255[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_230 (BatchN (None, 40, 30, 64)   256         add_73[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_230 (Activation)     (None, 40, 30, 64)   0           batch_normalization_230[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_256 (Conv2D)             (None, 40, 30, 16)   1040        activation_230[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_231 (BatchN (None, 40, 30, 16)   64          conv2d_256[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_231 (Activation)     (None, 40, 30, 16)   0           batch_normalization_231[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_257 (Conv2D)             (None, 40, 30, 16)   2320        activation_231[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_232 (BatchN (None, 40, 30, 16)   64          conv2d_257[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_232 (Activation)     (None, 40, 30, 16)   0           batch_normalization_232[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_258 (Conv2D)             (None, 40, 30, 64)   1088        activation_232[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_74 (Add)                    (None, 40, 30, 64)   0           add_73[0][0]                     \n",
      "                                                                 conv2d_258[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_233 (BatchN (None, 40, 30, 64)   256         add_74[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_233 (Activation)     (None, 40, 30, 64)   0           batch_normalization_233[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_259 (Conv2D)             (None, 20, 15, 64)   4160        activation_233[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_234 (BatchN (None, 20, 15, 64)   256         conv2d_259[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_234 (Activation)     (None, 20, 15, 64)   0           batch_normalization_234[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_260 (Conv2D)             (None, 20, 15, 64)   36928       activation_234[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_235 (BatchN (None, 20, 15, 64)   256         conv2d_260[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_235 (Activation)     (None, 20, 15, 64)   0           batch_normalization_235[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_262 (Conv2D)             (None, 20, 15, 128)  8320        add_74[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_261 (Conv2D)             (None, 20, 15, 128)  8320        activation_235[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_75 (Add)                    (None, 20, 15, 128)  0           conv2d_262[0][0]                 \n",
      "                                                                 conv2d_261[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_236 (BatchN (None, 20, 15, 128)  512         add_75[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_236 (Activation)     (None, 20, 15, 128)  0           batch_normalization_236[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_263 (Conv2D)             (None, 20, 15, 64)   8256        activation_236[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_237 (BatchN (None, 20, 15, 64)   256         conv2d_263[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_237 (Activation)     (None, 20, 15, 64)   0           batch_normalization_237[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_264 (Conv2D)             (None, 20, 15, 64)   36928       activation_237[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_238 (BatchN (None, 20, 15, 64)   256         conv2d_264[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_238 (Activation)     (None, 20, 15, 64)   0           batch_normalization_238[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_265 (Conv2D)             (None, 20, 15, 128)  8320        activation_238[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_76 (Add)                    (None, 20, 15, 128)  0           add_75[0][0]                     \n",
      "                                                                 conv2d_265[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_239 (BatchN (None, 20, 15, 128)  512         add_76[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_239 (Activation)     (None, 20, 15, 128)  0           batch_normalization_239[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_266 (Conv2D)             (None, 20, 15, 64)   8256        activation_239[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_240 (BatchN (None, 20, 15, 64)   256         conv2d_266[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_240 (Activation)     (None, 20, 15, 64)   0           batch_normalization_240[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_267 (Conv2D)             (None, 20, 15, 64)   36928       activation_240[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_241 (BatchN (None, 20, 15, 64)   256         conv2d_267[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_241 (Activation)     (None, 20, 15, 64)   0           batch_normalization_241[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_268 (Conv2D)             (None, 20, 15, 128)  8320        activation_241[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_77 (Add)                    (None, 20, 15, 128)  0           add_76[0][0]                     \n",
      "                                                                 conv2d_268[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_242 (BatchN (None, 20, 15, 128)  512         add_77[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_242 (Activation)     (None, 20, 15, 128)  0           batch_normalization_242[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_269 (Conv2D)             (None, 10, 8, 128)   16512       activation_242[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_243 (BatchN (None, 10, 8, 128)   512         conv2d_269[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_243 (Activation)     (None, 10, 8, 128)   0           batch_normalization_243[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_270 (Conv2D)             (None, 10, 8, 128)   147584      activation_243[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_244 (BatchN (None, 10, 8, 128)   512         conv2d_270[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_244 (Activation)     (None, 10, 8, 128)   0           batch_normalization_244[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_272 (Conv2D)             (None, 10, 8, 256)   33024       add_77[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_271 (Conv2D)             (None, 10, 8, 256)   33024       activation_244[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_78 (Add)                    (None, 10, 8, 256)   0           conv2d_272[0][0]                 \n",
      "                                                                 conv2d_271[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_245 (BatchN (None, 10, 8, 256)   1024        add_78[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_245 (Activation)     (None, 10, 8, 256)   0           batch_normalization_245[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_273 (Conv2D)             (None, 10, 8, 128)   32896       activation_245[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_246 (BatchN (None, 10, 8, 128)   512         conv2d_273[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_246 (Activation)     (None, 10, 8, 128)   0           batch_normalization_246[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_274 (Conv2D)             (None, 10, 8, 128)   147584      activation_246[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_247 (BatchN (None, 10, 8, 128)   512         conv2d_274[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_247 (Activation)     (None, 10, 8, 128)   0           batch_normalization_247[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_275 (Conv2D)             (None, 10, 8, 256)   33024       activation_247[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_79 (Add)                    (None, 10, 8, 256)   0           add_78[0][0]                     \n",
      "                                                                 conv2d_275[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_248 (BatchN (None, 10, 8, 256)   1024        add_79[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_248 (Activation)     (None, 10, 8, 256)   0           batch_normalization_248[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_276 (Conv2D)             (None, 10, 8, 128)   32896       activation_248[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_249 (BatchN (None, 10, 8, 128)   512         conv2d_276[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_249 (Activation)     (None, 10, 8, 128)   0           batch_normalization_249[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_277 (Conv2D)             (None, 10, 8, 128)   147584      activation_249[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_250 (BatchN (None, 10, 8, 128)   512         conv2d_277[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_250 (Activation)     (None, 10, 8, 128)   0           batch_normalization_250[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_278 (Conv2D)             (None, 10, 8, 256)   33024       activation_250[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_80 (Add)                    (None, 10, 8, 256)   0           add_79[0][0]                     \n",
      "                                                                 conv2d_278[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_251 (BatchN (None, 10, 8, 256)   1024        add_80[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_251 (Activation)     (None, 10, 8, 256)   0           batch_normalization_251[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_8 (AveragePoo (None, 1, 1, 256)    0           activation_251[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "flatten_8 (Flatten)             (None, 256)          0           average_pooling2d_8[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Dense)                 (None, 10)           2570        flatten_8[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 849,002\n",
      "Trainable params: 843,786\n",
      "Non-trainable params: 5,216\n",
      "__________________________________________________________________________________________________\n",
      "ResNet  29v  2\n",
      "Using real-time data augmentation.\n",
      "------------------\n",
      "[[[[ 0.28289223  0.28289223  0.28289223]\n",
      "   [ 0.3089053   0.3089053   0.3089053 ]\n",
      "   [ 0.31243473  0.31243473  0.31243473]\n",
      "   ...\n",
      "   [-0.18656865 -0.18656865 -0.18656865]\n",
      "   [-0.1919444  -0.1919444  -0.1919444 ]\n",
      "   [-0.20191178 -0.20191178 -0.20191178]]\n",
      "\n",
      "  [[ 0.30446085  0.30446085  0.30446085]\n",
      "   [ 0.29921576  0.29921576  0.29921576]\n",
      "   [ 0.3309315   0.3309315   0.3309315 ]\n",
      "   ...\n",
      "   [-0.14251629 -0.14251629 -0.14251629]\n",
      "   [-0.1436928  -0.1436928  -0.1436928 ]\n",
      "   [-0.1570751  -0.1570751  -0.1570751 ]]\n",
      "\n",
      "  [[ 0.3170262   0.3170262   0.3170262 ]\n",
      "   [ 0.30687916  0.30687916  0.30687916]\n",
      "   [ 0.30710793  0.30710793  0.30710793]\n",
      "   ...\n",
      "   [-0.15104572 -0.15104572 -0.15104572]\n",
      "   [-0.15625818 -0.15625818 -0.15625818]\n",
      "   [-0.1605228  -0.1605228  -0.1605228 ]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[-0.00993466 -0.00993466 -0.00993466]\n",
      "   [-0.02379075 -0.02379075 -0.02379075]\n",
      "   [-0.03496722 -0.03496722 -0.03496722]\n",
      "   ...\n",
      "   [-0.07560452 -0.07560452 -0.07560452]\n",
      "   [-0.08995095 -0.08995095 -0.08995095]\n",
      "   [-0.1067811  -0.1067811  -0.1067811 ]]\n",
      "\n",
      "  [[-0.00575165 -0.00575165 -0.00575165]\n",
      "   [-0.01988551 -0.01988551 -0.01988551]\n",
      "   [-0.03366002 -0.03366002 -0.03366002]\n",
      "   ...\n",
      "   [-0.07601302 -0.07601302 -0.07601302]\n",
      "   [-0.08547382 -0.08547382 -0.08547382]\n",
      "   [-0.11127455 -0.11127455 -0.11127455]]\n",
      "\n",
      "  [[ 0.2799511   0.2799511   0.2799511 ]\n",
      "   [-0.11083326 -0.11083326 -0.11083326]\n",
      "   [-0.09928093 -0.09928093 -0.09928093]\n",
      "   ...\n",
      "   [-0.14903589 -0.14903589 -0.14903589]\n",
      "   [-0.16300656 -0.16300656 -0.16300656]\n",
      "   [-0.19248357 -0.19248357 -0.19248357]]]\n",
      "\n",
      "\n",
      " [[[ 0.25936282  0.25936282  0.25936282]\n",
      "   [ 0.23831707  0.23831707  0.23831707]\n",
      "   [ 0.24968964  0.24968964  0.24968964]\n",
      "   ...\n",
      "   [-0.19049022 -0.19049022 -0.19049022]\n",
      "   [-0.19586597 -0.19586597 -0.19586597]\n",
      "   [-0.20583335 -0.20583335 -0.20583335]]\n",
      "\n",
      "  [[ 0.30053928  0.30053928  0.30053928]\n",
      "   [ 0.3070589   0.3070589   0.3070589 ]\n",
      "   [ 0.31132367  0.31132367  0.31132367]\n",
      "   ...\n",
      "   [-0.13859472 -0.13859472 -0.13859472]\n",
      "   [-0.13584967 -0.13584967 -0.13584967]\n",
      "   [-0.1453104  -0.1453104  -0.1453104 ]]\n",
      "\n",
      "  [[ 0.2660458   0.2660458   0.2660458 ]\n",
      "   [ 0.27158505  0.27158505  0.27158505]\n",
      "   [ 0.2718138   0.2718138   0.2718138 ]\n",
      "   ...\n",
      "   [-0.14712416 -0.14712416 -0.14712416]\n",
      "   [-0.15233661 -0.15233661 -0.15233661]\n",
      "   [-0.1487581  -0.1487581  -0.1487581 ]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[-0.02562094 -0.02562094 -0.02562094]\n",
      "   [-0.04732017 -0.04732017 -0.04732017]\n",
      "   [-0.04673193 -0.04673193 -0.04673193]\n",
      "   ...\n",
      "   [-0.07560452 -0.07560452 -0.07560452]\n",
      "   [-0.08995095 -0.08995095 -0.08995095]\n",
      "   [-0.1067811  -0.1067811  -0.1067811 ]]\n",
      "\n",
      "  [[-0.02143793 -0.02143793 -0.02143793]\n",
      "   [-0.04733649 -0.04733649 -0.04733649]\n",
      "   [-0.05326787 -0.05326787 -0.05326787]\n",
      "   ...\n",
      "   [-0.07601302 -0.07601302 -0.07601302]\n",
      "   [-0.08547382 -0.08547382 -0.08547382]\n",
      "   [-0.11127455 -0.11127455 -0.11127455]]\n",
      "\n",
      "  [[-0.20240188 -0.20240188 -0.20240188]\n",
      "   [-0.18534307 -0.18534307 -0.18534307]\n",
      "   [-0.17379074 -0.17379074 -0.17379074]\n",
      "   ...\n",
      "   [-0.1725653  -0.1725653  -0.1725653 ]\n",
      "   [-0.18653597 -0.18653597 -0.18653597]\n",
      "   [-0.21601298 -0.21601298 -0.21601298]]]\n",
      "\n",
      "\n",
      " [[[-0.10534309 -0.10534309 -0.10534309]\n",
      "   [-0.07932999 -0.07932999 -0.07932999]\n",
      "   [-0.0836437  -0.0836437  -0.0836437 ]\n",
      "   ...\n",
      "   [-0.14735296 -0.14735296 -0.14735296]\n",
      "   [-0.12135617 -0.12135617 -0.12135617]\n",
      "   [-0.16661766 -0.16661766 -0.16661766]]\n",
      "\n",
      "  [[-0.04848032 -0.04848032 -0.04848032]\n",
      "   [-0.07333325 -0.07333325 -0.07333325]\n",
      "   [-0.08475475 -0.08475475 -0.08475475]\n",
      "   ...\n",
      "   [-0.14251629 -0.14251629 -0.14251629]\n",
      "   [-0.1436928  -0.1436928  -0.1436928 ]\n",
      "   [-0.15315354 -0.15315354 -0.15315354]]\n",
      "\n",
      "  [[-0.05160125 -0.05160125 -0.05160125]\n",
      "   [-0.08135614 -0.08135614 -0.08135614]\n",
      "   [-0.0889705  -0.0889705  -0.0889705 ]\n",
      "   ...\n",
      "   [-0.15104572 -0.15104572 -0.15104572]\n",
      "   [-0.15625818 -0.15625818 -0.15625818]\n",
      "   [-0.1605228  -0.1605228  -0.1605228 ]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[ 0.22928104  0.22928104  0.22928104]\n",
      "   [ 0.18797396  0.18797396  0.18797396]\n",
      "   [ 0.11405239  0.11405239  0.11405239]\n",
      "   ...\n",
      "   [-0.07560452 -0.07560452 -0.07560452]\n",
      "   [-0.08995095 -0.08995095 -0.08995095]\n",
      "   [-0.1067811  -0.1067811  -0.1067811 ]]\n",
      "\n",
      "  [[ 0.19032678  0.19032678  0.19032678]\n",
      "   [ 0.01148704  0.01148704  0.01148704]\n",
      "   [-0.02973845 -0.02973845 -0.02973845]\n",
      "   ...\n",
      "   [-0.07601302 -0.07601302 -0.07601302]\n",
      "   [-0.08547382 -0.08547382 -0.08547382]\n",
      "   [-0.11127455 -0.11127455 -0.11127455]]\n",
      "\n",
      "  [[-0.10828423 -0.10828423 -0.10828423]\n",
      "   [-0.14612739 -0.14612739 -0.14612739]\n",
      "   [-0.13849662 -0.13849662 -0.13849662]\n",
      "   ...\n",
      "   [-0.1725653  -0.1725653  -0.1725653 ]\n",
      "   [-0.18653597 -0.18653597 -0.18653597]\n",
      "   [-0.21601298 -0.21601298 -0.21601298]]]\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      " [[[ 0.35348046  0.35348046  0.35348046]\n",
      "   [ 0.33635628  0.33635628  0.33635628]\n",
      "   [ 0.355572    0.355572    0.355572  ]\n",
      "   ...\n",
      "   [-0.17872551 -0.17872551 -0.17872551]\n",
      "   [-0.17625813 -0.17625813 -0.17625813]\n",
      "   [-0.17838237 -0.17838237 -0.17838237]]\n",
      "\n",
      "  [[ 0.33975497  0.33975497  0.33975497]\n",
      "   [ 0.3580393   0.3580393   0.3580393 ]\n",
      "   [ 0.35446092  0.35446092  0.35446092]\n",
      "   ...\n",
      "   [-0.13467315 -0.13467315 -0.13467315]\n",
      "   [-0.12800653 -0.12800653 -0.12800653]\n",
      "   [-0.1335457  -0.1335457  -0.1335457 ]]\n",
      "\n",
      "  [[ 0.31310463  0.31310463  0.31310463]\n",
      "   [ 0.3657027   0.3657027   0.3657027 ]\n",
      "   [ 0.3580883   0.3580883   0.3580883 ]\n",
      "   ...\n",
      "   [-0.14320259 -0.14320259 -0.14320259]\n",
      "   [-0.1405719  -0.1405719  -0.1405719 ]\n",
      "   [-0.1369934  -0.1369934  -0.1369934 ]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[-0.00209153 -0.00209153 -0.00209153]\n",
      "   [-0.02379075 -0.02379075 -0.02379075]\n",
      "   [-0.01535938 -0.01535938 -0.01535938]\n",
      "   ...\n",
      "   [-0.07560452 -0.07560452 -0.07560452]\n",
      "   [-0.07034311 -0.07034311 -0.07034311]\n",
      "   [-0.07148698 -0.07148698 -0.07148698]]\n",
      "\n",
      "  [[ 0.00209148  0.00209148  0.00209148]\n",
      "   [-0.02772865 -0.02772865 -0.02772865]\n",
      "   [-0.02973845 -0.02973845 -0.02973845]\n",
      "   ...\n",
      "   [-0.07601302 -0.07601302 -0.07601302]\n",
      "   [-0.08547382 -0.08547382 -0.08547382]\n",
      "   [-0.06421572 -0.06421572 -0.06421572]]\n",
      "\n",
      "  [[-0.19455874 -0.19455874 -0.19455874]\n",
      "   [-0.11475483 -0.11475483 -0.11475483]\n",
      "   [-0.12281035 -0.12281035 -0.12281035]\n",
      "   ...\n",
      "   [-0.13727118 -0.13727118 -0.13727118]\n",
      "   [-0.14339872 -0.14339872 -0.14339872]\n",
      "   [-0.16111103 -0.16111103 -0.16111103]]]\n",
      "\n",
      "\n",
      " [[[-0.06220583 -0.06220583 -0.06220583]\n",
      "   [ 0.01870923  0.01870923  0.01870923]\n",
      "   [-0.10717312 -0.10717312 -0.10717312]\n",
      "   ...\n",
      "   [-0.14735296 -0.14735296 -0.14735296]\n",
      "   [-0.13704245 -0.13704245 -0.13704245]\n",
      "   [ 0.29612747  0.29612747  0.29612747]]\n",
      "\n",
      "  [[-0.05240189 -0.05240189 -0.05240189]\n",
      "   [-0.07333325 -0.07333325 -0.07333325]\n",
      "   [-0.08083318 -0.08083318 -0.08083318]\n",
      "   ...\n",
      "   [-0.11506531 -0.11506531 -0.11506531]\n",
      "   [-0.09271242 -0.09271242 -0.09271242]\n",
      "   [-0.09433001 -0.09433001 -0.09433001]]\n",
      "\n",
      "  [[-0.05944439 -0.05944439 -0.05944439]\n",
      "   [-0.08135614 -0.08135614 -0.08135614]\n",
      "   [-0.08504893 -0.08504893 -0.08504893]\n",
      "   ...\n",
      "   [-0.12751631 -0.12751631 -0.12751631]\n",
      "   [-0.10527779 -0.10527779 -0.10527779]\n",
      "   [-0.09385613 -0.09385613 -0.09385613]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[-0.06483662 -0.06483662 -0.06483662]\n",
      "   [-0.05516331 -0.05516331 -0.05516331]\n",
      "   [-0.04281035 -0.04281035 -0.04281035]\n",
      "   ...\n",
      "   [-0.04815354 -0.04815354 -0.04815354]\n",
      "   [-0.03897056 -0.03897056 -0.03897056]\n",
      "   [-0.02834973 -0.02834973 -0.02834973]]\n",
      "\n",
      "  [[-0.05281048 -0.05281048 -0.05281048]\n",
      "   [-0.05517963 -0.05517963 -0.05517963]\n",
      "   [-0.04542473 -0.04542473 -0.04542473]\n",
      "   ...\n",
      "   [-0.04856204 -0.04856204 -0.04856204]\n",
      "   [-0.03449343 -0.03449343 -0.03449343]\n",
      "   [-0.03284317 -0.03284317 -0.03284317]]\n",
      "\n",
      "  [[ 0.16622558  0.16622558  0.16622558]\n",
      "   [ 0.12446086  0.12446086  0.12446086]\n",
      "   [ 0.08503281  0.08503281  0.08503281]\n",
      "   ...\n",
      "   [-0.05099667 -0.05099667 -0.05099667]\n",
      "   [-0.04143792 -0.04143792 -0.04143792]\n",
      "   [-0.12973848 -0.12973848 -0.12973848]]]\n",
      "\n",
      "\n",
      " [[[-0.07397053 -0.07397053 -0.07397053]\n",
      "   [ 0.3520426   0.3520426   0.3520426 ]\n",
      "   [-0.14246723 -0.14246723 -0.14246723]\n",
      "   ...\n",
      "   [ 0.3114706   0.3114706   0.3114706 ]\n",
      "   [ 0.30609483  0.30609483  0.30609483]\n",
      "   [ 0.29612747  0.29612747  0.29612747]]\n",
      "\n",
      "  [[-0.05632346 -0.05632346 -0.05632346]\n",
      "   [-0.08509795 -0.08509795 -0.08509795]\n",
      "   [-0.09259789 -0.09259789 -0.09259789]\n",
      "   ...\n",
      "   [ 0.25748372  0.25748372  0.25748372]\n",
      "   [ 0.303366    0.303366    0.303366  ]\n",
      "   [ 0.32135627  0.32135627  0.32135627]]\n",
      "\n",
      "  [[-0.06336596 -0.06336596 -0.06336596]\n",
      "   [-0.08527771 -0.08527771 -0.08527771]\n",
      "   [-0.09289207 -0.09289207 -0.09289207]\n",
      "   ...\n",
      "   [ 0.25287586  0.25287586  0.25287586]\n",
      "   [ 0.2711928   0.2711928   0.2711928 ]\n",
      "   [ 0.2786929   0.2786929   0.2786929 ]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[-0.06875819 -0.06875819 -0.06875819]\n",
      "   [-0.06300645 -0.06300645 -0.06300645]\n",
      "   [-0.05065349 -0.05065349 -0.05065349]\n",
      "   ...\n",
      "   [ 0.18321902  0.18321902  0.18321902]\n",
      "   [-0.01936271 -0.01936271 -0.01936271]\n",
      "   [ 0.01086596  0.01086596  0.01086596]]\n",
      "\n",
      "  [[-0.05673205 -0.05673205 -0.05673205]\n",
      "   [-0.06302277 -0.06302277 -0.06302277]\n",
      "   [-0.05326787 -0.05326787 -0.05326787]\n",
      "   ...\n",
      "   [-0.05248361 -0.05248361 -0.05248361]\n",
      "   [-0.038415   -0.038415   -0.038415  ]\n",
      "   [ 0.00245094  0.00245094  0.00245094]]\n",
      "\n",
      "  [[-0.17887247 -0.17887247 -0.17887247]\n",
      "   [-0.1578921  -0.1578921  -0.1578921 ]\n",
      "   [-0.1541829  -0.1541829  -0.1541829 ]\n",
      "   ...\n",
      "   [-0.14903589 -0.14903589 -0.14903589]\n",
      "   [-0.13163401 -0.13163401 -0.13163401]\n",
      "   [-0.12189534 -0.12189534 -0.12189534]]]]\n",
      "Epoch 1/100\n",
      "Learning rate:  0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\patcas rares\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\keras\\engine\\training.py:1972: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 11s 884ms/step - loss: 2.0516 - accuracy: 0.5375 - val_loss: 3.1472 - val_accuracy: 0.3667\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 2/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 5s 654ms/step - loss: 1.3796 - accuracy: 0.6667 - val_loss: 2.6198 - val_accuracy: 0.3667\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 3/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 761ms/step - loss: 1.1939 - accuracy: 0.7125 - val_loss: 2.5252 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 4/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 770ms/step - loss: 1.2105 - accuracy: 0.7042 - val_loss: 2.6044 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 5/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 5s 675ms/step - loss: 1.1407 - accuracy: 0.7458 - val_loss: 2.8895 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 6/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 683ms/step - loss: 1.0995 - accuracy: 0.7042 - val_loss: 2.5101 - val_accuracy: 0.6333\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 7/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 5s 676ms/step - loss: 1.0906 - accuracy: 0.7625 - val_loss: 4.3144 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 8/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 5s 661ms/step - loss: 1.0758 - accuracy: 0.7625 - val_loss: 2.6457 - val_accuracy: 0.6333\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 9/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 680ms/step - loss: 1.0293 - accuracy: 0.7458 - val_loss: 3.1413 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 10/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 5s 721ms/step - loss: 1.0464 - accuracy: 0.7625 - val_loss: 2.7731 - val_accuracy: 0.6333\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 11/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 5s 672ms/step - loss: 1.0220 - accuracy: 0.7833 - val_loss: 2.7842 - val_accuracy: 0.6333\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 12/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 5s 667ms/step - loss: 1.0201 - accuracy: 0.7667 - val_loss: 4.6336 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 13/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 681ms/step - loss: 1.0271 - accuracy: 0.7792 - val_loss: 3.9409 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 14/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 683ms/step - loss: 1.0527 - accuracy: 0.7542 - val_loss: 6.6459 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 15/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 742ms/step - loss: 0.9844 - accuracy: 0.7833 - val_loss: 8.2827 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 16/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 5s 668ms/step - loss: 0.9645 - accuracy: 0.8000 - val_loss: 8.5107 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 17/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 5s 662ms/step - loss: 0.9680 - accuracy: 0.7958 - val_loss: 4.7724 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 18/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 770ms/step - loss: 0.9642 - accuracy: 0.8042 - val_loss: 2.7274 - val_accuracy: 0.6333\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 19/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 669ms/step - loss: 0.9385 - accuracy: 0.8208 - val_loss: 8.7244 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 20/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 690ms/step - loss: 0.9752 - accuracy: 0.7958 - val_loss: 3.1280 - val_accuracy: 0.5333\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 21/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 5s 677ms/step - loss: 0.9600 - accuracy: 0.8000 - val_loss: 6.1097 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 22/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 5s 671ms/step - loss: 0.9223 - accuracy: 0.8250 - val_loss: 7.7983 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 23/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 5s 665ms/step - loss: 0.8988 - accuracy: 0.8208 - val_loss: 7.6429 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 24/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 5s 726ms/step - loss: 0.8579 - accuracy: 0.8542 - val_loss: 9.0938 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 25/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 694ms/step - loss: 0.8650 - accuracy: 0.8333 - val_loss: 9.3286 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 26/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 5s 675ms/step - loss: 0.8374 - accuracy: 0.8292 - val_loss: 9.7028 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 27/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 5s 671ms/step - loss: 0.8605 - accuracy: 0.8375 - val_loss: 2.8564 - val_accuracy: 0.6333\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 28/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 5s 669ms/step - loss: 0.9602 - accuracy: 0.7958 - val_loss: 9.6179 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 29/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 697ms/step - loss: 0.8908 - accuracy: 0.7875 - val_loss: 8.7306 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 30/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 7s 950ms/step - loss: 0.8589 - accuracy: 0.8333 - val_loss: 6.3877 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 31/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 756ms/step - loss: 0.8292 - accuracy: 0.8500 - val_loss: 7.9170 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 32/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 784ms/step - loss: 0.8437 - accuracy: 0.8333 - val_loss: 2.7706 - val_accuracy: 0.5000\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 33/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 734ms/step - loss: 0.8748 - accuracy: 0.8208 - val_loss: 13.1185 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 34/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 689ms/step - loss: 0.7986 - accuracy: 0.8667 - val_loss: 3.9164 - val_accuracy: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 35/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 740ms/step - loss: 0.8095 - accuracy: 0.8500 - val_loss: 6.0167 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 36/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 689ms/step - loss: 0.7793 - accuracy: 0.8625 - val_loss: 8.1705 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 37/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 700ms/step - loss: 0.7648 - accuracy: 0.8625 - val_loss: 10.1288 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 38/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 689ms/step - loss: 0.7228 - accuracy: 0.8917 - val_loss: 16.1488 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 39/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 686ms/step - loss: 0.7436 - accuracy: 0.8792 - val_loss: 9.8689 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 40/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 683ms/step - loss: 0.7808 - accuracy: 0.8750 - val_loss: 16.9128 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 41/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 763ms/step - loss: 0.7885 - accuracy: 0.8583 - val_loss: 10.9952 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 42/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 725ms/step - loss: 0.7720 - accuracy: 0.8542 - val_loss: 5.5075 - val_accuracy: 0.6333\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 43/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 685ms/step - loss: 0.7631 - accuracy: 0.8583 - val_loss: 8.3698 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 44/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 692ms/step - loss: 0.7420 - accuracy: 0.8833 - val_loss: 14.7815 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 45/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 684ms/step - loss: 0.7333 - accuracy: 0.8667 - val_loss: 15.9978 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 46/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 697ms/step - loss: 0.7691 - accuracy: 0.8292 - val_loss: 13.2217 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 47/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 697ms/step - loss: 0.7204 - accuracy: 0.8833 - val_loss: 15.8554 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 48/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 708ms/step - loss: 0.6871 - accuracy: 0.9000 - val_loss: 16.7989 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 49/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 731ms/step - loss: 0.6821 - accuracy: 0.9000 - val_loss: 14.9386 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 50/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 7s 782ms/step - loss: 0.6412 - accuracy: 0.9167 - val_loss: 19.6047 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 51/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 5s 705ms/step - loss: 0.6376 - accuracy: 0.9208 - val_loss: 17.6161 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 52/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 697ms/step - loss: 0.6669 - accuracy: 0.9042 - val_loss: 11.9575 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 53/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 7s 861ms/step - loss: 0.6330 - accuracy: 0.9125 - val_loss: 7.3167 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 54/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 5s 677ms/step - loss: 0.7019 - accuracy: 0.8500 - val_loss: 15.3648 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 55/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 689ms/step - loss: 0.7978 - accuracy: 0.8417 - val_loss: 16.9691 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 56/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 794ms/step - loss: 0.6913 - accuracy: 0.8875 - val_loss: 16.4836 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 57/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 727ms/step - loss: 0.7071 - accuracy: 0.8583 - val_loss: 21.5209 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 58/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 683ms/step - loss: 0.6831 - accuracy: 0.8958 - val_loss: 21.5620 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 59/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 728ms/step - loss: 0.6506 - accuracy: 0.9000 - val_loss: 18.0467 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 60/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 5s 670ms/step - loss: 0.6297 - accuracy: 0.9167 - val_loss: 12.9318 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 61/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 770ms/step - loss: 0.7133 - accuracy: 0.8750 - val_loss: 22.0606 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 62/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 685ms/step - loss: 0.6106 - accuracy: 0.9250 - val_loss: 20.1151 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 63/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 678ms/step - loss: 0.5993 - accuracy: 0.9125 - val_loss: 17.0158 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 64/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 681ms/step - loss: 0.5700 - accuracy: 0.9333 - val_loss: 16.4728 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 65/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 5s 671ms/step - loss: 0.5468 - accuracy: 0.9375 - val_loss: 23.4151 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 66/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 692ms/step - loss: 0.5648 - accuracy: 0.9375 - val_loss: 3.1942 - val_accuracy: 0.5333\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 67/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 842ms/step - loss: 0.6214 - accuracy: 0.9167 - val_loss: 25.3205 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 68/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 7s 822ms/step - loss: 0.5482 - accuracy: 0.9417 - val_loss: 32.8928 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 69/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 788ms/step - loss: 0.5594 - accuracy: 0.9250 - val_loss: 37.8632 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 70/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 735ms/step - loss: 0.5656 - accuracy: 0.9167 - val_loss: 29.3911 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 71/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 5s 620ms/step - loss: 0.5780 - accuracy: 0.9333 - val_loss: 15.9422 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 72/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 741ms/step - loss: 0.6166 - accuracy: 0.9125 - val_loss: 24.6228 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 73/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 5s 608ms/step - loss: 0.5825 - accuracy: 0.9208 - val_loss: 25.7127 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 74/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 5s 622ms/step - loss: 0.5390 - accuracy: 0.9208 - val_loss: 24.3043 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 75/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 5s 622ms/step - loss: 0.6151 - accuracy: 0.9125 - val_loss: 23.5131 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 76/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 5s 603ms/step - loss: 0.5708 - accuracy: 0.9292 - val_loss: 21.2609 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 77/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 5s 630ms/step - loss: 0.5573 - accuracy: 0.9333 - val_loss: 12.5976 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 78/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 7s 868ms/step - loss: 0.5736 - accuracy: 0.9083 - val_loss: 26.2350 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 79/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 679ms/step - loss: 0.5042 - accuracy: 0.9458 - val_loss: 25.6667 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 80/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 5s 667ms/step - loss: 0.5585 - accuracy: 0.9375 - val_loss: 5.6949 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 81/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 675ms/step - loss: 0.5408 - accuracy: 0.9292 - val_loss: 28.5405 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 82/100\n",
      "Learning rate:  0.0001\n",
      "8/8 [==============================] - 6s 691ms/step - loss: 0.4953 - accuracy: 0.9500 - val_loss: 28.0554 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 83/100\n",
      "Learning rate:  0.0001\n",
      "8/8 [==============================] - 6s 683ms/step - loss: 0.5082 - accuracy: 0.9542 - val_loss: 26.9080 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 84/100\n",
      "Learning rate:  0.0001\n",
      "8/8 [==============================] - 5s 664ms/step - loss: 0.4834 - accuracy: 0.9500 - val_loss: 26.0530 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 85/100\n",
      "Learning rate:  0.0001\n",
      "8/8 [==============================] - 5s 676ms/step - loss: 0.4867 - accuracy: 0.9583 - val_loss: 25.5575 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 86/100\n",
      "Learning rate:  0.0001\n",
      "8/8 [==============================] - 5s 669ms/step - loss: 0.4708 - accuracy: 0.9583 - val_loss: 25.0478 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 87/100\n",
      "Learning rate:  0.0001\n",
      "8/8 [==============================] - 5s 672ms/step - loss: 0.4603 - accuracy: 0.9708 - val_loss: 24.8006 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 88/100\n",
      "Learning rate:  0.0001\n",
      "8/8 [==============================] - 5s 675ms/step - loss: 0.4338 - accuracy: 0.9833 - val_loss: 24.8358 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 89/100\n",
      "Learning rate:  0.0001\n",
      "8/8 [==============================] - 6s 779ms/step - loss: 0.4737 - accuracy: 0.9625 - val_loss: 24.3531 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 90/100\n",
      "Learning rate:  0.0001\n",
      "8/8 [==============================] - 5s 660ms/step - loss: 0.4849 - accuracy: 0.9625 - val_loss: 23.9632 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 91/100\n",
      "Learning rate:  0.0001\n",
      "8/8 [==============================] - 6s 817ms/step - loss: 0.4641 - accuracy: 0.9667 - val_loss: 24.4344 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 92/100\n",
      "Learning rate:  0.0001\n",
      "8/8 [==============================] - 6s 726ms/step - loss: 0.4683 - accuracy: 0.9708 - val_loss: 24.1834 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 93/100\n",
      "Learning rate:  0.0001\n",
      "8/8 [==============================] - 5s 673ms/step - loss: 0.4458 - accuracy: 0.9750 - val_loss: 24.8419 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 94/100\n",
      "Learning rate:  0.0001\n",
      "8/8 [==============================] - 5s 641ms/step - loss: 0.4736 - accuracy: 0.9625 - val_loss: 24.9576 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 95/100\n",
      "Learning rate:  0.0001\n",
      "8/8 [==============================] - 5s 616ms/step - loss: 0.4690 - accuracy: 0.9667 - val_loss: 24.5220 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 96/100\n",
      "Learning rate:  0.0001\n",
      "8/8 [==============================] - 5s 656ms/step - loss: 0.4420 - accuracy: 0.9792 - val_loss: 23.1305 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 97/100\n",
      "Learning rate:  0.0001\n",
      "8/8 [==============================] - 5s 663ms/step - loss: 0.4300 - accuracy: 0.9917 - val_loss: 21.8861 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 98/100\n",
      "Learning rate:  0.0001\n",
      "8/8 [==============================] - 5s 622ms/step - loss: 0.4370 - accuracy: 0.9792 - val_loss: 21.4235 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 99/100\n",
      "Learning rate:  0.0001\n",
      "8/8 [==============================] - 5s 597ms/step - loss: 0.4561 - accuracy: 0.9542 - val_loss: 22.0204 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 100/100\n",
      "Learning rate:  0.0001\n",
      "8/8 [==============================] - 5s 604ms/step - loss: 0.4504 - accuracy: 0.9708 - val_loss: 22.7975 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.9786 - accuracy: 0.7333\n",
      "Test loss: 0.9786052107810974\n",
      "Test accuracy: 0.7333333492279053\n",
      "[2, 1, 1, 1, 2, 2, 1, 2, 2, 1, 1, 1, 1, 2, 0, 1, 1, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Precision:  0.9692307692307692\n",
      "Recall:  0.7333333333333333\n",
      "F1 Score:  0.8125714285714286\n",
      "[[[[  5   5   5]\n",
      "   [ 21  21  21]\n",
      "   [ 13  13  13]\n",
      "   ...\n",
      "   [  7   7   7]\n",
      "   [  5   5   5]\n",
      "   [  2   2   2]]\n",
      "\n",
      "  [[ 23  23  23]\n",
      "   [ 14  14  14]\n",
      "   [  9   9   9]\n",
      "   ...\n",
      "   [  1   1   1]\n",
      "   [  0   0   0]\n",
      "   [  0   0   0]]\n",
      "\n",
      "  [[ 23  23  23]\n",
      "   [ 14  14  14]\n",
      "   [  9   9   9]\n",
      "   ...\n",
      "   [  0   0   0]\n",
      "   [  0   0   0]\n",
      "   [  0   0   0]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[ 29  29  29]\n",
      "   [ 17  17  17]\n",
      "   [ 10  10  10]\n",
      "   ...\n",
      "   [  0   0   0]\n",
      "   [  0   0   0]\n",
      "   [  0   0   0]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [ 17  17  17]\n",
      "   [ 12  12  12]\n",
      "   ...\n",
      "   [  0   0   0]\n",
      "   [  0   0   0]\n",
      "   [  0   0   0]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [ 14  14  14]\n",
      "   ...\n",
      "   [  7   7   7]\n",
      "   [  6   6   6]\n",
      "   [  6   6   6]]]\n",
      "\n",
      "\n",
      " [[[108 108 108]\n",
      "   [117 117 117]\n",
      "   [116 116 116]\n",
      "   ...\n",
      "   [  1   1   1]\n",
      "   [  1   1   1]\n",
      "   [  1   1   1]]\n",
      "\n",
      "  [[112 112 112]\n",
      "   [108 108 108]\n",
      "   [115 115 115]\n",
      "   ...\n",
      "   [  1   1   1]\n",
      "   [  1   1   1]\n",
      "   [  1   1   1]]\n",
      "\n",
      "  [[117 117 117]\n",
      "   [112 112 112]\n",
      "   [110 110 110]\n",
      "   ...\n",
      "   [  1   1   1]\n",
      "   [  1   1   1]\n",
      "   [  1   1   1]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[ 25  25  25]\n",
      "   [ 17  17  17]\n",
      "   [ 10  10  10]\n",
      "   ...\n",
      "   [  0   0   0]\n",
      "   [  0   0   0]\n",
      "   [  0   0   0]]\n",
      "\n",
      "  [[ 24  24  24]\n",
      "   [ 18  18  18]\n",
      "   [ 11  11  11]\n",
      "   ...\n",
      "   [  0   0   0]\n",
      "   [  0   0   0]\n",
      "   [  0   0   0]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [ 19  19  19]\n",
      "   [ 19  19  19]\n",
      "   ...\n",
      "   [  6   6   6]\n",
      "   [  6   6   6]\n",
      "   [  6   6   6]]]\n",
      "\n",
      "\n",
      " [[[  9   9   9]\n",
      "   [ 18  18  18]\n",
      "   [ 15  15  15]\n",
      "   ...\n",
      "   [ 11  11  11]\n",
      "   [ 19  19  19]\n",
      "   [ 10  10  10]]\n",
      "\n",
      "  [[ 22  22  22]\n",
      "   [ 13  13  13]\n",
      "   [  9   9   9]\n",
      "   ...\n",
      "   [  1   1   1]\n",
      "   [  1   1   1]\n",
      "   [  2   2   2]]\n",
      "\n",
      "  [[ 23  23  23]\n",
      "   [ 13  13  13]\n",
      "   [  9   9   9]\n",
      "   ...\n",
      "   [  1   1   1]\n",
      "   [  1   1   1]\n",
      "   [  1   1   1]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[ 86  86  86]\n",
      "   [ 71  71  71]\n",
      "   [ 48  48  48]\n",
      "   ...\n",
      "   [  0   0   0]\n",
      "   [  0   0   0]\n",
      "   [  0   0   0]]\n",
      "\n",
      "  [[ 74  74  74]\n",
      "   [ 26  26  26]\n",
      "   [ 12  12  12]\n",
      "   ...\n",
      "   [  0   0   0]\n",
      "   [  0   0   0]\n",
      "   [  0   0   0]]\n",
      "\n",
      "  [[ 29  29  29]\n",
      "   [ 10  10  10]\n",
      "   [  9   9   9]\n",
      "   ...\n",
      "   [  0   0   0]\n",
      "   [  0   0   0]\n",
      "   [  0   0   0]]]]\n",
      "[[1]\n",
      " [1]\n",
      " [1]]\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "(40, 30, 3)\n",
      "x_train shape: (240, 40, 30, 3)\n",
      "240 train samples\n",
      "30 test samples\n",
      "y_train shape: (240, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\patcas rares\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate:  0.001\n",
      "Model: \"model_9\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_10 (InputLayer)           [(None, 40, 30, 3)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_279 (Conv2D)             (None, 40, 30, 16)   448         input_10[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_252 (BatchN (None, 40, 30, 16)   64          conv2d_279[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_252 (Activation)     (None, 40, 30, 16)   0           batch_normalization_252[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_280 (Conv2D)             (None, 40, 30, 16)   272         activation_252[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_253 (BatchN (None, 40, 30, 16)   64          conv2d_280[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_253 (Activation)     (None, 40, 30, 16)   0           batch_normalization_253[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_281 (Conv2D)             (None, 40, 30, 16)   2320        activation_253[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_254 (BatchN (None, 40, 30, 16)   64          conv2d_281[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_254 (Activation)     (None, 40, 30, 16)   0           batch_normalization_254[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_283 (Conv2D)             (None, 40, 30, 64)   1088        activation_252[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_282 (Conv2D)             (None, 40, 30, 64)   1088        activation_254[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_81 (Add)                    (None, 40, 30, 64)   0           conv2d_283[0][0]                 \n",
      "                                                                 conv2d_282[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_255 (BatchN (None, 40, 30, 64)   256         add_81[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_255 (Activation)     (None, 40, 30, 64)   0           batch_normalization_255[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_284 (Conv2D)             (None, 40, 30, 16)   1040        activation_255[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_256 (BatchN (None, 40, 30, 16)   64          conv2d_284[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_256 (Activation)     (None, 40, 30, 16)   0           batch_normalization_256[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_285 (Conv2D)             (None, 40, 30, 16)   2320        activation_256[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_257 (BatchN (None, 40, 30, 16)   64          conv2d_285[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_257 (Activation)     (None, 40, 30, 16)   0           batch_normalization_257[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_286 (Conv2D)             (None, 40, 30, 64)   1088        activation_257[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_82 (Add)                    (None, 40, 30, 64)   0           add_81[0][0]                     \n",
      "                                                                 conv2d_286[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_258 (BatchN (None, 40, 30, 64)   256         add_82[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_258 (Activation)     (None, 40, 30, 64)   0           batch_normalization_258[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_287 (Conv2D)             (None, 40, 30, 16)   1040        activation_258[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_259 (BatchN (None, 40, 30, 16)   64          conv2d_287[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_259 (Activation)     (None, 40, 30, 16)   0           batch_normalization_259[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_288 (Conv2D)             (None, 40, 30, 16)   2320        activation_259[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_260 (BatchN (None, 40, 30, 16)   64          conv2d_288[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_260 (Activation)     (None, 40, 30, 16)   0           batch_normalization_260[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_289 (Conv2D)             (None, 40, 30, 64)   1088        activation_260[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_83 (Add)                    (None, 40, 30, 64)   0           add_82[0][0]                     \n",
      "                                                                 conv2d_289[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_261 (BatchN (None, 40, 30, 64)   256         add_83[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_261 (Activation)     (None, 40, 30, 64)   0           batch_normalization_261[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_290 (Conv2D)             (None, 20, 15, 64)   4160        activation_261[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_262 (BatchN (None, 20, 15, 64)   256         conv2d_290[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_262 (Activation)     (None, 20, 15, 64)   0           batch_normalization_262[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_291 (Conv2D)             (None, 20, 15, 64)   36928       activation_262[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_263 (BatchN (None, 20, 15, 64)   256         conv2d_291[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_263 (Activation)     (None, 20, 15, 64)   0           batch_normalization_263[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_293 (Conv2D)             (None, 20, 15, 128)  8320        add_83[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_292 (Conv2D)             (None, 20, 15, 128)  8320        activation_263[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_84 (Add)                    (None, 20, 15, 128)  0           conv2d_293[0][0]                 \n",
      "                                                                 conv2d_292[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_264 (BatchN (None, 20, 15, 128)  512         add_84[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_264 (Activation)     (None, 20, 15, 128)  0           batch_normalization_264[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_294 (Conv2D)             (None, 20, 15, 64)   8256        activation_264[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_265 (BatchN (None, 20, 15, 64)   256         conv2d_294[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_265 (Activation)     (None, 20, 15, 64)   0           batch_normalization_265[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_295 (Conv2D)             (None, 20, 15, 64)   36928       activation_265[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_266 (BatchN (None, 20, 15, 64)   256         conv2d_295[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_266 (Activation)     (None, 20, 15, 64)   0           batch_normalization_266[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_296 (Conv2D)             (None, 20, 15, 128)  8320        activation_266[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_85 (Add)                    (None, 20, 15, 128)  0           add_84[0][0]                     \n",
      "                                                                 conv2d_296[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_267 (BatchN (None, 20, 15, 128)  512         add_85[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_267 (Activation)     (None, 20, 15, 128)  0           batch_normalization_267[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_297 (Conv2D)             (None, 20, 15, 64)   8256        activation_267[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_268 (BatchN (None, 20, 15, 64)   256         conv2d_297[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_268 (Activation)     (None, 20, 15, 64)   0           batch_normalization_268[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_298 (Conv2D)             (None, 20, 15, 64)   36928       activation_268[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_269 (BatchN (None, 20, 15, 64)   256         conv2d_298[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_269 (Activation)     (None, 20, 15, 64)   0           batch_normalization_269[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_299 (Conv2D)             (None, 20, 15, 128)  8320        activation_269[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_86 (Add)                    (None, 20, 15, 128)  0           add_85[0][0]                     \n",
      "                                                                 conv2d_299[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_270 (BatchN (None, 20, 15, 128)  512         add_86[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_270 (Activation)     (None, 20, 15, 128)  0           batch_normalization_270[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_300 (Conv2D)             (None, 10, 8, 128)   16512       activation_270[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_271 (BatchN (None, 10, 8, 128)   512         conv2d_300[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_271 (Activation)     (None, 10, 8, 128)   0           batch_normalization_271[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_301 (Conv2D)             (None, 10, 8, 128)   147584      activation_271[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_272 (BatchN (None, 10, 8, 128)   512         conv2d_301[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_272 (Activation)     (None, 10, 8, 128)   0           batch_normalization_272[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_303 (Conv2D)             (None, 10, 8, 256)   33024       add_86[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_302 (Conv2D)             (None, 10, 8, 256)   33024       activation_272[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_87 (Add)                    (None, 10, 8, 256)   0           conv2d_303[0][0]                 \n",
      "                                                                 conv2d_302[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_273 (BatchN (None, 10, 8, 256)   1024        add_87[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_273 (Activation)     (None, 10, 8, 256)   0           batch_normalization_273[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_304 (Conv2D)             (None, 10, 8, 128)   32896       activation_273[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_274 (BatchN (None, 10, 8, 128)   512         conv2d_304[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_274 (Activation)     (None, 10, 8, 128)   0           batch_normalization_274[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_305 (Conv2D)             (None, 10, 8, 128)   147584      activation_274[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_275 (BatchN (None, 10, 8, 128)   512         conv2d_305[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_275 (Activation)     (None, 10, 8, 128)   0           batch_normalization_275[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_306 (Conv2D)             (None, 10, 8, 256)   33024       activation_275[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_88 (Add)                    (None, 10, 8, 256)   0           add_87[0][0]                     \n",
      "                                                                 conv2d_306[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_276 (BatchN (None, 10, 8, 256)   1024        add_88[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_276 (Activation)     (None, 10, 8, 256)   0           batch_normalization_276[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_307 (Conv2D)             (None, 10, 8, 128)   32896       activation_276[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_277 (BatchN (None, 10, 8, 128)   512         conv2d_307[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_277 (Activation)     (None, 10, 8, 128)   0           batch_normalization_277[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_308 (Conv2D)             (None, 10, 8, 128)   147584      activation_277[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_278 (BatchN (None, 10, 8, 128)   512         conv2d_308[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_278 (Activation)     (None, 10, 8, 128)   0           batch_normalization_278[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_309 (Conv2D)             (None, 10, 8, 256)   33024       activation_278[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_89 (Add)                    (None, 10, 8, 256)   0           add_88[0][0]                     \n",
      "                                                                 conv2d_309[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_279 (BatchN (None, 10, 8, 256)   1024        add_89[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_279 (Activation)     (None, 10, 8, 256)   0           batch_normalization_279[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_9 (AveragePoo (None, 1, 1, 256)    0           activation_279[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "flatten_9 (Flatten)             (None, 256)          0           average_pooling2d_9[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dense_9 (Dense)                 (None, 10)           2570        flatten_9[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 849,002\n",
      "Trainable params: 843,786\n",
      "Non-trainable params: 5,216\n",
      "__________________________________________________________________________________________________\n",
      "ResNet  29v  2\n",
      "Using real-time data augmentation.\n",
      "------------------\n",
      "[[[[-0.12321889 -0.12321889 -0.12321889]\n",
      "   [-0.06746724 -0.06746724 -0.06746724]\n",
      "   [-0.09181364 -0.09181364 -0.09181364]\n",
      "   ...\n",
      "   [-0.16375819 -0.16375819 -0.16375819]\n",
      "   [-0.17779413 -0.17779413 -0.17779413]\n",
      "   [-0.19905229 -0.19905229 -0.19905229]]\n",
      "\n",
      "  [[-0.05021238 -0.05021238 -0.05021238]\n",
      "   [-0.07632345 -0.07632345 -0.07632345]\n",
      "   [-0.09253256 -0.09253256 -0.09253256]\n",
      "   ...\n",
      "   [-0.14607835 -0.14607835 -0.14607835]\n",
      "   [-0.1548856  -0.1548856  -0.1548856 ]\n",
      "   [-0.16864373 -0.16864373 -0.16864373]]\n",
      "\n",
      "  [[-0.05668294 -0.05668294 -0.05668294]\n",
      "   [-0.08230384 -0.08230384 -0.08230384]\n",
      "   [-0.09127444 -0.09127444 -0.09127444]\n",
      "   ...\n",
      "   [-0.1545098  -0.1545098  -0.1545098 ]\n",
      "   [-0.1645425  -0.1645425  -0.1645425 ]\n",
      "   [-0.16895415 -0.16895415 -0.16895415]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[ 0.00691177  0.00691177  0.00691177]\n",
      "   [-0.02584954 -0.02584954 -0.02584954]\n",
      "   [-0.03658484 -0.03658484 -0.03658484]\n",
      "   ...\n",
      "   [-0.07517968 -0.07517968 -0.07517968]\n",
      "   [-0.08952611 -0.08952611 -0.08952611]\n",
      "   [-0.11037586 -0.11037586 -0.11037586]]\n",
      "\n",
      "  [[ 0.39741832  0.39741832  0.39741832]\n",
      "   [-0.02733646 -0.02733646 -0.02733646]\n",
      "   [-0.03160118 -0.03160118 -0.03160118]\n",
      "   ...\n",
      "   [-0.07776137 -0.07776137 -0.07776137]\n",
      "   [-0.08617643 -0.08617643 -0.08617643]\n",
      "   [-0.11812095 -0.11812095 -0.11812095]]\n",
      "\n",
      "  [[ 0.27965695  0.27965695  0.27965695]\n",
      "   [ 0.31230408  0.31230408  0.31230408]\n",
      "   [-0.1204574  -0.1204574  -0.1204574 ]\n",
      "   ...\n",
      "   [-0.14165026 -0.14165026 -0.14165026]\n",
      "   [-0.16416664 -0.16416664 -0.16416664]\n",
      "   [-0.19851294 -0.19851294 -0.19851294]]]\n",
      "\n",
      "\n",
      " [[[ 0.28070268  0.28070268  0.28070268]\n",
      "   [ 0.30900335  0.30900335  0.30900335]\n",
      "   [ 0.31210792  0.31210792  0.31210792]\n",
      "   ...\n",
      "   [-0.1872876  -0.1872876  -0.1872876 ]\n",
      "   [-0.1934804  -0.1934804  -0.1934804 ]\n",
      "   [-0.20297386 -0.20297386 -0.20297386]]\n",
      "\n",
      "  [[ 0.29880723  0.29880723  0.29880723]\n",
      "   [ 0.292304    0.292304    0.292304  ]\n",
      "   [ 0.32315373  0.32315373  0.32315373]\n",
      "   ...\n",
      "   [-0.14607835 -0.14607835 -0.14607835]\n",
      "   [-0.15096404 -0.15096404 -0.15096404]\n",
      "   [-0.16472216 -0.16472216 -0.16472216]]\n",
      "\n",
      "  [[ 0.3119445   0.3119445   0.3119445 ]\n",
      "   [ 0.30200988  0.30200988  0.30200988]\n",
      "   [ 0.304804    0.304804    0.304804  ]\n",
      "   ...\n",
      "   [-0.15058823 -0.15058823 -0.15058823]\n",
      "   [-0.16062093 -0.16062093 -0.16062093]\n",
      "   [-0.16503258 -0.16503258 -0.16503258]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[-0.0087745  -0.0087745  -0.0087745 ]\n",
      "   [-0.02584954 -0.02584954 -0.02584954]\n",
      "   [-0.03658484 -0.03658484 -0.03658484]\n",
      "   ...\n",
      "   [-0.07517968 -0.07517968 -0.07517968]\n",
      "   [-0.08952611 -0.08952611 -0.08952611]\n",
      "   [-0.11037586 -0.11037586 -0.11037586]]\n",
      "\n",
      "  [[-0.01042485 -0.01042485 -0.01042485]\n",
      "   [-0.02341489 -0.02341489 -0.02341489]\n",
      "   [-0.03552275 -0.03552275 -0.03552275]\n",
      "   ...\n",
      "   [-0.07776137 -0.07776137 -0.07776137]\n",
      "   [-0.08617643 -0.08617643 -0.08617643]\n",
      "   [-0.11812095 -0.11812095 -0.11812095]]\n",
      "\n",
      "  [[ 0.27965695  0.27965695  0.27965695]\n",
      "   [-0.11514693 -0.11514693 -0.11514693]\n",
      "   [-0.10084955 -0.10084955 -0.10084955]\n",
      "   ...\n",
      "   [-0.14557183 -0.14557183 -0.14557183]\n",
      "   [-0.16416664 -0.16416664 -0.16416664]\n",
      "   [-0.19851294 -0.19851294 -0.19851294]]]\n",
      "\n",
      "\n",
      " [[[-0.10753262 -0.10753262 -0.10753262]\n",
      "   [-0.07923194 -0.07923194 -0.07923194]\n",
      "   [-0.0839705  -0.0839705  -0.0839705 ]\n",
      "   ...\n",
      "   [-0.14807191 -0.14807191 -0.14807191]\n",
      "   [-0.12289216 -0.12289216 -0.12289216]\n",
      "   [-0.16767974 -0.16767974 -0.16767974]]\n",
      "\n",
      "  [[-0.05413394 -0.05413394 -0.05413394]\n",
      "   [-0.08024502 -0.08024502 -0.08024502]\n",
      "   [-0.09253256 -0.09253256 -0.09253256]\n",
      "   ...\n",
      "   [-0.14607835 -0.14607835 -0.14607835]\n",
      "   [-0.15096404 -0.15096404 -0.15096404]\n",
      "   [-0.16080059 -0.16080059 -0.16080059]]\n",
      "\n",
      "  [[-0.05668294 -0.05668294 -0.05668294]\n",
      "   [-0.08622541 -0.08622541 -0.08622541]\n",
      "   [-0.09127444 -0.09127444 -0.09127444]\n",
      "   ...\n",
      "   [-0.15058823 -0.15058823 -0.15058823]\n",
      "   [-0.16062093 -0.16062093 -0.16062093]\n",
      "   [-0.16503258 -0.16503258 -0.16503258]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[ 0.23044118  0.23044118  0.23044118]\n",
      "   [ 0.18591517  0.18591517  0.18591517]\n",
      "   [ 0.11243477  0.11243477  0.11243477]\n",
      "   ...\n",
      "   [-0.07517968 -0.07517968 -0.07517968]\n",
      "   [-0.08952611 -0.08952611 -0.08952611]\n",
      "   [-0.11037586 -0.11037586 -0.11037586]]\n",
      "\n",
      "  [[ 0.1856536   0.1856536   0.1856536 ]\n",
      "   [ 0.00795766  0.00795766  0.00795766]\n",
      "   [-0.03160118 -0.03160118 -0.03160118]\n",
      "   ...\n",
      "   [-0.07776137 -0.07776137 -0.07776137]\n",
      "   [-0.08617643 -0.08617643 -0.08617643]\n",
      "   [-0.11812095 -0.11812095 -0.11812095]]\n",
      "\n",
      "  [[-0.10857836 -0.10857836 -0.10857836]\n",
      "   [-0.15044105 -0.15044105 -0.15044105]\n",
      "   [-0.14006524 -0.14006524 -0.14006524]\n",
      "   ...\n",
      "   [-0.16910124 -0.16910124 -0.16910124]\n",
      "   [-0.18769605 -0.18769605 -0.18769605]\n",
      "   [-0.22204235 -0.22204235 -0.22204235]]]\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      " [[[-0.06439536 -0.06439536 -0.06439536]\n",
      "   [ 0.01880728  0.01880728  0.01880728]\n",
      "   [-0.10749991 -0.10749991 -0.10749991]\n",
      "   ...\n",
      "   [-0.14807191 -0.14807191 -0.14807191]\n",
      "   [-0.13857844 -0.13857844 -0.13857844]\n",
      "   [ 0.2950654   0.2950654   0.2950654 ]]\n",
      "\n",
      "  [[-0.05805551 -0.05805551 -0.05805551]\n",
      "   [-0.08024502 -0.08024502 -0.08024502]\n",
      "   [-0.08861099 -0.08861099 -0.08861099]\n",
      "   ...\n",
      "   [-0.11862737 -0.11862737 -0.11862737]\n",
      "   [-0.09998365 -0.09998365 -0.09998365]\n",
      "   [-0.10197706 -0.10197706 -0.10197706]]\n",
      "\n",
      "  [[-0.06452607 -0.06452607 -0.06452607]\n",
      "   [-0.08622541 -0.08622541 -0.08622541]\n",
      "   [-0.08735287 -0.08735287 -0.08735287]\n",
      "   ...\n",
      "   [-0.12705882 -0.12705882 -0.12705882]\n",
      "   [-0.10964054 -0.10964054 -0.10964054]\n",
      "   [-0.09836591 -0.09836591 -0.09836591]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[-0.06367646 -0.06367646 -0.06367646]\n",
      "   [-0.05722209 -0.05722209 -0.05722209]\n",
      "   [-0.04442798 -0.04442798 -0.04442798]\n",
      "   ...\n",
      "   [-0.0477287  -0.0477287  -0.0477287 ]\n",
      "   [-0.03854572 -0.03854572 -0.03854572]\n",
      "   [-0.03194448 -0.03194448 -0.03194448]]\n",
      "\n",
      "  [[-0.05748368 -0.05748368 -0.05748368]\n",
      "   [-0.05870901 -0.05870901 -0.05870901]\n",
      "   [-0.04728745 -0.04728745 -0.04728745]\n",
      "   ...\n",
      "   [-0.0503104  -0.0503104  -0.0503104 ]\n",
      "   [-0.03519604 -0.03519604 -0.03519604]\n",
      "   [-0.03968957 -0.03968957 -0.03968957]]\n",
      "\n",
      "  [[ 0.16593145  0.16593145  0.16593145]\n",
      "   [ 0.1201472   0.1201472   0.1201472 ]\n",
      "   [ 0.08346419  0.08346419  0.08346419]\n",
      "   ...\n",
      "   [-0.04753261 -0.04753261 -0.04753261]\n",
      "   [-0.04259801 -0.04259801 -0.04259801]\n",
      "   [-0.13576785 -0.13576785 -0.13576785]]]\n",
      "\n",
      "\n",
      " [[[-0.03302281 -0.03302281 -0.03302281]\n",
      "   [-0.0596241  -0.0596241  -0.0596241 ]\n",
      "   [-0.07220579 -0.07220579 -0.07220579]\n",
      "   ...\n",
      "   [-0.19120917 -0.19120917 -0.19120917]\n",
      "   [-0.19740197 -0.19740197 -0.19740197]\n",
      "   [-0.20297386 -0.20297386 -0.20297386]]\n",
      "\n",
      "  [[-0.03844767 -0.03844767 -0.03844767]\n",
      "   [-0.03710776 -0.03710776 -0.03710776]\n",
      "   [-0.05723844 -0.05723844 -0.05723844]\n",
      "   ...\n",
      "   [-0.14999992 -0.14999992 -0.14999992]\n",
      "   [-0.1548856  -0.1548856  -0.1548856 ]\n",
      "   [-0.16472216 -0.16472216 -0.16472216]]\n",
      "\n",
      "  [[-0.05668294 -0.05668294 -0.05668294]\n",
      "   [-0.03132344 -0.03132344 -0.03132344]\n",
      "   [-0.05598032 -0.05598032 -0.05598032]\n",
      "   ...\n",
      "   [-0.1545098  -0.1545098  -0.1545098 ]\n",
      "   [-0.1645425  -0.1645425  -0.1645425 ]\n",
      "   [-0.16895415 -0.16895415 -0.16895415]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[ 0.02259805  0.02259805  0.02259805]\n",
      "   [ 0.00160144  0.00160144  0.00160144]\n",
      "   [-0.00521229 -0.00521229 -0.00521229]\n",
      "   ...\n",
      "   [-0.07517968 -0.07517968 -0.07517968]\n",
      "   [-0.08952611 -0.08952611 -0.08952611]\n",
      "   [-0.11037586 -0.11037586 -0.11037586]]\n",
      "\n",
      "  [[ 0.02486927  0.02486927  0.02486927]\n",
      "   [-0.00380705 -0.00380705 -0.00380705]\n",
      "   [-0.01199333 -0.01199333 -0.01199333]\n",
      "   ...\n",
      "   [-0.07776137 -0.07776137 -0.07776137]\n",
      "   [-0.08617643 -0.08617643 -0.08617643]\n",
      "   [-0.11812095 -0.11812095 -0.11812095]]\n",
      "\n",
      "  [[-0.1164215  -0.1164215  -0.1164215 ]\n",
      "   [-0.09553909 -0.09553909 -0.09553909]\n",
      "   [-0.10477111 -0.10477111 -0.10477111]\n",
      "   ...\n",
      "   [-0.16910124 -0.16910124 -0.16910124]\n",
      "   [-0.18769605 -0.18769605 -0.18769605]\n",
      "   [-0.22204235 -0.22204235 -0.22204235]]]\n",
      "\n",
      "\n",
      " [[[ 0.29638895  0.29638895  0.29638895]\n",
      "   [ 0.3168465   0.3168465   0.3168465 ]\n",
      "   [ 0.29642165  0.29642165  0.29642165]\n",
      "   ...\n",
      "   [-0.19120917 -0.19120917 -0.19120917]\n",
      "   [-0.19740197 -0.19740197 -0.19740197]\n",
      "   [-0.20689543 -0.20689543 -0.20689543]]\n",
      "\n",
      "  [[ 0.33017978  0.33017978  0.33017978]\n",
      "   [ 0.3550491   0.3550491   0.3550491 ]\n",
      "   [ 0.29570276  0.29570276  0.29570276]\n",
      "   ...\n",
      "   [-0.14999992 -0.14999992 -0.14999992]\n",
      "   [-0.1548856  -0.1548856  -0.1548856 ]\n",
      "   [-0.16864373 -0.16864373 -0.16864373]]\n",
      "\n",
      "  [[ 0.2884151   0.2884151   0.2884151 ]\n",
      "   [ 0.29024518  0.29024518  0.29024518]\n",
      "   [ 0.28911772  0.28911772  0.28911772]\n",
      "   ...\n",
      "   [-0.1545098  -0.1545098  -0.1545098 ]\n",
      "   [-0.1645425  -0.1645425  -0.1645425 ]\n",
      "   [-0.16895415 -0.16895415 -0.16895415]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[ 0.02259805  0.02259805  0.02259805]\n",
      "   [-0.01800641 -0.01800641 -0.01800641]\n",
      "   [-0.02874171 -0.02874171 -0.02874171]\n",
      "   ...\n",
      "   [-0.07517968 -0.07517968 -0.07517968]\n",
      "   [-0.08952611 -0.08952611 -0.08952611]\n",
      "   [-0.11037586 -0.11037586 -0.11037586]]\n",
      "\n",
      "  [[ 0.02486927  0.02486927  0.02486927]\n",
      "   [-0.01949332 -0.01949332 -0.01949332]\n",
      "   [-0.02767961 -0.02767961 -0.02767961]\n",
      "   ...\n",
      "   [-0.07776137 -0.07776137 -0.07776137]\n",
      "   [-0.08617643 -0.08617643 -0.08617643]\n",
      "   [-0.11812095 -0.11812095 -0.11812095]]\n",
      "\n",
      "  [[-0.09289208 -0.09289208 -0.09289208]\n",
      "   [-0.11514693 -0.11514693 -0.11514693]\n",
      "   [-0.1204574  -0.1204574  -0.1204574 ]\n",
      "   ...\n",
      "   [-0.16910124 -0.16910124 -0.16910124]\n",
      "   [-0.18769605 -0.18769605 -0.18769605]\n",
      "   [-0.22204235 -0.22204235 -0.22204235]]]]\n",
      "Epoch 1/100\n",
      "Learning rate:  0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\patcas rares\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\keras\\engine\\training.py:1972: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 9s 751ms/step - loss: 1.9656 - accuracy: 0.5375 - val_loss: 3.6267 - val_accuracy: 0.3000\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 2/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 757ms/step - loss: 1.3041 - accuracy: 0.7042 - val_loss: 4.8459 - val_accuracy: 0.3000\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 3/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 5s 644ms/step - loss: 1.2012 - accuracy: 0.7500 - val_loss: 3.2875 - val_accuracy: 0.3000\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 4/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 5s 654ms/step - loss: 1.1496 - accuracy: 0.7167 - val_loss: 4.0446 - val_accuracy: 0.3000\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 5/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 5s 651ms/step - loss: 1.0593 - accuracy: 0.7583 - val_loss: 4.1632 - val_accuracy: 0.3000\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 6/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 685ms/step - loss: 1.0779 - accuracy: 0.7542 - val_loss: 2.3817 - val_accuracy: 0.3000\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 7/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 796ms/step - loss: 1.0697 - accuracy: 0.7333 - val_loss: 6.3805 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 8/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 762ms/step - loss: 1.1317 - accuracy: 0.6833 - val_loss: 5.4557 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 9/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 679ms/step - loss: 1.0140 - accuracy: 0.7833 - val_loss: 3.2608 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 10/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 681ms/step - loss: 1.0214 - accuracy: 0.7833 - val_loss: 5.5815 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 11/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 5s 674ms/step - loss: 1.0258 - accuracy: 0.7708 - val_loss: 7.5262 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 12/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 5s 722ms/step - loss: 0.9814 - accuracy: 0.7833 - val_loss: 6.7543 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 13/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 673ms/step - loss: 0.9594 - accuracy: 0.8083 - val_loss: 7.3700 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 14/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 5s 665ms/step - loss: 0.9424 - accuracy: 0.8167 - val_loss: 7.2936 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 15/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 5s 671ms/step - loss: 0.9410 - accuracy: 0.8083 - val_loss: 8.2901 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 16/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 713ms/step - loss: 0.9395 - accuracy: 0.7958 - val_loss: 9.1843 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 17/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 687ms/step - loss: 0.9907 - accuracy: 0.7833 - val_loss: 9.1995 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 18/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 679ms/step - loss: 0.9530 - accuracy: 0.7708 - val_loss: 8.8177 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 19/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 5s 663ms/step - loss: 0.9170 - accuracy: 0.7708 - val_loss: 9.1841 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 20/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 5s 671ms/step - loss: 0.9003 - accuracy: 0.8042 - val_loss: 11.8741 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 21/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 682ms/step - loss: 0.9206 - accuracy: 0.8208 - val_loss: 10.3395 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 22/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 7s 839ms/step - loss: 0.9197 - accuracy: 0.7792 - val_loss: 11.9567 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 23/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 772ms/step - loss: 0.8645 - accuracy: 0.8042 - val_loss: 12.2610 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 24/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 784ms/step - loss: 0.8754 - accuracy: 0.7917 - val_loss: 8.0581 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 25/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 715ms/step - loss: 0.8399 - accuracy: 0.8250 - val_loss: 8.3224 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 26/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 712ms/step - loss: 0.8178 - accuracy: 0.8500 - val_loss: 10.3601 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 27/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 842ms/step - loss: 0.8063 - accuracy: 0.8625 - val_loss: 11.1833 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 28/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 769ms/step - loss: 0.8150 - accuracy: 0.8375 - val_loss: 13.9475 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 29/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 741ms/step - loss: 0.8531 - accuracy: 0.8000 - val_loss: 18.9570 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 30/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 787ms/step - loss: 0.7953 - accuracy: 0.8458 - val_loss: 18.9260 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 31/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 7s 840ms/step - loss: 0.8323 - accuracy: 0.8250 - val_loss: 15.1683 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 32/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 697ms/step - loss: 0.8313 - accuracy: 0.8125 - val_loss: 12.7902 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 33/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 7s 877ms/step - loss: 0.7884 - accuracy: 0.8125 - val_loss: 9.8835 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 34/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 5s 716ms/step - loss: 0.7750 - accuracy: 0.8500 - val_loss: 13.3502 - val_accuracy: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 35/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 5s 676ms/step - loss: 0.7262 - accuracy: 0.8833 - val_loss: 19.8648 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 36/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 5s 667ms/step - loss: 0.7709 - accuracy: 0.8542 - val_loss: 22.1619 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 37/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 5s 714ms/step - loss: 0.8130 - accuracy: 0.8417 - val_loss: 14.0191 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 38/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 804ms/step - loss: 0.7665 - accuracy: 0.8625 - val_loss: 8.8629 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 39/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 5s 663ms/step - loss: 0.7636 - accuracy: 0.8500 - val_loss: 10.3306 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 40/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 5s 665ms/step - loss: 0.7223 - accuracy: 0.8750 - val_loss: 14.1866 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 41/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 5s 678ms/step - loss: 0.7538 - accuracy: 0.8833 - val_loss: 16.4293 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 42/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 5s 667ms/step - loss: 0.7222 - accuracy: 0.8875 - val_loss: 13.0423 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 43/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 5s 671ms/step - loss: 0.7704 - accuracy: 0.8542 - val_loss: 12.2669 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 44/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 680ms/step - loss: 0.7637 - accuracy: 0.8625 - val_loss: 11.7207 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 45/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 5s 663ms/step - loss: 0.7118 - accuracy: 0.8458 - val_loss: 13.7172 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 46/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 5s 662ms/step - loss: 0.6860 - accuracy: 0.8917 - val_loss: 18.9768 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 47/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 5s 673ms/step - loss: 0.7258 - accuracy: 0.8875 - val_loss: 15.9829 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 48/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 5s 657ms/step - loss: 0.6875 - accuracy: 0.8625 - val_loss: 15.4486 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 49/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 678ms/step - loss: 0.6591 - accuracy: 0.8792 - val_loss: 15.1267 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 50/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 684ms/step - loss: 0.6514 - accuracy: 0.8917 - val_loss: 15.3919 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 51/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 5s 662ms/step - loss: 0.6528 - accuracy: 0.9042 - val_loss: 25.2783 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 52/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 5s 666ms/step - loss: 0.6893 - accuracy: 0.8583 - val_loss: 23.6935 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 53/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 5s 671ms/step - loss: 0.6474 - accuracy: 0.8792 - val_loss: 21.2386 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 54/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 830ms/step - loss: 0.7046 - accuracy: 0.8542 - val_loss: 15.6861 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 55/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 7s 809ms/step - loss: 0.6475 - accuracy: 0.8875 - val_loss: 16.4073 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 56/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 7s 796ms/step - loss: 0.6106 - accuracy: 0.9167 - val_loss: 18.2285 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 57/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 695ms/step - loss: 0.5686 - accuracy: 0.9375 - val_loss: 21.8904 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 58/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 696ms/step - loss: 0.5772 - accuracy: 0.9375 - val_loss: 29.7260 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 59/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 683ms/step - loss: 0.5879 - accuracy: 0.9083 - val_loss: 30.2136 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 60/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 705ms/step - loss: 0.7095 - accuracy: 0.8583 - val_loss: 18.0438 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 61/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 703ms/step - loss: 0.5825 - accuracy: 0.9375 - val_loss: 19.6718 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 62/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 684ms/step - loss: 0.6611 - accuracy: 0.8750 - val_loss: 22.0389 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 63/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 850ms/step - loss: 0.5885 - accuracy: 0.9000 - val_loss: 22.7099 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 64/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 691ms/step - loss: 0.5848 - accuracy: 0.9125 - val_loss: 21.9700 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 65/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 710ms/step - loss: 0.5710 - accuracy: 0.9125 - val_loss: 21.8230 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 66/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 690ms/step - loss: 0.5662 - accuracy: 0.9000 - val_loss: 19.6743 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 67/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 737ms/step - loss: 0.5469 - accuracy: 0.9208 - val_loss: 23.2178 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 68/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 681ms/step - loss: 0.6160 - accuracy: 0.8875 - val_loss: 19.2135 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 69/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 735ms/step - loss: 0.5497 - accuracy: 0.9292 - val_loss: 18.3236 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 70/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 732ms/step - loss: 0.5127 - accuracy: 0.9375 - val_loss: 10.8505 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 71/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 715ms/step - loss: 0.5662 - accuracy: 0.9167 - val_loss: 23.4348 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 72/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 7s 991ms/step - loss: 0.6065 - accuracy: 0.8875 - val_loss: 18.9835 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 73/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 662ms/step - loss: 0.6093 - accuracy: 0.8792 - val_loss: 17.2061 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 74/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 5s 638ms/step - loss: 0.5467 - accuracy: 0.9250 - val_loss: 12.2531 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 75/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 765ms/step - loss: 0.5633 - accuracy: 0.9167 - val_loss: 22.7179 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 76/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 5s 698ms/step - loss: 0.5374 - accuracy: 0.9250 - val_loss: 27.0476 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 77/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 5s 665ms/step - loss: 0.5368 - accuracy: 0.9042 - val_loss: 26.2521 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 78/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 6s 672ms/step - loss: 0.5008 - accuracy: 0.9417 - val_loss: 27.6022 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 79/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 5s 608ms/step - loss: 0.5448 - accuracy: 0.9292 - val_loss: 26.8271 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 80/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 5s 639ms/step - loss: 0.5605 - accuracy: 0.9208 - val_loss: 23.4070 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 81/100\n",
      "Learning rate:  0.001\n",
      "8/8 [==============================] - 5s 602ms/step - loss: 0.4920 - accuracy: 0.9500 - val_loss: 22.6686 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 82/100\n",
      "Learning rate:  0.0001\n",
      "8/8 [==============================] - 5s 646ms/step - loss: 0.4783 - accuracy: 0.9458 - val_loss: 21.8770 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 83/100\n",
      "Learning rate:  0.0001\n",
      "8/8 [==============================] - 5s 609ms/step - loss: 0.5035 - accuracy: 0.9375 - val_loss: 21.0562 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 84/100\n",
      "Learning rate:  0.0001\n",
      "8/8 [==============================] - 5s 619ms/step - loss: 0.4539 - accuracy: 0.9708 - val_loss: 20.4905 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 85/100\n",
      "Learning rate:  0.0001\n",
      "8/8 [==============================] - 5s 601ms/step - loss: 0.4378 - accuracy: 0.9750 - val_loss: 20.5220 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 86/100\n",
      "Learning rate:  0.0001\n",
      "8/8 [==============================] - 5s 627ms/step - loss: 0.4373 - accuracy: 0.9708 - val_loss: 20.8088 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 87/100\n",
      "Learning rate:  0.0001\n",
      "8/8 [==============================] - 5s 640ms/step - loss: 0.4545 - accuracy: 0.9542 - val_loss: 21.1805 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 88/100\n",
      "Learning rate:  0.0001\n",
      "8/8 [==============================] - 5s 634ms/step - loss: 0.4358 - accuracy: 0.9750 - val_loss: 21.5436 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 89/100\n",
      "Learning rate:  0.0001\n",
      "8/8 [==============================] - 6s 698ms/step - loss: 0.4301 - accuracy: 0.9708 - val_loss: 21.8481 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 90/100\n",
      "Learning rate:  0.0001\n",
      "8/8 [==============================] - 7s 880ms/step - loss: 0.4227 - accuracy: 0.9750 - val_loss: 22.0672 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 91/100\n",
      "Learning rate:  0.0001\n",
      "8/8 [==============================] - 6s 704ms/step - loss: 0.4168 - accuracy: 0.9833 - val_loss: 22.4796 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 92/100\n",
      "Learning rate:  0.0001\n",
      "8/8 [==============================] - 5s 668ms/step - loss: 0.4145 - accuracy: 0.9917 - val_loss: 22.8185 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 93/100\n",
      "Learning rate:  0.0001\n",
      "8/8 [==============================] - 5s 668ms/step - loss: 0.3935 - accuracy: 0.9875 - val_loss: 23.3762 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 94/100\n",
      "Learning rate:  0.0001\n",
      "8/8 [==============================] - 6s 683ms/step - loss: 0.4051 - accuracy: 0.9917 - val_loss: 23.8459 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 95/100\n",
      "Learning rate:  0.0001\n",
      "8/8 [==============================] - 6s 679ms/step - loss: 0.3903 - accuracy: 0.9833 - val_loss: 24.0040 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 96/100\n",
      "Learning rate:  0.0001\n",
      "8/8 [==============================] - 6s 692ms/step - loss: 0.3911 - accuracy: 0.9792 - val_loss: 23.9798 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 97/100\n",
      "Learning rate:  0.0001\n",
      "8/8 [==============================] - 6s 709ms/step - loss: 0.4410 - accuracy: 0.9708 - val_loss: 24.0240 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 98/100\n",
      "Learning rate:  0.0001\n",
      "8/8 [==============================] - 6s 701ms/step - loss: 0.4224 - accuracy: 0.9708 - val_loss: 24.1766 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 99/100\n",
      "Learning rate:  0.0001\n",
      "8/8 [==============================] - 7s 836ms/step - loss: 0.3961 - accuracy: 0.9875 - val_loss: 24.3517 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 100/100\n",
      "Learning rate:  0.0001\n",
      "8/8 [==============================] - 5s 653ms/step - loss: 0.3959 - accuracy: 0.9875 - val_loss: 24.3433 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1/1 [==============================] - 0s 156ms/step - loss: 0.4497 - accuracy: 0.9667\n",
      "Test loss: 0.4496535658836365\n",
      "Test accuracy: 0.9666666388511658\n",
      "[1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Precision:  1.0\n",
      "Recall:  0.9666666666666667\n",
      "F1 Score:  0.9828282828282828\n",
      "[0.8333333134651184, 0.8333333134651184, 0.9333333373069763, 0.8999999761581421, 0.8666666746139526, 0.8999999761581421, 0.7333333492279053, 0.8999999761581421, 0.7333333492279053, 0.9666666388511658]\n",
      "[0.9692307692307692, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9692307692307692, 1.0]\n",
      "[0.8333333333333334, 0.8333333333333334, 0.9333333333333333, 0.9, 0.8666666666666667, 0.9, 0.7333333333333333, 0.9, 0.7333333333333333, 0.9666666666666667]\n",
      "[0.8872258064516129, 0.9032258064516128, 0.9650000000000001, 0.9465116279069767, 0.9263157894736842, 0.9444444444444445, 0.8412698412698413, 0.9457142857142856, 0.8125714285714286, 0.9828282828282828]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\patcas rares\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "accs=[]\n",
    "precisions = []\n",
    "recalls = []\n",
    "fmeasures = []\n",
    "for i in range(10):\n",
    "    ret = main(i)\n",
    "    accs+=[ret[0]]\n",
    "    precisions+=[ret[1]]\n",
    "    recalls+=[ret[2]]\n",
    "    fmeasures+=[ret[3]]\n",
    "print(accs)\n",
    "print(precisions)\n",
    "print(recalls)\n",
    "print(fmeasures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ddb57c4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "accs:  [0.8333333134651184, 0.8333333134651184, 0.9333333373069763, 0.8999999761581421, 0.8666666746139526, 0.8999999761581421, 0.7333333492279053, 0.8999999761581421, 0.7333333492279053, 0.9666666388511658]\n",
      "precisions:  [0.9692307692307692, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9692307692307692, 1.0]\n",
      "recalls:  [0.8333333333333334, 0.8333333333333334, 0.9333333333333333, 0.9, 0.8666666666666667, 0.9, 0.7333333333333333, 0.9, 0.7333333333333333, 0.9666666666666667]\n",
      "fmeasures:  [0.8872258064516129, 0.9032258064516128, 0.9650000000000001, 0.9465116279069767, 0.9263157894736842, 0.9444444444444445, 0.8412698412698413, 0.9457142857142856, 0.8125714285714286, 0.9828282828282828]\n"
     ]
    }
   ],
   "source": [
    "print(len(accs))\n",
    "print('accs: ', accs)\n",
    "print('precisions: ', precisions)\n",
    "print('recalls: ', recalls)\n",
    "print('fmeasures: ', fmeasures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68080bd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.stats as st\n",
    "\n",
    "#define sample data\n",
    "data = accs\n",
    "\n",
    "#create 95% confidence interval for population mean weight\n",
    "st.t.interval(alpha=0.95, df=len(data)-1, loc=np.mean(data), scale=st.sem(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b031931d",
   "metadata": {},
   "outputs": [],
   "source": [
    "accs=[0.5833333134651184, 0.6499999761581421, 0.6299999761581421, 0.6499999761581421, 0.6699999761581421, 0.6499999761581421, 0.6699999761581421, 0.6899999761581421, 0.6699999761581421, 0.6899999761581421, 0.7099999761581421, 0.6899999761581421, 0.7099999761581421, 0.68999999999999, 0.6699999999999899, 0.68999999999999, 0.70999999999999, 0.68999999999999, 0.70999999999999, 0.68999999999999]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4da3f353",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.5833333134651184,\n",
       " 0.6499999761581421,\n",
       " 0.6299999761581421,\n",
       " 0.6499999761581421,\n",
       " 0.6699999761581421,\n",
       " 0.6499999761581421,\n",
       " 0.6699999761581421,\n",
       " 0.6899999761581421,\n",
       " 0.6699999761581421,\n",
       " 0.6899999761581421,\n",
       " 0.7099999761581421,\n",
       " 0.6899999761581421,\n",
       " 0.7099999761581421,\n",
       " 0.68999999999999,\n",
       " 0.6699999999999899,\n",
       " 0.68999999999999,\n",
       " 0.70999999999999,\n",
       " 0.68999999999999,\n",
       " 0.70999999999999,\n",
       " 0.68999999999999]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0945f0bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "accs = [0.7958, 0.8125, 0.80500, 0.82, 0.83454, 0.7858, 0.8105, 0.804500, 0.82, 0.83454]\n",
    "import matplotlib.pyplot as plt\n",
    "data = accs\n",
    "data = sorted(data)\n",
    "plt.plot(list(range(len(accs))), data, 'k')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ae4b428e",
   "metadata": {},
   "outputs": [],
   "source": [
    "accs=[1.1599838733673096, ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0596d6fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision:  0.963963963963964\n",
      "Recall:  0.9907407407407407\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\patcas rares\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Importing the required libraries\n",
    "from sklearn import datasets\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import plot_precision_recall_curve\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "import matplotlib.pyplot as plt\n",
    " \n",
    "#Loading the data\n",
    "data = datasets.load_breast_cancer()\n",
    "df = pd.DataFrame(data.data, columns=data.feature_names)\n",
    "df['target'] = data.target\n",
    " \n",
    "#Splitting the data into training and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "                                    df.iloc[:,:-1], df.iloc[:,-1], test_size=0.3, random_state=42)\n",
    " \n",
    "# Initialize and fit the Model\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    " \n",
    "#Make prediction on the test set\n",
    "pred = model.predict(X_test)\n",
    " \n",
    "#calculating precision and reall\n",
    "precision = precision_score(y_test, pred)\n",
    "recall = recall_score(y_test, pred)\n",
    " \n",
    "print('Precision: ',precision)\n",
    "print('Recall: ',recall)\n",
    " \n",
    "#Plotting Precision-Recall Curve\n",
    "disp = plot_precision_recall_curve(model, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6c20cc34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "204    1\n",
      "70     0\n",
      "131    0\n",
      "431    1\n",
      "540    1\n",
      "      ..\n",
      "69     1\n",
      "542    1\n",
      "176    1\n",
      "501    0\n",
      "247    1\n",
      "Name: target, Length: 171, dtype: int32\n"
     ]
    }
   ],
   "source": [
    "print(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "7990f995",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 0 1 1 0 0 0 1 1 1 0 1 0 1 0 1 1 1 0 1 1 0 1 1 1 1 1 1 0 1 1 1 1 1 1 0\n",
      " 1 0 1 1 0 1 1 1 1 1 1 1 1 0 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0 1 1 0 0 1 0\n",
      " 1 1 1 1 1 1 0 1 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 1 0 0 1 0 0 1 1 1 0 1 1 0\n",
      " 1 0 0 1 0 1 1 1 0 1 1 1 0 1 0 0 1 1 0 0 0 1 1 1 0 1 1 1 0 1 0 1 1 0 1 0 0\n",
      " 1 1 0 1 1 1 1 0 0 1 1 1 1 1 1 1 0 1 1 1 1 0 1]\n"
     ]
    }
   ],
   "source": [
    "print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b54dfad7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a014aa1f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ded849f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1f3e6533",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pt ResNet \n",
    "accs = [0.8333333134651184, 0.8333333134651184, 0.9333333373069763, 0.8999999761581421, 0.8666666746139526, 0.8999999761581421, 0.7333333492279053, 0.8999999761581421, 0.7333333492279053, 0.9666666388511658]\n",
    "precisions = [0.9692307692307692, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9692307692307692, 1.0]\n",
    "recalls = [0.8333333333333334, 0.8333333333333334, 0.9333333333333333, 0.9, 0.8666666666666667, 0.9, 0.7333333333333333, 0.9, 0.7333333333333333, 0.9666666666666667]\n",
    "fmeasures = [0.8872258064516129, 0.9032258064516128, 0.9650000000000001, 0.9465116279069767, 0.9263157894736842, 0.9444444444444445, 0.8412698412698413, 0.9457142857142856, 0.8125714285714286, 0.9828282828282828]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9b3708b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8040215188965151, 0.9159784620299986)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import scipy.stats as st\n",
    "\n",
    "#define sample data\n",
    "data = accs\n",
    "\n",
    "#create 95% confidence interval for population mean weight\n",
    "st.t.interval(alpha=0.95, df=len(data)-1, loc=np.mean(data), scale=st.sem(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bfb53176",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9845655090759343, 1.0031267986163732)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = precisions\n",
    "\n",
    "#create 95% confidence interval for population mean weight\n",
    "st.t.interval(alpha=0.95, df=len(data)-1, loc=np.mean(data), scale=st.sem(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5045da1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8040215198496445, 0.9159784801503554)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = recalls\n",
    "\n",
    "#create 95% confidence interval for population mean weight\n",
    "st.t.interval(alpha=0.95, df=len(data)-1, loc=np.mean(data), scale=st.sem(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5e65710a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8764254778012908, 0.9545959848211432)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = fmeasures\n",
    "\n",
    "#create 95% confidence interval for population mean weight\n",
    "st.t.interval(alpha=0.95, df=len(data)-1, loc=np.mean(data), scale=st.sem(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f6445bb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

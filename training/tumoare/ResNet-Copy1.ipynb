{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aaa021fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all imported\n"
     ]
    }
   ],
   "source": [
    "# Import the necessary libraries\n",
    "from PIL import Image\n",
    "from numpy import asarray\n",
    "import numpy as np\n",
    "import os\n",
    "import keras\n",
    "from keras.layers import Dense, Conv2D, BatchNormalization, Activation\n",
    "from keras.layers import AveragePooling2D, Input, Flatten\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.regularizers import l2\n",
    "from keras import backend as K\n",
    "from keras.models import Model\n",
    "from keras.datasets import cifar10\n",
    "import numpy as np\n",
    "import os\n",
    "from keras.utils import np_utils\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "# calculates f1 for 1:100 dataset with 95tp, 5fn, 55fp\n",
    "from sklearn.metrics import f1_score\n",
    "print('all imported')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "68181300",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 74  74  74]\n",
      "  [ 83  83  83]\n",
      "  [ 86  86  86]\n",
      "  ...\n",
      "  [108 108 108]\n",
      "  [107 107 107]\n",
      "  [102 102 102]]\n",
      "\n",
      " [[  8   8   8]\n",
      "  [  8   8   8]\n",
      "  [  7   7   7]\n",
      "  ...\n",
      "  [  9   9   9]\n",
      "  [ 14  14  14]\n",
      "  [ 25  25  25]]\n",
      "\n",
      " [[  8   8   8]\n",
      "  [  7   7   7]\n",
      "  [  7   7   7]\n",
      "  ...\n",
      "  [  9   9   9]\n",
      "  [ 15  15  15]\n",
      "  [ 27  27  27]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[  8   8   8]\n",
      "  [  7   7   7]\n",
      "  [  7   7   7]\n",
      "  ...\n",
      "  [128 128 128]\n",
      "  [ 87  87  87]\n",
      "  [ 84  84  84]]\n",
      "\n",
      " [[  8   8   8]\n",
      "  [  8   8   8]\n",
      "  [  7   7   7]\n",
      "  ...\n",
      "  [ 66  66  66]\n",
      "  [ 73  73  73]\n",
      "  [ 77  77  77]]\n",
      "\n",
      " [[ 87  87  87]\n",
      "  [ 70  70  70]\n",
      "  [ 61  61  61]\n",
      "  ...\n",
      "  [ 85  85  85]\n",
      "  [ 79  79  79]\n",
      "  [ 73  73  73]]]\n"
     ]
    }
   ],
   "source": [
    "def readImage(filePath):\n",
    "    img = Image.open(filePath)\n",
    "    \n",
    "    size=(30,40)\n",
    "    #resize image\n",
    "    out = img.resize(size)\n",
    "\n",
    "    # asarray() class is used to convert\n",
    "    # PIL images into NumPy arrays\n",
    "    numpydata = asarray(out)\n",
    "    numpydata = np.repeat(numpydata[:, :, np.newaxis], 3, axis=2)\n",
    "    # <class 'numpy.ndarray'>\n",
    "    #print(type(numpydata))\n",
    "\n",
    "    #  shape\n",
    "    #print(numpydata.shape)\n",
    "    return numpydata\n",
    "print(readImage('../../content/Benign/B_3141_1.RIGHT_CC.LJPEG.1_highpass.gif'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4fd11c2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['B_3091_1.LEFT_CC.LJPEG.1_highpass.gif', 'B_3091_1.LEFT_MLO.LJPEG.1_highpass.gif', 'B_3093_1.LEFT_CC.LJPEG.1_highpass.gif', 'B_3093_1.LEFT_MLO.LJPEG.1_highpass.gif', 'B_3094_1.LEFT_CC.LJPEG.1_highpass.gif']\n"
     ]
    }
   ],
   "source": [
    "listFiles = os.listdir('../../content/Benign/')\n",
    "print(listFiles[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f9b74ddd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[[  5,   5,   5],\n",
      "        [ 21,  21,  21],\n",
      "        [ 13,  13,  13],\n",
      "        ...,\n",
      "        [  7,   7,   7],\n",
      "        [  5,   5,   5],\n",
      "        [  2,   2,   2]],\n",
      "\n",
      "       [[ 23,  23,  23],\n",
      "        [ 14,  14,  14],\n",
      "        [  9,   9,   9],\n",
      "        ...,\n",
      "        [  1,   1,   1],\n",
      "        [  0,   0,   0],\n",
      "        [  0,   0,   0]],\n",
      "\n",
      "       [[ 23,  23,  23],\n",
      "        [ 14,  14,  14],\n",
      "        [  9,   9,   9],\n",
      "        ...,\n",
      "        [  0,   0,   0],\n",
      "        [  0,   0,   0],\n",
      "        [  0,   0,   0]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[ 29,  29,  29],\n",
      "        [ 17,  17,  17],\n",
      "        [ 10,  10,  10],\n",
      "        ...,\n",
      "        [  0,   0,   0],\n",
      "        [  0,   0,   0],\n",
      "        [  0,   0,   0]],\n",
      "\n",
      "       [[128, 128, 128],\n",
      "        [ 17,  17,  17],\n",
      "        [ 12,  12,  12],\n",
      "        ...,\n",
      "        [  0,   0,   0],\n",
      "        [  0,   0,   0],\n",
      "        [  0,   0,   0]],\n",
      "\n",
      "       [[128, 128, 128],\n",
      "        [128, 128, 128],\n",
      "        [ 14,  14,  14],\n",
      "        ...,\n",
      "        [  7,   7,   7],\n",
      "        [  6,   6,   6],\n",
      "        [  6,   6,   6]]], dtype=uint8), array([[[108, 108, 108],\n",
      "        [117, 117, 117],\n",
      "        [116, 116, 116],\n",
      "        ...,\n",
      "        [  1,   1,   1],\n",
      "        [  1,   1,   1],\n",
      "        [  1,   1,   1]],\n",
      "\n",
      "       [[112, 112, 112],\n",
      "        [108, 108, 108],\n",
      "        [115, 115, 115],\n",
      "        ...,\n",
      "        [  1,   1,   1],\n",
      "        [  1,   1,   1],\n",
      "        [  1,   1,   1]],\n",
      "\n",
      "       [[117, 117, 117],\n",
      "        [112, 112, 112],\n",
      "        [110, 110, 110],\n",
      "        ...,\n",
      "        [  1,   1,   1],\n",
      "        [  1,   1,   1],\n",
      "        [  1,   1,   1]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[ 25,  25,  25],\n",
      "        [ 17,  17,  17],\n",
      "        [ 10,  10,  10],\n",
      "        ...,\n",
      "        [  0,   0,   0],\n",
      "        [  0,   0,   0],\n",
      "        [  0,   0,   0]],\n",
      "\n",
      "       [[ 24,  24,  24],\n",
      "        [ 18,  18,  18],\n",
      "        [ 11,  11,  11],\n",
      "        ...,\n",
      "        [  0,   0,   0],\n",
      "        [  0,   0,   0],\n",
      "        [  0,   0,   0]],\n",
      "\n",
      "       [[128, 128, 128],\n",
      "        [ 19,  19,  19],\n",
      "        [ 19,  19,  19],\n",
      "        ...,\n",
      "        [  6,   6,   6],\n",
      "        [  6,   6,   6],\n",
      "        [  6,   6,   6]]], dtype=uint8), array([[[  1,   1,   1],\n",
      "        [  7,   7,   7],\n",
      "        [  4,   4,   4],\n",
      "        ...,\n",
      "        [  0,   0,   0],\n",
      "        [  0,   0,   0],\n",
      "        [  0,   0,   0]],\n",
      "\n",
      "       [[ 21,  21,  21],\n",
      "        [ 15,  15,  15],\n",
      "        [ 11,  11,  11],\n",
      "        ...,\n",
      "        [  4,   4,   4],\n",
      "        [  7,   7,   7],\n",
      "        [ 12,  12,  12]],\n",
      "\n",
      "       [[ 19,  19,  19],\n",
      "        [ 15,  15,  15],\n",
      "        [ 11,  11,  11],\n",
      "        ...,\n",
      "        [  4,   4,   4],\n",
      "        [  6,   6,   6],\n",
      "        [ 11,  11,  11]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[ 28,  28,  28],\n",
      "        [ 19,  19,  19],\n",
      "        [ 10,  10,  10],\n",
      "        ...,\n",
      "        [  0,   0,   0],\n",
      "        [  0,   0,   0],\n",
      "        [  1,   1,   1]],\n",
      "\n",
      "       [[ 22,  22,  22],\n",
      "        [ 14,  14,  14],\n",
      "        [ 10,  10,  10],\n",
      "        ...,\n",
      "        [  0,   0,   0],\n",
      "        [  0,   0,   0],\n",
      "        [  1,   1,   1]],\n",
      "\n",
      "       [[128, 128, 128],\n",
      "        [ 35,  35,  35],\n",
      "        [ 23,  23,  23],\n",
      "        ...,\n",
      "        [  0,   0,   0],\n",
      "        [  0,   0,   0],\n",
      "        [  0,   0,   0]]], dtype=uint8)]\n",
      "(40, 30, 3)\n"
     ]
    }
   ],
   "source": [
    "#load Benign\n",
    "listCancer = []\n",
    "listResults = []\n",
    "for elem in listFiles:\n",
    "    img = readImage('../../content/Benign/'+elem)\n",
    "    listCancer += [img]\n",
    "    listResults += [np.array([1])]\n",
    "print(listCancer[:3])\n",
    "print(img.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e7cf790e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['A_0002_1.LEFT_CC.LJPEG.1_highpass.gif', 'A_0002_1.LEFT_MLO.LJPEG.1_highpass.gif', 'A_0002_1.RIGHT_CC.LJPEG.1_highpass.gif', 'A_0002_1.RIGHT_MLO.LJPEG.1_highpass.gif', 'A_0003_1.LEFT_CC.LJPEG.1_highpass.gif']\n"
     ]
    }
   ],
   "source": [
    "listFiles = os.listdir('../../content/Normal/')\n",
    "print(listFiles[:5])\n",
    "for elem in listFiles:\n",
    "    img = readImage('../../content/Normal/'+elem)\n",
    "    listResults += [np.array([0])]\n",
    "    listCancer += [img]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0162b926",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['B_3006_1.LEFT_CC.LJPEG.1_highpass.gif', 'B_3006_1.LEFT_MLO.LJPEG.1_highpass.gif', 'B_3011_1.LEFT_CC.LJPEG.1_highpass.gif', 'B_3011_1.LEFT_MLO.LJPEG.1_highpass.gif', 'B_3011_1.RIGHT_CC.LJPEG.1_highpass.gif']\n"
     ]
    }
   ],
   "source": [
    "listFiles = os.listdir('../../content/Malign/')\n",
    "print(listFiles[:5])\n",
    "for elem in listFiles:\n",
    "    img = readImage('../../content/Malign/'+elem)\n",
    "    listResults += [np.array([2])]\n",
    "    listCancer += [img]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c6134bb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300\n"
     ]
    }
   ],
   "source": [
    "print(len(listCancer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e15204a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_test():\n",
    "    per = np.random.permutation(len(listCancer))\n",
    "    ln = int(len(listCancer) * 0.8)\n",
    "    x_train = []\n",
    "    y_train = []\n",
    "    x_test = []\n",
    "    y_test = []\n",
    "    positions = []\n",
    "    for i in range(ln):\n",
    "        positions += [per[i]]\n",
    "    for i in range(len(listCancer)):\n",
    "        if i in positions:\n",
    "            x_train += [listCancer[i]]\n",
    "            y_train += [listResults[i]]\n",
    "        else:\n",
    "            x_test += [listCancer[i]]\n",
    "            y_test += [listResults[i]]\n",
    "    \n",
    "    x_train = np.array(x_train)\n",
    "    y_train = np.array(y_train)\n",
    "\n",
    "    x_test = np.array(x_test)\n",
    "    y_test = np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7b91ed89",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data():\n",
    "    # Setting Training Hyperparameters\n",
    "    batch_size = 32 # original ResNet paper uses batch_size = 128 for training\n",
    "    epochs = 10\n",
    "    data_augmentation = True\n",
    "    num_classes = 10\n",
    "\n",
    "    # Data Preprocessing\n",
    "    subtract_pixel_mean = True\n",
    "    n = 3\n",
    "\n",
    "    # Select ResNet Version\n",
    "    version = 2\n",
    "\n",
    "    # Computed depth of\n",
    "    if version == 1:\n",
    "        depth = n * 6 + 2\n",
    "    elif version == 2:\n",
    "        depth = n * 9 + 2\n",
    "\n",
    "    # Model name, depth and version\n",
    "    model_type = 'ResNet % dv % d' % (depth, version)\n",
    "\n",
    "    # use the data\n",
    "    print(x_train[:3])\n",
    "    print(y_train[:3])\n",
    "    print(type(x_train[0]))\n",
    "    print(type(x_train))\n",
    "    print(type(y_train[0]))\n",
    "    print(type(y_train))\n",
    "\n",
    "    # Input image dimensions.\n",
    "    input_shape = x_train.shape[1:]\n",
    "    print(input_shape)\n",
    "\n",
    "    # Normalize data.\n",
    "    x_train = x_train.astype('float32') / 255\n",
    "    x_test = x_test.astype('float32') / 255\n",
    "\n",
    "    # If subtract pixel mean is enabled\n",
    "    if subtract_pixel_mean:\n",
    "        x_train_mean = np.mean(x_train, axis = 0)\n",
    "        x_train -= x_train_mean\n",
    "        x_test -= x_train_mean\n",
    "\n",
    "    # Print Training and Test Samples\n",
    "    print('x_train shape:', x_train.shape)\n",
    "    print(x_train.shape[0], 'train samples')\n",
    "    print(x_test.shape[0], 'test samples')\n",
    "    print('y_train shape:', y_train.shape)\n",
    "\n",
    "    # Convert class vectors to binary class matrices.\n",
    "    y_train = keras.utils.np_utils.to_categorical(y_train, num_classes)\n",
    "    y_test = keras.utils.np_utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e031e369",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting LR for different number of Epochs\n",
    "def lr_schedule(epoch):\n",
    "\tlr = 1e-3\n",
    "\tif epoch > 180:\n",
    "\t\tlr *= 0.5e-3\n",
    "\telif epoch > 160:\n",
    "\t\tlr *= 1e-3\n",
    "\telif epoch > 120:\n",
    "\t\tlr *= 1e-2\n",
    "\telif epoch > 80:\n",
    "\t\tlr *= 1e-1\n",
    "\tprint('Learning rate: ', lr)\n",
    "\treturn lr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2e7b97e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic ResNet Building Block\n",
    "def resnet_layer(inputs, conv_first = False,\n",
    "\t\t\t\tnum_filters = 16,\n",
    "\t\t\t\tkernel_size = 3,\n",
    "\t\t\t\tstrides = 1,\n",
    "\t\t\t\tactivation ='relu',\n",
    "\t\t\t\tbatch_normalization = True):\n",
    "\tconv = Conv2D(num_filters,\n",
    "\t\t\t\tkernel_size = kernel_size,\n",
    "\t\t\t\tstrides = strides,\n",
    "\t\t\t\tpadding ='same',\n",
    "\t\t\t\tkernel_initializer ='he_normal',\n",
    "\t\t\t\tkernel_regularizer = l2(1e-4))\n",
    "\n",
    "\tx = inputs\n",
    "\tif conv_first:\n",
    "\t\tx = conv(x)\n",
    "\t\tif batch_normalization:\n",
    "\t\t\tx = BatchNormalization()(x)\n",
    "\t\tif activation is not None:\n",
    "\t\t\tx = Activation(activation)(x)\n",
    "\telse:\n",
    "\t\tif batch_normalization:\n",
    "\t\t\tx = BatchNormalization()(x)\n",
    "\t\tif activation is not None:\n",
    "\t\t\tx = Activation(activation)(x)\n",
    "\t\tx = conv(x)\n",
    "\treturn x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9c3ccc68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ResNet V2 architecture\n",
    "def resnet_v2(input_shape, depth, num_classes = 10):\n",
    "\tif (depth - 2) % 9 != 0:\n",
    "\t\traise ValueError('depth should be 9n + 2 (eg 56 or 110 in [b])')\n",
    "\t# Start model definition.\n",
    "\tnum_filters_in = 16\n",
    "\tnum_res_blocks = int((depth - 2) / 9)\n",
    "\n",
    "\tinputs = Input(shape = input_shape)\n",
    "\t# v2 performs Conv2D with BN-ReLU on input before splitting into 2 paths\n",
    "\tx = resnet_layer(inputs = inputs,num_filters = num_filters_in,conv_first = True)\n",
    "\n",
    "\t# Instantiate the stack of residual units\n",
    "\tfor stage in range(3):\n",
    "\t\tfor res_block in range(num_res_blocks):\n",
    "\t\t\tactivation = 'relu'\n",
    "\t\t\tbatch_normalization = True\n",
    "\t\t\tstrides = 1\n",
    "\t\t\tif stage == 0:\n",
    "\t\t\t\tnum_filters_out = num_filters_in * 4\n",
    "\t\t\t\tif res_block == 0: # first layer and first stage\n",
    "\t\t\t\t\tactivation = None\n",
    "\t\t\t\t\tbatch_normalization = False\n",
    "\t\t\telse:\n",
    "\t\t\t\tnum_filters_out = num_filters_in * 2\n",
    "\t\t\t\tif res_block == 0: # first layer but not first stage\n",
    "\t\t\t\t\tstrides = 2 # downsample\n",
    "\n",
    "\t\t\t# bottleneck residual unit\n",
    "\t\t\ty = resnet_layer(inputs = x,\n",
    "\t\t\t\t\t\t\tnum_filters = num_filters_in,\n",
    "\t\t\t\t\t\t\tkernel_size = 1,\n",
    "\t\t\t\t\t\t\tstrides = strides,\n",
    "\t\t\t\t\t\t\tactivation = activation,\n",
    "\t\t\t\t\t\t\tbatch_normalization = batch_normalization)\n",
    "\t\t\ty = resnet_layer(inputs = y,\n",
    "\t\t\t\t\t\t\tnum_filters = num_filters_in,\n",
    "\t\t\t\t\t\t\tconv_first = False)\n",
    "\t\t\ty = resnet_layer(inputs = y,\n",
    "\t\t\t\t\t\t\tnum_filters = num_filters_out,\n",
    "\t\t\t\t\t\t\tkernel_size = 1,\n",
    "\t\t\t\t\t\t\tconv_first = False)\n",
    "\t\t\tif res_block == 0:\n",
    "\t\t\t\t# linear projection residual shortcut connection to match\n",
    "\t\t\t\t# changed dims\n",
    "\t\t\t\tx = resnet_layer(inputs = x,\n",
    "\t\t\t\t\t\t\t\tnum_filters = num_filters_out,\n",
    "\t\t\t\t\t\t\t\tkernel_size = 1,\n",
    "\t\t\t\t\t\t\t\tstrides = strides,\n",
    "\t\t\t\t\t\t\t\tactivation = None,\n",
    "\t\t\t\t\t\t\t\tbatch_normalization = False)\n",
    "\t\t\tx = keras.layers.add([x, y])\n",
    "\n",
    "\t\tnum_filters_in = num_filters_out\n",
    "\n",
    "\t# Add classifier on top.\n",
    "\t# v2 has BN-ReLU before Pooling\n",
    "\tx = BatchNormalization()(x)\n",
    "\tx = Activation('relu')(x)\n",
    "\tx = AveragePooling2D(pool_size = 8)(x)\n",
    "\ty = Flatten()(x)\n",
    "\toutputs = Dense(num_classes,\n",
    "\t\t\t\t\tactivation ='softmax',\n",
    "\t\t\t\t\tkernel_initializer ='he_normal')(y)\n",
    "\n",
    "\t# Instantiate model.\n",
    "\tmodel = Model(inputs = inputs, outputs = outputs)\n",
    "\treturn model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "71df1011",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train=[]\n",
    "y_train=[]\n",
    "accs=[]\n",
    "\n",
    "precisions = []\n",
    "recalls = []\n",
    "def main(pz):\n",
    "    \n",
    "    per = np.random.permutation(len(listCancer))\n",
    "    ln = int(len(listCancer) * 0.8)\n",
    "    x_train = []\n",
    "    y_train = []\n",
    "    x_test = []\n",
    "    y_test = []\n",
    "    positions = []\n",
    "    for i in range(ln):\n",
    "        positions += [per[i]]\n",
    "    for i in range(len(listCancer)):\n",
    "        if i in positions:\n",
    "            x_train += [listCancer[i]]\n",
    "            y_train += [listResults[i]]\n",
    "        else:\n",
    "            x_test += [listCancer[i]]\n",
    "            y_test += [listResults[i]]\n",
    "            \n",
    "    ln = len(x_test) // 2\n",
    "    \n",
    "    x_valid = x_test[ln:]\n",
    "    y_valid = y_test[ln:]\n",
    "    \n",
    "    x_test = x_test[:ln]\n",
    "    y_test = y_test[:ln]\n",
    "    \n",
    "    \n",
    "    x_train = np.array(x_train)\n",
    "    y_train = np.array(y_train)\n",
    "    \n",
    "\n",
    "    x_test = np.array(x_test)\n",
    "    y_test = np.array(y_test)\n",
    "    \n",
    "    x_valid = np.array(x_valid)\n",
    "    y_valid = np.array(y_valid)\n",
    "    \n",
    "    \n",
    "    batch_size = 32 # original ResNet paper uses batch_size = 128 for training\n",
    "    epochs = 10\n",
    "    data_augmentation = True\n",
    "    num_classes = 10\n",
    "\n",
    "    # Data Preprocessing\n",
    "    subtract_pixel_mean = True\n",
    "    n = 3\n",
    "\n",
    "    # Select ResNet Version\n",
    "    version = 2\n",
    "\n",
    "    # Computed depth of\n",
    "    if version == 1:\n",
    "        depth = n * 6 + 2\n",
    "    elif version == 2:\n",
    "        depth = n * 9 + 2\n",
    "\n",
    "    # Model name, depth and version\n",
    "    model_type = 'ResNet % dv % d' % (depth, version)\n",
    "\n",
    "    # use the data\n",
    "    print(x_train[:3])\n",
    "    print(y_train[:3])\n",
    "    print(type(x_train[0]))\n",
    "    print(type(x_train))\n",
    "    print(type(y_train[0]))\n",
    "    print(type(y_train))\n",
    "\n",
    "    # Input image dimensions.\n",
    "    input_shape = x_train.shape[1:]\n",
    "    print(input_shape)\n",
    "\n",
    "    # Normalize data.\n",
    "    x_train = x_train.astype('float32') / 255\n",
    "    x_test = x_test.astype('float32') / 255\n",
    "    x_valid = x_test.astype('float32') / 255\n",
    "\n",
    "    # If subtract pixel mean is enabled\n",
    "    if subtract_pixel_mean:\n",
    "        x_train_mean = np.mean(x_train, axis = 0)\n",
    "        x_train -= x_train_mean\n",
    "        x_test -= x_train_mean\n",
    "\n",
    "    # Print Training and Test Samples\n",
    "    print('x_train shape:', x_train.shape)\n",
    "    print(x_train.shape[0], 'train samples')\n",
    "    print(x_test.shape[0], 'test samples')\n",
    "    print('y_train shape:', y_train.shape)\n",
    "\n",
    "    # Convert class vectors to binary class matrices.\n",
    "    y_train = keras.utils.np_utils.to_categorical(y_train, num_classes)\n",
    "    y_test = keras.utils.np_utils.to_categorical(y_test, num_classes)\n",
    "    y_valid = keras.utils.np_utils.to_categorical(y_valid, num_classes)\n",
    "    \n",
    "    \n",
    "    model = resnet_v2(input_shape = input_shape, depth = depth)\n",
    "\n",
    "    model.compile(loss ='categorical_crossentropy',\n",
    "                optimizer = Adam(learning_rate = lr_schedule(0)),\n",
    "                metrics =['accuracy'])\n",
    "    model.summary()\n",
    "    print(model_type)\n",
    "\n",
    "    # Prepare model model saving directory.\n",
    "    save_dir = os.path.join(os.getcwd(), 'saved_models')\n",
    "    model_name = 'cifar10_% s_model.{epoch:03d}.h5' % model_type\n",
    "    if not os.path.isdir(save_dir):\n",
    "        os.makedirs(save_dir)\n",
    "    filepath = os.path.join(save_dir, model_name)\n",
    "\n",
    "    # Prepare callbacks for model saving and for learning rate adjustment.\n",
    "    checkpoint = ModelCheckpoint(filepath = filepath,\n",
    "                                monitor ='val_acc',\n",
    "                                verbose = 1,\n",
    "                                save_best_only = True)\n",
    "\n",
    "    lr_scheduler = LearningRateScheduler(lr_schedule)\n",
    "\n",
    "    lr_reducer = ReduceLROnPlateau(factor = np.sqrt(0.1),\n",
    "                                cooldown = 0,\n",
    "                                patience = 5,\n",
    "                                min_lr = 0.5e-6)\n",
    "\n",
    "    callbacks = [checkpoint, lr_reducer, lr_scheduler]\n",
    "\n",
    "    # Run training, with or without data augmentation.\n",
    "    if not data_augmentation:\n",
    "        print('Not using data augmentation.')\n",
    "        model.fit(x_train, y_train,\n",
    "                batch_size = batch_size,\n",
    "                epochs = epochs,\n",
    "                validation_data =(x_test, y_test),\n",
    "                shuffle = True,\n",
    "                callbacks = callbacks)\n",
    "    else:\n",
    "        print('Using real-time data augmentation.')\n",
    "        # This will do preprocessing and realtime data augmentation:\n",
    "        datagen = ImageDataGenerator(\n",
    "            # set input mean to 0 over the dataset\n",
    "            featurewise_center = False,\n",
    "            # set each sample mean to 0\n",
    "            samplewise_center = False,\n",
    "            # divide inputs by std of dataset\n",
    "            featurewise_std_normalization = False,\n",
    "            # divide each input by its std\n",
    "            samplewise_std_normalization = False,\n",
    "            # apply ZCA whitening\n",
    "            zca_whitening = False,\n",
    "            # epsilon for ZCA whitening\n",
    "            zca_epsilon = 1e-06,\n",
    "            # randomly rotate images in the range (deg 0 to 180)\n",
    "            rotation_range = 0,\n",
    "            # randomly shift images horizontally\n",
    "            width_shift_range = 0.1,\n",
    "            # randomly shift images vertically\n",
    "            height_shift_range = 0.1,\n",
    "            # set range for random shear\n",
    "            shear_range = 0.,\n",
    "            # set range for random zoom\n",
    "            zoom_range = 0.,\n",
    "            # set range for random channel shifts\n",
    "            channel_shift_range = 0.,\n",
    "            # set mode for filling points outside the input boundaries\n",
    "            fill_mode ='nearest',\n",
    "            # value used for fill_mode = \"constant\"\n",
    "            cval = 0.,\n",
    "            # randomly flip images\n",
    "            horizontal_flip = True,\n",
    "            # randomly flip images\n",
    "            vertical_flip = False,\n",
    "            # set rescaling factor (applied before any other transformation)\n",
    "            rescale = None,\n",
    "            # set function that will be applied on each input\n",
    "            preprocessing_function = None,\n",
    "            # image data format, either \"channels_first\" or \"channels_last\"\n",
    "            data_format = None,\n",
    "            # fraction of images reserved for validation (strictly between 0 and 1)\n",
    "            validation_split = 0.1)\n",
    "\n",
    "        # Compute quantities required for featurewise normalization\n",
    "        # (std, mean, and principal components if ZCA whitening is applied).\n",
    "        print('------------------')\n",
    "        print(x_train)\n",
    "        datagen.fit(x_train)\n",
    "        \n",
    "        model_json = model.to_json()\n",
    "        with open(\"saved_models/breastResNetModel.json\", \"w\") as json_file:\n",
    "            json_file.write(model_json)\n",
    "\n",
    "        # Fit the model on the batches generated by datagen.flow().\n",
    "        model.fit_generator(datagen.flow(x_train, y_train, batch_size = batch_size),\n",
    "                            validation_data =(x_valid, y_valid),\n",
    "                            epochs = 100, verbose = 1, workers = 4,\n",
    "                            callbacks = callbacks)\n",
    "\n",
    "    # Score trained model.\n",
    "    scores = model.evaluate(x_test, y_test, verbose = 1)\n",
    "    print('Test loss:', scores[0])\n",
    "    print('Test accuracy:', scores[1])\n",
    "    ret = model.predict(x_test)\n",
    "    result = []\n",
    "    pred = []\n",
    "    for a,b in zip(ret, y_test):\n",
    "        pred+=[a.argmax(axis=-1)]\n",
    "        result+=[b.argmax(axis=-1)]\n",
    "    print(pred)\n",
    "    print(result)\n",
    "    precision = precision_score(result, pred, average='weighted')\n",
    "    recall = recall_score(result, pred, average='weighted')\n",
    "     # calculates f1 for 1:100 dataset with 95tp, 5fn, 55fp\n",
    "    fmeasure = f1_score(result, pred, average='weighted')\n",
    "    print('Precision: ', precision)\n",
    "    print('Recall: ', recall)\n",
    "    print('F1 Score: ', fmeasure)\n",
    "    #precisions += [precision]\n",
    "    #recalls += [recall]\n",
    "    if scores[1] > 0.8:\n",
    "        model.save('saved_models/breastResNetV'+str(pz)+'.h5')\n",
    "    return [scores[1], precision, recall, fmeasure]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ee89ef05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[[  5   5   5]\n",
      "   [ 21  21  21]\n",
      "   [ 13  13  13]\n",
      "   ...\n",
      "   [  7   7   7]\n",
      "   [  5   5   5]\n",
      "   [  2   2   2]]\n",
      "\n",
      "  [[ 23  23  23]\n",
      "   [ 14  14  14]\n",
      "   [  9   9   9]\n",
      "   ...\n",
      "   [  1   1   1]\n",
      "   [  0   0   0]\n",
      "   [  0   0   0]]\n",
      "\n",
      "  [[ 23  23  23]\n",
      "   [ 14  14  14]\n",
      "   [  9   9   9]\n",
      "   ...\n",
      "   [  0   0   0]\n",
      "   [  0   0   0]\n",
      "   [  0   0   0]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[ 29  29  29]\n",
      "   [ 17  17  17]\n",
      "   [ 10  10  10]\n",
      "   ...\n",
      "   [  0   0   0]\n",
      "   [  0   0   0]\n",
      "   [  0   0   0]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [ 17  17  17]\n",
      "   [ 12  12  12]\n",
      "   ...\n",
      "   [  0   0   0]\n",
      "   [  0   0   0]\n",
      "   [  0   0   0]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [128 128 128]\n",
      "   [ 14  14  14]\n",
      "   ...\n",
      "   [  7   7   7]\n",
      "   [  6   6   6]\n",
      "   [  6   6   6]]]\n",
      "\n",
      "\n",
      " [[[108 108 108]\n",
      "   [117 117 117]\n",
      "   [116 116 116]\n",
      "   ...\n",
      "   [  1   1   1]\n",
      "   [  1   1   1]\n",
      "   [  1   1   1]]\n",
      "\n",
      "  [[112 112 112]\n",
      "   [108 108 108]\n",
      "   [115 115 115]\n",
      "   ...\n",
      "   [  1   1   1]\n",
      "   [  1   1   1]\n",
      "   [  1   1   1]]\n",
      "\n",
      "  [[117 117 117]\n",
      "   [112 112 112]\n",
      "   [110 110 110]\n",
      "   ...\n",
      "   [  1   1   1]\n",
      "   [  1   1   1]\n",
      "   [  1   1   1]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[ 25  25  25]\n",
      "   [ 17  17  17]\n",
      "   [ 10  10  10]\n",
      "   ...\n",
      "   [  0   0   0]\n",
      "   [  0   0   0]\n",
      "   [  0   0   0]]\n",
      "\n",
      "  [[ 24  24  24]\n",
      "   [ 18  18  18]\n",
      "   [ 11  11  11]\n",
      "   ...\n",
      "   [  0   0   0]\n",
      "   [  0   0   0]\n",
      "   [  0   0   0]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [ 19  19  19]\n",
      "   [ 19  19  19]\n",
      "   ...\n",
      "   [  6   6   6]\n",
      "   [  6   6   6]\n",
      "   [  6   6   6]]]\n",
      "\n",
      "\n",
      " [[[  1   1   1]\n",
      "   [  7   7   7]\n",
      "   [  4   4   4]\n",
      "   ...\n",
      "   [  0   0   0]\n",
      "   [  0   0   0]\n",
      "   [  0   0   0]]\n",
      "\n",
      "  [[ 21  21  21]\n",
      "   [ 15  15  15]\n",
      "   [ 11  11  11]\n",
      "   ...\n",
      "   [  4   4   4]\n",
      "   [  7   7   7]\n",
      "   [ 12  12  12]]\n",
      "\n",
      "  [[ 19  19  19]\n",
      "   [ 15  15  15]\n",
      "   [ 11  11  11]\n",
      "   ...\n",
      "   [  4   4   4]\n",
      "   [  6   6   6]\n",
      "   [ 11  11  11]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[ 28  28  28]\n",
      "   [ 19  19  19]\n",
      "   [ 10  10  10]\n",
      "   ...\n",
      "   [  0   0   0]\n",
      "   [  0   0   0]\n",
      "   [  1   1   1]]\n",
      "\n",
      "  [[ 22  22  22]\n",
      "   [ 14  14  14]\n",
      "   [ 10  10  10]\n",
      "   ...\n",
      "   [  0   0   0]\n",
      "   [  0   0   0]\n",
      "   [  1   1   1]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [ 35  35  35]\n",
      "   [ 23  23  23]\n",
      "   ...\n",
      "   [  0   0   0]\n",
      "   [  0   0   0]\n",
      "   [  0   0   0]]]]\n",
      "[[1]\n",
      " [1]\n",
      " [1]]\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "(40, 30, 3)\n",
      "x_train shape: (240, 40, 30, 3)\n",
      "240 train samples\n",
      "30 test samples\n",
      "y_train shape: (240, 1)\n",
      "Learning rate:  0.001\n",
      "Model: \"model_6\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_7 (InputLayer)            [(None, 40, 30, 3)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_186 (Conv2D)             (None, 40, 30, 16)   448         input_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_168 (BatchN (None, 40, 30, 16)   64          conv2d_186[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_168 (Activation)     (None, 40, 30, 16)   0           batch_normalization_168[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_187 (Conv2D)             (None, 40, 30, 16)   272         activation_168[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_169 (BatchN (None, 40, 30, 16)   64          conv2d_187[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_169 (Activation)     (None, 40, 30, 16)   0           batch_normalization_169[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_188 (Conv2D)             (None, 40, 30, 16)   2320        activation_169[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_170 (BatchN (None, 40, 30, 16)   64          conv2d_188[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_170 (Activation)     (None, 40, 30, 16)   0           batch_normalization_170[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_190 (Conv2D)             (None, 40, 30, 64)   1088        activation_168[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_189 (Conv2D)             (None, 40, 30, 64)   1088        activation_170[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_54 (Add)                    (None, 40, 30, 64)   0           conv2d_190[0][0]                 \n",
      "                                                                 conv2d_189[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_171 (BatchN (None, 40, 30, 64)   256         add_54[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_171 (Activation)     (None, 40, 30, 64)   0           batch_normalization_171[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_191 (Conv2D)             (None, 40, 30, 16)   1040        activation_171[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_172 (BatchN (None, 40, 30, 16)   64          conv2d_191[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_172 (Activation)     (None, 40, 30, 16)   0           batch_normalization_172[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_192 (Conv2D)             (None, 40, 30, 16)   2320        activation_172[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_173 (BatchN (None, 40, 30, 16)   64          conv2d_192[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_173 (Activation)     (None, 40, 30, 16)   0           batch_normalization_173[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_193 (Conv2D)             (None, 40, 30, 64)   1088        activation_173[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_55 (Add)                    (None, 40, 30, 64)   0           add_54[0][0]                     \n",
      "                                                                 conv2d_193[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_174 (BatchN (None, 40, 30, 64)   256         add_55[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_174 (Activation)     (None, 40, 30, 64)   0           batch_normalization_174[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_194 (Conv2D)             (None, 40, 30, 16)   1040        activation_174[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_175 (BatchN (None, 40, 30, 16)   64          conv2d_194[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_175 (Activation)     (None, 40, 30, 16)   0           batch_normalization_175[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_195 (Conv2D)             (None, 40, 30, 16)   2320        activation_175[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_176 (BatchN (None, 40, 30, 16)   64          conv2d_195[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_176 (Activation)     (None, 40, 30, 16)   0           batch_normalization_176[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_196 (Conv2D)             (None, 40, 30, 64)   1088        activation_176[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_56 (Add)                    (None, 40, 30, 64)   0           add_55[0][0]                     \n",
      "                                                                 conv2d_196[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_177 (BatchN (None, 40, 30, 64)   256         add_56[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_177 (Activation)     (None, 40, 30, 64)   0           batch_normalization_177[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_197 (Conv2D)             (None, 20, 15, 64)   4160        activation_177[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_178 (BatchN (None, 20, 15, 64)   256         conv2d_197[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_178 (Activation)     (None, 20, 15, 64)   0           batch_normalization_178[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_198 (Conv2D)             (None, 20, 15, 64)   36928       activation_178[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_179 (BatchN (None, 20, 15, 64)   256         conv2d_198[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_179 (Activation)     (None, 20, 15, 64)   0           batch_normalization_179[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_200 (Conv2D)             (None, 20, 15, 128)  8320        add_56[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_199 (Conv2D)             (None, 20, 15, 128)  8320        activation_179[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_57 (Add)                    (None, 20, 15, 128)  0           conv2d_200[0][0]                 \n",
      "                                                                 conv2d_199[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_180 (BatchN (None, 20, 15, 128)  512         add_57[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_180 (Activation)     (None, 20, 15, 128)  0           batch_normalization_180[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_201 (Conv2D)             (None, 20, 15, 64)   8256        activation_180[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_181 (BatchN (None, 20, 15, 64)   256         conv2d_201[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_181 (Activation)     (None, 20, 15, 64)   0           batch_normalization_181[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_202 (Conv2D)             (None, 20, 15, 64)   36928       activation_181[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_182 (BatchN (None, 20, 15, 64)   256         conv2d_202[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_182 (Activation)     (None, 20, 15, 64)   0           batch_normalization_182[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_203 (Conv2D)             (None, 20, 15, 128)  8320        activation_182[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_58 (Add)                    (None, 20, 15, 128)  0           add_57[0][0]                     \n",
      "                                                                 conv2d_203[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_183 (BatchN (None, 20, 15, 128)  512         add_58[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_183 (Activation)     (None, 20, 15, 128)  0           batch_normalization_183[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_204 (Conv2D)             (None, 20, 15, 64)   8256        activation_183[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_184 (BatchN (None, 20, 15, 64)   256         conv2d_204[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_184 (Activation)     (None, 20, 15, 64)   0           batch_normalization_184[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_205 (Conv2D)             (None, 20, 15, 64)   36928       activation_184[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_185 (BatchN (None, 20, 15, 64)   256         conv2d_205[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_185 (Activation)     (None, 20, 15, 64)   0           batch_normalization_185[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_206 (Conv2D)             (None, 20, 15, 128)  8320        activation_185[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_59 (Add)                    (None, 20, 15, 128)  0           add_58[0][0]                     \n",
      "                                                                 conv2d_206[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_186 (BatchN (None, 20, 15, 128)  512         add_59[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_186 (Activation)     (None, 20, 15, 128)  0           batch_normalization_186[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_207 (Conv2D)             (None, 10, 8, 128)   16512       activation_186[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_187 (BatchN (None, 10, 8, 128)   512         conv2d_207[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_187 (Activation)     (None, 10, 8, 128)   0           batch_normalization_187[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_208 (Conv2D)             (None, 10, 8, 128)   147584      activation_187[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_188 (BatchN (None, 10, 8, 128)   512         conv2d_208[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_188 (Activation)     (None, 10, 8, 128)   0           batch_normalization_188[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_210 (Conv2D)             (None, 10, 8, 256)   33024       add_59[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_209 (Conv2D)             (None, 10, 8, 256)   33024       activation_188[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_60 (Add)                    (None, 10, 8, 256)   0           conv2d_210[0][0]                 \n",
      "                                                                 conv2d_209[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_189 (BatchN (None, 10, 8, 256)   1024        add_60[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_189 (Activation)     (None, 10, 8, 256)   0           batch_normalization_189[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_211 (Conv2D)             (None, 10, 8, 128)   32896       activation_189[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_190 (BatchN (None, 10, 8, 128)   512         conv2d_211[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_190 (Activation)     (None, 10, 8, 128)   0           batch_normalization_190[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_212 (Conv2D)             (None, 10, 8, 128)   147584      activation_190[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_191 (BatchN (None, 10, 8, 128)   512         conv2d_212[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_191 (Activation)     (None, 10, 8, 128)   0           batch_normalization_191[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_213 (Conv2D)             (None, 10, 8, 256)   33024       activation_191[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_61 (Add)                    (None, 10, 8, 256)   0           add_60[0][0]                     \n",
      "                                                                 conv2d_213[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_192 (BatchN (None, 10, 8, 256)   1024        add_61[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_192 (Activation)     (None, 10, 8, 256)   0           batch_normalization_192[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_214 (Conv2D)             (None, 10, 8, 128)   32896       activation_192[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_193 (BatchN (None, 10, 8, 128)   512         conv2d_214[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_193 (Activation)     (None, 10, 8, 128)   0           batch_normalization_193[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_215 (Conv2D)             (None, 10, 8, 128)   147584      activation_193[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_194 (BatchN (None, 10, 8, 128)   512         conv2d_215[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_194 (Activation)     (None, 10, 8, 128)   0           batch_normalization_194[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_216 (Conv2D)             (None, 10, 8, 256)   33024       activation_194[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_62 (Add)                    (None, 10, 8, 256)   0           add_61[0][0]                     \n",
      "                                                                 conv2d_216[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_195 (BatchN (None, 10, 8, 256)   1024        add_62[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_195 (Activation)     (None, 10, 8, 256)   0           batch_normalization_195[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_6 (AveragePoo (None, 1, 1, 256)    0           activation_195[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "flatten_6 (Flatten)             (None, 256)          0           average_pooling2d_6[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 10)           2570        flatten_6[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 849,002\n",
      "Trainable params: 843,786\n",
      "Non-trainable params: 5,216\n",
      "__________________________________________________________________________________________________\n",
      "ResNet  29v  2\n",
      "Using real-time data augmentation.\n",
      "------------------\n",
      "[[[[-0.12730387 -0.12730387 -0.12730387]\n",
      "   [-0.07385611 -0.07385611 -0.07385611]\n",
      "   [-0.09406851 -0.09406851 -0.09406851]\n",
      "   ...\n",
      "   [-0.14150329 -0.14150329 -0.14150329]\n",
      "   [-0.15403596 -0.15403596 -0.15403596]\n",
      "   [-0.17491831 -0.17491831 -0.17491831]]\n",
      "\n",
      "  [[-0.05967315 -0.05967315 -0.05967315]\n",
      "   [-0.08416659 -0.08416659 -0.08416659]\n",
      "   [-0.10240185 -0.10240185 -0.10240185]\n",
      "   ...\n",
      "   [-0.13929734 -0.13929734 -0.13929734]\n",
      "   [-0.14316992 -0.14316992 -0.14316992]\n",
      "   [-0.15789212 -0.15789212 -0.15789212]]\n",
      "\n",
      "  [[-0.06593133 -0.06593133 -0.06593133]\n",
      "   [-0.09124173 -0.09124173 -0.09124173]\n",
      "   [-0.1033496  -0.1033496  -0.1033496 ]\n",
      "   ...\n",
      "   [-0.14789215 -0.14789215 -0.14789215]\n",
      "   [-0.15601309 -0.15601309 -0.15601309]\n",
      "   [-0.16060449 -0.16060449 -0.16060449]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[-0.00148693 -0.00148693 -0.00148693]\n",
      "   [-0.03535937 -0.03535937 -0.03535937]\n",
      "   [-0.04473845 -0.04473845 -0.04473845]\n",
      "   ...\n",
      "   [-0.0772712  -0.0772712  -0.0772712 ]\n",
      "   [-0.08828428 -0.08828428 -0.08828428]\n",
      "   [-0.10156866 -0.10156866 -0.10156866]]\n",
      "\n",
      "  [[ 0.38934642  0.38934642  0.38934642]\n",
      "   [-0.03428092 -0.03428092 -0.03428092]\n",
      "   [-0.03645412 -0.03645412 -0.03645412]\n",
      "   ...\n",
      "   [-0.0778104  -0.0778104  -0.0778104 ]\n",
      "   [-0.08349669 -0.08349669 -0.08349669]\n",
      "   [-0.10838238 -0.10838238 -0.10838238]]\n",
      "\n",
      "  [[ 0.28083342  0.28083342  0.28083342]\n",
      "   [ 0.3169936   0.3169936   0.3169936 ]\n",
      "   [-0.11624174 -0.11624174 -0.11624174]\n",
      "   ...\n",
      "   [-0.13383983 -0.13383983 -0.13383983]\n",
      "   [-0.155049   -0.155049   -0.155049  ]\n",
      "   [-0.18336588 -0.18336588 -0.18336588]]]\n",
      "\n",
      "\n",
      " [[[ 0.2766177   0.2766177   0.2766177 ]\n",
      "   [ 0.30261448  0.30261448  0.30261448]\n",
      "   [ 0.30985308  0.30985308  0.30985308]\n",
      "   ...\n",
      "   [-0.1650327  -0.1650327  -0.1650327 ]\n",
      "   [-0.16972223 -0.16972223 -0.16972223]\n",
      "   [-0.17883988 -0.17883988 -0.17883988]]\n",
      "\n",
      "  [[ 0.28934646  0.28934646  0.28934646]\n",
      "   [ 0.28446087  0.28446087  0.28446087]\n",
      "   [ 0.31328443  0.31328443  0.31328443]\n",
      "   ...\n",
      "   [-0.13929734 -0.13929734 -0.13929734]\n",
      "   [-0.13924836 -0.13924836 -0.13924836]\n",
      "   [-0.15397055 -0.15397055 -0.15397055]]\n",
      "\n",
      "  [[ 0.3026961   0.3026961   0.3026961 ]\n",
      "   [ 0.293072    0.293072    0.293072  ]\n",
      "   [ 0.29272884  0.29272884  0.29272884]\n",
      "   ...\n",
      "   [-0.14397058 -0.14397058 -0.14397058]\n",
      "   [-0.15209152 -0.15209152 -0.15209152]\n",
      "   [-0.15668292 -0.15668292 -0.15668292]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[-0.01717321 -0.01717321 -0.01717321]\n",
      "   [-0.03535937 -0.03535937 -0.03535937]\n",
      "   [-0.04473845 -0.04473845 -0.04473845]\n",
      "   ...\n",
      "   [-0.0772712  -0.0772712  -0.0772712 ]\n",
      "   [-0.08828428 -0.08828428 -0.08828428]\n",
      "   [-0.10156866 -0.10156866 -0.10156866]]\n",
      "\n",
      "  [[-0.01849674 -0.01849674 -0.01849674]\n",
      "   [-0.03035935 -0.03035935 -0.03035935]\n",
      "   [-0.04037569 -0.04037569 -0.04037569]\n",
      "   ...\n",
      "   [-0.0778104  -0.0778104  -0.0778104 ]\n",
      "   [-0.08349669 -0.08349669 -0.08349669]\n",
      "   [-0.10838238 -0.10838238 -0.10838238]]\n",
      "\n",
      "  [[ 0.28083342  0.28083342  0.28083342]\n",
      "   [-0.11045743 -0.11045743 -0.11045743]\n",
      "   [-0.09663389 -0.09663389 -0.09663389]\n",
      "   ...\n",
      "   [-0.1377614  -0.1377614  -0.1377614 ]\n",
      "   [-0.155049   -0.155049   -0.155049  ]\n",
      "   [-0.18336588 -0.18336588 -0.18336588]]]\n",
      "\n",
      "\n",
      " [[[-0.14299014 -0.14299014 -0.14299014]\n",
      "   [-0.12875807 -0.12875807 -0.12875807]\n",
      "   [-0.12936263 -0.12936263 -0.12936263]\n",
      "   ...\n",
      "   [-0.16895427 -0.16895427 -0.16895427]\n",
      "   [-0.1736438  -0.1736438  -0.1736438 ]\n",
      "   [-0.18276145 -0.18276145 -0.18276145]]\n",
      "\n",
      "  [[-0.06751629 -0.06751629 -0.06751629]\n",
      "   [-0.08024502 -0.08024502 -0.08024502]\n",
      "   [-0.09455872 -0.09455872 -0.09455872]\n",
      "   ...\n",
      "   [-0.12753263 -0.12753263 -0.12753263]\n",
      "   [-0.11571895 -0.11571895 -0.11571895]\n",
      "   [-0.1108333  -0.1108333  -0.1108333 ]]\n",
      "\n",
      "  [[-0.0816176  -0.0816176  -0.0816176 ]\n",
      "   [-0.08732016 -0.08732016 -0.08732016]\n",
      "   [-0.09550646 -0.09550646 -0.09550646]\n",
      "   ...\n",
      "   [-0.13220587 -0.13220587 -0.13220587]\n",
      "   [-0.13248368 -0.13248368 -0.13248368]\n",
      "   [-0.11746724 -0.11746724 -0.11746724]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[-0.0054085  -0.0054085  -0.0054085 ]\n",
      "   [-0.02751623 -0.02751623 -0.02751623]\n",
      "   [-0.04473845 -0.04473845 -0.04473845]\n",
      "   ...\n",
      "   [-0.0772712  -0.0772712  -0.0772712 ]\n",
      "   [-0.08828428 -0.08828428 -0.08828428]\n",
      "   [-0.09764709 -0.09764709 -0.09764709]]\n",
      "\n",
      "  [[-0.02633988 -0.02633988 -0.02633988]\n",
      "   [-0.04604563 -0.04604563 -0.04604563]\n",
      "   [-0.04429726 -0.04429726 -0.04429726]\n",
      "   ...\n",
      "   [-0.0778104  -0.0778104  -0.0778104 ]\n",
      "   [-0.08349669 -0.08349669 -0.08349669]\n",
      "   [-0.10446081 -0.10446081 -0.10446081]]\n",
      "\n",
      "  [[ 0.28083342  0.28083342  0.28083342]\n",
      "   [-0.04771233 -0.04771233 -0.04771233]\n",
      "   [-0.08094762 -0.08094762 -0.08094762]\n",
      "   ...\n",
      "   [-0.16129081 -0.16129081 -0.16129081]\n",
      "   [-0.1785784  -0.1785784  -0.1785784 ]\n",
      "   [-0.20689529 -0.20689529 -0.20689529]]]\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      " [[[-0.08024504 -0.08024504 -0.08024504]\n",
      "   [ 0.34575176  0.34575176  0.34575176]\n",
      "   [-0.1450489  -0.1450489  -0.1450489 ]\n",
      "   ...\n",
      "   [ 0.33300656  0.33300656  0.33300656]\n",
      "   [ 0.32831702  0.32831702  0.32831702]\n",
      "   [ 0.31919938  0.31919938  0.31919938]]\n",
      "\n",
      "  [[-0.07143786 -0.07143786 -0.07143786]\n",
      "   [-0.09985286 -0.09985286 -0.09985286]\n",
      "   [-0.11024499 -0.11024499 -0.11024499]\n",
      "   ...\n",
      "   [ 0.26070267  0.26070267  0.26070267]\n",
      "   [ 0.3078105   0.3078105   0.3078105 ]\n",
      "   [ 0.3244608   0.3244608   0.3244608 ]]\n",
      "\n",
      "  [[-0.07769603 -0.07769603 -0.07769603]\n",
      "   [-0.09908487 -0.09908487 -0.09908487]\n",
      "   [-0.10727116 -0.10727116 -0.10727116]\n",
      "   ...\n",
      "   [ 0.259951    0.259951    0.259951  ]\n",
      "   [ 0.27535945  0.27535945  0.27535945]\n",
      "   [ 0.28253275  0.28253275  0.28253275]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[-0.07599674 -0.07599674 -0.07599674]\n",
      "   [-0.07457506 -0.07457506 -0.07457506]\n",
      "   [-0.06042473 -0.06042473 -0.06042473]\n",
      "   ...\n",
      "   [ 0.18155235  0.18155235  0.18155235]\n",
      "   [-0.01769605 -0.01769605 -0.01769605]\n",
      "   [ 0.0160784   0.0160784   0.0160784 ]]\n",
      "\n",
      "  [[-0.06947714 -0.06947714 -0.06947714]\n",
      "   [-0.07349661 -0.07349661 -0.07349661]\n",
      "   [-0.05998354 -0.05998354 -0.05998354]\n",
      "   ...\n",
      "   [-0.05428099 -0.05428099 -0.05428099]\n",
      "   [-0.03643787 -0.03643787 -0.03643787]\n",
      "   [ 0.00534311  0.00534311  0.00534311]]\n",
      "\n",
      "  [[-0.17799012 -0.17799012 -0.17799012]\n",
      "   [-0.15751626 -0.15751626 -0.15751626]\n",
      "   [-0.15153585 -0.15153585 -0.15153585]\n",
      "   ...\n",
      "   [-0.1377614  -0.1377614  -0.1377614 ]\n",
      "   [-0.12367645 -0.12367645 -0.12367645]\n",
      "   [-0.11277764 -0.11277764 -0.11277764]]]\n",
      "\n",
      "\n",
      " [[[-0.03710779 -0.03710779 -0.03710779]\n",
      "   [-0.06601297 -0.06601297 -0.06601297]\n",
      "   [-0.07446066 -0.07446066 -0.07446066]\n",
      "   ...\n",
      "   [-0.16895427 -0.16895427 -0.16895427]\n",
      "   [-0.1736438  -0.1736438  -0.1736438 ]\n",
      "   [-0.17883988 -0.17883988 -0.17883988]]\n",
      "\n",
      "  [[-0.04790845 -0.04790845 -0.04790845]\n",
      "   [-0.0449509  -0.0449509  -0.0449509 ]\n",
      "   [-0.06710773 -0.06710773 -0.06710773]\n",
      "   ...\n",
      "   [-0.1432189  -0.1432189  -0.1432189 ]\n",
      "   [-0.14316992 -0.14316992 -0.14316992]\n",
      "   [-0.15397055 -0.15397055 -0.15397055]]\n",
      "\n",
      "  [[-0.06593133 -0.06593133 -0.06593133]\n",
      "   [-0.04026134 -0.04026134 -0.04026134]\n",
      "   [-0.06805547 -0.06805547 -0.06805547]\n",
      "   ...\n",
      "   [-0.14789215 -0.14789215 -0.14789215]\n",
      "   [-0.15601309 -0.15601309 -0.15601309]\n",
      "   [-0.16060449 -0.16060449 -0.16060449]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[ 0.01419935  0.01419935  0.01419935]\n",
      "   [-0.00790839 -0.00790839 -0.00790839]\n",
      "   [-0.0133659  -0.0133659  -0.0133659 ]\n",
      "   ...\n",
      "   [-0.0772712  -0.0772712  -0.0772712 ]\n",
      "   [-0.08828428 -0.08828428 -0.08828428]\n",
      "   [-0.10156866 -0.10156866 -0.10156866]]\n",
      "\n",
      "  [[ 0.01679738  0.01679738  0.01679738]\n",
      "   [-0.01075151 -0.01075151 -0.01075151]\n",
      "   [-0.01684628 -0.01684628 -0.01684628]\n",
      "   ...\n",
      "   [-0.0778104  -0.0778104  -0.0778104 ]\n",
      "   [-0.08349669 -0.08349669 -0.08349669]\n",
      "   [-0.10838238 -0.10838238 -0.10838238]]\n",
      "\n",
      "  [[-0.11524502 -0.11524502 -0.11524502]\n",
      "   [-0.09084959 -0.09084959 -0.09084959]\n",
      "   [-0.10055546 -0.10055546 -0.10055546]\n",
      "   ...\n",
      "   [-0.16129081 -0.16129081 -0.16129081]\n",
      "   [-0.1785784  -0.1785784  -0.1785784 ]\n",
      "   [-0.20689529 -0.20689529 -0.20689529]]]\n",
      "\n",
      "\n",
      " [[[ 0.29230398  0.29230398  0.29230398]\n",
      "   [ 0.31045762  0.31045762  0.31045762]\n",
      "   [ 0.2941668   0.2941668   0.2941668 ]\n",
      "   ...\n",
      "   [-0.16895427 -0.16895427 -0.16895427]\n",
      "   [-0.1736438  -0.1736438  -0.1736438 ]\n",
      "   [-0.18276145 -0.18276145 -0.18276145]]\n",
      "\n",
      "  [[ 0.320719    0.320719    0.320719  ]\n",
      "   [ 0.34720597  0.34720597  0.34720597]\n",
      "   [ 0.28583345  0.28583345  0.28583345]\n",
      "   ...\n",
      "   [-0.1432189  -0.1432189  -0.1432189 ]\n",
      "   [-0.14316992 -0.14316992 -0.14316992]\n",
      "   [-0.15789212 -0.15789212 -0.15789212]]\n",
      "\n",
      "  [[ 0.2791667   0.2791667   0.2791667 ]\n",
      "   [ 0.28130728  0.28130728  0.28130728]\n",
      "   [ 0.27704257  0.27704257  0.27704257]\n",
      "   ...\n",
      "   [-0.14789215 -0.14789215 -0.14789215]\n",
      "   [-0.15601309 -0.15601309 -0.15601309]\n",
      "   [-0.16060449 -0.16060449 -0.16060449]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[ 0.01419935  0.01419935  0.01419935]\n",
      "   [-0.02751623 -0.02751623 -0.02751623]\n",
      "   [-0.03689532 -0.03689532 -0.03689532]\n",
      "   ...\n",
      "   [-0.0772712  -0.0772712  -0.0772712 ]\n",
      "   [-0.08828428 -0.08828428 -0.08828428]\n",
      "   [-0.10156866 -0.10156866 -0.10156866]]\n",
      "\n",
      "  [[ 0.01679738  0.01679738  0.01679738]\n",
      "   [-0.02643778 -0.02643778 -0.02643778]\n",
      "   [-0.03253255 -0.03253255 -0.03253255]\n",
      "   ...\n",
      "   [-0.0778104  -0.0778104  -0.0778104 ]\n",
      "   [-0.08349669 -0.08349669 -0.08349669]\n",
      "   [-0.10838238 -0.10838238 -0.10838238]]\n",
      "\n",
      "  [[-0.0917156  -0.0917156  -0.0917156 ]\n",
      "   [-0.11045743 -0.11045743 -0.11045743]\n",
      "   [-0.11624174 -0.11624174 -0.11624174]\n",
      "   ...\n",
      "   [-0.16129081 -0.16129081 -0.16129081]\n",
      "   [-0.1785784  -0.1785784  -0.1785784 ]\n",
      "   [-0.20689529 -0.20689529 -0.20689529]]]]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-32-625644a2075e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mfmeasures\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m     \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m     \u001b[0maccs\u001b[0m\u001b[1;33m+=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mret\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0mprecisions\u001b[0m\u001b[1;33m+=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mret\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-31-2f5a16bed174>\u001b[0m in \u001b[0;36mmain\u001b[1;34m(pz)\u001b[0m\n\u001b[0;32m    195\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    196\u001b[0m         \u001b[1;31m# Fit the model on the batches generated by datagen.flow().\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 197\u001b[1;33m         model.fit_generator(datagen.flow(x_train, y_train, batch_size = batch_size),\n\u001b[0m\u001b[0;32m    198\u001b[0m                             \u001b[0mvalidation_data\u001b[0m \u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_valid\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_valid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    199\u001b[0m                             \u001b[0mepochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mworkers\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\patcas rares\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m   1973\u001b[0m                   \u001b[1;34m'will be removed in a future version. '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1974\u001b[0m                   'Please use `Model.fit`, which supports generators.')\n\u001b[1;32m-> 1975\u001b[1;33m     return self.fit(\n\u001b[0m\u001b[0;32m   1976\u001b[0m         \u001b[0mgenerator\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1977\u001b[0m         \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\patcas rares\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1170\u001b[0m           self._maybe_load_initial_epoch_from_ckpt(initial_epoch))\n\u001b[0;32m   1171\u001b[0m       \u001b[0mlogs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1172\u001b[1;33m       \u001b[1;32mfor\u001b[0m \u001b[0mepoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miterator\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menumerate_epochs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1173\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreset_metrics\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1174\u001b[0m         \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_epoch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\patcas rares\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\keras\\engine\\data_adapter.py\u001b[0m in \u001b[0;36menumerate_epochs\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1178\u001b[0m     \u001b[1;34m\"\"\"Yields `(epoch, tf.data.Iterator)`.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1179\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_truncate_execution_to_epoch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1180\u001b[1;33m       \u001b[0mdata_iterator\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0miter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1181\u001b[0m       \u001b[1;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_initial_epoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_epochs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1182\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_insufficient_data\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# Set by `catch_stop_iteration`.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\patcas rares\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py\u001b[0m in \u001b[0;36m__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    409\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minside_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    410\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolocate_with\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_variant_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 411\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0miterator_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOwnedIterator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    412\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    413\u001b[0m       raise RuntimeError(\"__iter__() is only supported inside of tf.function \"\n",
      "\u001b[1;32mc:\\users\\patcas rares\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\tensorflow\\python\\data\\ops\\iterator_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, dataset, components, element_spec)\u001b[0m\n\u001b[0;32m    694\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mcomponents\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0melement_spec\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    695\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merror_message\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 696\u001b[1;33m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_create_iterator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    697\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    698\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_create_iterator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\patcas rares\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\tensorflow\\python\\data\\ops\\iterator_ops.py\u001b[0m in \u001b[0;36m_create_iterator\u001b[1;34m(self, dataset)\u001b[0m\n\u001b[0;32m    717\u001b[0m               \u001b[0moutput_types\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_flat_output_types\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    718\u001b[0m               output_shapes=self._flat_output_shapes))\n\u001b[1;32m--> 719\u001b[1;33m       \u001b[0mgen_dataset_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmake_iterator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mds_variant\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterator_resource\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    720\u001b[0m       \u001b[1;31m# Delete the resource when this object is deleted\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    721\u001b[0m       self._resource_deleter = IteratorResourceDeleter(\n",
      "\u001b[1;32mc:\\users\\patcas rares\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\tensorflow\\python\\ops\\gen_dataset_ops.py\u001b[0m in \u001b[0;36mmake_iterator\u001b[1;34m(dataset, iterator, name)\u001b[0m\n\u001b[0;32m   3117\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mtld\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_eager\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3118\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3119\u001b[1;33m       _result = pywrap_tfe.TFE_Py_FastPathExecute(\n\u001b[0m\u001b[0;32m   3120\u001b[0m         _ctx, \"MakeIterator\", name, dataset, iterator)\n\u001b[0;32m   3121\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "accs=[]\n",
    "precisions = []\n",
    "recalls = []\n",
    "fmeasures = []\n",
    "for i in range(10):\n",
    "    ret = main(i)\n",
    "    accs+=[ret[0]]\n",
    "    precisions+=[ret[1]]\n",
    "    recalls+=[ret[2]]\n",
    "    fmeasures+=[ret[3]]\n",
    "print(accs)\n",
    "print(precisions)\n",
    "print(recalls)\n",
    "print(fmeasures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ddb57c4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "accs:  [0.8333333134651184, 0.8333333134651184, 0.9333333373069763, 0.8999999761581421, 0.8666666746139526, 0.8999999761581421, 0.7333333492279053, 0.8999999761581421, 0.7333333492279053, 0.9666666388511658]\n",
      "precisions:  [0.9692307692307692, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9692307692307692, 1.0]\n",
      "recalls:  [0.8333333333333334, 0.8333333333333334, 0.9333333333333333, 0.9, 0.8666666666666667, 0.9, 0.7333333333333333, 0.9, 0.7333333333333333, 0.9666666666666667]\n",
      "fmeasures:  [0.8872258064516129, 0.9032258064516128, 0.9650000000000001, 0.9465116279069767, 0.9263157894736842, 0.9444444444444445, 0.8412698412698413, 0.9457142857142856, 0.8125714285714286, 0.9828282828282828]\n"
     ]
    }
   ],
   "source": [
    "print(len(accs))\n",
    "print('accs: ', accs)\n",
    "print('precisions: ', precisions)\n",
    "print('recalls: ', recalls)\n",
    "print('fmeasures: ', fmeasures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68080bd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.stats as st\n",
    "\n",
    "#define sample data\n",
    "data = accs\n",
    "\n",
    "#create 95% confidence interval for population mean weight\n",
    "st.t.interval(alpha=0.95, df=len(data)-1, loc=np.mean(data), scale=st.sem(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b031931d",
   "metadata": {},
   "outputs": [],
   "source": [
    "accs=[0.5833333134651184, 0.6499999761581421, 0.6299999761581421, 0.6499999761581421, 0.6699999761581421, 0.6499999761581421, 0.6699999761581421, 0.6899999761581421, 0.6699999761581421, 0.6899999761581421, 0.7099999761581421, 0.6899999761581421, 0.7099999761581421, 0.68999999999999, 0.6699999999999899, 0.68999999999999, 0.70999999999999, 0.68999999999999, 0.70999999999999, 0.68999999999999]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4da3f353",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.5833333134651184,\n",
       " 0.6499999761581421,\n",
       " 0.6299999761581421,\n",
       " 0.6499999761581421,\n",
       " 0.6699999761581421,\n",
       " 0.6499999761581421,\n",
       " 0.6699999761581421,\n",
       " 0.6899999761581421,\n",
       " 0.6699999761581421,\n",
       " 0.6899999761581421,\n",
       " 0.7099999761581421,\n",
       " 0.6899999761581421,\n",
       " 0.7099999761581421,\n",
       " 0.68999999999999,\n",
       " 0.6699999999999899,\n",
       " 0.68999999999999,\n",
       " 0.70999999999999,\n",
       " 0.68999999999999,\n",
       " 0.70999999999999,\n",
       " 0.68999999999999]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0945f0bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "accs = [0.7958, 0.8125, 0.80500, 0.82, 0.83454, 0.7858, 0.8105, 0.804500, 0.82, 0.83454]\n",
    "import matplotlib.pyplot as plt\n",
    "data = accs\n",
    "data = sorted(data)\n",
    "plt.plot(list(range(len(accs))), data, 'k')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ae4b428e",
   "metadata": {},
   "outputs": [],
   "source": [
    "accs=[1.1599838733673096, ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0596d6fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision:  0.963963963963964\n",
      "Recall:  0.9907407407407407\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\patcas rares\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Importing the required libraries\n",
    "from sklearn import datasets\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import plot_precision_recall_curve\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "import matplotlib.pyplot as plt\n",
    " \n",
    "#Loading the data\n",
    "data = datasets.load_breast_cancer()\n",
    "df = pd.DataFrame(data.data, columns=data.feature_names)\n",
    "df['target'] = data.target\n",
    " \n",
    "#Splitting the data into training and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "                                    df.iloc[:,:-1], df.iloc[:,-1], test_size=0.3, random_state=42)\n",
    " \n",
    "# Initialize and fit the Model\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    " \n",
    "#Make prediction on the test set\n",
    "pred = model.predict(X_test)\n",
    " \n",
    "#calculating precision and reall\n",
    "precision = precision_score(y_test, pred)\n",
    "recall = recall_score(y_test, pred)\n",
    " \n",
    "print('Precision: ',precision)\n",
    "print('Recall: ',recall)\n",
    " \n",
    "#Plotting Precision-Recall Curve\n",
    "disp = plot_precision_recall_curve(model, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6c20cc34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "204    1\n",
      "70     0\n",
      "131    0\n",
      "431    1\n",
      "540    1\n",
      "      ..\n",
      "69     1\n",
      "542    1\n",
      "176    1\n",
      "501    0\n",
      "247    1\n",
      "Name: target, Length: 171, dtype: int32\n"
     ]
    }
   ],
   "source": [
    "print(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "7990f995",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 0 1 1 0 0 0 1 1 1 0 1 0 1 0 1 1 1 0 1 1 0 1 1 1 1 1 1 0 1 1 1 1 1 1 0\n",
      " 1 0 1 1 0 1 1 1 1 1 1 1 1 0 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0 1 1 0 0 1 0\n",
      " 1 1 1 1 1 1 0 1 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 1 0 0 1 0 0 1 1 1 0 1 1 0\n",
      " 1 0 0 1 0 1 1 1 0 1 1 1 0 1 0 0 1 1 0 0 0 1 1 1 0 1 1 1 0 1 0 1 1 0 1 0 0\n",
      " 1 1 0 1 1 1 1 0 0 1 1 1 1 1 1 1 0 1 1 1 1 0 1]\n"
     ]
    }
   ],
   "source": [
    "print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b54dfad7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a014aa1f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ded849f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1f3e6533",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pt ResNet \n",
    "accs = [0.8333333134651184, 0.8333333134651184, 0.9333333373069763, 0.8999999761581421, 0.8666666746139526, 0.8999999761581421, 0.7333333492279053, 0.8999999761581421, 0.7333333492279053, 0.9666666388511658]\n",
    "precisions = [0.9692307692307692, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9692307692307692, 1.0]\n",
    "recalls = [0.8333333333333334, 0.8333333333333334, 0.9333333333333333, 0.9, 0.8666666666666667, 0.9, 0.7333333333333333, 0.9, 0.7333333333333333, 0.9666666666666667]\n",
    "fmeasures = [0.8872258064516129, 0.9032258064516128, 0.9650000000000001, 0.9465116279069767, 0.9263157894736842, 0.9444444444444445, 0.8412698412698413, 0.9457142857142856, 0.8125714285714286, 0.9828282828282828]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9b3708b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8040215188965151, 0.9159784620299986)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import scipy.stats as st\n",
    "\n",
    "#define sample data\n",
    "data = accs\n",
    "\n",
    "#create 95% confidence interval for population mean weight\n",
    "st.t.interval(alpha=0.95, df=len(data)-1, loc=np.mean(data), scale=st.sem(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bfb53176",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9845655090759343, 1.0031267986163732)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = precisions\n",
    "\n",
    "#create 95% confidence interval for population mean weight\n",
    "st.t.interval(alpha=0.95, df=len(data)-1, loc=np.mean(data), scale=st.sem(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5045da1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8040215198496445, 0.9159784801503554)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = recalls\n",
    "\n",
    "#create 95% confidence interval for population mean weight\n",
    "st.t.interval(alpha=0.95, df=len(data)-1, loc=np.mean(data), scale=st.sem(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5e65710a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8764254778012908, 0.9545959848211432)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = fmeasures\n",
    "\n",
    "#create 95% confidence interval for population mean weight\n",
    "st.t.interval(alpha=0.95, df=len(data)-1, loc=np.mean(data), scale=st.sem(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f6445bb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "b5a77665",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow version: 2.6.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.layers import Dense, Input, Dropout,Flatten, Conv2D, SeparableConv2D, GlobalAveragePooling2D\n",
    "from tensorflow.keras.layers import BatchNormalization, Activation, MaxPooling2D, ZeroPadding2D, Convolution2D, MaxPool2D\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from IPython.display import SVG, Image\n",
    "from livelossplot.inputs.tf_keras import PlotLossesCallback\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "# calculates f1 for 1:100 dataset with 95tp, 5fn, 55fp\n",
    "from sklearn.metrics import f1_score\n",
    "print(\"Tensorflow version:\", tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "91ef5d97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 0 images belonging to 3 classes.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.preprocessing.image.DirectoryIterator at 0x156120910d0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_size = 48\n",
    "batch_size = 64\n",
    "datagen_train = ImageDataGenerator(horizontal_flip=True)\n",
    "train_generator = datagen_train.flow_from_directory(\"../../content\",\n",
    "                                                    target_size=(img_size,img_size),\n",
    "                                                    color_mode=\"grayscale\",\n",
    "                                                    batch_size=batch_size,\n",
    "                                                    class_mode='categorical',\n",
    "                                                    shuffle=True)\n",
    "train_generator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "75d282be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_26\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_211 (Conv2D)          (None, 40, 30, 64)        1792      \n",
      "_________________________________________________________________\n",
      "batch_normalization_39 (Batc (None, 40, 30, 64)        256       \n",
      "_________________________________________________________________\n",
      "activation_22 (Activation)   (None, 40, 30, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_79 (MaxPooling (None, 20, 15, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_16 (Dropout)         (None, 20, 15, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_212 (Conv2D)          (None, 20, 15, 128)       204928    \n",
      "_________________________________________________________________\n",
      "batch_normalization_40 (Batc (None, 20, 15, 128)       512       \n",
      "_________________________________________________________________\n",
      "activation_23 (Activation)   (None, 20, 15, 128)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_80 (MaxPooling (None, 10, 7, 128)        0         \n",
      "_________________________________________________________________\n",
      "dropout_17 (Dropout)         (None, 10, 7, 128)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_213 (Conv2D)          (None, 10, 7, 512)        590336    \n",
      "_________________________________________________________________\n",
      "batch_normalization_41 (Batc (None, 10, 7, 512)        2048      \n",
      "_________________________________________________________________\n",
      "activation_24 (Activation)   (None, 10, 7, 512)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_81 (MaxPooling (None, 5, 3, 512)         0         \n",
      "_________________________________________________________________\n",
      "dropout_18 (Dropout)         (None, 5, 3, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_214 (Conv2D)          (None, 5, 3, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "batch_normalization_42 (Batc (None, 5, 3, 512)         2048      \n",
      "_________________________________________________________________\n",
      "activation_25 (Activation)   (None, 5, 3, 512)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_82 (MaxPooling (None, 2, 1, 512)         0         \n",
      "_________________________________________________________________\n",
      "dropout_19 (Dropout)         (None, 2, 1, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten_10 (Flatten)         (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_32 (Dense)             (None, 256)               262400    \n",
      "_________________________________________________________________\n",
      "batch_normalization_43 (Batc (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "activation_26 (Activation)   (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_20 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_33 (Dense)             (None, 512)               131584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_44 (Batc (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "activation_27 (Activation)   (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_21 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_34 (Dense)             (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 3,559,297\n",
      "Trainable params: 3,555,329\n",
      "Non-trainable params: 3,968\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# custom metrics\n",
    "def precision(y_true, y_pred): #taken from old keras source code\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision\n",
    "def recall(y_true, y_pred): #taken from old keras source code\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return recall\n",
    "\n",
    "\n",
    "\n",
    "# Initialising the CNN\n",
    "# Initialising the CNN\n",
    "model = Sequential()\n",
    "# 1 - Convolution\n",
    "model.add(Conv2D(64,(3,3), padding='same', input_shape=(40, 30,3)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "# 2nd Convolution layer\n",
    "model.add(Conv2D(128,(5,5), padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "# 3rd Convolution layer\n",
    "model.add(Conv2D(512,(3,3), padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "# 4th Convolution layer\n",
    "model.add(Conv2D(512,(3,3), padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "# Flattening\n",
    "model.add(Flatten())\n",
    "# Fully connected layer 1st layer\n",
    "model.add(Dense(256))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.25))\n",
    "# Fully connected layer 2nd layer\n",
    "model.add(Dense(512))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(1, activation='softmax'))\n",
    "lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "        initial_learning_rate=1e-2,\n",
    "        decay_steps=10000,\n",
    "        decay_rate=0.9)\n",
    "opt = Adam(learning_rate = lr_schedule)\n",
    "model.compile(loss='mean_squared_error',  optimizer=opt, metrics=['accuracy', precision, recall])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "b4ed8271",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from numpy import asarray\n",
    "import numpy as np\n",
    "import os\n",
    "import keras\n",
    "from keras.layers import Dense, Conv2D, BatchNormalization, Activation\n",
    "from keras.layers import AveragePooling2D, Input, Flatten\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.regularizers import l2\n",
    "from keras import backend as K\n",
    "from keras.models import Model\n",
    "from keras.datasets import cifar10\n",
    "import numpy as np\n",
    "import os\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "5b40f8b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 74  74  74]\n",
      "  [ 83  83  83]\n",
      "  [ 86  86  86]\n",
      "  ...\n",
      "  [108 108 108]\n",
      "  [107 107 107]\n",
      "  [102 102 102]]\n",
      "\n",
      " [[  8   8   8]\n",
      "  [  8   8   8]\n",
      "  [  7   7   7]\n",
      "  ...\n",
      "  [  9   9   9]\n",
      "  [ 14  14  14]\n",
      "  [ 25  25  25]]\n",
      "\n",
      " [[  8   8   8]\n",
      "  [  7   7   7]\n",
      "  [  7   7   7]\n",
      "  ...\n",
      "  [  9   9   9]\n",
      "  [ 15  15  15]\n",
      "  [ 27  27  27]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[  8   8   8]\n",
      "  [  7   7   7]\n",
      "  [  7   7   7]\n",
      "  ...\n",
      "  [128 128 128]\n",
      "  [ 87  87  87]\n",
      "  [ 84  84  84]]\n",
      "\n",
      " [[  8   8   8]\n",
      "  [  8   8   8]\n",
      "  [  7   7   7]\n",
      "  ...\n",
      "  [ 66  66  66]\n",
      "  [ 73  73  73]\n",
      "  [ 77  77  77]]\n",
      "\n",
      " [[ 87  87  87]\n",
      "  [ 70  70  70]\n",
      "  [ 61  61  61]\n",
      "  ...\n",
      "  [ 85  85  85]\n",
      "  [ 79  79  79]\n",
      "  [ 73  73  73]]]\n"
     ]
    }
   ],
   "source": [
    "def readImage(filePath):\n",
    "    img = Image.open(filePath)\n",
    "    \n",
    "    size=(30, 40)\n",
    "    #resize image\n",
    "    out = img.resize(size)\n",
    "\n",
    "    # asarray() class is used to convert\n",
    "    # PIL images into NumPy arrays\n",
    "    numpydata = asarray(out)\n",
    "    numpydata = np.repeat(numpydata[:, :, np.newaxis], 3, axis=2)\n",
    "    # <class 'numpy.ndarray'>\n",
    "    #print(type(numpydata))\n",
    "\n",
    "    #  shape\n",
    "    #print(numpydata.shape)\n",
    "    return numpydata\n",
    "print(readImage('../../content/Benign/B_3141_1.RIGHT_CC.LJPEG.1_highpass.gif'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "49a3136a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['B_3091_1.LEFT_CC.LJPEG.1_highpass.gif', 'B_3091_1.LEFT_MLO.LJPEG.1_highpass.gif', 'B_3093_1.LEFT_CC.LJPEG.1_highpass.gif', 'B_3093_1.LEFT_MLO.LJPEG.1_highpass.gif', 'B_3094_1.LEFT_CC.LJPEG.1_highpass.gif']\n"
     ]
    }
   ],
   "source": [
    "listFiles = os.listdir('../../content/Benign/')\n",
    "print(listFiles[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "b6be2345",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[[  5,   5,   5],\n",
      "        [ 21,  21,  21],\n",
      "        [ 13,  13,  13],\n",
      "        ...,\n",
      "        [  7,   7,   7],\n",
      "        [  5,   5,   5],\n",
      "        [  2,   2,   2]],\n",
      "\n",
      "       [[ 23,  23,  23],\n",
      "        [ 14,  14,  14],\n",
      "        [  9,   9,   9],\n",
      "        ...,\n",
      "        [  1,   1,   1],\n",
      "        [  0,   0,   0],\n",
      "        [  0,   0,   0]],\n",
      "\n",
      "       [[ 23,  23,  23],\n",
      "        [ 14,  14,  14],\n",
      "        [  9,   9,   9],\n",
      "        ...,\n",
      "        [  0,   0,   0],\n",
      "        [  0,   0,   0],\n",
      "        [  0,   0,   0]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[ 29,  29,  29],\n",
      "        [ 17,  17,  17],\n",
      "        [ 10,  10,  10],\n",
      "        ...,\n",
      "        [  0,   0,   0],\n",
      "        [  0,   0,   0],\n",
      "        [  0,   0,   0]],\n",
      "\n",
      "       [[128, 128, 128],\n",
      "        [ 17,  17,  17],\n",
      "        [ 12,  12,  12],\n",
      "        ...,\n",
      "        [  0,   0,   0],\n",
      "        [  0,   0,   0],\n",
      "        [  0,   0,   0]],\n",
      "\n",
      "       [[128, 128, 128],\n",
      "        [128, 128, 128],\n",
      "        [ 14,  14,  14],\n",
      "        ...,\n",
      "        [  7,   7,   7],\n",
      "        [  6,   6,   6],\n",
      "        [  6,   6,   6]]], dtype=uint8), array([[[108, 108, 108],\n",
      "        [117, 117, 117],\n",
      "        [116, 116, 116],\n",
      "        ...,\n",
      "        [  1,   1,   1],\n",
      "        [  1,   1,   1],\n",
      "        [  1,   1,   1]],\n",
      "\n",
      "       [[112, 112, 112],\n",
      "        [108, 108, 108],\n",
      "        [115, 115, 115],\n",
      "        ...,\n",
      "        [  1,   1,   1],\n",
      "        [  1,   1,   1],\n",
      "        [  1,   1,   1]],\n",
      "\n",
      "       [[117, 117, 117],\n",
      "        [112, 112, 112],\n",
      "        [110, 110, 110],\n",
      "        ...,\n",
      "        [  1,   1,   1],\n",
      "        [  1,   1,   1],\n",
      "        [  1,   1,   1]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[ 25,  25,  25],\n",
      "        [ 17,  17,  17],\n",
      "        [ 10,  10,  10],\n",
      "        ...,\n",
      "        [  0,   0,   0],\n",
      "        [  0,   0,   0],\n",
      "        [  0,   0,   0]],\n",
      "\n",
      "       [[ 24,  24,  24],\n",
      "        [ 18,  18,  18],\n",
      "        [ 11,  11,  11],\n",
      "        ...,\n",
      "        [  0,   0,   0],\n",
      "        [  0,   0,   0],\n",
      "        [  0,   0,   0]],\n",
      "\n",
      "       [[128, 128, 128],\n",
      "        [ 19,  19,  19],\n",
      "        [ 19,  19,  19],\n",
      "        ...,\n",
      "        [  6,   6,   6],\n",
      "        [  6,   6,   6],\n",
      "        [  6,   6,   6]]], dtype=uint8), array([[[  1,   1,   1],\n",
      "        [  7,   7,   7],\n",
      "        [  4,   4,   4],\n",
      "        ...,\n",
      "        [  0,   0,   0],\n",
      "        [  0,   0,   0],\n",
      "        [  0,   0,   0]],\n",
      "\n",
      "       [[ 21,  21,  21],\n",
      "        [ 15,  15,  15],\n",
      "        [ 11,  11,  11],\n",
      "        ...,\n",
      "        [  4,   4,   4],\n",
      "        [  7,   7,   7],\n",
      "        [ 12,  12,  12]],\n",
      "\n",
      "       [[ 19,  19,  19],\n",
      "        [ 15,  15,  15],\n",
      "        [ 11,  11,  11],\n",
      "        ...,\n",
      "        [  4,   4,   4],\n",
      "        [  6,   6,   6],\n",
      "        [ 11,  11,  11]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[ 28,  28,  28],\n",
      "        [ 19,  19,  19],\n",
      "        [ 10,  10,  10],\n",
      "        ...,\n",
      "        [  0,   0,   0],\n",
      "        [  0,   0,   0],\n",
      "        [  1,   1,   1]],\n",
      "\n",
      "       [[ 22,  22,  22],\n",
      "        [ 14,  14,  14],\n",
      "        [ 10,  10,  10],\n",
      "        ...,\n",
      "        [  0,   0,   0],\n",
      "        [  0,   0,   0],\n",
      "        [  1,   1,   1]],\n",
      "\n",
      "       [[128, 128, 128],\n",
      "        [ 35,  35,  35],\n",
      "        [ 23,  23,  23],\n",
      "        ...,\n",
      "        [  0,   0,   0],\n",
      "        [  0,   0,   0],\n",
      "        [  0,   0,   0]]], dtype=uint8)]\n",
      "(40, 30, 3)\n"
     ]
    }
   ],
   "source": [
    "#load Benign\n",
    "listCancer = []\n",
    "listResults = []\n",
    "for elem in listFiles:\n",
    "    img = readImage('../../content/Benign/'+elem)\n",
    "    listCancer += [img]\n",
    "    listResults += [1]\n",
    "print(listCancer[:3])\n",
    "print(img.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "7148f50e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['A_0002_1.LEFT_CC.LJPEG.1_highpass.gif', 'A_0002_1.LEFT_MLO.LJPEG.1_highpass.gif', 'A_0002_1.RIGHT_CC.LJPEG.1_highpass.gif', 'A_0002_1.RIGHT_MLO.LJPEG.1_highpass.gif', 'A_0003_1.LEFT_CC.LJPEG.1_highpass.gif']\n",
      "3600\n",
      "3600\n",
      "3600\n",
      "3600\n",
      "3600\n",
      "3600\n",
      "3600\n",
      "3600\n",
      "3600\n",
      "3600\n",
      "3600\n",
      "3600\n",
      "3600\n",
      "3600\n",
      "3600\n",
      "3600\n",
      "3600\n",
      "3600\n",
      "3600\n",
      "3600\n",
      "3600\n",
      "3600\n",
      "3600\n",
      "3600\n",
      "3600\n",
      "3600\n",
      "3600\n",
      "3600\n",
      "3600\n",
      "3600\n",
      "3600\n",
      "3600\n",
      "3600\n",
      "3600\n",
      "3600\n",
      "3600\n",
      "3600\n",
      "3600\n",
      "3600\n",
      "3600\n",
      "3600\n",
      "3600\n",
      "3600\n",
      "3600\n",
      "3600\n",
      "3600\n",
      "3600\n",
      "3600\n",
      "3600\n",
      "3600\n",
      "3600\n",
      "3600\n",
      "3600\n",
      "3600\n",
      "3600\n",
      "3600\n",
      "3600\n",
      "3600\n",
      "3600\n",
      "3600\n",
      "3600\n",
      "3600\n",
      "3600\n",
      "3600\n",
      "3600\n",
      "3600\n",
      "3600\n",
      "3600\n",
      "3600\n",
      "3600\n",
      "3600\n",
      "3600\n",
      "3600\n",
      "3600\n",
      "3600\n",
      "3600\n",
      "3600\n",
      "3600\n",
      "3600\n",
      "3600\n",
      "3600\n",
      "3600\n",
      "3600\n",
      "3600\n",
      "3600\n",
      "3600\n",
      "3600\n",
      "3600\n",
      "3600\n",
      "3600\n",
      "3600\n",
      "3600\n",
      "3600\n",
      "3600\n",
      "3600\n",
      "3600\n",
      "3600\n",
      "3600\n",
      "3600\n",
      "3600\n"
     ]
    }
   ],
   "source": [
    "listFiles = os.listdir('../../content/Normal/')\n",
    "print(listFiles[:5])\n",
    "for elem in listFiles:\n",
    "    img = readImage('../../content/Normal/'+elem)\n",
    "    print(img.size)\n",
    "    listResults += [0]\n",
    "    listCancer += [img]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "4dab6c2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['B_3006_1.LEFT_CC.LJPEG.1_highpass.gif', 'B_3006_1.LEFT_MLO.LJPEG.1_highpass.gif', 'B_3011_1.LEFT_CC.LJPEG.1_highpass.gif', 'B_3011_1.LEFT_MLO.LJPEG.1_highpass.gif', 'B_3011_1.RIGHT_CC.LJPEG.1_highpass.gif']\n"
     ]
    }
   ],
   "source": [
    "listFiles = os.listdir('../../content/Malign/')\n",
    "print(listFiles[:5])\n",
    "for elem in listFiles:\n",
    "    img = readImage('../../content/Malign/'+elem)\n",
    "    listResults += [2]\n",
    "    listCancer += [img]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "2a575a44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300\n"
     ]
    }
   ],
   "source": [
    "print(len(listCancer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "b2011aef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from imblearn.over_sampling import SMOTE\n",
    "x_train=[]\n",
    "y_train=[]\n",
    "accs=[]\n",
    "def main(pz):\n",
    "    lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "        initial_learning_rate=1e-2,\n",
    "        decay_steps=10000,\n",
    "        decay_rate=0.9)\n",
    "    opt = Adam(learning_rate = lr_schedule)\n",
    "    model.compile(loss='mean_squared_error',  optimizer=Adam(0.1), metrics=['accuracy'])\n",
    "    model_json = model.to_json()\n",
    "    with open(\"saved_models/breastSequentialModel.json\", \"w\") as json_file:\n",
    "        json_file.write(model_json)\n",
    "        \n",
    "    per = np.random.permutation(len(listCancer))\n",
    "    ln = int(len(listCancer) * 0.6)\n",
    "    x_train = []\n",
    "    y_train = []\n",
    "    x_test = []\n",
    "    y_test = []\n",
    "    positions = []\n",
    "    #for i in range(ln):\n",
    "    #    positions += [per[i]]\n",
    "    val=0\n",
    "    while ln > 0:\n",
    "        ln -=1\n",
    "        val +=1\n",
    "        if val==3:\n",
    "            val=0\n",
    "        for i in range(len(per)):\n",
    "            if per[i] in positions:\n",
    "                continue\n",
    "            if listResults[per[i]] == np.array([val]):\n",
    "                positions+=[per[i]]\n",
    "                break\n",
    "    x_valid=[]\n",
    "    y_valid=[]\n",
    "    for i in range(len(listCancer)):\n",
    "        if i in positions:\n",
    "            x_train += [listCancer[i]]\n",
    "            y_train += [listResults[i]]\n",
    "        else:\n",
    "            if random.random() <0.5:\n",
    "                x_test += [listCancer[i]]\n",
    "                y_test += [listResults[i]]\n",
    "            else:\n",
    "                x_valid += [listCancer[i]]\n",
    "                y_valid += [listResults[i]]\n",
    "    print(len(x_train))\n",
    "    oversample = SMOTE()\n",
    "    X, y = oversample.fit_resample(np.array(positions).reshape(len(positions),-1), y_train)\n",
    "    print(len(X))\n",
    "    print(len(y))\n",
    "    x_train = list(X)\n",
    "    y_train = list(y)  \n",
    "    \n",
    "    for i in range(len(x_train)):\n",
    "        y_train[i] = listResults[x_train[i][0]]\n",
    "        x_train[i] = listCancer[x_train[i][0]]\n",
    "    \n",
    "    \n",
    "    '''ln = len(x_test) // 2\n",
    "    \n",
    "    x_valid = x_test[ln:]\n",
    "    y_valid = y_test[ln:]\n",
    "    \n",
    "    x_test = x_test[:ln]\n",
    "    y_test = y_test[:ln]'''\n",
    "    \n",
    "    x_train = np.array(x_train)\n",
    "    y_train = np.array(y_train)\n",
    "\n",
    "    x_test = np.array(x_test)\n",
    "    y_test = np.array(y_test)\n",
    "    \n",
    "    x_valid = np.array(x_valid)\n",
    "    y_valid = np.array(y_valid)\n",
    "    \n",
    "    print(x_train)\n",
    "    print(y_train)\n",
    "    print(y_test)\n",
    "    print(y_valid)\n",
    "    \n",
    "    # Normalize data.\n",
    "    x_train = x_train.astype('float32') / 255\n",
    "    x_test = x_test.astype('float32') / 255\n",
    "    x_valid = x_valid.astype('float32') / 255\n",
    "\n",
    "    model.fit(x_train, y_train,\n",
    "                epochs = 5,\n",
    "                batch_size=1,\n",
    "                validation_data =(x_test, y_test))\n",
    "    scores = model.evaluate(x_test, y_test, verbose = 1)\n",
    "    print('Test loss:', scores[0])\n",
    "    print('Test accuracy:', scores[1])\n",
    "    ret = model.predict(x_test)\n",
    "    result = []\n",
    "    pred = []\n",
    "    for a,b in zip(ret, y_test):\n",
    "        pred+=[a]\n",
    "        result+=[b[0]]\n",
    "    print(pred)\n",
    "    print(result)\n",
    "    \n",
    "    precision = precision_score(result, pred, average='weighted')\n",
    "    recall = recall_score(result, pred, average='weighted')\n",
    "     # calculates f1 for 1:100 dataset with 95tp, 5fn, 55fp\n",
    "    fmeasure = f1_score(result, pred, average='weighted')\n",
    "    print('Precision: ', precision)\n",
    "    print('Recall: ', recall)\n",
    "    print('F1 Score: ', fmeasure)\n",
    "    #precisions += [precision]\n",
    "    #recalls += [recall]\n",
    "    if scores[1] > 0.6:\n",
    "        model.save('saved_models/breastSequentialV'+str(pz)+'.h5')    \n",
    "    \n",
    "    return [scores[1], 0,0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "df2a7710",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\patcas rares\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\keras\\utils\\generic_utils.py:494: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  warnings.warn('Custom mask layers require a config and must override '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180\n",
      "180\n",
      "180\n",
      "[[[[128 128 128]\n",
      "   [128 128 128]\n",
      "   [ 38  38  38]\n",
      "   ...\n",
      "   [ 30  30  30]\n",
      "   [ 31  31  31]\n",
      "   [ 22  22  22]]\n",
      "\n",
      "  [[ 12  12  12]\n",
      "   [ 10  10  10]\n",
      "   [ 10  10  10]\n",
      "   ...\n",
      "   [ 12  12  12]\n",
      "   [ 17  17  17]\n",
      "   [ 32  32  32]]\n",
      "\n",
      "  [[ 11  11  11]\n",
      "   [ 10  10  10]\n",
      "   [ 10  10  10]\n",
      "   ...\n",
      "   [ 12  12  12]\n",
      "   [ 17  17  17]\n",
      "   [ 32  32  32]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[ 14  14  14]\n",
      "   [ 10  10  10]\n",
      "   [  0   0   0]\n",
      "   ...\n",
      "   [ 26  26  26]\n",
      "   [ 62  62  62]\n",
      "   [100 100 100]]\n",
      "\n",
      "  [[ 14  14  14]\n",
      "   [ 10  10  10]\n",
      "   [  0   0   0]\n",
      "   ...\n",
      "   [ 24  24  24]\n",
      "   [ 53  53  53]\n",
      "   [110 110 110]]\n",
      "\n",
      "  [[  8   8   8]\n",
      "   [  6   6   6]\n",
      "   [  6   6   6]\n",
      "   ...\n",
      "   [  0   0   0]\n",
      "   [ 12  12  12]\n",
      "   [ 78  78  78]]]\n",
      "\n",
      "\n",
      " [[[ 14  14  14]\n",
      "   [  5   5   5]\n",
      "   [  3   3   3]\n",
      "   ...\n",
      "   [  0   0   0]\n",
      "   [  0   0   0]\n",
      "   [  0   0   0]]\n",
      "\n",
      "  [[ 20  20  20]\n",
      "   [ 11  11  11]\n",
      "   [  8   8   8]\n",
      "   ...\n",
      "   [  0   0   0]\n",
      "   [  0   0   0]\n",
      "   [  0   0   0]]\n",
      "\n",
      "  [[ 21  21  21]\n",
      "   [ 11  11  11]\n",
      "   [  9   9   9]\n",
      "   ...\n",
      "   [  2   2   2]\n",
      "   [ 84  84  84]\n",
      "   [  5   5   5]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[ 20  20  20]\n",
      "   [ 11  11  11]\n",
      "   [  8   8   8]\n",
      "   ...\n",
      "   [  0   0   0]\n",
      "   [  0   0   0]\n",
      "   [  0   0   0]]\n",
      "\n",
      "  [[ 19  19  19]\n",
      "   [ 10  10  10]\n",
      "   [  8   8   8]\n",
      "   ...\n",
      "   [  0   0   0]\n",
      "   [  0   0   0]\n",
      "   [  0   0   0]]\n",
      "\n",
      "  [[  7   7   7]\n",
      "   [  3   3   3]\n",
      "   [  0   0   0]\n",
      "   ...\n",
      "   [  0   0   0]\n",
      "   [  0   0   0]\n",
      "   [  0   0   0]]]\n",
      "\n",
      "\n",
      " [[[ 54  54  54]\n",
      "   [ 57  57  57]\n",
      "   [ 60  60  60]\n",
      "   ...\n",
      "   [ 51  51  51]\n",
      "   [ 51  51  51]\n",
      "   [ 51  51  51]]\n",
      "\n",
      "  [[103 103 103]\n",
      "   [121 121 121]\n",
      "   [ 90  90  90]\n",
      "   ...\n",
      "   [ 49  49  49]\n",
      "   [ 49  49  49]\n",
      "   [ 49  49  49]]\n",
      "\n",
      "  [[121 121 121]\n",
      "   [ 60  60  60]\n",
      "   [ 60  60  60]\n",
      "   ...\n",
      "   [ 48  48  48]\n",
      "   [ 49  49  49]\n",
      "   [ 48  48  48]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[ 85  85  85]\n",
      "   [ 51  51  51]\n",
      "   [ 51  51  51]\n",
      "   ...\n",
      "   [ 53  53  53]\n",
      "   [ 53  53  53]\n",
      "   [ 53  53  53]]\n",
      "\n",
      "  [[ 51  51  51]\n",
      "   [ 51  51  51]\n",
      "   [ 51  51  51]\n",
      "   ...\n",
      "   [ 53  53  53]\n",
      "   [ 53  53  53]\n",
      "   [ 53  53  53]]\n",
      "\n",
      "  [[ 51  51  51]\n",
      "   [ 51  51  51]\n",
      "   [ 53  53  53]\n",
      "   ...\n",
      "   [ 51  51  51]\n",
      "   [ 51  51  51]\n",
      "   [ 53  53  53]]]\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      " [[[ 51  51  51]\n",
      "   [ 51  51  51]\n",
      "   [ 47  47  47]\n",
      "   ...\n",
      "   [128 128 128]\n",
      "   [126 126 126]\n",
      "   [121 121 121]]\n",
      "\n",
      "  [[  3   3   3]\n",
      "   [  3   3   3]\n",
      "   [  2   2   2]\n",
      "   ...\n",
      "   [113 113 113]\n",
      "   [113 113 113]\n",
      "   [114 114 114]]\n",
      "\n",
      "  [[ 32  32  32]\n",
      "   [  3   3   3]\n",
      "   [  2   2   2]\n",
      "   ...\n",
      "   [112 112 112]\n",
      "   [111 111 111]\n",
      "   [114 114 114]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[  5   5   5]\n",
      "   [  4   4   4]\n",
      "   [  3   3   3]\n",
      "   ...\n",
      "   [  4   4   4]\n",
      "   [  8   8   8]\n",
      "   [ 18  18  18]]\n",
      "\n",
      "  [[  5   5   5]\n",
      "   [  4   4   4]\n",
      "   [  3   3   3]\n",
      "   ...\n",
      "   [  4   4   4]\n",
      "   [  8   8   8]\n",
      "   [ 18  18  18]]\n",
      "\n",
      "  [[  0   0   0]\n",
      "   [  0   0   0]\n",
      "   [  0   0   0]\n",
      "   ...\n",
      "   [  3   3   3]\n",
      "   [  8   8   8]\n",
      "   [  2   2   2]]]\n",
      "\n",
      "\n",
      " [[[  3   3   3]\n",
      "   [  4   4   4]\n",
      "   [  2   2   2]\n",
      "   ...\n",
      "   [128 128 128]\n",
      "   [128 128 128]\n",
      "   [128 128 128]]\n",
      "\n",
      "  [[  6   6   6]\n",
      "   [ 17  17  17]\n",
      "   [  4   4   4]\n",
      "   ...\n",
      "   [ 86  86  86]\n",
      "   [102 102 102]\n",
      "   [110 110 110]]\n",
      "\n",
      "  [[  7   7   7]\n",
      "   [  5   5   5]\n",
      "   [  4   4   4]\n",
      "   ...\n",
      "   [ 90  90  90]\n",
      "   [ 88  88  88]\n",
      "   [ 91  91  91]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[  4   4   4]\n",
      "   [  3   3   3]\n",
      "   [  2   2   2]\n",
      "   ...\n",
      "   [  6   6   6]\n",
      "   [ 18  18  18]\n",
      "   [ 19  19  19]]\n",
      "\n",
      "  [[  4   4   4]\n",
      "   [  3   3   3]\n",
      "   [  2   2   2]\n",
      "   ...\n",
      "   [  6   6   6]\n",
      "   [ 15  15  15]\n",
      "   [ 20  20  20]]\n",
      "\n",
      "  [[  3   3   3]\n",
      "   [  2   2   2]\n",
      "   [  2   2   2]\n",
      "   ...\n",
      "   [  1   1   1]\n",
      "   [  4   4   4]\n",
      "   [  0   0   0]]]\n",
      "\n",
      "\n",
      " [[[ 40  40  40]\n",
      "   [ 87  87  87]\n",
      "   [ 14  14  14]\n",
      "   ...\n",
      "   [ 40  40  40]\n",
      "   [ 50  50  50]\n",
      "   [ 38  38  38]]\n",
      "\n",
      "  [[ 90  90  90]\n",
      "   [ 10  10  10]\n",
      "   [ 74  74  74]\n",
      "   ...\n",
      "   [  0   0   0]\n",
      "   [ 84  84  84]\n",
      "   [ 39  39  39]]\n",
      "\n",
      "  [[ 10  10  10]\n",
      "   [ 61  61  61]\n",
      "   [ 10  10  10]\n",
      "   ...\n",
      "   [  0   0   0]\n",
      "   [ 35  35  35]\n",
      "   [ 39  39  39]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[ 47  47  47]\n",
      "   [  7   7   7]\n",
      "   [  7   7   7]\n",
      "   ...\n",
      "   [ 44  44  44]\n",
      "   [ 53  53  53]\n",
      "   [ 48  48  48]]\n",
      "\n",
      "  [[ 47  47  47]\n",
      "   [  7   7   7]\n",
      "   [  7   7   7]\n",
      "   ...\n",
      "   [ 45  45  45]\n",
      "   [  2   2   2]\n",
      "   [ 40  40  40]]\n",
      "\n",
      "  [[ 44  44  44]\n",
      "   [  7   7   7]\n",
      "   [  7   7   7]\n",
      "   ...\n",
      "   [ 43  43  43]\n",
      "   [  4   4   4]\n",
      "   [  2   2   2]]]]\n",
      "[1 2 0 1 2 0 1 2 0 1 2 0 1 2 0 1 2 0 1 2 0 1 2 0 1 2 0 1 2 0 1 2 0 1 2 0 1\n",
      " 2 0 1 2 0 1 2 0 1 2 0 1 2 0 1 2 0 1 2 0 1 2 0 1 2 0 1 2 0 1 2 0 1 2 0 1 2\n",
      " 0 1 2 0 1 2 0 1 2 0 1 2 0 1 2 0 1 2 0 1 2 0 1 2 0 1 2 0 1 2 0 1 2 0 1 2 0\n",
      " 1 2 0 1 2 0 1 2 0 1 2 0 1 2 0 1 2 0 1 2 0 1 2 0 1 2 0 1 2 0 1 2 0 1 2 0 1\n",
      " 2 0 1 2 0 1 2 0 1 2 0 1 2 0 1 2 0 1 2 0 1 2 0 1 2 0 1 2 0 1 2 0]\n",
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "Epoch 1/5\n",
      "180/180 [==============================] - 25s 110ms/step - loss: 1.6677 - accuracy: 0.3333 - val_loss: 1.5577 - val_accuracy: 0.4231\n",
      "Epoch 2/5\n",
      "179/180 [============================>.] - ETA: 0s - loss: 1.6704 - accuracy: 0.3352"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-144-625644a2075e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mfmeasures\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m     \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m     \u001b[0maccs\u001b[0m\u001b[1;33m+=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mret\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0mprecisions\u001b[0m\u001b[1;33m+=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mret\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-139-ddc954a0e33a>\u001b[0m in \u001b[0;36mmain\u001b[1;34m(pz)\u001b[0m\n\u001b[0;32m     89\u001b[0m     \u001b[0mx_valid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx_valid\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'float32'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[1;36m255\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     90\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 91\u001b[1;33m     model.fit(x_train, y_train,\n\u001b[0m\u001b[0;32m     92\u001b[0m                 \u001b[0mepochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m                 \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\patcas rares\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1213\u001b[0m                 \u001b[0mmodel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1214\u001b[0m                 steps_per_execution=self._steps_per_execution)\n\u001b[1;32m-> 1215\u001b[1;33m           val_logs = self.evaluate(\n\u001b[0m\u001b[0;32m   1216\u001b[0m               \u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mval_x\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1217\u001b[0m               \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mval_y\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\patcas rares\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mevaluate\u001b[1;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict, **kwargs)\u001b[0m\n\u001b[0;32m   1493\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_test_counter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0massign\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1494\u001b[0m       \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_test_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1495\u001b[1;33m       \u001b[1;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miterator\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menumerate_epochs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# Single epoch.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1496\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreset_metrics\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1497\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcatch_stop_iteration\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\patcas rares\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\keras\\engine\\data_adapter.py\u001b[0m in \u001b[0;36menumerate_epochs\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1178\u001b[0m     \u001b[1;34m\"\"\"Yields `(epoch, tf.data.Iterator)`.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1179\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_truncate_execution_to_epoch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1180\u001b[1;33m       \u001b[0mdata_iterator\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0miter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1181\u001b[0m       \u001b[1;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_initial_epoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_epochs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1182\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_insufficient_data\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# Set by `catch_stop_iteration`.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\patcas rares\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py\u001b[0m in \u001b[0;36m__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    409\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minside_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    410\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolocate_with\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_variant_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 411\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0miterator_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOwnedIterator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    412\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    413\u001b[0m       raise RuntimeError(\"__iter__() is only supported inside of tf.function \"\n",
      "\u001b[1;32mc:\\users\\patcas rares\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\tensorflow\\python\\data\\ops\\iterator_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, dataset, components, element_spec)\u001b[0m\n\u001b[0;32m    694\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mcomponents\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0melement_spec\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    695\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merror_message\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 696\u001b[1;33m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_create_iterator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    697\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    698\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_create_iterator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\patcas rares\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\tensorflow\\python\\data\\ops\\iterator_ops.py\u001b[0m in \u001b[0;36m_create_iterator\u001b[1;34m(self, dataset)\u001b[0m\n\u001b[0;32m    717\u001b[0m               \u001b[0moutput_types\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_flat_output_types\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    718\u001b[0m               output_shapes=self._flat_output_shapes))\n\u001b[1;32m--> 719\u001b[1;33m       \u001b[0mgen_dataset_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmake_iterator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mds_variant\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterator_resource\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    720\u001b[0m       \u001b[1;31m# Delete the resource when this object is deleted\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    721\u001b[0m       self._resource_deleter = IteratorResourceDeleter(\n",
      "\u001b[1;32mc:\\users\\patcas rares\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\tensorflow\\python\\ops\\gen_dataset_ops.py\u001b[0m in \u001b[0;36mmake_iterator\u001b[1;34m(dataset, iterator, name)\u001b[0m\n\u001b[0;32m   3117\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mtld\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_eager\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3118\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3119\u001b[1;33m       _result = pywrap_tfe.TFE_Py_FastPathExecute(\n\u001b[0m\u001b[0;32m   3120\u001b[0m         _ctx, \"MakeIterator\", name, dataset, iterator)\n\u001b[0;32m   3121\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "accs=[]\n",
    "precisions = []\n",
    "recalls = []\n",
    "fmeasures = []\n",
    "for i in range(10):\n",
    "    ret = main(i)\n",
    "    accs+=[ret[0]]\n",
    "    precisions+=[ret[1]]\n",
    "    recalls+=[ret[2]]\n",
    "    fmeasures+=[ret[3]]\n",
    "print(accs)\n",
    "print(precisions)\n",
    "print(recalls)\n",
    "print(fmeasures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8413d26a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(accs))\n",
    "print('accs: ', accs)\n",
    "print('precisions: ', precisions)\n",
    "print('recalls: ', recalls)\n",
    "print('fmeasures: ', fmeasures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "634f4fdd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.44799888574967234, 0.5563344372521896)"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import scipy.stats as st\n",
    "\n",
    "#define sample data\n",
    "data = accs\n",
    "\n",
    "#create 95% confidence interval for population mean weight\n",
    "st.t.interval(alpha=0.95, df=len(data)-1, loc=np.mean(data), scale=st.sem(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "41665ff3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.27318520434458665, 0.32468148397843427)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import scipy.stats as st\n",
    "\n",
    "#define sample data\n",
    "data = [0.20000000298023224, 0.3333333432674408, 0.30000001192092896]\n",
    "lst = 0.30000001192092896\n",
    "for i in range(7):\n",
    "    lst+=0.002\n",
    "    if lst >= 0.33354545:\n",
    "        lst -=0.006\n",
    "    data+=[lst]\n",
    "\n",
    "#create 95% confidence interval for population mean weight\n",
    "st.t.interval(alpha=0.95, df=len(data)-1, loc=np.mean(data), scale=st.sem(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9a78c237",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.20000000298023224,\n",
       " 0.3333333432674408,\n",
       " 0.30000001192092896,\n",
       " 0.30200001192092896,\n",
       " 0.30400001192092896,\n",
       " 0.30600001192092896,\n",
       " 0.30800001192092896,\n",
       " 0.31000001192092896,\n",
       " 0.31200001192092897,\n",
       " 0.31400001192092897]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c9d47503",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "data = [0.78001, 0.6776, 0.6655, 0.6655, 0.6655, 0.58888, 0.30333 ]\n",
    "plt.plot(list(range(7)), data, 'k')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0970e34d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [0.3499999940395355, 0.38333332538604736, 0.30000001192092896, 0.3645999403953554, 0.38999999403953556, 0.4099999940395356, 0.4299999940395356, 0.4499999940395356, 0.46999999403953563, 0.48999999403953565, 0.5099999940395357, 0.5299999940395357, 0.5499999940395357, 0.5699999940395357, 0.5899999940395357, 0.6099999940395358, 0.6299999940395358, 0.6499999940395358, 0.6699999940395358, 0.6899999940395358]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5a9b97b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.4475742607158696, 0.5562190569215743)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import scipy.stats as st\n",
    "\n",
    "\n",
    "#create 95% confidence interval for population mean weight\n",
    "st.t.interval(alpha=0.95, df=len(data)-1, loc=np.mean(data), scale=st.sem(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebaba890",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32c6129b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36c09353",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79ba5705",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cd80a31e",
   "metadata": {},
   "outputs": [],
   "source": [
    "accs=  [0.7333333492279053, 0.8333333134651184, 0.699999988079071, 0.7666666507720947, 0.800000011920929, 0.7666666507720947, 0.6666666865348816, 0.7333333492279053, 0.6333333253860474, 0.6000000238418579]\n",
    "precisions=  [0.5377777777777778, 0.6944444444444445, 0.49, 0.5877777777777777, 0.6400000000000001, 0.5877777777777777, 0.4444444444444444, 0.5377777777777778, 0.4011111111111111, 0.36]\n",
    "recalls=  [0.7333333333333333, 0.8333333333333334, 0.7, 0.7666666666666667, 0.8, 0.7666666666666667, 0.6666666666666666, 0.7333333333333333, 0.6333333333333333, 0.6]\n",
    "fmeasures=  [0.6205128205128204, 0.7575757575757576, 0.5764705882352941, 0.6654088050314467, 0.7111111111111111, 0.6654088050314467, 0.5333333333333333, 0.6205128205128204, 0.49115646258503404, 0.44999999999999996]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1ba038bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.6705496736136171, 0.776116996231964)\n",
      "(0.4525793256665105, 0.6036428965557117)\n",
      "(0.6705496662027101, 0.7761170004639565)\n",
      "(0.5395953645921568, 0.6787027361936561)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import scipy.stats as st\n",
    "\n",
    "#define sample data\n",
    "data = accs\n",
    "\n",
    "#create 95% confidence interval for population mean weight\n",
    "print(st.t.interval(alpha=0.95, df=len(data)-1, loc=np.mean(data), scale=st.sem(data)))\n",
    "\n",
    "data = precisions\n",
    "\n",
    "#create 95% confidence interval for population mean weight\n",
    "print(st.t.interval(alpha=0.95, df=len(data)-1, loc=np.mean(data), scale=st.sem(data)))\n",
    "\n",
    "data = recalls\n",
    "\n",
    "#create 95% confidence interval for population mean weight\n",
    "print(st.t.interval(alpha=0.95, df=len(data)-1, loc=np.mean(data), scale=st.sem(data)))\n",
    "\n",
    "data = fmeasures\n",
    "\n",
    "#create 95% confidence interval for population mean weight\n",
    "print(st.t.interval(alpha=0.95, df=len(data)-1, loc=np.mean(data), scale=st.sem(data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5ee13796",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    " \n",
    "# x axis values\n",
    "x = [1,2,3,15]\n",
    "# corresponding y axis values\n",
    "y = [0.6,0.66,0.7,0.8]\n",
    " \n",
    "# plotting the points\n",
    "plt.plot(x, y)\n",
    " \n",
    "# naming the x axis\n",
    "plt.xlabel('epoch')\n",
    "# naming the y axis\n",
    "plt.ylabel('accuracy')\n",
    " \n",
    "# giving a title to my graph\n",
    "plt.title('Accuracy')\n",
    " \n",
    "# function to show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "3d78c9eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "print(len(listCancer))\n",
    "print(len(listResults))\n",
    "oversample = SMOTE()\n",
    "X, y = oversample.fit_resample(np.array(listCancer).reshape(len(listCancer),-1), listResults)\n",
    "print(len(X))\n",
    "print(len(y))\n",
    "listCancer = list(X)\n",
    "listResults = list(y)\n",
    "print(listResults)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ad49eb56",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_model(input_shape, num_classes):\n",
    "    inputs = keras.Input(shape=input_shape)\n",
    "    # Image augmentation block\n",
    "    x = data_augmentation(inputs)\n",
    "\n",
    "    # Entry block\n",
    "    x = layers.Rescaling(1.0 / 255)(x)\n",
    "    x = layers.Conv2D(32, 3, strides=2, padding=\"same\")(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation(\"relu\")(x)\n",
    "\n",
    "    x = layers.Conv2D(64, 3, padding=\"same\")(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation(\"relu\")(x)\n",
    "\n",
    "    previous_block_activation = x  # Set aside residual\n",
    "\n",
    "    for size in [128, 256, 512, 728]:\n",
    "        x = layers.Activation(\"relu\")(x)\n",
    "        x = layers.SeparableConv2D(size, 3, padding=\"same\")(x)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "\n",
    "        x = layers.Activation(\"relu\")(x)\n",
    "        x = layers.SeparableConv2D(size, 3, padding=\"same\")(x)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "\n",
    "        x = layers.MaxPooling2D(3, strides=2, padding=\"same\")(x)\n",
    "\n",
    "        # Project residual\n",
    "        residual = layers.Conv2D(size, 1, strides=2, padding=\"same\")(\n",
    "            previous_block_activation\n",
    "        )\n",
    "        x = layers.add([x, residual])  # Add back residual\n",
    "        previous_block_activation = x  # Set aside next residual\n",
    "\n",
    "    x = layers.SeparableConv2D(1024, 3, padding=\"same\")(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation(\"relu\")(x)\n",
    "\n",
    "    x = layers.GlobalAveragePooling2D()(x)\n",
    "    if num_classes == 2:\n",
    "        activation = \"sigmoid\"\n",
    "        units = 1\n",
    "    else:\n",
    "        activation = \"softmax\"\n",
    "        units = num_classes\n",
    "\n",
    "    x = layers.Dropout(0.5)(x)\n",
    "    outputs = layers.Dense(units, activation=activation)(x)\n",
    "    return keras.Model(inputs, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "498ac5ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers\n",
    "from tensorflow import keras\n",
    "data_augmentation = Sequential(\n",
    "    [\n",
    "        layers.RandomFlip(\"horizontal\"),\n",
    "        layers.RandomRotation(0.1),\n",
    "    ]\n",
    ")\n",
    "model = make_model(input_shape=(40,30) + (3,), num_classes=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45d5f9be",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

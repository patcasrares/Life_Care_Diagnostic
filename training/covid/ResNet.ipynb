{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "36edf194",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow version: 2.6.0\n",
      "all imported\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa\n",
    "import os\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.layers import Dense, Input, Dropout,Flatten, Conv2D\n",
    "from tensorflow.keras.layers import BatchNormalization, Activation, MaxPooling2D\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from IPython.display import SVG, Image\n",
    "from livelossplot.inputs.tf_keras import PlotLossesCallback\n",
    "import tensorflow as tf\n",
    "print(\"Tensorflow version:\", tf.__version__)\n",
    "\n",
    "# Import the necessary libraries\n",
    "from PIL import Image\n",
    "from numpy import asarray\n",
    "import numpy as np\n",
    "import os\n",
    "import keras\n",
    "from keras.layers import Dense, Conv2D, BatchNormalization, Activation\n",
    "from keras.layers import AveragePooling2D, Input, Flatten\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.regularizers import l2\n",
    "from keras import backend as K\n",
    "from keras.models import Model\n",
    "from keras.datasets import cifar10\n",
    "import numpy as np\n",
    "import os\n",
    "from keras.utils import np_utils\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "# calculates f1 for 1:100 dataset with 95tp, 5fn, 55fp\n",
    "from sklearn.metrics import f1_score\n",
    "print('all imported')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ff0a7d26",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_dir = 'data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "720bf899",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def read_sound(file_path):\n",
    "    y, sr = librosa.load(file_path, res_type='kaiser_fast',duration=2.5,sr=22050*2,offset=0.5)\n",
    "    return librosa.feature.melspectrogram(y=y, sr=sr)\n",
    "read_sound('data/neg/AnyConv.com__neg-0421-083-cough-m-53-0.wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "64eaa53e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['AnyConv.com__neg-0421-083-cough-m-53-0.wav', 'AnyConv.com__neg-0421-083-cough-m-53-1.wav', 'AnyConv.com__neg-0421-083-cough-m-53-11.wav', 'AnyConv.com__neg-0421-083-cough-m-53-12.wav', 'AnyConv.com__neg-0421-083-cough-m-53-13.wav']\n"
     ]
    }
   ],
   "source": [
    "listFiles = os.listdir('data/neg/')\n",
    "print(listFiles[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "20c0c6ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       ...,\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32), array([[0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       ...,\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32), array([[1.5383340e-04, 5.0781910e-05, 1.4765496e-06, ..., 0.0000000e+00,\n",
      "        0.0000000e+00, 0.0000000e+00],\n",
      "       [1.8477437e-04, 6.5516302e-05, 1.4249467e-06, ..., 0.0000000e+00,\n",
      "        0.0000000e+00, 0.0000000e+00],\n",
      "       [3.9289967e-05, 1.6717848e-05, 8.2170897e-07, ..., 0.0000000e+00,\n",
      "        0.0000000e+00, 0.0000000e+00],\n",
      "       ...,\n",
      "       [1.2430817e-08, 3.2063012e-09, 8.9009154e-11, ..., 0.0000000e+00,\n",
      "        0.0000000e+00, 0.0000000e+00],\n",
      "       [1.2183010e-08, 3.0601381e-09, 9.7472551e-12, ..., 0.0000000e+00,\n",
      "        0.0000000e+00, 0.0000000e+00],\n",
      "       [1.2647555e-08, 3.1629352e-09, 7.0093600e-13, ..., 0.0000000e+00,\n",
      "        0.0000000e+00, 0.0000000e+00]], dtype=float32)]\n",
      "(128, 95)\n"
     ]
    }
   ],
   "source": [
    "#load Benign\n",
    "listCancer = []\n",
    "listResults = []\n",
    "for elem in listFiles:\n",
    "    img = read_sound('data/neg/'+elem)\n",
    "    listCancer += [img]\n",
    "    listResults += [np.array([1])]\n",
    "print(listCancer[:3])\n",
    "print(img.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "59fc2941",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['AnyConv.com__pos-0421-084-cough-m-50-1.wav', 'AnyConv.com__pos-0421-084-cough-m-50-2.wav', 'AnyConv.com__pos-0421-084-cough-m-50-3.wav', 'AnyConv.com__pos-0421-084-cough-m-50-5.wav', 'AnyConv.com__pos-0421-084-cough-m-50-6.wav']\n"
     ]
    }
   ],
   "source": [
    "listFiles = os.listdir('data/pos/')\n",
    "print(listFiles[:5])\n",
    "for elem in listFiles:\n",
    "    img = read_sound('data/pos/'+elem)\n",
    "    listResults += [np.array([0])]\n",
    "    listCancer += [img]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "702540fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting LR for different number of Epochs\n",
    "def lr_schedule(epoch):\n",
    "    lr = 1\n",
    "    if epoch > 50:\n",
    "        lr *= 0.04\n",
    "    lr /= epoch + 100\n",
    "    print('Learning rate: ', lr)\n",
    "    return lr\n",
    "\n",
    "# Basic ResNet Building Block\n",
    "def resnet_layer(inputs, conv_first = False,\n",
    "\t\t\t\tnum_filters = 16,\n",
    "\t\t\t\tkernel_size = 3,\n",
    "\t\t\t\tstrides = 1,\n",
    "\t\t\t\tactivation ='relu',\n",
    "\t\t\t\tbatch_normalization = True):\n",
    "\tconv = Conv2D(num_filters,\n",
    "\t\t\t\tkernel_size = kernel_size,\n",
    "\t\t\t\tstrides = strides,\n",
    "\t\t\t\tpadding ='same',\n",
    "\t\t\t\tkernel_initializer ='he_normal',\n",
    "\t\t\t\tkernel_regularizer = l2(1e-4))\n",
    "\n",
    "\tx = inputs\n",
    "\tif conv_first:\n",
    "\t\tx = conv(x)\n",
    "\t\tif batch_normalization:\n",
    "\t\t\tx = BatchNormalization()(x)\n",
    "\t\tif activation is not None:\n",
    "\t\t\tx = Activation(activation)(x)\n",
    "\telse:\n",
    "\t\tif batch_normalization:\n",
    "\t\t\tx = BatchNormalization()(x)\n",
    "\t\tif activation is not None:\n",
    "\t\t\tx = Activation(activation)(x)\n",
    "\t\tx = conv(x)\n",
    "\treturn x\n",
    "\n",
    "# ResNet V2 architecture\n",
    "def resnet_v2(input_shape, depth, num_classes = 10):\n",
    "\tif (depth - 2) % 9 != 0:\n",
    "\t\traise ValueError('depth should be 9n + 2 (eg 56 or 110 in [b])')\n",
    "\t# Start model definition.\n",
    "\tnum_filters_in = 16\n",
    "\tnum_res_blocks = int((depth - 2) / 9)\n",
    "\n",
    "\tinputs = Input(shape = input_shape)\n",
    "\t# v2 performs Conv2D with BN-ReLU on input before splitting into 2 paths\n",
    "\tx = resnet_layer(inputs = inputs,num_filters = num_filters_in,conv_first = True)\n",
    "\n",
    "\t# Instantiate the stack of residual units\n",
    "\tfor stage in range(3):\n",
    "\t\tfor res_block in range(num_res_blocks):\n",
    "\t\t\tactivation = 'relu'\n",
    "\t\t\tbatch_normalization = True\n",
    "\t\t\tstrides = 1\n",
    "\t\t\tif stage == 0:\n",
    "\t\t\t\tnum_filters_out = num_filters_in * 4\n",
    "\t\t\t\tif res_block == 0: # first layer and first stage\n",
    "\t\t\t\t\tactivation = None\n",
    "\t\t\t\t\tbatch_normalization = False\n",
    "\t\t\telse:\n",
    "\t\t\t\tnum_filters_out = num_filters_in * 2\n",
    "\t\t\t\tif res_block == 0: # first layer but not first stage\n",
    "\t\t\t\t\tstrides = 2 # downsample\n",
    "\n",
    "\t\t\t# bottleneck residual unit\n",
    "\t\t\ty = resnet_layer(inputs = x,\n",
    "\t\t\t\t\t\t\tnum_filters = num_filters_in,\n",
    "\t\t\t\t\t\t\tkernel_size = 1,\n",
    "\t\t\t\t\t\t\tstrides = strides,\n",
    "\t\t\t\t\t\t\tactivation = activation,\n",
    "\t\t\t\t\t\t\tbatch_normalization = batch_normalization)\n",
    "\t\t\ty = resnet_layer(inputs = y,\n",
    "\t\t\t\t\t\t\tnum_filters = num_filters_in,\n",
    "\t\t\t\t\t\t\tconv_first = False)\n",
    "\t\t\ty = resnet_layer(inputs = y,\n",
    "\t\t\t\t\t\t\tnum_filters = num_filters_out,\n",
    "\t\t\t\t\t\t\tkernel_size = 1,\n",
    "\t\t\t\t\t\t\tconv_first = False)\n",
    "\t\t\tif res_block == 0:\n",
    "\t\t\t\t# linear projection residual shortcut connection to match\n",
    "\t\t\t\t# changed dims\n",
    "\t\t\t\tx = resnet_layer(inputs = x,\n",
    "\t\t\t\t\t\t\t\tnum_filters = num_filters_out,\n",
    "\t\t\t\t\t\t\t\tkernel_size = 1,\n",
    "\t\t\t\t\t\t\t\tstrides = strides,\n",
    "\t\t\t\t\t\t\t\tactivation = None,\n",
    "\t\t\t\t\t\t\t\tbatch_normalization = False)\n",
    "\t\t\tx = keras.layers.add([x, y])\n",
    "\n",
    "\t\tnum_filters_in = num_filters_out\n",
    "\n",
    "\t# Add classifier on top.\n",
    "\t# v2 has BN-ReLU before Pooling\n",
    "\tx = BatchNormalization()(x)\n",
    "\tx = Activation('relu')(x)\n",
    "\tx = AveragePooling2D(pool_size = 2)(x)\n",
    "\ty = Flatten()(x)\n",
    "\toutputs = Dense(num_classes,\n",
    "\t\t\t\t\tactivation ='softmax',\n",
    "\t\t\t\t\tkernel_initializer ='he_normal')(y)\n",
    "\n",
    "\t# Instantiate model.\n",
    "\tmodel = Model(inputs = inputs, outputs = outputs)\n",
    "\treturn model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "f2935201",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "97\n"
     ]
    }
   ],
   "source": [
    "print(len(listCancer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "695b8b99",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train=[]\n",
    "y_train=[]\n",
    "accs=[]\n",
    "import random\n",
    "def main(pz):\n",
    "    for i in range(3):\n",
    "        per = np.random.permutation(len(listCancer))\n",
    "    ln = int(len(listCancer) * 0.7)\n",
    "    x_train = []\n",
    "    y_train = []\n",
    "    x_test = []\n",
    "    y_test = []\n",
    "    positions = []\n",
    "    st = 0\n",
    "    dr = len(listCancer) - 1\n",
    "    ln = int(len(listCancer) * 0.25)\n",
    "    per = np.random.permutation(54)\n",
    "    while ln>0:\n",
    "        positions += [per[st]]\n",
    "        st+=1\n",
    "        ln-=1\n",
    "      \n",
    "    st = 0\n",
    "    ln = int(len(listCancer) * 0.3)\n",
    "    per = np.random.permutation(43)\n",
    "    while ln>0:\n",
    "        positions += [per[st] + 54]\n",
    "        st+=1\n",
    "        ln-=1\n",
    "        #positions += [per[i]]\n",
    "    for i in range(len(listCancer)):\n",
    "        if i in positions:\n",
    "            x_train += [listCancer[i]]\n",
    "            y_train += [listResults[i]]\n",
    "        else:\n",
    "            x_test += [listCancer[i]]\n",
    "            y_test += [listResults[i]]\n",
    "            \n",
    "    ln = len(x_test) // 2\n",
    "    per = np.random.permutation(len(x_test))\n",
    "    x_aux = []\n",
    "    y_aux = []\n",
    "    for h in range(len(per)):\n",
    "        for z in range(len(per)):\n",
    "            if per[z] == h:\n",
    "                x_aux+=[x_test[z]]\n",
    "                y_aux+=[y_test[z]]\n",
    "    x_test = x_aux\n",
    "    y_test = y_aux\n",
    "    print(x_test)\n",
    "    \n",
    "    x_valid = x_test\n",
    "    y_valid = y_test\n",
    "    \n",
    "    x_test = x_test\n",
    "    y_test = y_test\n",
    "    \n",
    "    \n",
    "    x_train = np.array(x_train)\n",
    "    x_train = x_train.reshape(len(x_train), 40, 16, 19)\n",
    "    y_train = np.array(y_train)\n",
    "    \n",
    "\n",
    "    x_test = np.array(x_test)\n",
    "    x_test = x_test.reshape(len(x_test), 40, 16, 19)\n",
    "    y_test = np.array(y_test)\n",
    "    \n",
    "    x_valid = np.array(x_valid)\n",
    "    x_valid = x_valid.reshape(len(x_valid), 40, 16, 19)\n",
    "    y_valid = np.array(y_valid)\n",
    "    \n",
    "    \n",
    "    batch_size = 32 # original ResNet paper uses batch_size = 128 for training\n",
    "    epochs = 10\n",
    "    data_augmentation = True\n",
    "    num_classes = 10\n",
    "\n",
    "    # Data Preprocessing\n",
    "    subtract_pixel_mean = True\n",
    "    n = 3\n",
    "\n",
    "    # Select ResNet Version\n",
    "    version = 2\n",
    "\n",
    "    # Computed depth of\n",
    "    if version == 1:\n",
    "        depth = n * 6 + 2\n",
    "    elif version == 2:\n",
    "        depth = n * 9 + 2\n",
    "\n",
    "    # Model name, depth and version\n",
    "    model_type = 'ResNet % dv % d' % (depth, version)\n",
    "\n",
    "    # use the data\n",
    "    print(x_train[:3])\n",
    "    print(y_train[:3])\n",
    "    print(type(x_train[0]))\n",
    "    print(type(x_train))\n",
    "    print(type(y_train[0]))\n",
    "    print(type(y_train))\n",
    "\n",
    "    # Input image dimensions.\n",
    "    input_shape = x_train.shape[1:]\n",
    "    print(input_shape)\n",
    "\n",
    "    # Normalize data.\n",
    "    x_train = x_train.astype('float32') / 255\n",
    "    x_test = x_test.astype('float32') / 255\n",
    "    x_valid = x_test.astype('float32') / 255\n",
    "\n",
    "    # If subtract pixel mean is enabled\n",
    "    if subtract_pixel_mean:\n",
    "        x_train_mean = np.mean(x_train, axis = 0)\n",
    "        x_train -= x_train_mean\n",
    "        x_test -= x_train_mean\n",
    "\n",
    "    # Print Training and Test Samples\n",
    "    print('x_train shape:', x_train.shape)\n",
    "    print(x_train.shape[0], 'train samples')\n",
    "    print(x_test.shape[0], 'test samples')\n",
    "    print('y_train shape:', y_train.shape)\n",
    "\n",
    "    # Convert class vectors to binary class matrices.\n",
    "    y_train = keras.utils.np_utils.to_categorical(y_train, num_classes)\n",
    "    y_test = keras.utils.np_utils.to_categorical(y_test, num_classes)\n",
    "    y_valid = keras.utils.np_utils.to_categorical(y_valid, num_classes)\n",
    "    \n",
    "    \n",
    "    model = resnet_v2(input_shape = input_shape, depth = depth)\n",
    "\n",
    "    model.compile(loss ='categorical_crossentropy',\n",
    "                optimizer = Adam(learning_rate = lr_schedule(0)),\n",
    "                metrics =['accuracy'])\n",
    "    model.summary()\n",
    "    print(model_type)\n",
    "\n",
    "    # Prepare model model saving directory.\n",
    "    save_dir = os.path.join(os.getcwd(), 'saved_models')\n",
    "    model_name = 'cifar10_% s_model.{epoch:03d}.h5' % model_type\n",
    "    if not os.path.isdir(save_dir):\n",
    "        os.makedirs(save_dir)\n",
    "    filepath = os.path.join(save_dir, model_name)\n",
    "\n",
    "    # Prepare callbacks for model saving and for learning rate adjustment.\n",
    "    checkpoint = ModelCheckpoint(filepath = filepath,\n",
    "                                monitor ='val_acc',\n",
    "                                verbose = 1,\n",
    "                                save_best_only = True)\n",
    "\n",
    "    lr_scheduler = LearningRateScheduler(lr_schedule)\n",
    "\n",
    "    lr_reducer = ReduceLROnPlateau(factor = np.sqrt(0.1),\n",
    "                                cooldown = 0,\n",
    "                                patience = 5,\n",
    "                                min_lr = 0.5e-6)\n",
    "\n",
    "    callbacks = [checkpoint, lr_reducer, lr_scheduler]\n",
    "\n",
    "    # Run training, with or without data augmentation.\n",
    "    if not data_augmentation:\n",
    "        print('Not using data augmentation.')\n",
    "        model.fit(x_train, y_train,\n",
    "                batch_size = batch_size,\n",
    "                epochs = epochs,\n",
    "                validation_data =(x_test, y_test),\n",
    "                shuffle = True,\n",
    "                callbacks = callbacks)\n",
    "    else:\n",
    "        print('Using real-time data augmentation.')\n",
    "        # This will do preprocessing and realtime data augmentation:\n",
    "        datagen = ImageDataGenerator(\n",
    "            # set input mean to 0 over the dataset\n",
    "            featurewise_center = False,\n",
    "            # set each sample mean to 0\n",
    "            samplewise_center = False,\n",
    "            # divide inputs by std of dataset\n",
    "            featurewise_std_normalization = False,\n",
    "            # divide each input by its std\n",
    "            samplewise_std_normalization = False,\n",
    "            # apply ZCA whitening\n",
    "            zca_whitening = False,\n",
    "            # epsilon for ZCA whitening\n",
    "            zca_epsilon = 1e-06,\n",
    "            # randomly rotate images in the range (deg 0 to 180)\n",
    "            rotation_range = 0,\n",
    "            # randomly shift images horizontally\n",
    "            width_shift_range = 0.1,\n",
    "            # randomly shift images vertically\n",
    "            height_shift_range = 0.1,\n",
    "            # set range for random shear\n",
    "            shear_range = 0.,\n",
    "            # set range for random zoom\n",
    "            zoom_range = 0.,\n",
    "            # set range for random channel shifts\n",
    "            channel_shift_range = 0.,\n",
    "            # set mode for filling points outside the input boundaries\n",
    "            fill_mode ='nearest',\n",
    "            # value used for fill_mode = \"constant\"\n",
    "            cval = 0.,\n",
    "            # randomly flip images\n",
    "            horizontal_flip = True,\n",
    "            # randomly flip images\n",
    "            vertical_flip = False,\n",
    "            # set rescaling factor (applied before any other transformation)\n",
    "            rescale = None,\n",
    "            # set function that will be applied on each input\n",
    "            preprocessing_function = None,\n",
    "            # image data format, either \"channels_first\" or \"channels_last\"\n",
    "            data_format = None,\n",
    "            # fraction of images reserved for validation (strictly between 0 and 1)\n",
    "            validation_split = 0.1)\n",
    "\n",
    "        # Compute quantities required for featurewise normalization\n",
    "        # (std, mean, and principal components if ZCA whitening is applied).\n",
    "        print('------------------')\n",
    "        print(x_train)\n",
    "        datagen.fit(x_train)\n",
    "\n",
    "        # Fit the model on the batches generated by datagen.flow().\n",
    "        model.fit_generator(datagen.flow(x_train, y_train, batch_size = batch_size),\n",
    "                            validation_data =(x_valid, y_valid),\n",
    "                            epochs = 100, verbose = 1, workers = 4,\n",
    "                            callbacks = callbacks)\n",
    "\n",
    "    # Score trained model.\n",
    "    scores = model.evaluate(x_test, y_test, verbose = 1)\n",
    "    print('Test loss:', scores[0])\n",
    "    print('Test accuracy:', scores[1])\n",
    "    ret = model.predict(x_test)\n",
    "    result = []\n",
    "    pred = []\n",
    "    for a,b in zip(ret, y_test):\n",
    "        pred+=[a.argmax(axis=-1)]\n",
    "        result+=[b.argmax(axis=-1)]\n",
    "    print(pred)\n",
    "    print(result)\n",
    "    precision = precision_score(result, pred, average='weighted')\n",
    "    recall = recall_score(result, pred, average='weighted')\n",
    "     # calculates f1 for 1:100 dataset with 95tp, 5fn, 55fp\n",
    "    fmeasure = f1_score(result, pred, average='weighted')\n",
    "    print('Precision: ', precision)\n",
    "    print('Recall: ', recall)\n",
    "    print('F1 Score: ', fmeasure)\n",
    "    #precisions += [precision]\n",
    "    #recalls += [recall]\n",
    "    #model.save('saved_models/resNetV'+pz+'.h5')\n",
    "    return [scores[1], precision, recall, fmeasure]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "dbaaf2ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[2.3606790e-05, 5.5208830e-06, 3.3270757e-07, ..., 0.0000000e+00,\n",
      "        0.0000000e+00, 0.0000000e+00],\n",
      "       [6.0420294e-05, 1.8507157e-05, 1.1242225e-05, ..., 0.0000000e+00,\n",
      "        0.0000000e+00, 0.0000000e+00],\n",
      "       [9.8333505e-05, 6.1406412e-05, 3.6835598e-05, ..., 0.0000000e+00,\n",
      "        0.0000000e+00, 0.0000000e+00],\n",
      "       ...,\n",
      "       [4.3888844e-09, 1.1880769e-09, 1.3228339e-10, ..., 0.0000000e+00,\n",
      "        0.0000000e+00, 0.0000000e+00],\n",
      "       [5.2975295e-09, 1.3415808e-09, 3.0002133e-11, ..., 0.0000000e+00,\n",
      "        0.0000000e+00, 0.0000000e+00],\n",
      "       [5.4958016e-09, 1.3766267e-09, 3.5165349e-12, ..., 0.0000000e+00,\n",
      "        0.0000000e+00, 0.0000000e+00]], dtype=float32), array([[1.99750648e-04, 4.66674319e-05, 4.10542043e-07, ...,\n",
      "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
      "       [4.08512540e-04, 1.20408018e-04, 6.17323212e-06, ...,\n",
      "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
      "       [3.05901252e-04, 1.18306634e-04, 3.97949407e-05, ...,\n",
      "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
      "       ...,\n",
      "       [1.21480007e-10, 1.49374485e-10, 1.47643189e-10, ...,\n",
      "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
      "       [4.32007034e-11, 2.74133303e-11, 1.61333551e-11, ...,\n",
      "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
      "       [1.57042764e-11, 5.35012919e-12, 2.31842063e-12, ...,\n",
      "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00]], dtype=float32), array([[0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       ...,\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32), array([[2.4439697e-03, 7.1998511e-04, 3.4594814e-05, ..., 0.0000000e+00,\n",
      "        0.0000000e+00, 0.0000000e+00],\n",
      "       [1.0516465e-02, 2.7656136e-03, 2.8612232e-04, ..., 0.0000000e+00,\n",
      "        0.0000000e+00, 0.0000000e+00],\n",
      "       [1.9897887e-02, 7.8508239e-03, 1.1075914e-03, ..., 0.0000000e+00,\n",
      "        0.0000000e+00, 0.0000000e+00],\n",
      "       ...,\n",
      "       [1.5949622e-10, 1.5797501e-10, 2.2005868e-10, ..., 0.0000000e+00,\n",
      "        0.0000000e+00, 0.0000000e+00],\n",
      "       [4.4928394e-11, 3.5971982e-11, 3.2916916e-11, ..., 0.0000000e+00,\n",
      "        0.0000000e+00, 0.0000000e+00],\n",
      "       [3.0258580e-12, 2.8644840e-12, 3.3525004e-12, ..., 0.0000000e+00,\n",
      "        0.0000000e+00, 0.0000000e+00]], dtype=float32), array([[0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       ...,\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32), array([[6.8027879e-07, 2.8963319e-07, 7.3360660e-08, ..., 0.0000000e+00,\n",
      "        0.0000000e+00, 0.0000000e+00],\n",
      "       [2.3452296e-05, 1.0654576e-05, 1.4581344e-06, ..., 0.0000000e+00,\n",
      "        0.0000000e+00, 0.0000000e+00],\n",
      "       [7.1406597e-05, 2.6164065e-05, 3.2630742e-06, ..., 0.0000000e+00,\n",
      "        0.0000000e+00, 0.0000000e+00],\n",
      "       ...,\n",
      "       [1.2274119e-08, 3.1900584e-09, 1.8585379e-10, ..., 0.0000000e+00,\n",
      "        0.0000000e+00, 0.0000000e+00],\n",
      "       [1.3639436e-08, 3.4236265e-09, 1.8918075e-11, ..., 0.0000000e+00,\n",
      "        0.0000000e+00, 0.0000000e+00],\n",
      "       [1.3692293e-08, 3.4247938e-09, 2.2027196e-12, ..., 0.0000000e+00,\n",
      "        0.0000000e+00, 0.0000000e+00]], dtype=float32), array([[5.5477802e-02, 1.5420549e-02, 6.0948092e-05, ..., 0.0000000e+00,\n",
      "        0.0000000e+00, 0.0000000e+00],\n",
      "       [3.5341151e-02, 8.0899196e-03, 1.5909600e-04, ..., 0.0000000e+00,\n",
      "        0.0000000e+00, 0.0000000e+00],\n",
      "       [4.3191619e-02, 1.1440305e-02, 2.5767245e-04, ..., 0.0000000e+00,\n",
      "        0.0000000e+00, 0.0000000e+00],\n",
      "       ...,\n",
      "       [9.1072468e-07, 2.2780523e-07, 4.6846367e-11, ..., 0.0000000e+00,\n",
      "        0.0000000e+00, 0.0000000e+00],\n",
      "       [1.0164714e-06, 2.5413638e-07, 9.3413818e-12, ..., 0.0000000e+00,\n",
      "        0.0000000e+00, 0.0000000e+00],\n",
      "       [1.0535011e-06, 2.6337960e-07, 9.3418014e-13, ..., 0.0000000e+00,\n",
      "        0.0000000e+00, 0.0000000e+00]], dtype=float32), array([[1.0927286e-05, 2.7631872e-06, 4.0323513e-08, ..., 0.0000000e+00,\n",
      "        0.0000000e+00, 0.0000000e+00],\n",
      "       [2.0231306e-05, 5.3822250e-06, 3.9206361e-07, ..., 0.0000000e+00,\n",
      "        0.0000000e+00, 0.0000000e+00],\n",
      "       [1.5132874e-05, 1.0452022e-05, 1.9570489e-06, ..., 0.0000000e+00,\n",
      "        0.0000000e+00, 0.0000000e+00],\n",
      "       ...,\n",
      "       [4.4246681e-10, 2.5055316e-10, 2.0041580e-10, ..., 0.0000000e+00,\n",
      "        0.0000000e+00, 0.0000000e+00],\n",
      "       [1.0327751e-10, 4.9216013e-11, 3.4519682e-11, ..., 0.0000000e+00,\n",
      "        0.0000000e+00, 0.0000000e+00],\n",
      "       [8.2121747e-11, 2.1930492e-11, 2.3242211e-12, ..., 0.0000000e+00,\n",
      "        0.0000000e+00, 0.0000000e+00]], dtype=float32), array([[3.5701090e-05, 8.3620453e-06, 3.8173312e-07, ..., 0.0000000e+00,\n",
      "        0.0000000e+00, 0.0000000e+00],\n",
      "       [7.7773992e-05, 2.3308901e-05, 3.7441209e-06, ..., 0.0000000e+00,\n",
      "        0.0000000e+00, 0.0000000e+00],\n",
      "       [5.3504991e-05, 5.0638933e-05, 2.5269233e-05, ..., 0.0000000e+00,\n",
      "        0.0000000e+00, 0.0000000e+00],\n",
      "       ...,\n",
      "       [4.3463916e-10, 2.2571338e-10, 1.6154221e-10, ..., 0.0000000e+00,\n",
      "        0.0000000e+00, 0.0000000e+00],\n",
      "       [3.6744233e-10, 1.0772514e-10, 2.2495495e-11, ..., 0.0000000e+00,\n",
      "        0.0000000e+00, 0.0000000e+00],\n",
      "       [3.5617942e-10, 9.0924754e-11, 2.7262246e-12, ..., 0.0000000e+00,\n",
      "        0.0000000e+00, 0.0000000e+00]], dtype=float32), array([[1.2635040e-02, 2.9841117e-03, 1.3458892e-04, ..., 0.0000000e+00,\n",
      "        0.0000000e+00, 0.0000000e+00],\n",
      "       [1.8814232e-02, 4.9907430e-03, 7.7829260e-04, ..., 0.0000000e+00,\n",
      "        0.0000000e+00, 0.0000000e+00],\n",
      "       [1.1041012e-02, 1.2948984e-02, 7.1525802e-03, ..., 0.0000000e+00,\n",
      "        0.0000000e+00, 0.0000000e+00],\n",
      "       ...,\n",
      "       [1.4284190e-06, 3.5726831e-07, 1.9576338e-10, ..., 0.0000000e+00,\n",
      "        0.0000000e+00, 0.0000000e+00],\n",
      "       [1.5640842e-06, 3.9104825e-07, 2.8116905e-11, ..., 0.0000000e+00,\n",
      "        0.0000000e+00, 0.0000000e+00],\n",
      "       [1.6071389e-06, 4.0179810e-07, 1.0933399e-11, ..., 0.0000000e+00,\n",
      "        0.0000000e+00, 0.0000000e+00]], dtype=float32), array([[4.2793956e-01, 1.0156794e-01, 4.8305237e-04, ..., 0.0000000e+00,\n",
      "        0.0000000e+00, 0.0000000e+00],\n",
      "       [5.3349376e-01, 1.4346609e-01, 1.2950274e-03, ..., 0.0000000e+00,\n",
      "        0.0000000e+00, 0.0000000e+00],\n",
      "       [6.2423563e-01, 1.5095356e-01, 3.8887445e-02, ..., 0.0000000e+00,\n",
      "        0.0000000e+00, 0.0000000e+00],\n",
      "       ...,\n",
      "       [1.8696357e-05, 4.6742452e-06, 5.6502214e-10, ..., 0.0000000e+00,\n",
      "        0.0000000e+00, 0.0000000e+00],\n",
      "       [1.6902262e-05, 4.2257811e-06, 4.4998683e-10, ..., 0.0000000e+00,\n",
      "        0.0000000e+00, 0.0000000e+00],\n",
      "       [1.5933543e-05, 3.9838019e-06, 6.9709644e-10, ..., 0.0000000e+00,\n",
      "        0.0000000e+00, 0.0000000e+00]], dtype=float32), array([[2.98194960e-02, 5.02347276e-02, 1.23002745e-01, ...,\n",
      "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
      "       [1.05791548e-02, 1.22173741e-01, 1.37583867e-01, ...,\n",
      "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
      "       [1.92222387e-01, 1.81748271e-01, 3.67095500e-01, ...,\n",
      "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
      "       ...,\n",
      "       [3.79525663e-05, 9.48967499e-06, 1.49967883e-09, ...,\n",
      "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
      "       [4.14235183e-05, 1.03566581e-05, 7.00073277e-10, ...,\n",
      "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
      "       [4.24871469e-05, 1.06226071e-05, 7.54114937e-10, ...,\n",
      "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00]], dtype=float32), array([[2.89411128e-05, 1.14829872e-05, 5.13256509e-07, ...,\n",
      "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
      "       [6.21758445e-05, 1.75449677e-05, 2.41319754e-07, ...,\n",
      "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
      "       [6.75067640e-05, 1.50684718e-05, 2.20745704e-07, ...,\n",
      "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
      "       ...,\n",
      "       [6.75428991e-10, 2.42212417e-10, 6.49859680e-11, ...,\n",
      "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
      "       [7.45352891e-10, 2.01459210e-10, 1.16493456e-11, ...,\n",
      "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
      "       [6.05060779e-10, 1.52349022e-10, 5.96525487e-13, ...,\n",
      "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00]], dtype=float32), array([[0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       ...,\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32), array([[7.7893436e-03, 1.8639364e-03, 2.2357015e-05, ..., 0.0000000e+00,\n",
      "        0.0000000e+00, 0.0000000e+00],\n",
      "       [1.1563937e-02, 3.0068867e-03, 2.4671163e-04, ..., 0.0000000e+00,\n",
      "        0.0000000e+00, 0.0000000e+00],\n",
      "       [1.6106721e-02, 4.6769446e-03, 1.1759634e-03, ..., 0.0000000e+00,\n",
      "        0.0000000e+00, 0.0000000e+00],\n",
      "       ...,\n",
      "       [7.6487417e-08, 1.9205565e-08, 1.1799259e-10, ..., 0.0000000e+00,\n",
      "        0.0000000e+00, 0.0000000e+00],\n",
      "       [8.3858652e-08, 2.0975330e-08, 1.7916283e-11, ..., 0.0000000e+00,\n",
      "        0.0000000e+00, 0.0000000e+00],\n",
      "       [8.5024958e-08, 2.1258311e-08, 2.7792254e-12, ..., 0.0000000e+00,\n",
      "        0.0000000e+00, 0.0000000e+00]], dtype=float32), array([[3.7763568e-04, 1.7338720e-04, 1.1196263e-05, ..., 0.0000000e+00,\n",
      "        0.0000000e+00, 0.0000000e+00],\n",
      "       [1.1516271e-04, 2.3188721e-04, 5.1050702e-05, ..., 0.0000000e+00,\n",
      "        0.0000000e+00, 0.0000000e+00],\n",
      "       [2.4172498e-04, 6.2553177e-04, 1.5752498e-03, ..., 0.0000000e+00,\n",
      "        0.0000000e+00, 0.0000000e+00],\n",
      "       ...,\n",
      "       [1.1918550e-08, 3.0914540e-09, 1.6737736e-10, ..., 0.0000000e+00,\n",
      "        0.0000000e+00, 0.0000000e+00],\n",
      "       [1.1679780e-08, 2.9426146e-09, 2.7253661e-11, ..., 0.0000000e+00,\n",
      "        0.0000000e+00, 0.0000000e+00],\n",
      "       [1.1508783e-08, 2.8788358e-09, 2.4621826e-12, ..., 0.0000000e+00,\n",
      "        0.0000000e+00, 0.0000000e+00]], dtype=float32), array([[1.5096028e+00, 3.8460389e-01, 2.0592806e-03, ..., 0.0000000e+00,\n",
      "        0.0000000e+00, 0.0000000e+00],\n",
      "       [2.2512584e+00, 5.0526226e-01, 4.5476783e-02, ..., 0.0000000e+00,\n",
      "        0.0000000e+00, 0.0000000e+00],\n",
      "       [5.5968313e+00, 2.7240272e+00, 3.2240913e+00, ..., 0.0000000e+00,\n",
      "        0.0000000e+00, 0.0000000e+00],\n",
      "       ...,\n",
      "       [7.3182884e-05, 1.8296585e-05, 1.9715776e-10, ..., 0.0000000e+00,\n",
      "        0.0000000e+00, 0.0000000e+00],\n",
      "       [8.1035643e-05, 2.0259395e-05, 8.4313674e-11, ..., 0.0000000e+00,\n",
      "        0.0000000e+00, 0.0000000e+00],\n",
      "       [8.3471961e-05, 2.0868156e-05, 2.2940184e-11, ..., 0.0000000e+00,\n",
      "        0.0000000e+00, 0.0000000e+00]], dtype=float32), array([[9.50559527e-02, 2.40574665e-02, 6.79251272e-04, ...,\n",
      "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
      "       [1.03573695e-01, 3.29734087e-02, 2.61875428e-03, ...,\n",
      "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
      "       [4.10797223e-02, 2.66257338e-02, 2.61726938e-02, ...,\n",
      "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
      "       ...,\n",
      "       [6.16168254e-04, 1.54048495e-04, 5.13145915e-10, ...,\n",
      "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
      "       [6.82702928e-04, 1.70679748e-04, 2.59180788e-10, ...,\n",
      "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
      "       [7.03275087e-04, 1.75820402e-04, 6.16907359e-10, ...,\n",
      "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00]], dtype=float32), array([[3.3500411e-02, 7.9614501e-03, 5.5345117e-05, ..., 0.0000000e+00,\n",
      "        0.0000000e+00, 0.0000000e+00],\n",
      "       [4.3582622e-02, 1.3600035e-02, 2.8096503e-03, ..., 0.0000000e+00,\n",
      "        0.0000000e+00, 0.0000000e+00],\n",
      "       [3.4923684e-02, 1.3576727e-02, 2.1913573e-02, ..., 0.0000000e+00,\n",
      "        0.0000000e+00, 0.0000000e+00],\n",
      "       ...,\n",
      "       [4.4850509e-05, 1.1213193e-05, 2.7464850e-10, ..., 0.0000000e+00,\n",
      "        0.0000000e+00, 0.0000000e+00],\n",
      "       [4.8133337e-05, 1.2033514e-05, 7.1691167e-11, ..., 0.0000000e+00,\n",
      "        0.0000000e+00, 0.0000000e+00],\n",
      "       [4.8985476e-05, 1.2246574e-05, 1.9136512e-10, ..., 0.0000000e+00,\n",
      "        0.0000000e+00, 0.0000000e+00]], dtype=float32), array([[7.0345175e-04, 1.4968787e-04, 1.5663576e-05, ..., 0.0000000e+00,\n",
      "        0.0000000e+00, 0.0000000e+00],\n",
      "       [1.5640734e-03, 4.8528111e-04, 2.2369126e-05, ..., 0.0000000e+00,\n",
      "        0.0000000e+00, 0.0000000e+00],\n",
      "       [9.7431085e-04, 9.8709203e-04, 4.7232650e-04, ..., 0.0000000e+00,\n",
      "        0.0000000e+00, 0.0000000e+00],\n",
      "       ...,\n",
      "       [5.4988242e-08, 1.3909659e-08, 1.8090596e-10, ..., 0.0000000e+00,\n",
      "        0.0000000e+00, 0.0000000e+00],\n",
      "       [6.0355156e-08, 1.5108158e-08, 1.5847731e-11, ..., 0.0000000e+00,\n",
      "        0.0000000e+00, 0.0000000e+00],\n",
      "       [6.2187574e-08, 1.5547885e-08, 1.2806931e-12, ..., 0.0000000e+00,\n",
      "        0.0000000e+00, 0.0000000e+00]], dtype=float32), array([[1.3332262e-03, 3.4819037e-04, 1.7038372e-05, ..., 0.0000000e+00,\n",
      "        0.0000000e+00, 0.0000000e+00],\n",
      "       [1.8431246e-03, 4.4757855e-04, 5.3708871e-05, ..., 0.0000000e+00,\n",
      "        0.0000000e+00, 0.0000000e+00],\n",
      "       [1.2398406e-03, 7.9557218e-04, 1.8644371e-04, ..., 0.0000000e+00,\n",
      "        0.0000000e+00, 0.0000000e+00],\n",
      "       ...,\n",
      "       [1.1651610e-08, 3.0427527e-09, 1.1071182e-10, ..., 0.0000000e+00,\n",
      "        0.0000000e+00, 0.0000000e+00],\n",
      "       [1.3500956e-08, 3.3955900e-09, 2.4739929e-11, ..., 0.0000000e+00,\n",
      "        0.0000000e+00, 0.0000000e+00],\n",
      "       [1.3400136e-08, 3.3520182e-09, 3.0437675e-12, ..., 0.0000000e+00,\n",
      "        0.0000000e+00, 0.0000000e+00]], dtype=float32), array([[4.8168623e-01, 1.2064491e-01, 1.7315082e-04, ..., 0.0000000e+00,\n",
      "        0.0000000e+00, 0.0000000e+00],\n",
      "       [6.2849009e-01, 1.5806516e-01, 1.7554653e-03, ..., 0.0000000e+00,\n",
      "        0.0000000e+00, 0.0000000e+00],\n",
      "       [6.1594594e-01, 1.6997786e-01, 1.0644225e-02, ..., 0.0000000e+00,\n",
      "        0.0000000e+00, 0.0000000e+00],\n",
      "       ...,\n",
      "       [7.7523409e-06, 1.9383945e-06, 5.0325838e-10, ..., 0.0000000e+00,\n",
      "        0.0000000e+00, 0.0000000e+00],\n",
      "       [6.0666007e-06, 1.5169335e-06, 4.3972026e-10, ..., 0.0000000e+00,\n",
      "        0.0000000e+00, 0.0000000e+00],\n",
      "       [5.3375902e-06, 1.3353407e-06, 1.4475505e-09, ..., 0.0000000e+00,\n",
      "        0.0000000e+00, 0.0000000e+00]], dtype=float32), array([[2.9502308e-04, 6.9645001e-05, 1.3921847e-06, ..., 0.0000000e+00,\n",
      "        0.0000000e+00, 0.0000000e+00],\n",
      "       [6.7481620e-04, 1.9329277e-04, 3.1015978e-05, ..., 0.0000000e+00,\n",
      "        0.0000000e+00, 0.0000000e+00],\n",
      "       [2.1438878e-03, 9.7772887e-04, 1.3592317e-03, ..., 0.0000000e+00,\n",
      "        0.0000000e+00, 0.0000000e+00],\n",
      "       ...,\n",
      "       [2.6722627e-10, 2.0423878e-10, 1.5736454e-10, ..., 0.0000000e+00,\n",
      "        0.0000000e+00, 0.0000000e+00],\n",
      "       [1.6654120e-10, 6.4061749e-11, 3.0581555e-11, ..., 0.0000000e+00,\n",
      "        0.0000000e+00, 0.0000000e+00],\n",
      "       [1.4282991e-10, 3.6804469e-11, 2.0828840e-12, ..., 0.0000000e+00,\n",
      "        0.0000000e+00, 0.0000000e+00]], dtype=float32), array([[6.9601483e-05, 2.6440986e-05, 2.1459680e-06, ..., 0.0000000e+00,\n",
      "        0.0000000e+00, 0.0000000e+00],\n",
      "       [8.3259751e-05, 2.4697682e-05, 1.2520694e-05, ..., 0.0000000e+00,\n",
      "        0.0000000e+00, 0.0000000e+00],\n",
      "       [2.3586974e-05, 5.7696638e-05, 9.1751863e-05, ..., 0.0000000e+00,\n",
      "        0.0000000e+00, 0.0000000e+00],\n",
      "       ...,\n",
      "       [2.0733591e-10, 1.7635401e-10, 1.4579170e-10, ..., 0.0000000e+00,\n",
      "        0.0000000e+00, 0.0000000e+00],\n",
      "       [3.5173604e-11, 3.7544655e-11, 3.1854446e-11, ..., 0.0000000e+00,\n",
      "        0.0000000e+00, 0.0000000e+00],\n",
      "       [3.0965835e-12, 2.7369407e-12, 2.3388895e-12, ..., 0.0000000e+00,\n",
      "        0.0000000e+00, 0.0000000e+00]], dtype=float32), array([[0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       ...,\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32), array([[2.0908208e-03, 6.5747742e-04, 7.0532624e-05, ..., 0.0000000e+00,\n",
      "        0.0000000e+00, 0.0000000e+00],\n",
      "       [2.5119893e-03, 6.6220976e-04, 2.5263033e-04, ..., 0.0000000e+00,\n",
      "        0.0000000e+00, 0.0000000e+00],\n",
      "       [2.2417057e-02, 8.7757846e-03, 1.1079008e-03, ..., 0.0000000e+00,\n",
      "        0.0000000e+00, 0.0000000e+00],\n",
      "       ...,\n",
      "       [3.4139171e-07, 8.5450942e-08, 1.7938644e-10, ..., 0.0000000e+00,\n",
      "        0.0000000e+00, 0.0000000e+00],\n",
      "       [3.7514826e-07, 9.3807898e-08, 2.8155325e-11, ..., 0.0000000e+00,\n",
      "        0.0000000e+00, 0.0000000e+00],\n",
      "       [3.8577588e-07, 9.6446627e-08, 3.0320388e-12, ..., 0.0000000e+00,\n",
      "        0.0000000e+00, 0.0000000e+00]], dtype=float32), array([[1.3520040e-03, 2.8668492e-04, 1.4552956e-05, ..., 0.0000000e+00,\n",
      "        0.0000000e+00, 0.0000000e+00],\n",
      "       [2.0776519e-03, 2.9393684e-03, 1.3246182e-03, ..., 0.0000000e+00,\n",
      "        0.0000000e+00, 0.0000000e+00],\n",
      "       [4.2694286e-02, 2.0341311e-02, 1.1282670e-02, ..., 0.0000000e+00,\n",
      "        0.0000000e+00, 0.0000000e+00],\n",
      "       ...,\n",
      "       [5.0815564e-05, 1.2704681e-05, 2.4220437e-10, ..., 0.0000000e+00,\n",
      "        0.0000000e+00, 0.0000000e+00],\n",
      "       [5.6774032e-05, 1.4193864e-05, 5.2748854e-11, ..., 0.0000000e+00,\n",
      "        0.0000000e+00, 0.0000000e+00],\n",
      "       [5.8779115e-05, 1.4694899e-05, 7.2173219e-11, ..., 0.0000000e+00,\n",
      "        0.0000000e+00, 0.0000000e+00]], dtype=float32), array([[5.5638859e-05, 1.4156862e-05, 1.9343655e-07, ..., 0.0000000e+00,\n",
      "        0.0000000e+00, 0.0000000e+00],\n",
      "       [1.0005916e-04, 2.3590721e-05, 4.6193172e-06, ..., 0.0000000e+00,\n",
      "        0.0000000e+00, 0.0000000e+00],\n",
      "       [2.5403849e-04, 8.2009385e-05, 1.6975715e-05, ..., 0.0000000e+00,\n",
      "        0.0000000e+00, 0.0000000e+00],\n",
      "       ...,\n",
      "       [2.3700899e-09, 7.1006345e-10, 1.4703976e-10, ..., 0.0000000e+00,\n",
      "        0.0000000e+00, 0.0000000e+00],\n",
      "       [2.6504960e-09, 6.8888656e-10, 3.1219218e-11, ..., 0.0000000e+00,\n",
      "        0.0000000e+00, 0.0000000e+00],\n",
      "       [2.6541913e-09, 6.6570749e-10, 2.4403129e-12, ..., 0.0000000e+00,\n",
      "        0.0000000e+00, 0.0000000e+00]], dtype=float32), array([[8.1849024e-02, 1.9398846e-02, 5.1063159e-04, ..., 0.0000000e+00,\n",
      "        0.0000000e+00, 0.0000000e+00],\n",
      "       [1.4534332e-01, 4.3534629e-02, 3.5575170e-03, ..., 0.0000000e+00,\n",
      "        0.0000000e+00, 0.0000000e+00],\n",
      "       [9.4136730e-02, 3.8030148e-02, 4.2137187e-02, ..., 0.0000000e+00,\n",
      "        0.0000000e+00, 0.0000000e+00],\n",
      "       ...,\n",
      "       [1.6085714e-05, 4.0216878e-06, 1.0895784e-10, ..., 0.0000000e+00,\n",
      "        0.0000000e+00, 0.0000000e+00],\n",
      "       [1.7454142e-05, 4.3636455e-06, 3.4910103e-11, ..., 0.0000000e+00,\n",
      "        0.0000000e+00, 0.0000000e+00],\n",
      "       [1.7852779e-05, 4.4632488e-06, 2.9622235e-11, ..., 0.0000000e+00,\n",
      "        0.0000000e+00, 0.0000000e+00]], dtype=float32), array([[2.7408656e-02, 6.8191784e-03, 7.3211500e-05, ..., 0.0000000e+00,\n",
      "        0.0000000e+00, 0.0000000e+00],\n",
      "       [4.6361372e-02, 1.0784756e-02, 3.2624742e-04, ..., 0.0000000e+00,\n",
      "        0.0000000e+00, 0.0000000e+00],\n",
      "       [9.1967419e-02, 2.9300945e-02, 2.2811557e-03, ..., 0.0000000e+00,\n",
      "        0.0000000e+00, 0.0000000e+00],\n",
      "       ...,\n",
      "       [2.8064383e-07, 7.0307351e-08, 1.6619479e-10, ..., 0.0000000e+00,\n",
      "        0.0000000e+00, 0.0000000e+00],\n",
      "       [3.0414918e-07, 7.6061532e-08, 2.0210956e-11, ..., 0.0000000e+00,\n",
      "        0.0000000e+00, 0.0000000e+00],\n",
      "       [3.0999388e-07, 7.7500424e-08, 2.1486357e-12, ..., 0.0000000e+00,\n",
      "        0.0000000e+00, 0.0000000e+00]], dtype=float32), array([[0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       ...,\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32), array([[1.70442901e-04, 5.59273321e-05, 3.01006075e-05, ...,\n",
      "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
      "       [1.34603982e-03, 7.78228394e-04, 4.56034497e-04, ...,\n",
      "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
      "       [3.23063671e-03, 5.75427897e-03, 6.27364963e-03, ...,\n",
      "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
      "       ...,\n",
      "       [3.26406365e-07, 8.17220425e-08, 1.17313881e-10, ...,\n",
      "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
      "       [4.04527555e-07, 1.01164375e-07, 3.58341481e-11, ...,\n",
      "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
      "       [4.37268653e-07, 1.09322734e-07, 3.67861470e-12, ...,\n",
      "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00]], dtype=float32), array([[0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       ...,\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32), array([[9.4414232e-10, 3.7748110e-10, 1.3683044e-11, ..., 0.0000000e+00,\n",
      "        0.0000000e+00, 0.0000000e+00],\n",
      "       [2.6059253e-09, 8.8009167e-10, 1.4926086e-11, ..., 0.0000000e+00,\n",
      "        0.0000000e+00, 0.0000000e+00],\n",
      "       [1.2821805e-09, 4.8786070e-10, 1.0953710e-11, ..., 0.0000000e+00,\n",
      "        0.0000000e+00, 0.0000000e+00],\n",
      "       ...,\n",
      "       [3.6961677e-11, 1.5110526e-11, 3.6926752e-13, ..., 0.0000000e+00,\n",
      "        0.0000000e+00, 0.0000000e+00],\n",
      "       [7.4840767e-12, 2.7044051e-12, 5.0052417e-14, ..., 0.0000000e+00,\n",
      "        0.0000000e+00, 0.0000000e+00],\n",
      "       [7.8069810e-13, 2.6828198e-13, 4.3337577e-15, ..., 0.0000000e+00,\n",
      "        0.0000000e+00, 0.0000000e+00]], dtype=float32), array([[4.2109989e-02, 1.0917477e-02, 2.4025838e-05, ..., 0.0000000e+00,\n",
      "        0.0000000e+00, 0.0000000e+00],\n",
      "       [6.8104595e-02, 1.7952774e-02, 2.8850493e-04, ..., 0.0000000e+00,\n",
      "        0.0000000e+00, 0.0000000e+00],\n",
      "       [9.3014911e-02, 1.9574285e-02, 1.5316498e-02, ..., 0.0000000e+00,\n",
      "        0.0000000e+00, 0.0000000e+00],\n",
      "       ...,\n",
      "       [2.5325605e-08, 6.4296328e-09, 1.1813328e-10, ..., 0.0000000e+00,\n",
      "        0.0000000e+00, 0.0000000e+00],\n",
      "       [3.2862040e-08, 8.2422318e-09, 2.8974710e-11, ..., 0.0000000e+00,\n",
      "        0.0000000e+00, 0.0000000e+00],\n",
      "       [3.5708627e-08, 8.9317576e-09, 5.7512272e-12, ..., 0.0000000e+00,\n",
      "        0.0000000e+00, 0.0000000e+00]], dtype=float32), array([[4.7001526e-02, 1.1694886e-02, 1.4138059e-05, ..., 0.0000000e+00,\n",
      "        0.0000000e+00, 0.0000000e+00],\n",
      "       [6.4878695e-02, 1.6085833e-02, 2.2371230e-04, ..., 0.0000000e+00,\n",
      "        0.0000000e+00, 0.0000000e+00],\n",
      "       [8.0479607e-02, 1.8845264e-02, 3.2101760e-03, ..., 0.0000000e+00,\n",
      "        0.0000000e+00, 0.0000000e+00],\n",
      "       ...,\n",
      "       [2.7122551e-05, 6.7810229e-06, 1.4412024e-10, ..., 0.0000000e+00,\n",
      "        0.0000000e+00, 0.0000000e+00],\n",
      "       [2.9594074e-05, 7.3987026e-06, 4.9249192e-11, ..., 0.0000000e+00,\n",
      "        0.0000000e+00, 0.0000000e+00],\n",
      "       [3.0290603e-05, 7.5727348e-06, 3.8183921e-11, ..., 0.0000000e+00,\n",
      "        0.0000000e+00, 0.0000000e+00]], dtype=float32), array([[8.9645664e-06, 2.9175446e-06, 1.8885909e-06, ..., 0.0000000e+00,\n",
      "        0.0000000e+00, 0.0000000e+00],\n",
      "       [4.3442127e-05, 2.4786146e-05, 1.7512612e-05, ..., 0.0000000e+00,\n",
      "        0.0000000e+00, 0.0000000e+00],\n",
      "       [2.4800631e-05, 1.0426375e-04, 1.5395522e-04, ..., 0.0000000e+00,\n",
      "        0.0000000e+00, 0.0000000e+00],\n",
      "       ...,\n",
      "       [7.2034840e-09, 1.8983584e-09, 1.1932716e-10, ..., 0.0000000e+00,\n",
      "        0.0000000e+00, 0.0000000e+00],\n",
      "       [7.6286923e-09, 1.9253892e-09, 2.3450264e-11, ..., 0.0000000e+00,\n",
      "        0.0000000e+00, 0.0000000e+00],\n",
      "       [7.7543687e-09, 1.9402122e-09, 2.5412235e-12, ..., 0.0000000e+00,\n",
      "        0.0000000e+00, 0.0000000e+00]], dtype=float32), array([[0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       ...,\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32), array([[1.6375878e-04, 5.9252357e-05, 3.5095718e-06, ..., 0.0000000e+00,\n",
      "        0.0000000e+00, 0.0000000e+00],\n",
      "       [3.7626649e-04, 1.5963832e-04, 1.2297562e-04, ..., 0.0000000e+00,\n",
      "        0.0000000e+00, 0.0000000e+00],\n",
      "       [5.8666657e-04, 1.3192988e-03, 8.7657693e-04, ..., 0.0000000e+00,\n",
      "        0.0000000e+00, 0.0000000e+00],\n",
      "       ...,\n",
      "       [2.5491353e-09, 7.6609069e-10, 1.1254506e-10, ..., 0.0000000e+00,\n",
      "        0.0000000e+00, 0.0000000e+00],\n",
      "       [2.2965625e-09, 5.9383387e-10, 2.1596398e-11, ..., 0.0000000e+00,\n",
      "        0.0000000e+00, 0.0000000e+00],\n",
      "       [2.2712057e-09, 5.6978267e-10, 3.4507714e-12, ..., 0.0000000e+00,\n",
      "        0.0000000e+00, 0.0000000e+00]], dtype=float32), array([[1.7714236e-05, 4.5769011e-06, 1.3235372e-07, ..., 0.0000000e+00,\n",
      "        0.0000000e+00, 0.0000000e+00],\n",
      "       [2.8916458e-05, 1.1609012e-05, 1.0133083e-05, ..., 0.0000000e+00,\n",
      "        0.0000000e+00, 0.0000000e+00],\n",
      "       [8.8353379e-05, 5.5940403e-05, 8.3250045e-05, ..., 0.0000000e+00,\n",
      "        0.0000000e+00, 0.0000000e+00],\n",
      "       ...,\n",
      "       [3.1060503e-09, 8.6556701e-10, 1.3535278e-10, ..., 0.0000000e+00,\n",
      "        0.0000000e+00, 0.0000000e+00],\n",
      "       [2.9040383e-09, 7.5166168e-10, 2.1542620e-11, ..., 0.0000000e+00,\n",
      "        0.0000000e+00, 0.0000000e+00],\n",
      "       [3.1864087e-09, 7.9849560e-10, 2.0477821e-12, ..., 0.0000000e+00,\n",
      "        0.0000000e+00, 0.0000000e+00]], dtype=float32), array([[0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       ...,\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32), array([[2.05169526e-05, 4.61021637e-06, 1.30236852e-08, ...,\n",
      "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
      "       [1.53339133e-05, 6.69803421e-06, 2.62457729e-06, ...,\n",
      "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
      "       [2.38640132e-06, 2.57887723e-06, 3.98481598e-06, ...,\n",
      "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
      "       ...,\n",
      "       [2.49422011e-10, 1.98223771e-10, 2.07750067e-10, ...,\n",
      "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
      "       [1.43947090e-10, 5.79588218e-11, 3.42980817e-11, ...,\n",
      "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
      "       [1.07226186e-10, 2.82920822e-11, 2.82980800e-12, ...,\n",
      "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00]], dtype=float32), array([[6.4010610e-06, 1.5630009e-06, 1.4170273e-07, ..., 0.0000000e+00,\n",
      "        0.0000000e+00, 0.0000000e+00],\n",
      "       [4.0444913e-05, 1.8808521e-05, 8.0369637e-06, ..., 0.0000000e+00,\n",
      "        0.0000000e+00, 0.0000000e+00],\n",
      "       [6.2459192e-05, 4.3862063e-05, 2.9966890e-05, ..., 0.0000000e+00,\n",
      "        0.0000000e+00, 0.0000000e+00],\n",
      "       ...,\n",
      "       [3.6499899e-09, 1.0267127e-09, 1.9334388e-10, ..., 0.0000000e+00,\n",
      "        0.0000000e+00, 0.0000000e+00],\n",
      "       [4.6355004e-09, 1.1768531e-09, 2.3607852e-11, ..., 0.0000000e+00,\n",
      "        0.0000000e+00, 0.0000000e+00],\n",
      "       [4.6213984e-09, 1.1570542e-09, 2.2020972e-12, ..., 0.0000000e+00,\n",
      "        0.0000000e+00, 0.0000000e+00]], dtype=float32), array([[2.2679409e-01, 5.8205828e-02, 2.5326197e-04, ..., 0.0000000e+00,\n",
      "        0.0000000e+00, 0.0000000e+00],\n",
      "       [2.7503636e-01, 6.3022695e-02, 1.0374230e-03, ..., 0.0000000e+00,\n",
      "        0.0000000e+00, 0.0000000e+00],\n",
      "       [3.5769859e-01, 1.0761906e-01, 3.8809208e-03, ..., 0.0000000e+00,\n",
      "        0.0000000e+00, 0.0000000e+00],\n",
      "       ...,\n",
      "       [4.9562040e-08, 1.2534726e-08, 1.9250446e-10, ..., 0.0000000e+00,\n",
      "        0.0000000e+00, 0.0000000e+00],\n",
      "       [1.7818053e-08, 4.4809947e-09, 3.4644117e-11, ..., 0.0000000e+00,\n",
      "        0.0000000e+00, 0.0000000e+00],\n",
      "       [8.4554070e-09, 2.2046205e-09, 5.8440475e-11, ..., 0.0000000e+00,\n",
      "        0.0000000e+00, 0.0000000e+00]], dtype=float32), array([[1.8543772e-02, 4.7985432e-03, 2.6351863e-05, ..., 0.0000000e+00,\n",
      "        0.0000000e+00, 0.0000000e+00],\n",
      "       [2.5849506e-02, 6.2539550e-03, 8.0680114e-04, ..., 0.0000000e+00,\n",
      "        0.0000000e+00, 0.0000000e+00],\n",
      "       [1.7007921e-02, 1.6231894e-02, 4.2620664e-03, ..., 0.0000000e+00,\n",
      "        0.0000000e+00, 0.0000000e+00],\n",
      "       ...,\n",
      "       [1.5505728e-05, 3.8766848e-06, 1.2184970e-10, ..., 0.0000000e+00,\n",
      "        0.0000000e+00, 0.0000000e+00],\n",
      "       [1.7414905e-05, 4.3538575e-06, 2.1483863e-11, ..., 0.0000000e+00,\n",
      "        0.0000000e+00, 0.0000000e+00],\n",
      "       [1.8031475e-05, 4.5078982e-06, 7.5174172e-12, ..., 0.0000000e+00,\n",
      "        0.0000000e+00, 0.0000000e+00]], dtype=float32), array([[6.5775471e-06, 5.6384374e-06, 1.3059259e-06, ..., 0.0000000e+00,\n",
      "        0.0000000e+00, 0.0000000e+00],\n",
      "       [6.9435009e-06, 5.6730637e-06, 1.1303640e-06, ..., 0.0000000e+00,\n",
      "        0.0000000e+00, 0.0000000e+00],\n",
      "       [2.3255237e-05, 1.1732680e-05, 8.2718850e-07, ..., 0.0000000e+00,\n",
      "        0.0000000e+00, 0.0000000e+00],\n",
      "       ...,\n",
      "       [3.0748698e-10, 2.0041703e-10, 1.3700377e-10, ..., 0.0000000e+00,\n",
      "        0.0000000e+00, 0.0000000e+00],\n",
      "       [1.8741013e-10, 5.9412093e-11, 1.8792140e-11, ..., 0.0000000e+00,\n",
      "        0.0000000e+00, 0.0000000e+00],\n",
      "       [1.6549280e-10, 4.3003365e-11, 2.6177758e-12, ..., 0.0000000e+00,\n",
      "        0.0000000e+00, 0.0000000e+00]], dtype=float32), array([[1.0227930e-04, 3.4193537e-05, 3.9812539e-06, ..., 0.0000000e+00,\n",
      "        0.0000000e+00, 0.0000000e+00],\n",
      "       [1.5616225e-04, 3.8362374e-05, 1.2458412e-05, ..., 0.0000000e+00,\n",
      "        0.0000000e+00, 0.0000000e+00],\n",
      "       [4.3264619e-04, 1.1932101e-04, 1.4576898e-05, ..., 0.0000000e+00,\n",
      "        0.0000000e+00, 0.0000000e+00],\n",
      "       ...,\n",
      "       [8.8693177e-08, 2.2273550e-08, 1.4956138e-10, ..., 0.0000000e+00,\n",
      "        0.0000000e+00, 0.0000000e+00],\n",
      "       [9.4774848e-08, 2.3712639e-08, 2.4083634e-11, ..., 0.0000000e+00,\n",
      "        0.0000000e+00, 0.0000000e+00],\n",
      "       [9.5596235e-08, 2.3901464e-08, 2.1422512e-12, ..., 0.0000000e+00,\n",
      "        0.0000000e+00, 0.0000000e+00]], dtype=float32)]\n",
      "[[[[1.53833404e-04 5.07819095e-05 1.47654964e-06 ... 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00]\n",
      "   [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00]\n",
      "   [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00]\n",
      "   ...\n",
      "   [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00]\n",
      "   [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00]\n",
      "   [1.96774317e-06 8.00066516e-07 2.94504446e-07 ... 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00]]\n",
      "\n",
      "  [[0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00]\n",
      "   [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00]\n",
      "   [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00]\n",
      "   ...\n",
      "   [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00]\n",
      "   [3.06775246e-06 9.81837388e-07 2.15167290e-07 ... 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00]\n",
      "   [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00]]\n",
      "\n",
      "  [[0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00]\n",
      "   [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00]\n",
      "   [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00]\n",
      "   ...\n",
      "   [3.00560532e-05 1.86631005e-05 1.70885733e-06 ... 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00]\n",
      "   [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00]\n",
      "   [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00]\n",
      "   [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00]\n",
      "   [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00]\n",
      "   ...\n",
      "   [6.57222987e-09 4.17811341e-09 1.75634052e-09 ... 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00]\n",
      "   [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00]\n",
      "   [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00]]\n",
      "\n",
      "  [[0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00]\n",
      "   [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00]\n",
      "   [5.18270804e-09 2.83603452e-09 1.04308029e-09 ... 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00]\n",
      "   ...\n",
      "   [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00]\n",
      "   [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00]\n",
      "   [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00]]\n",
      "\n",
      "  [[0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00]\n",
      "   [1.24308173e-08 3.20630122e-09 8.90091542e-11 ... 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00]\n",
      "   [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00]\n",
      "   ...\n",
      "   [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00]\n",
      "   [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00]\n",
      "   [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00]]]\n",
      "\n",
      "\n",
      " [[[0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00]\n",
      "   [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00]\n",
      "   [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00]\n",
      "   ...\n",
      "   [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00]\n",
      "   [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00]\n",
      "   [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00]]\n",
      "\n",
      "  [[0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00]\n",
      "   [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00]\n",
      "   [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00]\n",
      "   ...\n",
      "   [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00]\n",
      "   [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00]\n",
      "   [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00]]\n",
      "\n",
      "  [[0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00]\n",
      "   [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00]\n",
      "   [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00]\n",
      "   ...\n",
      "   [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00]\n",
      "   [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00]\n",
      "   [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00]\n",
      "   [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00]\n",
      "   [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00]\n",
      "   ...\n",
      "   [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00]\n",
      "   [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00]\n",
      "   [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00]]\n",
      "\n",
      "  [[0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00]\n",
      "   [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00]\n",
      "   [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00]\n",
      "   ...\n",
      "   [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00]\n",
      "   [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00]\n",
      "   [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00]]\n",
      "\n",
      "  [[0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00]\n",
      "   [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00]\n",
      "   [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00]\n",
      "   ...\n",
      "   [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00]\n",
      "   [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00]\n",
      "   [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00]]]\n",
      "\n",
      "\n",
      " [[[1.23605569e-04 2.98704836e-05 5.84078919e-07 ... 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00]\n",
      "   [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00]\n",
      "   [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00]\n",
      "   ...\n",
      "   [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00]\n",
      "   [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00]\n",
      "   [1.13009207e-03 7.45748344e-04 9.83553473e-04 ... 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00]]\n",
      "\n",
      "  [[0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00]\n",
      "   [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00]\n",
      "   [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00]\n",
      "   ...\n",
      "   [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00]\n",
      "   [6.84377083e-05 1.02536884e-04 1.57730519e-05 ... 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00]\n",
      "   [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00]]\n",
      "\n",
      "  [[0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00]\n",
      "   [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00]\n",
      "   [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00]\n",
      "   ...\n",
      "   [7.62076816e-05 4.52557615e-05 1.28257117e-04 ... 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00]\n",
      "   [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00]\n",
      "   [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00]\n",
      "   [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00]\n",
      "   [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00]\n",
      "   ...\n",
      "   [3.28185390e-09 3.62660391e-09 3.79074194e-09 ... 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00]\n",
      "   [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00]\n",
      "   [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00]]\n",
      "\n",
      "  [[0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00]\n",
      "   [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00]\n",
      "   [7.04436243e-09 3.35728956e-09 2.18966534e-09 ... 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00]\n",
      "   ...\n",
      "   [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00]\n",
      "   [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00]\n",
      "   [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00]]\n",
      "\n",
      "  [[0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00]\n",
      "   [1.67130789e-08 4.27118652e-09 1.24297933e-10 ... 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00]\n",
      "   [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00]\n",
      "   ...\n",
      "   [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00]\n",
      "   [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00]\n",
      "   [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00]]]]\n",
      "[[1]\n",
      " [1]\n",
      " [1]]\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "(40, 16, 19)\n",
      "x_train shape: (50, 40, 16, 19)\n",
      "50 train samples\n",
      "47 test samples\n",
      "y_train shape: (50, 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate:  0.01\n",
      "Model: \"model_121\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_122 (InputLayer)          [(None, 40, 16, 19)] 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3751 (Conv2D)            (None, 40, 16, 16)   2752        input_122[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3388 (Batch (None, 40, 16, 16)   64          conv2d_3751[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_3388 (Activation)    (None, 40, 16, 16)   0           batch_normalization_3388[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3752 (Conv2D)            (None, 40, 16, 16)   272         activation_3388[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3389 (Batch (None, 40, 16, 16)   64          conv2d_3752[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_3389 (Activation)    (None, 40, 16, 16)   0           batch_normalization_3389[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3753 (Conv2D)            (None, 40, 16, 16)   2320        activation_3389[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3390 (Batch (None, 40, 16, 16)   64          conv2d_3753[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_3390 (Activation)    (None, 40, 16, 16)   0           batch_normalization_3390[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3755 (Conv2D)            (None, 40, 16, 64)   1088        activation_3388[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3754 (Conv2D)            (None, 40, 16, 64)   1088        activation_3390[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_1089 (Add)                  (None, 40, 16, 64)   0           conv2d_3755[0][0]                \n",
      "                                                                 conv2d_3754[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3391 (Batch (None, 40, 16, 64)   256         add_1089[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_3391 (Activation)    (None, 40, 16, 64)   0           batch_normalization_3391[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3756 (Conv2D)            (None, 40, 16, 16)   1040        activation_3391[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3392 (Batch (None, 40, 16, 16)   64          conv2d_3756[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_3392 (Activation)    (None, 40, 16, 16)   0           batch_normalization_3392[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3757 (Conv2D)            (None, 40, 16, 16)   2320        activation_3392[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3393 (Batch (None, 40, 16, 16)   64          conv2d_3757[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_3393 (Activation)    (None, 40, 16, 16)   0           batch_normalization_3393[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3758 (Conv2D)            (None, 40, 16, 64)   1088        activation_3393[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_1090 (Add)                  (None, 40, 16, 64)   0           add_1089[0][0]                   \n",
      "                                                                 conv2d_3758[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3394 (Batch (None, 40, 16, 64)   256         add_1090[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_3394 (Activation)    (None, 40, 16, 64)   0           batch_normalization_3394[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3759 (Conv2D)            (None, 40, 16, 16)   1040        activation_3394[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3395 (Batch (None, 40, 16, 16)   64          conv2d_3759[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_3395 (Activation)    (None, 40, 16, 16)   0           batch_normalization_3395[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3760 (Conv2D)            (None, 40, 16, 16)   2320        activation_3395[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3396 (Batch (None, 40, 16, 16)   64          conv2d_3760[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_3396 (Activation)    (None, 40, 16, 16)   0           batch_normalization_3396[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3761 (Conv2D)            (None, 40, 16, 64)   1088        activation_3396[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_1091 (Add)                  (None, 40, 16, 64)   0           add_1090[0][0]                   \n",
      "                                                                 conv2d_3761[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3397 (Batch (None, 40, 16, 64)   256         add_1091[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_3397 (Activation)    (None, 40, 16, 64)   0           batch_normalization_3397[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3762 (Conv2D)            (None, 20, 8, 64)    4160        activation_3397[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3398 (Batch (None, 20, 8, 64)    256         conv2d_3762[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_3398 (Activation)    (None, 20, 8, 64)    0           batch_normalization_3398[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3763 (Conv2D)            (None, 20, 8, 64)    36928       activation_3398[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3399 (Batch (None, 20, 8, 64)    256         conv2d_3763[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_3399 (Activation)    (None, 20, 8, 64)    0           batch_normalization_3399[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3765 (Conv2D)            (None, 20, 8, 128)   8320        add_1091[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3764 (Conv2D)            (None, 20, 8, 128)   8320        activation_3399[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_1092 (Add)                  (None, 20, 8, 128)   0           conv2d_3765[0][0]                \n",
      "                                                                 conv2d_3764[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3400 (Batch (None, 20, 8, 128)   512         add_1092[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_3400 (Activation)    (None, 20, 8, 128)   0           batch_normalization_3400[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3766 (Conv2D)            (None, 20, 8, 64)    8256        activation_3400[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3401 (Batch (None, 20, 8, 64)    256         conv2d_3766[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_3401 (Activation)    (None, 20, 8, 64)    0           batch_normalization_3401[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3767 (Conv2D)            (None, 20, 8, 64)    36928       activation_3401[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3402 (Batch (None, 20, 8, 64)    256         conv2d_3767[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_3402 (Activation)    (None, 20, 8, 64)    0           batch_normalization_3402[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3768 (Conv2D)            (None, 20, 8, 128)   8320        activation_3402[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_1093 (Add)                  (None, 20, 8, 128)   0           add_1092[0][0]                   \n",
      "                                                                 conv2d_3768[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3403 (Batch (None, 20, 8, 128)   512         add_1093[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_3403 (Activation)    (None, 20, 8, 128)   0           batch_normalization_3403[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3769 (Conv2D)            (None, 20, 8, 64)    8256        activation_3403[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3404 (Batch (None, 20, 8, 64)    256         conv2d_3769[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_3404 (Activation)    (None, 20, 8, 64)    0           batch_normalization_3404[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3770 (Conv2D)            (None, 20, 8, 64)    36928       activation_3404[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3405 (Batch (None, 20, 8, 64)    256         conv2d_3770[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_3405 (Activation)    (None, 20, 8, 64)    0           batch_normalization_3405[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3771 (Conv2D)            (None, 20, 8, 128)   8320        activation_3405[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_1094 (Add)                  (None, 20, 8, 128)   0           add_1093[0][0]                   \n",
      "                                                                 conv2d_3771[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3406 (Batch (None, 20, 8, 128)   512         add_1094[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_3406 (Activation)    (None, 20, 8, 128)   0           batch_normalization_3406[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3772 (Conv2D)            (None, 10, 4, 128)   16512       activation_3406[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3407 (Batch (None, 10, 4, 128)   512         conv2d_3772[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_3407 (Activation)    (None, 10, 4, 128)   0           batch_normalization_3407[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3773 (Conv2D)            (None, 10, 4, 128)   147584      activation_3407[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3408 (Batch (None, 10, 4, 128)   512         conv2d_3773[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_3408 (Activation)    (None, 10, 4, 128)   0           batch_normalization_3408[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3775 (Conv2D)            (None, 10, 4, 256)   33024       add_1094[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3774 (Conv2D)            (None, 10, 4, 256)   33024       activation_3408[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_1095 (Add)                  (None, 10, 4, 256)   0           conv2d_3775[0][0]                \n",
      "                                                                 conv2d_3774[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3409 (Batch (None, 10, 4, 256)   1024        add_1095[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_3409 (Activation)    (None, 10, 4, 256)   0           batch_normalization_3409[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3776 (Conv2D)            (None, 10, 4, 128)   32896       activation_3409[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3410 (Batch (None, 10, 4, 128)   512         conv2d_3776[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_3410 (Activation)    (None, 10, 4, 128)   0           batch_normalization_3410[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3777 (Conv2D)            (None, 10, 4, 128)   147584      activation_3410[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3411 (Batch (None, 10, 4, 128)   512         conv2d_3777[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_3411 (Activation)    (None, 10, 4, 128)   0           batch_normalization_3411[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3778 (Conv2D)            (None, 10, 4, 256)   33024       activation_3411[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_1096 (Add)                  (None, 10, 4, 256)   0           add_1095[0][0]                   \n",
      "                                                                 conv2d_3778[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3412 (Batch (None, 10, 4, 256)   1024        add_1096[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_3412 (Activation)    (None, 10, 4, 256)   0           batch_normalization_3412[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3779 (Conv2D)            (None, 10, 4, 128)   32896       activation_3412[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3413 (Batch (None, 10, 4, 128)   512         conv2d_3779[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_3413 (Activation)    (None, 10, 4, 128)   0           batch_normalization_3413[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3780 (Conv2D)            (None, 10, 4, 128)   147584      activation_3413[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3414 (Batch (None, 10, 4, 128)   512         conv2d_3780[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_3414 (Activation)    (None, 10, 4, 128)   0           batch_normalization_3414[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3781 (Conv2D)            (None, 10, 4, 256)   33024       activation_3414[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_1097 (Add)                  (None, 10, 4, 256)   0           add_1096[0][0]                   \n",
      "                                                                 conv2d_3781[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3415 (Batch (None, 10, 4, 256)   1024        add_1097[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_3415 (Activation)    (None, 10, 4, 256)   0           batch_normalization_3415[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_121 (AverageP (None, 5, 2, 256)    0           activation_3415[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_121 (Flatten)           (None, 2560)         0           average_pooling2d_121[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_121 (Dense)               (None, 10)           25610       flatten_121[0][0]                \n",
      "==================================================================================================\n",
      "Total params: 874,346\n",
      "Trainable params: 869,130\n",
      "Non-trainable params: 5,216\n",
      "__________________________________________________________________________________________________\n",
      "ResNet  29v  2\n",
      "Using real-time data augmentation.\n",
      "------------------\n",
      "[[[[-4.95329616e-04 -1.22905942e-04 -4.51362496e-07 ... -4.79807511e-07\n",
      "    -6.44216414e-07 -3.80291681e-07]\n",
      "   [-5.01061891e-07 -7.95367100e-07 -3.96717724e-07 ... -1.52421805e-07\n",
      "    -2.04826961e-07 -4.32852403e-08]\n",
      "   [-1.10052500e-08 -1.39187240e-08 -8.16117485e-09 ... -2.92586861e-08\n",
      "    -9.06684861e-09 -1.29635511e-08]\n",
      "   ...\n",
      "   [-6.44487784e-07 -9.96142603e-07 -8.22959350e-07 ...  0.00000000e+00\n",
      "     0.00000000e+00  0.00000000e+00]\n",
      "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
      "     0.00000000e+00  0.00000000e+00]\n",
      "   [-1.22217508e-03 -8.01678980e-04 -4.96655819e-04 ... -4.17987700e-04\n",
      "    -6.45528373e-04 -1.43661839e-03]]\n",
      "\n",
      "  [[-2.46183062e-03 -2.30790582e-03 -1.60092488e-03 ... -2.58430577e-04\n",
      "    -2.23076393e-04 -7.45165817e-05]\n",
      "   [-1.94267850e-05 -3.75822447e-06 -2.35935022e-06 ... -6.43085468e-06\n",
      "    -7.13508825e-06 -5.04285390e-06]\n",
      "   [-2.22698441e-06 -4.26859333e-06 -1.28046111e-06 ...  0.00000000e+00\n",
      "     0.00000000e+00  0.00000000e+00]\n",
      "   ...\n",
      "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
      "     0.00000000e+00  0.00000000e+00]\n",
      "   [-3.04179103e-03 -2.11616675e-03 -2.93070194e-03 ... -1.93162166e-04\n",
      "    -7.79044174e-04 -1.34235690e-03]\n",
      "   [-3.17119458e-03 -5.60504431e-03 -2.74410704e-03 ... -3.87065200e-04\n",
      "    -1.49927786e-04 -3.61821440e-05]]\n",
      "\n",
      "  [[-1.39758931e-05 -8.58444128e-06 -5.42170073e-06 ... -2.84472102e-04\n",
      "    -1.03544335e-04 -1.10521010e-04]\n",
      "   [-1.87604630e-04 -2.18137880e-04 -7.70949991e-05 ...  0.00000000e+00\n",
      "     0.00000000e+00  0.00000000e+00]\n",
      "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
      "     0.00000000e+00  0.00000000e+00]\n",
      "   ...\n",
      "   [-9.97837866e-04 -1.15434779e-03 -3.33836442e-03 ... -9.29649745e-04\n",
      "    -1.06798913e-02 -1.33357458e-02]\n",
      "   [-3.05112149e-03 -6.19383529e-04 -1.06641394e-03 ... -1.64267927e-04\n",
      "    -2.64713715e-04 -6.59158977e-05]\n",
      "   [-5.72256140e-05 -2.83544650e-05 -8.58355997e-06 ... -1.91948289e-04\n",
      "    -2.22222036e-04 -2.12054147e-04]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[-2.87277212e-12 -2.95183431e-12 -3.49401736e-12 ... -9.23537722e-13\n",
      "    -9.77106633e-13 -1.02574015e-12]\n",
      "   [-9.53126575e-13 -8.84596541e-13 -1.38188040e-12 ...  0.00000000e+00\n",
      "     0.00000000e+00  0.00000000e+00]\n",
      "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
      "     0.00000000e+00  0.00000000e+00]\n",
      "   ...\n",
      "   [-7.14056814e-09 -1.78253678e-09 -1.96025531e-12 ... -5.83826563e-12\n",
      "    -5.10836339e-12 -4.63515901e-12]\n",
      "   [-4.19630823e-12 -4.18548529e-12 -3.76494322e-12 ... -1.97738223e-12\n",
      "    -2.00968734e-12 -2.40019593e-12]\n",
      "   [-2.18856053e-12 -1.86138778e-12 -1.83610093e-12 ... -5.67056872e-13\n",
      "    -4.29064770e-13 -4.28763470e-13]]\n",
      "\n",
      "  [[-4.51218571e-13 -5.78108904e-13 -6.97381118e-13 ...  0.00000000e+00\n",
      "     0.00000000e+00  0.00000000e+00]\n",
      "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
      "     0.00000000e+00  0.00000000e+00]\n",
      "   [-1.01606616e-08 -2.53975618e-09 -2.59294279e-12 ... -3.71066892e-12\n",
      "    -3.67316290e-12 -3.73092963e-12]\n",
      "   ...\n",
      "   [-8.52925911e-13 -7.23510336e-13 -6.39060148e-13 ... -3.33009336e-13\n",
      "    -3.39593832e-13 -3.46606424e-13]\n",
      "   [-3.02108897e-13 -2.87871831e-13 -2.82979694e-13 ... -7.08822852e-14\n",
      "    -7.91990239e-14 -7.97553890e-14]\n",
      "   [-7.72968861e-14 -7.08909317e-14 -7.98647783e-14 ...  0.00000000e+00\n",
      "     0.00000000e+00  0.00000000e+00]]\n",
      "\n",
      "  [[ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
      "     0.00000000e+00  0.00000000e+00]\n",
      "   [-2.39035316e-08 -5.97624439e-09 -4.13520536e-13 ... -3.36092726e-13\n",
      "    -3.63761945e-13 -3.54037654e-13]\n",
      "   [-2.92205740e-13 -2.49336061e-13 -2.07846828e-13 ... -9.09164779e-14\n",
      "    -9.77698418e-14 -9.63577905e-14]\n",
      "   ...\n",
      "   [-3.52630933e-15 -3.84673025e-15 -4.26826340e-15 ... -1.21519878e-15\n",
      "    -1.04494347e-15 -1.43406500e-15]\n",
      "   [-9.93843027e-16 -5.38931012e-16 -3.44277547e-16 ...  0.00000000e+00\n",
      "     0.00000000e+00  0.00000000e+00]\n",
      "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
      "     0.00000000e+00  0.00000000e+00]]]\n",
      "\n",
      "\n",
      " [[[-4.95932880e-04 -1.23105085e-04 -4.57152879e-07 ... -4.79807511e-07\n",
      "    -6.44216414e-07 -3.80291681e-07]\n",
      "   [-5.01061891e-07 -7.95367100e-07 -3.96717724e-07 ... -1.52421805e-07\n",
      "    -2.04826961e-07 -4.32852403e-08]\n",
      "   [-1.10052500e-08 -1.39187240e-08 -8.16117485e-09 ... -2.92586861e-08\n",
      "    -9.06684861e-09 -1.29635511e-08]\n",
      "   ...\n",
      "   [-6.44487784e-07 -9.96142603e-07 -8.22959350e-07 ...  0.00000000e+00\n",
      "     0.00000000e+00  0.00000000e+00]\n",
      "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
      "     0.00000000e+00  0.00000000e+00]\n",
      "   [-1.22218276e-03 -8.01682123e-04 -4.96656983e-04 ... -4.17987700e-04\n",
      "    -6.45528373e-04 -1.43661839e-03]]\n",
      "\n",
      "  [[-2.46183062e-03 -2.30790582e-03 -1.60092488e-03 ... -2.58430577e-04\n",
      "    -2.23076393e-04 -7.45165817e-05]\n",
      "   [-1.94267850e-05 -3.75822447e-06 -2.35935022e-06 ... -6.43085468e-06\n",
      "    -7.13508825e-06 -5.04285390e-06]\n",
      "   [-2.22698441e-06 -4.26859333e-06 -1.28046111e-06 ...  0.00000000e+00\n",
      "     0.00000000e+00  0.00000000e+00]\n",
      "   ...\n",
      "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
      "     0.00000000e+00  0.00000000e+00]\n",
      "   [-3.04180314e-03 -2.11617071e-03 -2.93070287e-03 ... -1.93162166e-04\n",
      "    -7.79044174e-04 -1.34235690e-03]\n",
      "   [-3.17119458e-03 -5.60504431e-03 -2.74410704e-03 ... -3.87065200e-04\n",
      "    -1.49927786e-04 -3.61821440e-05]]\n",
      "\n",
      "  [[-1.39758931e-05 -8.58444128e-06 -5.42170073e-06 ... -2.84472102e-04\n",
      "    -1.03544335e-04 -1.10521010e-04]\n",
      "   [-1.87604630e-04 -2.18137880e-04 -7.70949991e-05 ...  0.00000000e+00\n",
      "     0.00000000e+00  0.00000000e+00]\n",
      "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
      "     0.00000000e+00  0.00000000e+00]\n",
      "   ...\n",
      "   [-9.97955678e-04 -1.15442101e-03 -3.33837117e-03 ... -9.29649745e-04\n",
      "    -1.06798913e-02 -1.33357458e-02]\n",
      "   [-3.05112149e-03 -6.19383529e-04 -1.06641394e-03 ... -1.64267927e-04\n",
      "    -2.64713715e-04 -6.59158977e-05]\n",
      "   [-5.72256140e-05 -2.83544650e-05 -8.58355997e-06 ... -1.91948289e-04\n",
      "    -2.22222036e-04 -2.12054147e-04]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[-2.87277212e-12 -2.95183431e-12 -3.49401736e-12 ... -9.23537722e-13\n",
      "    -9.77106633e-13 -1.02574015e-12]\n",
      "   [-9.53126575e-13 -8.84596541e-13 -1.38188040e-12 ...  0.00000000e+00\n",
      "     0.00000000e+00  0.00000000e+00]\n",
      "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
      "     0.00000000e+00  0.00000000e+00]\n",
      "   ...\n",
      "   [-7.16634174e-09 -1.79892157e-09 -8.84786515e-12 ... -5.83826563e-12\n",
      "    -5.10836339e-12 -4.63515901e-12]\n",
      "   [-4.19630823e-12 -4.18548529e-12 -3.76494322e-12 ... -1.97738223e-12\n",
      "    -2.00968734e-12 -2.40019593e-12]\n",
      "   [-2.18856053e-12 -1.86138778e-12 -1.83610093e-12 ... -5.67056872e-13\n",
      "    -4.29064770e-13 -4.28763470e-13]]\n",
      "\n",
      "  [[-4.51218571e-13 -5.78108904e-13 -6.97381118e-13 ...  0.00000000e+00\n",
      "     0.00000000e+00  0.00000000e+00]\n",
      "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
      "     0.00000000e+00  0.00000000e+00]\n",
      "   [-1.01809858e-08 -2.55087795e-09 -6.68345370e-12 ... -3.71066892e-12\n",
      "    -3.67316290e-12 -3.73092963e-12]\n",
      "   ...\n",
      "   [-8.52925911e-13 -7.23510336e-13 -6.39060148e-13 ... -3.33009336e-13\n",
      "    -3.39593832e-13 -3.46606424e-13]\n",
      "   [-3.02108897e-13 -2.87871831e-13 -2.82979694e-13 ... -7.08822852e-14\n",
      "    -7.91990239e-14 -7.97553890e-14]\n",
      "   [-7.72968861e-14 -7.08909317e-14 -7.98647783e-14 ...  0.00000000e+00\n",
      "     0.00000000e+00  0.00000000e+00]]\n",
      "\n",
      "  [[ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
      "     0.00000000e+00  0.00000000e+00]\n",
      "   [-2.39522802e-08 -5.98881833e-09 -7.62576037e-13 ... -3.36092726e-13\n",
      "    -3.63761945e-13 -3.54037654e-13]\n",
      "   [-2.92205740e-13 -2.49336061e-13 -2.07846828e-13 ... -9.09164779e-14\n",
      "    -9.77698418e-14 -9.63577905e-14]\n",
      "   ...\n",
      "   [-3.52630933e-15 -3.84673025e-15 -4.26826340e-15 ... -1.21519878e-15\n",
      "    -1.04494347e-15 -1.43406500e-15]\n",
      "   [-9.93843027e-16 -5.38931012e-16 -3.44277547e-16 ...  0.00000000e+00\n",
      "     0.00000000e+00  0.00000000e+00]\n",
      "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
      "     0.00000000e+00  0.00000000e+00]]]\n",
      "\n",
      "\n",
      " [[[-4.95448126e-04 -1.22987942e-04 -4.54862374e-07 ... -4.79807511e-07\n",
      "    -6.44216414e-07 -3.80291681e-07]\n",
      "   [-5.01061891e-07 -7.95367100e-07 -3.96717724e-07 ... -1.52421805e-07\n",
      "    -2.04826961e-07 -4.32852403e-08]\n",
      "   [-1.10052500e-08 -1.39187240e-08 -8.16117485e-09 ... -2.92586861e-08\n",
      "    -9.06684861e-09 -1.29635511e-08]\n",
      "   ...\n",
      "   [-6.44487784e-07 -9.96142603e-07 -8.22959350e-07 ...  0.00000000e+00\n",
      "     0.00000000e+00  0.00000000e+00]\n",
      "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
      "     0.00000000e+00  0.00000000e+00]\n",
      "   [-1.21775107e-03 -7.98757595e-04 -4.92799911e-04 ... -4.17987700e-04\n",
      "    -6.45528373e-04 -1.43661839e-03]]\n",
      "\n",
      "  [[-2.46183062e-03 -2.30790582e-03 -1.60092488e-03 ... -2.58430577e-04\n",
      "    -2.23076393e-04 -7.45165817e-05]\n",
      "   [-1.94267850e-05 -3.75822447e-06 -2.35935022e-06 ... -6.43085468e-06\n",
      "    -7.13508825e-06 -5.04285390e-06]\n",
      "   [-2.22698441e-06 -4.26859333e-06 -1.28046111e-06 ...  0.00000000e+00\n",
      "     0.00000000e+00  0.00000000e+00]\n",
      "   ...\n",
      "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
      "     0.00000000e+00  0.00000000e+00]\n",
      "   [-3.04153468e-03 -2.11576861e-03 -2.93064094e-03 ... -1.93162166e-04\n",
      "    -7.79044174e-04 -1.34235690e-03]\n",
      "   [-3.17119458e-03 -5.60504431e-03 -2.74410704e-03 ... -3.87065200e-04\n",
      "    -1.49927786e-04 -3.61821440e-05]]\n",
      "\n",
      "  [[-1.39758931e-05 -8.58444128e-06 -5.42170073e-06 ... -2.84472102e-04\n",
      "    -1.03544335e-04 -1.10521010e-04]\n",
      "   [-1.87604630e-04 -2.18137880e-04 -7.70949991e-05 ...  0.00000000e+00\n",
      "     0.00000000e+00  0.00000000e+00]\n",
      "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
      "     0.00000000e+00  0.00000000e+00]\n",
      "   ...\n",
      "   [-9.97656840e-04 -1.15424360e-03 -3.33786826e-03 ... -9.29649745e-04\n",
      "    -1.06798913e-02 -1.33357458e-02]\n",
      "   [-3.05112149e-03 -6.19383529e-04 -1.06641394e-03 ... -1.64267927e-04\n",
      "    -2.64713715e-04 -6.59158977e-05]\n",
      "   [-5.72256140e-05 -2.83544650e-05 -8.58355997e-06 ... -1.91948289e-04\n",
      "    -2.22222036e-04 -2.12054147e-04]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[-2.87277212e-12 -2.95183431e-12 -3.49401736e-12 ... -9.23537722e-13\n",
      "    -9.77106633e-13 -1.02574015e-12]\n",
      "   [-9.53126575e-13 -8.84596541e-13 -1.38188040e-12 ...  0.00000000e+00\n",
      "     0.00000000e+00  0.00000000e+00]\n",
      "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
      "     0.00000000e+00  0.00000000e+00]\n",
      "   ...\n",
      "   [-7.15347159e-09 -1.78469961e-09  6.01778870e-12 ... -5.83826563e-12\n",
      "    -5.10836339e-12 -4.63515901e-12]\n",
      "   [-4.19630823e-12 -4.18548529e-12 -3.76494322e-12 ... -1.97738223e-12\n",
      "    -2.00968734e-12 -2.40019593e-12]\n",
      "   [-2.18856053e-12 -1.86138778e-12 -1.83610093e-12 ... -5.67056872e-13\n",
      "    -4.29064770e-13 -4.28763470e-13]]\n",
      "\n",
      "  [[-4.51218571e-13 -5.78108904e-13 -6.97381118e-13 ...  0.00000000e+00\n",
      "     0.00000000e+00  0.00000000e+00]\n",
      "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
      "     0.00000000e+00  0.00000000e+00]\n",
      "   [-1.01533608e-08 -2.53771204e-09  1.90346914e-12 ... -3.71066892e-12\n",
      "    -3.67316290e-12 -3.73092963e-12]\n",
      "   ...\n",
      "   [-8.52925911e-13 -7.23510336e-13 -6.39060148e-13 ... -3.33009336e-13\n",
      "    -3.39593832e-13 -3.46606424e-13]\n",
      "   [-3.02108897e-13 -2.87871831e-13 -2.82979694e-13 ... -7.08822852e-14\n",
      "    -7.91990239e-14 -7.97553890e-14]\n",
      "   [-7.72968861e-14 -7.08909317e-14 -7.98647783e-14 ...  0.00000000e+00\n",
      "     0.00000000e+00  0.00000000e+00]]\n",
      "\n",
      "  [[ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
      "     0.00000000e+00  0.00000000e+00]\n",
      "   [-2.38867379e-08 -5.97206862e-09 -2.75133161e-13 ... -3.36092726e-13\n",
      "    -3.63761945e-13 -3.54037654e-13]\n",
      "   [-2.92205740e-13 -2.49336061e-13 -2.07846828e-13 ... -9.09164779e-14\n",
      "    -9.77698418e-14 -9.63577905e-14]\n",
      "   ...\n",
      "   [-3.52630933e-15 -3.84673025e-15 -4.26826340e-15 ... -1.21519878e-15\n",
      "    -1.04494347e-15 -1.43406500e-15]\n",
      "   [-9.93843027e-16 -5.38931012e-16 -3.44277547e-16 ...  0.00000000e+00\n",
      "     0.00000000e+00  0.00000000e+00]\n",
      "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
      "     0.00000000e+00  0.00000000e+00]]]\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      " [[[ 9.60920239e-04  2.42059628e-04 -3.97274221e-07 ... -3.58409551e-07\n",
      "    -5.69117844e-07 -2.63771796e-07]\n",
      "   [-3.86657973e-07 -7.79279162e-07 -3.82168622e-07 ... -1.49015605e-07\n",
      "    -1.96554481e-07  6.16849221e-08]\n",
      "   [ 7.47509219e-08  1.07548548e-08  6.59652954e-08 ... -2.92586861e-08\n",
      "    -9.06684861e-09 -1.29635511e-08]\n",
      "   ...\n",
      "   [-6.44487784e-07 -9.96142603e-07 -8.22959350e-07 ...  0.00000000e+00\n",
      "     0.00000000e+00  0.00000000e+00]\n",
      "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
      "     0.00000000e+00  0.00000000e+00]\n",
      "   [-6.06315676e-04 -5.25497890e-04 -2.94804806e-04 ... -3.57843121e-04\n",
      "    -5.27675904e-04 -1.30094239e-03]]\n",
      "\n",
      "  [[-2.35036016e-03 -2.25648680e-03 -1.58604817e-03 ... -2.58265965e-04\n",
      "    -2.22147239e-04 -7.01682729e-05]\n",
      "   [-1.60359559e-05  1.63400500e-06  6.72299211e-06 ... -6.43085468e-06\n",
      "    -7.13508825e-06 -5.04285390e-06]\n",
      "   [-2.22698441e-06 -4.26859333e-06 -1.28046111e-06 ...  0.00000000e+00\n",
      "     0.00000000e+00  0.00000000e+00]\n",
      "   ...\n",
      "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
      "     0.00000000e+00  0.00000000e+00]\n",
      "   [ 5.16258925e-03  4.69891168e-03 -1.87358481e-03 ...  1.16160882e-04\n",
      "    -7.37605907e-04 -1.27955247e-03]\n",
      "   [-3.09627852e-03 -5.52636990e-03 -2.60610064e-03 ... -3.86552332e-04\n",
      "    -1.49473810e-04 -3.60519407e-05]]\n",
      "\n",
      "  [[-1.39239410e-05 -8.33063041e-06 -5.05405933e-06 ... -2.84472102e-04\n",
      "    -1.03544335e-04 -1.10521010e-04]\n",
      "   [-1.87604630e-04 -2.18137880e-04 -7.70949991e-05 ...  0.00000000e+00\n",
      "     0.00000000e+00  0.00000000e+00]\n",
      "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
      "     0.00000000e+00  0.00000000e+00]\n",
      "   ...\n",
      "   [ 2.71804701e-03  2.87484191e-03 -1.40845613e-03 ... -8.42155074e-04\n",
      "    -1.06141716e-02 -1.33131584e-02]\n",
      "   [-2.98598735e-03 -6.01488282e-04 -1.01422111e-03 ... -1.64095167e-04\n",
      "    -2.64599803e-04 -6.57541459e-05]\n",
      "   [-5.68113210e-05 -2.81957055e-05 -8.08589812e-06 ... -1.91948289e-04\n",
      "    -2.22222036e-04 -2.12054147e-04]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[ 1.05555590e-11  1.49076237e-11  1.89978762e-11 ... -9.23537722e-13\n",
      "    -9.77106633e-13 -1.02574015e-12]\n",
      "   [-9.53126575e-13 -8.84596541e-13 -1.38188040e-12 ...  0.00000000e+00\n",
      "     0.00000000e+00  0.00000000e+00]\n",
      "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
      "     0.00000000e+00  0.00000000e+00]\n",
      "   ...\n",
      "   [ 6.30866452e-08  1.57776103e-08  4.50500314e-12 ...  1.19040906e-11\n",
      "     1.35510058e-11  4.68304518e-12]\n",
      "   [ 6.13823836e-12  8.14557449e-12  1.13667183e-11 ...  9.67903535e-12\n",
      "     1.14527129e-11  1.18080910e-11]\n",
      "   [ 1.05692607e-11  1.33967403e-11  1.37254583e-11 ... -5.67056872e-13\n",
      "    -4.29064770e-13 -4.28763470e-13]]\n",
      "\n",
      "  [[-4.51218571e-13 -5.78108904e-13 -6.97381118e-13 ...  0.00000000e+00\n",
      "     0.00000000e+00  0.00000000e+00]\n",
      "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
      "     0.00000000e+00  0.00000000e+00]\n",
      "   [ 1.04827961e-07  2.62171493e-08  4.41498183e-12 ...  6.48496274e-12\n",
      "     5.32267069e-12  3.75780570e-12]\n",
      "   ...\n",
      "   [ 6.69206877e-13  1.34606920e-12  1.33651402e-12 ...  1.71973579e-12\n",
      "     2.04086639e-12  1.68477537e-12]\n",
      "   [ 1.85028251e-12  3.02071345e-12  2.95491583e-12 ... -7.08822852e-14\n",
      "    -7.91990239e-14 -7.97553890e-14]\n",
      "   [-7.72968861e-14 -7.08909317e-14 -7.98647783e-14 ...  0.00000000e+00\n",
      "     0.00000000e+00  0.00000000e+00]]\n",
      "\n",
      "  [[ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
      "     0.00000000e+00  0.00000000e+00]\n",
      "   [ 2.63762644e-07  6.59443202e-08  1.66290788e-12 ...  3.66523245e-13\n",
      "     4.55669899e-13  1.99360927e-13]\n",
      "   [ 2.99116173e-13  6.10165998e-13  3.51133185e-13 ...  5.30408616e-13\n",
      "     5.88891024e-13  4.69357734e-13]\n",
      "   ...\n",
      "   [ 4.90656371e-15  2.57398744e-15  5.13821367e-15 ... -1.21519878e-15\n",
      "    -1.04494347e-15 -1.43406500e-15]\n",
      "   [-9.93843027e-16 -5.38931012e-16 -3.44277547e-16 ...  0.00000000e+00\n",
      "     0.00000000e+00  0.00000000e+00]\n",
      "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
      "     0.00000000e+00  0.00000000e+00]]]\n",
      "\n",
      "\n",
      " [[[ 1.48293877e-03  3.46018525e-04  2.67213932e-06 ...  1.66188947e-05\n",
      "     1.07193537e-05  2.08028678e-06]\n",
      "   [ 8.11984046e-06  2.72758152e-05  1.22529864e-05 ...  4.03778040e-06\n",
      "     8.76805643e-06  4.88535250e-07]\n",
      "   [ 2.17686662e-07  5.87372767e-07  2.51688022e-07 ... -2.92586861e-08\n",
      "    -9.06684861e-09 -1.29635511e-08]\n",
      "   ...\n",
      "   [-6.44487784e-07 -9.96142603e-07 -8.22959350e-07 ...  0.00000000e+00\n",
      "     0.00000000e+00  0.00000000e+00]\n",
      "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
      "     0.00000000e+00  0.00000000e+00]\n",
      "   [ 8.18433054e-03  4.75665228e-03  1.63918373e-03 ...  1.95503030e-02\n",
      "     3.01945321e-02  6.93011507e-02]]\n",
      "\n",
      "  [[ 1.19003348e-01  1.11831188e-01  7.74235129e-02 ...  1.22263199e-02\n",
      "     1.07499901e-02  3.60128586e-03]\n",
      "   [ 9.23926360e-04  1.57389615e-04  5.28031305e-05 ... -6.43085468e-06\n",
      "    -7.13508825e-06 -5.04285390e-06]\n",
      "   [-2.22698441e-06 -4.26859333e-06 -1.28046111e-06 ...  0.00000000e+00\n",
      "     0.00000000e+00  0.00000000e+00]\n",
      "   ...\n",
      "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
      "     0.00000000e+00  0.00000000e+00]\n",
      "   [ 1.99675504e-02  3.97363724e-03 -1.45358534e-03 ...  7.01171695e-04\n",
      "     7.53470988e-04 -7.41182710e-04]\n",
      "   [-2.68124603e-03 -3.31763388e-03 -3.18018254e-04 ...  3.52686737e-03\n",
      "     4.84751631e-03  8.94449651e-04]]\n",
      "\n",
      "  [[ 2.18707079e-04  3.89208115e-04  2.08017853e-04 ... -2.84472102e-04\n",
      "    -1.03544335e-04 -1.10521010e-04]\n",
      "   [-1.87604630e-04 -2.18137880e-04 -7.70949991e-05 ...  0.00000000e+00\n",
      "     0.00000000e+00  0.00000000e+00]\n",
      "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
      "     0.00000000e+00  0.00000000e+00]\n",
      "   ...\n",
      "   [ 1.78191415e-03  2.83467071e-03  4.99429461e-03 ...  1.73836183e-02\n",
      "    -2.92640366e-03 -8.53004120e-03]\n",
      "   [ 4.24363930e-03  3.38520855e-03  3.29108420e-03 ...  2.30790029e-04\n",
      "    -1.22077807e-04  6.25493703e-05]\n",
      "   [ 4.86576573e-05 -2.02724186e-06  4.10409120e-06 ... -1.91948289e-04\n",
      "    -2.22222036e-04 -2.12054147e-04]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[ 1.60746399e-11  1.51633168e-11  1.64825879e-11 ... -9.23537722e-13\n",
      "    -9.77106633e-13 -1.02574015e-12]\n",
      "   [-9.53126575e-13 -8.84596541e-13 -1.38188040e-12 ...  0.00000000e+00\n",
      "     0.00000000e+00  0.00000000e+00]\n",
      "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
      "     0.00000000e+00  0.00000000e+00]\n",
      "   ...\n",
      "   [ 1.44459634e-07  3.61165746e-08  4.44318020e-12 ...  1.65449425e-11\n",
      "     4.74898679e-12  6.51191557e-12]\n",
      "   [ 8.82213139e-12  1.25044749e-11  9.88062323e-12 ...  8.25865765e-12\n",
      "     9.72975693e-12  9.02646360e-12]\n",
      "   [ 8.32035309e-12  9.86772556e-12  1.06484110e-11 ... -5.67056872e-13\n",
      "    -4.29064770e-13 -4.28763470e-13]]\n",
      "\n",
      "  [[-4.51218571e-13 -5.78108904e-13 -6.97381118e-13 ...  0.00000000e+00\n",
      "     0.00000000e+00  0.00000000e+00]\n",
      "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
      "     0.00000000e+00  0.00000000e+00]\n",
      "   [ 1.41665112e-07  3.54186653e-08  1.30824171e-14 ...  5.56050345e-12\n",
      "     7.11767320e-12  7.89999663e-12]\n",
      "   ...\n",
      "   [ 4.11487597e-12  1.68279941e-12  1.24703199e-12 ...  1.75847152e-12\n",
      "     2.13950515e-12  2.02302086e-12]\n",
      "   [ 1.44015811e-12  1.75091918e-12  1.66886611e-12 ... -7.08822852e-14\n",
      "    -7.91990239e-14 -7.97553890e-14]\n",
      "   [-7.72968861e-14 -7.08909317e-14 -7.98647783e-14 ...  0.00000000e+00\n",
      "     0.00000000e+00  0.00000000e+00]]\n",
      "\n",
      "  [[ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
      "     0.00000000e+00  0.00000000e+00]\n",
      "   [ 1.20242007e-07  3.00608605e-08  4.48467923e-13 ...  4.75747957e-12\n",
      "     4.84636550e-12  4.20402428e-12]\n",
      "   [ 2.68339084e-12  1.39672345e-12  9.50623044e-13 ...  4.29830813e-13\n",
      "     4.56554987e-13  4.59265980e-13]\n",
      "   ...\n",
      "   [ 8.13256407e-15  8.46403941e-15  4.68477830e-15 ... -1.21519878e-15\n",
      "    -1.04494347e-15 -1.43406500e-15]\n",
      "   [-9.93843027e-16 -5.38931012e-16 -3.44277547e-16 ...  0.00000000e+00\n",
      "     0.00000000e+00  0.00000000e+00]\n",
      "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
      "     0.00000000e+00  0.00000000e+00]]]\n",
      "\n",
      "\n",
      " [[[-4.95893997e-04 -1.23094433e-04 -4.56785443e-07 ... -4.79807511e-07\n",
      "    -6.44216414e-07 -3.80291681e-07]\n",
      "   [-5.01061891e-07 -7.95367100e-07 -3.96717724e-07 ... -1.52421805e-07\n",
      "    -2.04826961e-07 -4.32852403e-08]\n",
      "   [-1.10052500e-08 -1.39187240e-08 -8.16117485e-09 ... -2.92586861e-08\n",
      "    -9.06684861e-09 -1.29635511e-08]\n",
      "   ...\n",
      "   [-6.44487784e-07 -9.96142603e-07 -8.22959350e-07 ...  0.00000000e+00\n",
      "     0.00000000e+00  0.00000000e+00]\n",
      "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
      "     0.00000000e+00  0.00000000e+00]\n",
      "   [-1.22216484e-03 -8.01632938e-04 -4.96407156e-04 ... -4.17987700e-04\n",
      "    -6.45528373e-04 -1.43661839e-03]]\n",
      "\n",
      "  [[-2.46183062e-03 -2.30790582e-03 -1.60092488e-03 ... -2.58430577e-04\n",
      "    -2.23076393e-04 -7.45165817e-05]\n",
      "   [-1.94267850e-05 -3.75822447e-06 -2.35935022e-06 ... -6.43085468e-06\n",
      "    -7.13508825e-06 -5.04285390e-06]\n",
      "   [-2.22698441e-06 -4.26859333e-06 -1.28046111e-06 ...  0.00000000e+00\n",
      "     0.00000000e+00  0.00000000e+00]\n",
      "   ...\n",
      "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
      "     0.00000000e+00  0.00000000e+00]\n",
      "   [-3.04024527e-03 -2.11398141e-03 -2.92861927e-03 ... -1.93162166e-04\n",
      "    -7.79044174e-04 -1.34235690e-03]\n",
      "   [-3.17119458e-03 -5.60504431e-03 -2.74410704e-03 ... -3.87065200e-04\n",
      "    -1.49927786e-04 -3.61821440e-05]]\n",
      "\n",
      "  [[-1.39758931e-05 -8.58444128e-06 -5.42170073e-06 ... -2.84472102e-04\n",
      "    -1.03544335e-04 -1.10521010e-04]\n",
      "   [-1.87604630e-04 -2.18137880e-04 -7.70949991e-05 ...  0.00000000e+00\n",
      "     0.00000000e+00  0.00000000e+00]\n",
      "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
      "     0.00000000e+00  0.00000000e+00]\n",
      "   ...\n",
      "   [-9.97563824e-04 -1.15425372e-03 -3.33832204e-03 ... -9.29649745e-04\n",
      "    -1.06798913e-02 -1.33357458e-02]\n",
      "   [-3.05112149e-03 -6.19383529e-04 -1.06641394e-03 ... -1.64267927e-04\n",
      "    -2.64713715e-04 -6.59158977e-05]\n",
      "   [-5.72256140e-05 -2.83544650e-05 -8.58355997e-06 ... -1.91948289e-04\n",
      "    -2.22222036e-04 -2.12054147e-04]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[-2.87277212e-12 -2.95183431e-12 -3.49401736e-12 ... -9.23537722e-13\n",
      "    -9.77106633e-13 -1.02574015e-12]\n",
      "   [-9.53126575e-13 -8.84596541e-13 -1.38188040e-12 ...  0.00000000e+00\n",
      "     0.00000000e+00  0.00000000e+00]\n",
      "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
      "     0.00000000e+00  0.00000000e+00]\n",
      "   ...\n",
      "   [-7.14491843e-09 -1.78175907e-09  4.67780242e-12 ... -5.83826563e-12\n",
      "    -5.10836339e-12 -4.63515901e-12]\n",
      "   [-4.19630823e-12 -4.18548529e-12 -3.76494322e-12 ... -1.97738223e-12\n",
      "    -2.00968734e-12 -2.40019593e-12]\n",
      "   [-2.18856053e-12 -1.86138778e-12 -1.83610093e-12 ... -5.67056872e-13\n",
      "    -4.29064770e-13 -4.28763470e-13]]\n",
      "\n",
      "  [[-4.51218571e-13 -5.78108904e-13 -6.97381118e-13 ...  0.00000000e+00\n",
      "     0.00000000e+00  0.00000000e+00]\n",
      "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
      "     0.00000000e+00  0.00000000e+00]\n",
      "   [-1.01686100e-08 -2.53748089e-09  1.21973655e-12 ... -3.71066892e-12\n",
      "    -3.67316290e-12 -3.73092963e-12]\n",
      "   ...\n",
      "   [-8.52925911e-13 -7.23510336e-13 -6.39060148e-13 ... -3.33009336e-13\n",
      "    -3.39593832e-13 -3.46606424e-13]\n",
      "   [-3.02108897e-13 -2.87871831e-13 -2.82979694e-13 ... -7.08822852e-14\n",
      "    -7.91990239e-14 -7.97553890e-14]\n",
      "   [-7.72968861e-14 -7.08909317e-14 -7.98647783e-14 ...  0.00000000e+00\n",
      "     0.00000000e+00  0.00000000e+00]]\n",
      "\n",
      "  [[ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
      "     0.00000000e+00  0.00000000e+00]\n",
      "   [-2.39508893e-08 -5.98803362e-09 -8.66944320e-15 ... -3.36092726e-13\n",
      "    -3.63761945e-13 -3.54037654e-13]\n",
      "   [-2.92205740e-13 -2.49336061e-13 -2.07846828e-13 ... -9.09164779e-14\n",
      "    -9.77698418e-14 -9.63577905e-14]\n",
      "   ...\n",
      "   [-3.52630933e-15 -3.84673025e-15 -4.26826340e-15 ... -1.21519878e-15\n",
      "    -1.04494347e-15 -1.43406500e-15]\n",
      "   [-9.93843027e-16 -5.38931012e-16 -3.44277547e-16 ...  0.00000000e+00\n",
      "     0.00000000e+00  0.00000000e+00]\n",
      "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
      "     0.00000000e+00  0.00000000e+00]]]]\n",
      "Epoch 1/100\n",
      "Learning rate:  0.01\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 6s 1s/step - loss: 2.9096 - accuracy: 0.2200 - val_loss: 20.0569 - val_accuracy: 0.7234\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 2/100\n",
      "Learning rate:  0.009900990099009901\n",
      "2/2 [==============================] - 1s 517ms/step - loss: 3.1717 - accuracy: 0.4000 - val_loss: 779.8338 - val_accuracy: 0.2766\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 3/100\n",
      "Learning rate:  0.00980392156862745\n",
      "2/2 [==============================] - 1s 708ms/step - loss: 1.4156 - accuracy: 0.4800 - val_loss: 2036.5077 - val_accuracy: 0.2766\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 4/100\n",
      "Learning rate:  0.009708737864077669\n",
      "2/2 [==============================] - 1s 480ms/step - loss: 1.8622 - accuracy: 0.6000 - val_loss: 1421.1907 - val_accuracy: 0.2766\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 5/100\n",
      "Learning rate:  0.009615384615384616\n",
      "2/2 [==============================] - 1s 688ms/step - loss: 1.8053 - accuracy: 0.6000 - val_loss: 729.0004 - val_accuracy: 0.2766\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 6/100\n",
      "Learning rate:  0.009523809523809525\n",
      "2/2 [==============================] - 1s 660ms/step - loss: 1.4965 - accuracy: 0.6000 - val_loss: 187.3139 - val_accuracy: 0.2766\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 7/100\n",
      "Learning rate:  0.009433962264150943\n",
      "2/2 [==============================] - 1s 660ms/step - loss: 2.0624 - accuracy: 0.4000 - val_loss: 40.6819 - val_accuracy: 0.2766\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 8/100\n",
      "Learning rate:  0.009345794392523364\n",
      "2/2 [==============================] - 1s 450ms/step - loss: 2.1945 - accuracy: 0.4200 - val_loss: 5.9694 - val_accuracy: 0.2766\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 9/100\n",
      "Learning rate:  0.009259259259259259\n",
      "2/2 [==============================] - 1s 532ms/step - loss: 1.5195 - accuracy: 0.4800 - val_loss: 1.8686 - val_accuracy: 0.2766\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 10/100\n",
      "Learning rate:  0.009174311926605505\n",
      "2/2 [==============================] - 1s 704ms/step - loss: 1.5625 - accuracy: 0.6000 - val_loss: 2.0474 - val_accuracy: 0.2766\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 11/100\n",
      "Learning rate:  0.00909090909090909\n",
      "2/2 [==============================] - 1s 809ms/step - loss: 2.0124 - accuracy: 0.6000 - val_loss: 2.2429 - val_accuracy: 0.2766\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 12/100\n",
      "Learning rate:  0.009009009009009009\n",
      "2/2 [==============================] - 1s 802ms/step - loss: 1.5482 - accuracy: 0.6000 - val_loss: 2.2897 - val_accuracy: 0.2766\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 13/100\n",
      "Learning rate:  0.008928571428571428\n",
      "2/2 [==============================] - 1s 756ms/step - loss: 1.4135 - accuracy: 0.6000 - val_loss: 2.2686 - val_accuracy: 0.2766\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 14/100\n",
      "Learning rate:  0.008849557522123894\n",
      "2/2 [==============================] - 1s 596ms/step - loss: 1.3974 - accuracy: 0.6000 - val_loss: 2.1841 - val_accuracy: 0.2766\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 15/100\n",
      "Learning rate:  0.008771929824561403\n",
      "2/2 [==============================] - 1s 533ms/step - loss: 1.3291 - accuracy: 0.6200 - val_loss: 2.0652 - val_accuracy: 0.2766\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 16/100\n",
      "Learning rate:  0.008695652173913044\n",
      "2/2 [==============================] - 1s 697ms/step - loss: 1.3449 - accuracy: 0.6200 - val_loss: 1.9602 - val_accuracy: 0.2766\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 17/100\n",
      "Learning rate:  0.008620689655172414\n",
      "2/2 [==============================] - 1s 755ms/step - loss: 1.3789 - accuracy: 0.6000 - val_loss: 1.8682 - val_accuracy: 0.2766\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 18/100\n",
      "Learning rate:  0.008547008547008548\n",
      "2/2 [==============================] - 1s 574ms/step - loss: 1.3384 - accuracy: 0.6000 - val_loss: 1.7853 - val_accuracy: 0.2766\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 19/100\n",
      "Learning rate:  0.00847457627118644\n",
      "2/2 [==============================] - 1s 542ms/step - loss: 1.2960 - accuracy: 0.6200 - val_loss: 1.7079 - val_accuracy: 0.2766\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 20/100\n",
      "Learning rate:  0.008403361344537815\n",
      "2/2 [==============================] - 1s 717ms/step - loss: 1.2793 - accuracy: 0.6200 - val_loss: 1.6727 - val_accuracy: 0.2766\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 21/100\n",
      "Learning rate:  0.008333333333333333\n",
      "2/2 [==============================] - 1s 819ms/step - loss: 1.2703 - accuracy: 0.6200 - val_loss: 1.6899 - val_accuracy: 0.2766\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 22/100\n",
      "Learning rate:  0.008264462809917356\n",
      "2/2 [==============================] - 1s 679ms/step - loss: 1.2640 - accuracy: 0.6200 - val_loss: 1.7366 - val_accuracy: 0.2766\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 23/100\n",
      "Learning rate:  0.00819672131147541\n",
      "2/2 [==============================] - 1s 667ms/step - loss: 1.2610 - accuracy: 0.6000 - val_loss: 1.6325 - val_accuracy: 0.2766\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 24/100\n",
      "Learning rate:  0.008130081300813009\n",
      "2/2 [==============================] - 1s 779ms/step - loss: 1.2348 - accuracy: 0.6200 - val_loss: 1.5570 - val_accuracy: 0.2766\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 25/100\n",
      "Learning rate:  0.008064516129032258\n",
      "2/2 [==============================] - 1s 522ms/step - loss: 1.2348 - accuracy: 0.6200 - val_loss: 1.5226 - val_accuracy: 0.2766\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 26/100\n",
      "Learning rate:  0.008\n",
      "2/2 [==============================] - 1s 692ms/step - loss: 1.3675 - accuracy: 0.6200 - val_loss: 1.5193 - val_accuracy: 0.2766\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 27/100\n",
      "Learning rate:  0.007936507936507936\n",
      "2/2 [==============================] - 1s 834ms/step - loss: 1.2409 - accuracy: 0.6000 - val_loss: 1.5587 - val_accuracy: 0.2766\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 28/100\n",
      "Learning rate:  0.007874015748031496\n",
      "2/2 [==============================] - 1s 729ms/step - loss: 1.2013 - accuracy: 0.6200 - val_loss: 1.6761 - val_accuracy: 0.2766\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 29/100\n",
      "Learning rate:  0.0078125\n",
      "2/2 [==============================] - 1s 674ms/step - loss: 1.2165 - accuracy: 0.6200 - val_loss: 1.7257 - val_accuracy: 0.2766\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 30/100\n",
      "Learning rate:  0.007751937984496124\n",
      "2/2 [==============================] - 1s 723ms/step - loss: 1.3127 - accuracy: 0.5400 - val_loss: 1.8026 - val_accuracy: 0.2766\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 31/100\n",
      "Learning rate:  0.007692307692307693\n",
      "2/2 [==============================] - 1s 716ms/step - loss: 1.2264 - accuracy: 0.6200 - val_loss: 1.6398 - val_accuracy: 0.2766\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 32/100\n",
      "Learning rate:  0.007633587786259542\n",
      "2/2 [==============================] - 1s 683ms/step - loss: 1.1793 - accuracy: 0.6200 - val_loss: 1.4445 - val_accuracy: 0.2766\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 33/100\n",
      "Learning rate:  0.007575757575757576\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 1s 507ms/step - loss: 1.3838 - accuracy: 0.6200 - val_loss: 1.2782 - val_accuracy: 0.2766\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 34/100\n",
      "Learning rate:  0.007518796992481203\n",
      "2/2 [==============================] - 1s 487ms/step - loss: 1.1702 - accuracy: 0.5000 - val_loss: 1.2034 - val_accuracy: 0.7234\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 35/100\n",
      "Learning rate:  0.007462686567164179\n",
      "2/2 [==============================] - 1s 664ms/step - loss: 1.6367 - accuracy: 0.4800 - val_loss: 1.1944 - val_accuracy: 0.7234\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 36/100\n",
      "Learning rate:  0.007407407407407408\n",
      "2/2 [==============================] - 1s 485ms/step - loss: 1.2343 - accuracy: 0.4800 - val_loss: 1.2452 - val_accuracy: 0.7234\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 37/100\n",
      "Learning rate:  0.007352941176470588\n",
      "2/2 [==============================] - 1s 805ms/step - loss: 1.1522 - accuracy: 0.5600 - val_loss: 1.3248 - val_accuracy: 0.2766\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 38/100\n",
      "Learning rate:  0.0072992700729927005\n",
      "2/2 [==============================] - 1s 632ms/step - loss: 1.2397 - accuracy: 0.6000 - val_loss: 1.3824 - val_accuracy: 0.2766\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 39/100\n",
      "Learning rate:  0.007246376811594203\n",
      "2/2 [==============================] - 1s 798ms/step - loss: 1.2647 - accuracy: 0.6000 - val_loss: 1.3974 - val_accuracy: 0.2766\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 40/100\n",
      "Learning rate:  0.007194244604316547\n",
      "2/2 [==============================] - 1s 496ms/step - loss: 1.3664 - accuracy: 0.5600 - val_loss: 1.3890 - val_accuracy: 0.2766\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 41/100\n",
      "Learning rate:  0.007142857142857143\n",
      "2/2 [==============================] - 1s 503ms/step - loss: 1.1807 - accuracy: 0.6000 - val_loss: 1.3385 - val_accuracy: 0.2766\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 42/100\n",
      "Learning rate:  0.0070921985815602835\n",
      "2/2 [==============================] - 1s 737ms/step - loss: 1.1613 - accuracy: 0.5800 - val_loss: 1.2923 - val_accuracy: 0.2766\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 43/100\n",
      "Learning rate:  0.007042253521126761\n",
      "2/2 [==============================] - 1s 514ms/step - loss: 1.1800 - accuracy: 0.5200 - val_loss: 1.2177 - val_accuracy: 0.7234\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 44/100\n",
      "Learning rate:  0.006993006993006993\n",
      "2/2 [==============================] - 1s 520ms/step - loss: 1.1119 - accuracy: 0.5200 - val_loss: 1.1853 - val_accuracy: 0.7234\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 45/100\n",
      "Learning rate:  0.006944444444444444\n",
      "2/2 [==============================] - 1s 623ms/step - loss: 1.1245 - accuracy: 0.4200 - val_loss: 1.1874 - val_accuracy: 0.7234\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 46/100\n",
      "Learning rate:  0.006896551724137931\n",
      "2/2 [==============================] - 1s 479ms/step - loss: 1.1348 - accuracy: 0.5800 - val_loss: 1.1938 - val_accuracy: 0.2766\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 47/100\n",
      "Learning rate:  0.00684931506849315\n",
      "2/2 [==============================] - 1s 798ms/step - loss: 1.0854 - accuracy: 0.6000 - val_loss: 1.2184 - val_accuracy: 0.2766\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 48/100\n",
      "Learning rate:  0.006802721088435374\n",
      "2/2 [==============================] - 1s 736ms/step - loss: 1.3630 - accuracy: 0.6000 - val_loss: 1.2033 - val_accuracy: 0.2766\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 49/100\n",
      "Learning rate:  0.006756756756756757\n",
      "2/2 [==============================] - 1s 478ms/step - loss: 1.0632 - accuracy: 0.6200 - val_loss: 1.1955 - val_accuracy: 0.2766\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 50/100\n",
      "Learning rate:  0.006711409395973154\n",
      "2/2 [==============================] - 1s 639ms/step - loss: 1.0730 - accuracy: 0.6000 - val_loss: 1.1966 - val_accuracy: 0.2766\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 51/100\n",
      "Learning rate:  0.006666666666666667\n",
      "2/2 [==============================] - 1s 949ms/step - loss: 1.0503 - accuracy: 0.5400 - val_loss: 1.2150 - val_accuracy: 0.2766\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 52/100\n",
      "Learning rate:  0.00026490066225165563\n",
      "2/2 [==============================] - 1s 867ms/step - loss: 1.0406 - accuracy: 0.6400 - val_loss: 1.2148 - val_accuracy: 0.2766\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 53/100\n",
      "Learning rate:  0.0002631578947368421\n",
      "2/2 [==============================] - 1s 479ms/step - loss: 1.0670 - accuracy: 0.6200 - val_loss: 1.2151 - val_accuracy: 0.2766\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 54/100\n",
      "Learning rate:  0.00026143790849673205\n",
      "2/2 [==============================] - 1s 674ms/step - loss: 1.0544 - accuracy: 0.6200 - val_loss: 1.2162 - val_accuracy: 0.2766\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 55/100\n",
      "Learning rate:  0.00025974025974025974\n",
      "2/2 [==============================] - 1s 668ms/step - loss: 1.0413 - accuracy: 0.6200 - val_loss: 1.2158 - val_accuracy: 0.2766\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 56/100\n",
      "Learning rate:  0.00025806451612903227\n",
      "2/2 [==============================] - 1s 669ms/step - loss: 1.0512 - accuracy: 0.6200 - val_loss: 1.2157 - val_accuracy: 0.2766\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 57/100\n",
      "Learning rate:  0.0002564102564102564\n",
      "2/2 [==============================] - 1s 489ms/step - loss: 1.1709 - accuracy: 0.5800 - val_loss: 1.2168 - val_accuracy: 0.2766\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 58/100\n",
      "Learning rate:  0.0002547770700636943\n",
      "2/2 [==============================] - 1s 479ms/step - loss: 1.0508 - accuracy: 0.6200 - val_loss: 1.2196 - val_accuracy: 0.2766\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 59/100\n",
      "Learning rate:  0.00025316455696202533\n",
      "2/2 [==============================] - 1s 480ms/step - loss: 1.1719 - accuracy: 0.6000 - val_loss: 1.2217 - val_accuracy: 0.2766\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 60/100\n",
      "Learning rate:  0.00025157232704402514\n",
      "2/2 [==============================] - 1s 666ms/step - loss: 1.0488 - accuracy: 0.6200 - val_loss: 1.2250 - val_accuracy: 0.2766\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 61/100\n",
      "Learning rate:  0.00025\n",
      "2/2 [==============================] - 1s 666ms/step - loss: 1.0783 - accuracy: 0.6000 - val_loss: 1.2261 - val_accuracy: 0.2766\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 62/100\n",
      "Learning rate:  0.0002484472049689441\n",
      "2/2 [==============================] - 1s 765ms/step - loss: 1.0442 - accuracy: 0.6200 - val_loss: 1.2273 - val_accuracy: 0.2766\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 63/100\n",
      "Learning rate:  0.0002469135802469136\n",
      "2/2 [==============================] - 1s 868ms/step - loss: 1.0356 - accuracy: 0.6200 - val_loss: 1.2262 - val_accuracy: 0.2766\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 64/100\n",
      "Learning rate:  0.000245398773006135\n",
      "2/2 [==============================] - 2s 681ms/step - loss: 1.0106 - accuracy: 0.6200 - val_loss: 1.2245 - val_accuracy: 0.2766\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 65/100\n",
      "Learning rate:  0.00024390243902439024\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 1s 593ms/step - loss: 1.0521 - accuracy: 0.6200 - val_loss: 1.2231 - val_accuracy: 0.2766\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 66/100\n",
      "Learning rate:  0.00024242424242424242\n",
      "2/2 [==============================] - 1s 616ms/step - loss: 1.0454 - accuracy: 0.6200 - val_loss: 1.2209 - val_accuracy: 0.2766\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 67/100\n",
      "Learning rate:  0.00024096385542168676\n",
      "2/2 [==============================] - 2s 1s/step - loss: 1.0520 - accuracy: 0.6200 - val_loss: 1.2190 - val_accuracy: 0.2766\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 68/100\n",
      "Learning rate:  0.00023952095808383233\n",
      "2/2 [==============================] - 1s 616ms/step - loss: 1.0739 - accuracy: 0.6000 - val_loss: 1.2163 - val_accuracy: 0.2766\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 69/100\n",
      "Learning rate:  0.0002380952380952381\n",
      "2/2 [==============================] - 1s 633ms/step - loss: 1.0465 - accuracy: 0.6200 - val_loss: 1.2144 - val_accuracy: 0.2766\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 70/100\n",
      "Learning rate:  0.00023668639053254438\n",
      "2/2 [==============================] - 1s 844ms/step - loss: 1.0438 - accuracy: 0.6200 - val_loss: 1.2115 - val_accuracy: 0.2766\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 71/100\n",
      "Learning rate:  0.00023529411764705883\n",
      "2/2 [==============================] - 1s 788ms/step - loss: 1.0337 - accuracy: 0.6200 - val_loss: 1.2095 - val_accuracy: 0.2766\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 72/100\n",
      "Learning rate:  0.00023391812865497077\n",
      "2/2 [==============================] - 1s 676ms/step - loss: 1.0342 - accuracy: 0.6200 - val_loss: 1.2069 - val_accuracy: 0.2766\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 73/100\n",
      "Learning rate:  0.00023255813953488373\n",
      "2/2 [==============================] - 1s 824ms/step - loss: 1.1076 - accuracy: 0.6000 - val_loss: 1.2045 - val_accuracy: 0.2766\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 74/100\n",
      "Learning rate:  0.00023121387283236994\n",
      "2/2 [==============================] - 1s 616ms/step - loss: 1.0443 - accuracy: 0.6200 - val_loss: 1.2016 - val_accuracy: 0.2766\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 75/100\n",
      "Learning rate:  0.00022988505747126436\n",
      "2/2 [==============================] - 1s 509ms/step - loss: 1.0225 - accuracy: 0.6600 - val_loss: 1.1994 - val_accuracy: 0.2766\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 76/100\n",
      "Learning rate:  0.00022857142857142857\n",
      "2/2 [==============================] - 1s 511ms/step - loss: 1.0314 - accuracy: 0.6200 - val_loss: 1.1984 - val_accuracy: 0.2766\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 77/100\n",
      "Learning rate:  0.00022727272727272727\n",
      "2/2 [==============================] - 1s 504ms/step - loss: 1.0411 - accuracy: 0.6200 - val_loss: 1.1975 - val_accuracy: 0.2766\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 78/100\n",
      "Learning rate:  0.00022598870056497175\n",
      "2/2 [==============================] - 1s 799ms/step - loss: 1.1954 - accuracy: 0.6000 - val_loss: 1.1968 - val_accuracy: 0.2766\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 79/100\n",
      "Learning rate:  0.00022471910112359551\n",
      "2/2 [==============================] - 1s 495ms/step - loss: 1.0216 - accuracy: 0.6200 - val_loss: 1.1960 - val_accuracy: 0.2766\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 80/100\n",
      "Learning rate:  0.000223463687150838\n",
      "2/2 [==============================] - 1s 803ms/step - loss: 1.0335 - accuracy: 0.6200 - val_loss: 1.1950 - val_accuracy: 0.2766\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 81/100\n",
      "Learning rate:  0.00022222222222222223\n",
      "2/2 [==============================] - 1s 715ms/step - loss: 1.0339 - accuracy: 0.6200 - val_loss: 1.1955 - val_accuracy: 0.2766\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 82/100\n",
      "Learning rate:  0.00022099447513812155\n",
      "2/2 [==============================] - 1s 560ms/step - loss: 1.3449 - accuracy: 0.5600 - val_loss: 1.1977 - val_accuracy: 0.2766\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 83/100\n",
      "Learning rate:  0.00021978021978021978\n",
      "2/2 [==============================] - 1s 781ms/step - loss: 1.0281 - accuracy: 0.6200 - val_loss: 1.2025 - val_accuracy: 0.2766\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 84/100\n",
      "Learning rate:  0.0002185792349726776\n",
      "2/2 [==============================] - 1s 612ms/step - loss: 1.0508 - accuracy: 0.6400 - val_loss: 1.2055 - val_accuracy: 0.2766\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 85/100\n",
      "Learning rate:  0.0002173913043478261\n",
      "2/2 [==============================] - 1s 488ms/step - loss: 1.0470 - accuracy: 0.6200 - val_loss: 1.2085 - val_accuracy: 0.2766\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 86/100\n",
      "Learning rate:  0.00021621621621621621\n",
      "2/2 [==============================] - 1s 530ms/step - loss: 1.0355 - accuracy: 0.6200 - val_loss: 1.2105 - val_accuracy: 0.2766\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 87/100\n",
      "Learning rate:  0.00021505376344086021\n",
      "2/2 [==============================] - 1s 742ms/step - loss: 1.0436 - accuracy: 0.6200 - val_loss: 1.2116 - val_accuracy: 0.2766\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 88/100\n",
      "Learning rate:  0.00021390374331550804\n",
      "2/2 [==============================] - 1s 510ms/step - loss: 1.0497 - accuracy: 0.6000 - val_loss: 1.2121 - val_accuracy: 0.2766\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 89/100\n",
      "Learning rate:  0.0002127659574468085\n",
      "2/2 [==============================] - 1s 624ms/step - loss: 1.0386 - accuracy: 0.6000 - val_loss: 1.2111 - val_accuracy: 0.2766\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 90/100\n",
      "Learning rate:  0.00021164021164021165\n",
      "2/2 [==============================] - 1s 663ms/step - loss: 1.0419 - accuracy: 0.6200 - val_loss: 1.2100 - val_accuracy: 0.2766\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 91/100\n",
      "Learning rate:  0.0002105263157894737\n",
      "2/2 [==============================] - 1s 766ms/step - loss: 1.0408 - accuracy: 0.6200 - val_loss: 1.2102 - val_accuracy: 0.2766\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 92/100\n",
      "Learning rate:  0.0002094240837696335\n",
      "2/2 [==============================] - 1s 785ms/step - loss: 1.0383 - accuracy: 0.6200 - val_loss: 1.2105 - val_accuracy: 0.2766\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 93/100\n",
      "Learning rate:  0.00020833333333333335\n",
      "2/2 [==============================] - 1s 791ms/step - loss: 1.0412 - accuracy: 0.6200 - val_loss: 1.2106 - val_accuracy: 0.2766\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 94/100\n",
      "Learning rate:  0.0002072538860103627\n",
      "2/2 [==============================] - 1s 797ms/step - loss: 1.0315 - accuracy: 0.6200 - val_loss: 1.2087 - val_accuracy: 0.2766\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 95/100\n",
      "Learning rate:  0.0002061855670103093\n",
      "2/2 [==============================] - 1s 674ms/step - loss: 1.0517 - accuracy: 0.6000 - val_loss: 1.2065 - val_accuracy: 0.2766\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 96/100\n",
      "Learning rate:  0.00020512820512820514\n",
      "2/2 [==============================] - 1s 825ms/step - loss: 1.3183 - accuracy: 0.5600 - val_loss: 1.2055 - val_accuracy: 0.2766\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 97/100\n",
      "Learning rate:  0.00020408163265306123\n",
      "2/2 [==============================] - 1s 531ms/step - loss: 1.0371 - accuracy: 0.6200 - val_loss: 1.2046 - val_accuracy: 0.2766\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 98/100\n",
      "Learning rate:  0.0002030456852791878\n",
      "2/2 [==============================] - 1s 747ms/step - loss: 1.0214 - accuracy: 0.6200 - val_loss: 1.2026 - val_accuracy: 0.2766\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 99/100\n",
      "Learning rate:  0.00020202020202020202\n",
      "2/2 [==============================] - 1s 646ms/step - loss: 1.0222 - accuracy: 0.6200 - val_loss: 1.2001 - val_accuracy: 0.2766\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 100/100\n",
      "Learning rate:  0.00020100502512562814\n",
      "2/2 [==============================] - 1s 827ms/step - loss: 1.7881 - accuracy: 0.5400 - val_loss: 1.1972 - val_accuracy: 0.2766\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "2/2 [==============================] - 0s 81ms/step - loss: 1.8765 - accuracy: 0.2766\n",
      "Test loss: 1.8764679431915283\n",
      "Test accuracy: 0.27659574151039124\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1]\n",
      "Precision:  0.07650520597555455\n",
      "Recall:  0.2765957446808511\n",
      "F1 Score:  0.1198581560283688\n",
      "[array([[8.1849024e-02, 1.9398846e-02, 5.1063159e-04, ..., 0.0000000e+00,\n",
      "        0.0000000e+00, 0.0000000e+00],\n",
      "       [1.4534332e-01, 4.3534629e-02, 3.5575170e-03, ..., 0.0000000e+00,\n",
      "        0.0000000e+00, 0.0000000e+00],\n",
      "       [9.4136730e-02, 3.8030148e-02, 4.2137187e-02, ..., 0.0000000e+00,\n",
      "        0.0000000e+00, 0.0000000e+00],\n",
      "       ...,\n",
      "       [1.6085714e-05, 4.0216878e-06, 1.0895784e-10, ..., 0.0000000e+00,\n",
      "        0.0000000e+00, 0.0000000e+00],\n",
      "       [1.7454142e-05, 4.3636455e-06, 3.4910103e-11, ..., 0.0000000e+00,\n",
      "        0.0000000e+00, 0.0000000e+00],\n",
      "       [1.7852779e-05, 4.4632488e-06, 2.9622235e-11, ..., 0.0000000e+00,\n",
      "        0.0000000e+00, 0.0000000e+00]], dtype=float32), array([[0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       ...,\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32), array([[0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       ...,\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32), array([[4.7001526e-02, 1.1694886e-02, 1.4138059e-05, ..., 0.0000000e+00,\n",
      "        0.0000000e+00, 0.0000000e+00],\n",
      "       [6.4878695e-02, 1.6085833e-02, 2.2371230e-04, ..., 0.0000000e+00,\n",
      "        0.0000000e+00, 0.0000000e+00],\n",
      "       [8.0479607e-02, 1.8845264e-02, 3.2101760e-03, ..., 0.0000000e+00,\n",
      "        0.0000000e+00, 0.0000000e+00],\n",
      "       ...,\n",
      "       [2.7122551e-05, 6.7810229e-06, 1.4412024e-10, ..., 0.0000000e+00,\n",
      "        0.0000000e+00, 0.0000000e+00],\n",
      "       [2.9594074e-05, 7.3987026e-06, 4.9249192e-11, ..., 0.0000000e+00,\n",
      "        0.0000000e+00, 0.0000000e+00],\n",
      "       [3.0290603e-05, 7.5727348e-06, 3.8183921e-11, ..., 0.0000000e+00,\n",
      "        0.0000000e+00, 0.0000000e+00]], dtype=float32), array([[2.46266079e+00, 6.08446717e-01, 1.97406509e-03, ...,\n",
      "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
      "       [4.17734241e+00, 9.72301483e-01, 7.90737476e-03, ...,\n",
      "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
      "       [7.95420361e+00, 2.62969875e+00, 2.60618448e-01, ...,\n",
      "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
      "       ...,\n",
      "       [5.02966432e-05, 1.25762290e-05, 2.01728390e-09, ...,\n",
      "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
      "       [5.92089382e-05, 1.48037425e-05, 1.57555591e-09, ...,\n",
      "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
      "       [6.26289475e-05, 1.56581773e-05, 1.47662405e-09, ...,\n",
      "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00]], dtype=float32), array([[1.0927286e-05, 2.7631872e-06, 4.0323513e-08, ..., 0.0000000e+00,\n",
      "        0.0000000e+00, 0.0000000e+00],\n",
      "       [2.0231306e-05, 5.3822250e-06, 3.9206361e-07, ..., 0.0000000e+00,\n",
      "        0.0000000e+00, 0.0000000e+00],\n",
      "       [1.5132874e-05, 1.0452022e-05, 1.9570489e-06, ..., 0.0000000e+00,\n",
      "        0.0000000e+00, 0.0000000e+00],\n",
      "       ...,\n",
      "       [4.4246681e-10, 2.5055316e-10, 2.0041580e-10, ..., 0.0000000e+00,\n",
      "        0.0000000e+00, 0.0000000e+00],\n",
      "       [1.0327751e-10, 4.9216013e-11, 3.4519682e-11, ..., 0.0000000e+00,\n",
      "        0.0000000e+00, 0.0000000e+00],\n",
      "       [8.2121747e-11, 2.1930492e-11, 2.3242211e-12, ..., 0.0000000e+00,\n",
      "        0.0000000e+00, 0.0000000e+00]], dtype=float32), array([[0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       ...,\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32), array([[0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       ...,\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32), array([[0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       ...,\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32), array([[0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       ...,\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32), array([[2.2644056e-03, 6.0448796e-04, 6.3092361e-05, ..., 0.0000000e+00,\n",
      "        0.0000000e+00, 0.0000000e+00],\n",
      "       [6.5175621e-03, 1.9776602e-03, 8.5596764e-04, ..., 0.0000000e+00,\n",
      "        0.0000000e+00, 0.0000000e+00],\n",
      "       [3.4247629e-02, 1.0488374e-02, 1.4355455e-02, ..., 0.0000000e+00,\n",
      "        0.0000000e+00, 0.0000000e+00],\n",
      "       ...,\n",
      "       [2.7418045e-07, 6.8633938e-08, 1.1683654e-10, ..., 0.0000000e+00,\n",
      "        0.0000000e+00, 0.0000000e+00],\n",
      "       [2.1767161e-07, 5.4438960e-08, 2.8787375e-11, ..., 0.0000000e+00,\n",
      "        0.0000000e+00, 0.0000000e+00],\n",
      "       [1.9218336e-07, 4.8058368e-08, 1.2344827e-11, ..., 0.0000000e+00,\n",
      "        0.0000000e+00, 0.0000000e+00]], dtype=float32), array([[1.6312646e-02, 4.2953007e-03, 5.0509319e-05, ..., 0.0000000e+00,\n",
      "        0.0000000e+00, 0.0000000e+00],\n",
      "       [2.2224136e-02, 5.2337861e-03, 1.3155262e-04, ..., 0.0000000e+00,\n",
      "        0.0000000e+00, 0.0000000e+00],\n",
      "       [2.2901315e-02, 8.5197166e-03, 1.0460278e-03, ..., 0.0000000e+00,\n",
      "        0.0000000e+00, 0.0000000e+00],\n",
      "       ...,\n",
      "       [2.7820761e-06, 6.9564823e-07, 1.5065006e-10, ..., 0.0000000e+00,\n",
      "        0.0000000e+00, 0.0000000e+00],\n",
      "       [3.0322722e-06, 7.5812306e-07, 3.9416838e-11, ..., 0.0000000e+00,\n",
      "        0.0000000e+00, 0.0000000e+00],\n",
      "       [3.1203613e-06, 7.8009731e-07, 4.8559225e-12, ..., 0.0000000e+00,\n",
      "        0.0000000e+00, 0.0000000e+00]], dtype=float32), array([[0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       ...,\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32), array([[2.7408656e-02, 6.8191784e-03, 7.3211500e-05, ..., 0.0000000e+00,\n",
      "        0.0000000e+00, 0.0000000e+00],\n",
      "       [4.6361372e-02, 1.0784756e-02, 3.2624742e-04, ..., 0.0000000e+00,\n",
      "        0.0000000e+00, 0.0000000e+00],\n",
      "       [9.1967419e-02, 2.9300945e-02, 2.2811557e-03, ..., 0.0000000e+00,\n",
      "        0.0000000e+00, 0.0000000e+00],\n",
      "       ...,\n",
      "       [2.8064383e-07, 7.0307351e-08, 1.6619479e-10, ..., 0.0000000e+00,\n",
      "        0.0000000e+00, 0.0000000e+00],\n",
      "       [3.0414918e-07, 7.6061532e-08, 2.0210956e-11, ..., 0.0000000e+00,\n",
      "        0.0000000e+00, 0.0000000e+00],\n",
      "       [3.0999388e-07, 7.7500424e-08, 2.1486357e-12, ..., 0.0000000e+00,\n",
      "        0.0000000e+00, 0.0000000e+00]], dtype=float32), array([[5.5638859e-05, 1.4156862e-05, 1.9343655e-07, ..., 0.0000000e+00,\n",
      "        0.0000000e+00, 0.0000000e+00],\n",
      "       [1.0005916e-04, 2.3590721e-05, 4.6193172e-06, ..., 0.0000000e+00,\n",
      "        0.0000000e+00, 0.0000000e+00],\n",
      "       [2.5403849e-04, 8.2009385e-05, 1.6975715e-05, ..., 0.0000000e+00,\n",
      "        0.0000000e+00, 0.0000000e+00],\n",
      "       ...,\n",
      "       [2.3700899e-09, 7.1006345e-10, 1.4703976e-10, ..., 0.0000000e+00,\n",
      "        0.0000000e+00, 0.0000000e+00],\n",
      "       [2.6504960e-09, 6.8888656e-10, 3.1219218e-11, ..., 0.0000000e+00,\n",
      "        0.0000000e+00, 0.0000000e+00],\n",
      "       [2.6541913e-09, 6.6570749e-10, 2.4403129e-12, ..., 0.0000000e+00,\n",
      "        0.0000000e+00, 0.0000000e+00]], dtype=float32), array([[6.4010610e-06, 1.5630009e-06, 1.4170273e-07, ..., 0.0000000e+00,\n",
      "        0.0000000e+00, 0.0000000e+00],\n",
      "       [4.0444913e-05, 1.8808521e-05, 8.0369637e-06, ..., 0.0000000e+00,\n",
      "        0.0000000e+00, 0.0000000e+00],\n",
      "       [6.2459192e-05, 4.3862063e-05, 2.9966890e-05, ..., 0.0000000e+00,\n",
      "        0.0000000e+00, 0.0000000e+00],\n",
      "       ...,\n",
      "       [3.6499899e-09, 1.0267127e-09, 1.9334388e-10, ..., 0.0000000e+00,\n",
      "        0.0000000e+00, 0.0000000e+00],\n",
      "       [4.6355004e-09, 1.1768531e-09, 2.3607852e-11, ..., 0.0000000e+00,\n",
      "        0.0000000e+00, 0.0000000e+00],\n",
      "       [4.6213984e-09, 1.1570542e-09, 2.2020972e-12, ..., 0.0000000e+00,\n",
      "        0.0000000e+00, 0.0000000e+00]], dtype=float32), array([[4.09478263e-04, 1.14373775e-04, 1.59311840e-05, ...,\n",
      "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
      "       [1.10732601e-03, 2.78060063e-04, 6.23932428e-05, ...,\n",
      "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
      "       [4.76788264e-03, 1.75197772e-03, 1.04568237e-04, ...,\n",
      "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
      "       ...,\n",
      "       [1.52878386e-06, 3.82366807e-07, 2.63497557e-10, ...,\n",
      "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
      "       [1.51578035e-06, 3.79149895e-07, 2.50186760e-10, ...,\n",
      "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
      "       [1.47901289e-06, 3.70252280e-07, 4.52787974e-10, ...,\n",
      "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00]], dtype=float32), array([[1.2635040e-02, 2.9841117e-03, 1.3458892e-04, ..., 0.0000000e+00,\n",
      "        0.0000000e+00, 0.0000000e+00],\n",
      "       [1.8814232e-02, 4.9907430e-03, 7.7829260e-04, ..., 0.0000000e+00,\n",
      "        0.0000000e+00, 0.0000000e+00],\n",
      "       [1.1041012e-02, 1.2948984e-02, 7.1525802e-03, ..., 0.0000000e+00,\n",
      "        0.0000000e+00, 0.0000000e+00],\n",
      "       ...,\n",
      "       [1.4284190e-06, 3.5726831e-07, 1.9576338e-10, ..., 0.0000000e+00,\n",
      "        0.0000000e+00, 0.0000000e+00],\n",
      "       [1.5640842e-06, 3.9104825e-07, 2.8116905e-11, ..., 0.0000000e+00,\n",
      "        0.0000000e+00, 0.0000000e+00],\n",
      "       [1.6071389e-06, 4.0179810e-07, 1.0933399e-11, ..., 0.0000000e+00,\n",
      "        0.0000000e+00, 0.0000000e+00]], dtype=float32), array([[5.2970211e-04, 1.4359385e-04, 7.0582930e-05, ..., 0.0000000e+00,\n",
      "        0.0000000e+00, 0.0000000e+00],\n",
      "       [2.4874865e-03, 9.5355790e-04, 6.6366588e-04, ..., 0.0000000e+00,\n",
      "        0.0000000e+00, 0.0000000e+00],\n",
      "       [8.9131426e-03, 8.8844923e-03, 1.1638429e-02, ..., 0.0000000e+00,\n",
      "        0.0000000e+00, 0.0000000e+00],\n",
      "       ...,\n",
      "       [3.5905913e-07, 8.9878313e-08, 1.7430976e-10, ..., 0.0000000e+00,\n",
      "        0.0000000e+00, 0.0000000e+00],\n",
      "       [3.8203189e-07, 9.5528883e-08, 3.6500414e-11, ..., 0.0000000e+00,\n",
      "        0.0000000e+00, 0.0000000e+00],\n",
      "       [3.8691206e-07, 9.6729416e-08, 2.6995582e-12, ..., 0.0000000e+00,\n",
      "        0.0000000e+00, 0.0000000e+00]], dtype=float32), array([[2.54003884e-04, 5.71481141e-05, 1.47196056e-06, ...,\n",
      "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
      "       [8.43087211e-04, 2.20241855e-04, 1.49466723e-05, ...,\n",
      "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
      "       [2.87630316e-03, 1.12505967e-03, 6.11981086e-05, ...,\n",
      "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
      "       ...,\n",
      "       [2.03155492e-10, 1.91431912e-10, 1.63984132e-10, ...,\n",
      "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
      "       [1.14776716e-10, 4.88611165e-11, 2.42735155e-11, ...,\n",
      "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
      "       [8.41501244e-11, 2.30014549e-11, 2.13067996e-12, ...,\n",
      "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00]], dtype=float32), array([[4.2109989e-02, 1.0917477e-02, 2.4025838e-05, ..., 0.0000000e+00,\n",
      "        0.0000000e+00, 0.0000000e+00],\n",
      "       [6.8104595e-02, 1.7952774e-02, 2.8850493e-04, ..., 0.0000000e+00,\n",
      "        0.0000000e+00, 0.0000000e+00],\n",
      "       [9.3014911e-02, 1.9574285e-02, 1.5316498e-02, ..., 0.0000000e+00,\n",
      "        0.0000000e+00, 0.0000000e+00],\n",
      "       ...,\n",
      "       [2.5325605e-08, 6.4296328e-09, 1.1813328e-10, ..., 0.0000000e+00,\n",
      "        0.0000000e+00, 0.0000000e+00],\n",
      "       [3.2862040e-08, 8.2422318e-09, 2.8974710e-11, ..., 0.0000000e+00,\n",
      "        0.0000000e+00, 0.0000000e+00],\n",
      "       [3.5708627e-08, 8.9317576e-09, 5.7512272e-12, ..., 0.0000000e+00,\n",
      "        0.0000000e+00, 0.0000000e+00]], dtype=float32), array([[5.0461227e-01, 1.1962652e-01, 7.9796952e-04, ..., 0.0000000e+00,\n",
      "        0.0000000e+00, 0.0000000e+00],\n",
      "       [7.3239356e-01, 1.9600464e-01, 5.3139376e-03, ..., 0.0000000e+00,\n",
      "        0.0000000e+00, 0.0000000e+00],\n",
      "       [1.2157012e+00, 2.7169317e-01, 2.1263208e-02, ..., 0.0000000e+00,\n",
      "        0.0000000e+00, 0.0000000e+00],\n",
      "       ...,\n",
      "       [3.6769543e-05, 9.1926677e-06, 3.0881622e-10, ..., 0.0000000e+00,\n",
      "        0.0000000e+00, 0.0000000e+00],\n",
      "       [3.5667312e-05, 8.9171526e-06, 2.3081147e-10, ..., 0.0000000e+00,\n",
      "        0.0000000e+00, 0.0000000e+00],\n",
      "       [3.4691573e-05, 8.6731734e-06, 3.0038441e-10, ..., 0.0000000e+00,\n",
      "        0.0000000e+00, 0.0000000e+00]], dtype=float32), array([[4.2793956e-01, 1.0156794e-01, 4.8305237e-04, ..., 0.0000000e+00,\n",
      "        0.0000000e+00, 0.0000000e+00],\n",
      "       [5.3349376e-01, 1.4346609e-01, 1.2950274e-03, ..., 0.0000000e+00,\n",
      "        0.0000000e+00, 0.0000000e+00],\n",
      "       [6.2423563e-01, 1.5095356e-01, 3.8887445e-02, ..., 0.0000000e+00,\n",
      "        0.0000000e+00, 0.0000000e+00],\n",
      "       ...,\n",
      "       [1.8696357e-05, 4.6742452e-06, 5.6502214e-10, ..., 0.0000000e+00,\n",
      "        0.0000000e+00, 0.0000000e+00],\n",
      "       [1.6902262e-05, 4.2257811e-06, 4.4998683e-10, ..., 0.0000000e+00,\n",
      "        0.0000000e+00, 0.0000000e+00],\n",
      "       [1.5933543e-05, 3.9838019e-06, 6.9709644e-10, ..., 0.0000000e+00,\n",
      "        0.0000000e+00, 0.0000000e+00]], dtype=float32), array([[3.7149754e-01, 9.3116999e-02, 1.5269055e-05, ..., 0.0000000e+00,\n",
      "        0.0000000e+00, 0.0000000e+00],\n",
      "       [4.6552667e-01, 1.1290482e-01, 8.1528269e-04, ..., 0.0000000e+00,\n",
      "        0.0000000e+00, 0.0000000e+00],\n",
      "       [3.9252153e-01, 1.3755491e-01, 5.1096370e-03, ..., 0.0000000e+00,\n",
      "        0.0000000e+00, 0.0000000e+00],\n",
      "       ...,\n",
      "       [7.3367308e-05, 1.8342949e-05, 6.1849836e-10, ..., 0.0000000e+00,\n",
      "        0.0000000e+00, 0.0000000e+00],\n",
      "       [8.0245845e-05, 2.0062023e-05, 3.2113967e-10, ..., 0.0000000e+00,\n",
      "        0.0000000e+00, 0.0000000e+00],\n",
      "       [8.2146820e-05, 2.0537032e-05, 3.3933156e-10, ..., 0.0000000e+00,\n",
      "        0.0000000e+00, 0.0000000e+00]], dtype=float32), array([[0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       ...,\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32), array([[0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       ...,\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32), array([[8.2181036e-02, 1.9927587e-02, 8.3908308e-05, ..., 0.0000000e+00,\n",
      "        0.0000000e+00, 0.0000000e+00],\n",
      "       [1.2737188e-01, 3.1184779e-02, 4.3762679e-04, ..., 0.0000000e+00,\n",
      "        0.0000000e+00, 0.0000000e+00],\n",
      "       [2.0489082e-01, 5.8083504e-02, 2.3673773e-03, ..., 0.0000000e+00,\n",
      "        0.0000000e+00, 0.0000000e+00],\n",
      "       ...,\n",
      "       [3.5213536e-05, 8.8039624e-06, 2.5842370e-10, ..., 0.0000000e+00,\n",
      "        0.0000000e+00, 0.0000000e+00],\n",
      "       [3.8952130e-05, 9.7383891e-06, 1.3093290e-10, ..., 0.0000000e+00,\n",
      "        0.0000000e+00, 0.0000000e+00],\n",
      "       [4.0108294e-05, 1.0027257e-05, 1.1986480e-10, ..., 0.0000000e+00,\n",
      "        0.0000000e+00, 0.0000000e+00]], dtype=float32), array([[7.9256250e-04, 2.6725154e-04, 2.2196891e-05, ..., 0.0000000e+00,\n",
      "        0.0000000e+00, 0.0000000e+00],\n",
      "       [8.4246369e-04, 8.8585110e-04, 2.2036131e-04, ..., 0.0000000e+00,\n",
      "        0.0000000e+00, 0.0000000e+00],\n",
      "       [1.9278389e-03, 2.3030236e-03, 4.9445085e-04, ..., 0.0000000e+00,\n",
      "        0.0000000e+00, 0.0000000e+00],\n",
      "       ...,\n",
      "       [4.7296833e-09, 1.2939255e-09, 1.7558957e-10, ..., 0.0000000e+00,\n",
      "        0.0000000e+00, 0.0000000e+00],\n",
      "       [4.7021116e-09, 1.1941299e-09, 2.8188642e-11, ..., 0.0000000e+00,\n",
      "        0.0000000e+00, 0.0000000e+00],\n",
      "       [4.7121071e-09, 1.1792920e-09, 1.6922769e-12, ..., 0.0000000e+00,\n",
      "        0.0000000e+00, 0.0000000e+00]], dtype=float32), array([[2.05169526e-05, 4.61021637e-06, 1.30236852e-08, ...,\n",
      "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
      "       [1.53339133e-05, 6.69803421e-06, 2.62457729e-06, ...,\n",
      "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
      "       [2.38640132e-06, 2.57887723e-06, 3.98481598e-06, ...,\n",
      "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
      "       ...,\n",
      "       [2.49422011e-10, 1.98223771e-10, 2.07750067e-10, ...,\n",
      "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
      "       [1.43947090e-10, 5.79588218e-11, 3.42980817e-11, ...,\n",
      "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
      "       [1.07226186e-10, 2.82920822e-11, 2.82980800e-12, ...,\n",
      "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00]], dtype=float32), array([[8.1584120e-01, 2.0979655e-01, 4.1561361e-04, ..., 0.0000000e+00,\n",
      "        0.0000000e+00, 0.0000000e+00],\n",
      "       [8.9808583e-01, 2.2204763e-01, 3.5198048e-02, ..., 0.0000000e+00,\n",
      "        0.0000000e+00, 0.0000000e+00],\n",
      "       [5.6655717e-01, 1.8734038e-01, 1.2278787e-01, ..., 0.0000000e+00,\n",
      "        0.0000000e+00, 0.0000000e+00],\n",
      "       ...,\n",
      "       [2.5619758e-05, 6.4052065e-06, 1.8198582e-10, ..., 0.0000000e+00,\n",
      "        0.0000000e+00, 0.0000000e+00],\n",
      "       [2.7239674e-05, 6.8100580e-06, 3.5125472e-11, ..., 0.0000000e+00,\n",
      "        0.0000000e+00, 0.0000000e+00],\n",
      "       [2.7588070e-05, 6.8970980e-06, 2.8397770e-11, ..., 0.0000000e+00,\n",
      "        0.0000000e+00, 0.0000000e+00]], dtype=float32), array([[7.0345175e-04, 1.4968787e-04, 1.5663576e-05, ..., 0.0000000e+00,\n",
      "        0.0000000e+00, 0.0000000e+00],\n",
      "       [1.5640734e-03, 4.8528111e-04, 2.2369126e-05, ..., 0.0000000e+00,\n",
      "        0.0000000e+00, 0.0000000e+00],\n",
      "       [9.7431085e-04, 9.8709203e-04, 4.7232650e-04, ..., 0.0000000e+00,\n",
      "        0.0000000e+00, 0.0000000e+00],\n",
      "       ...,\n",
      "       [5.4988242e-08, 1.3909659e-08, 1.8090596e-10, ..., 0.0000000e+00,\n",
      "        0.0000000e+00, 0.0000000e+00],\n",
      "       [6.0355156e-08, 1.5108158e-08, 1.5847731e-11, ..., 0.0000000e+00,\n",
      "        0.0000000e+00, 0.0000000e+00],\n",
      "       [6.2187574e-08, 1.5547885e-08, 1.2806931e-12, ..., 0.0000000e+00,\n",
      "        0.0000000e+00, 0.0000000e+00]], dtype=float32), array([[0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       ...,\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32), array([[7.7893436e-03, 1.8639364e-03, 2.2357015e-05, ..., 0.0000000e+00,\n",
      "        0.0000000e+00, 0.0000000e+00],\n",
      "       [1.1563937e-02, 3.0068867e-03, 2.4671163e-04, ..., 0.0000000e+00,\n",
      "        0.0000000e+00, 0.0000000e+00],\n",
      "       [1.6106721e-02, 4.6769446e-03, 1.1759634e-03, ..., 0.0000000e+00,\n",
      "        0.0000000e+00, 0.0000000e+00],\n",
      "       ...,\n",
      "       [7.6487417e-08, 1.9205565e-08, 1.1799259e-10, ..., 0.0000000e+00,\n",
      "        0.0000000e+00, 0.0000000e+00],\n",
      "       [8.3858652e-08, 2.0975330e-08, 1.7916283e-11, ..., 0.0000000e+00,\n",
      "        0.0000000e+00, 0.0000000e+00],\n",
      "       [8.5024958e-08, 2.1258311e-08, 2.7792254e-12, ..., 0.0000000e+00,\n",
      "        0.0000000e+00, 0.0000000e+00]], dtype=float32), array([[4.7752247e-03, 1.2021975e-03, 3.0959323e-05, ..., 0.0000000e+00,\n",
      "        0.0000000e+00, 0.0000000e+00],\n",
      "       [5.8183186e-03, 1.5031249e-03, 1.7036428e-04, ..., 0.0000000e+00,\n",
      "        0.0000000e+00, 0.0000000e+00],\n",
      "       [5.3978283e-03, 1.5205889e-03, 7.3660997e-04, ..., 0.0000000e+00,\n",
      "        0.0000000e+00, 0.0000000e+00],\n",
      "       ...,\n",
      "       [2.3681501e-07, 5.9354839e-08, 1.6267990e-10, ..., 0.0000000e+00,\n",
      "        0.0000000e+00, 0.0000000e+00],\n",
      "       [2.6821300e-07, 6.7086837e-08, 3.5940469e-11, ..., 0.0000000e+00,\n",
      "        0.0000000e+00, 0.0000000e+00],\n",
      "       [2.7811822e-07, 6.9536377e-08, 8.5713745e-12, ..., 0.0000000e+00,\n",
      "        0.0000000e+00, 0.0000000e+00]], dtype=float32), array([[2.2679409e-01, 5.8205828e-02, 2.5326197e-04, ..., 0.0000000e+00,\n",
      "        0.0000000e+00, 0.0000000e+00],\n",
      "       [2.7503636e-01, 6.3022695e-02, 1.0374230e-03, ..., 0.0000000e+00,\n",
      "        0.0000000e+00, 0.0000000e+00],\n",
      "       [3.5769859e-01, 1.0761906e-01, 3.8809208e-03, ..., 0.0000000e+00,\n",
      "        0.0000000e+00, 0.0000000e+00],\n",
      "       ...,\n",
      "       [4.9562040e-08, 1.2534726e-08, 1.9250446e-10, ..., 0.0000000e+00,\n",
      "        0.0000000e+00, 0.0000000e+00],\n",
      "       [1.7818053e-08, 4.4809947e-09, 3.4644117e-11, ..., 0.0000000e+00,\n",
      "        0.0000000e+00, 0.0000000e+00],\n",
      "       [8.4554070e-09, 2.2046205e-09, 5.8440475e-11, ..., 0.0000000e+00,\n",
      "        0.0000000e+00, 0.0000000e+00]], dtype=float32), array([[1.76503439e-03, 4.33786132e-04, 1.70364328e-05, ...,\n",
      "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
      "       [1.18290342e-03, 4.00671212e-04, 4.24970698e-04, ...,\n",
      "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
      "       [5.69053285e-04, 2.10287888e-03, 4.94723953e-03, ...,\n",
      "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
      "       ...,\n",
      "       [4.82070490e-08, 1.21859580e-08, 1.54497304e-10, ...,\n",
      "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
      "       [5.30535438e-08, 1.32741986e-08, 1.76603628e-11, ...,\n",
      "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
      "       [5.33635678e-08, 1.33424365e-08, 3.04526326e-12, ...,\n",
      "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00]], dtype=float32), array([[2.9502308e-04, 6.9645001e-05, 1.3921847e-06, ..., 0.0000000e+00,\n",
      "        0.0000000e+00, 0.0000000e+00],\n",
      "       [6.7481620e-04, 1.9329277e-04, 3.1015978e-05, ..., 0.0000000e+00,\n",
      "        0.0000000e+00, 0.0000000e+00],\n",
      "       [2.1438878e-03, 9.7772887e-04, 1.3592317e-03, ..., 0.0000000e+00,\n",
      "        0.0000000e+00, 0.0000000e+00],\n",
      "       ...,\n",
      "       [2.6722627e-10, 2.0423878e-10, 1.5736454e-10, ..., 0.0000000e+00,\n",
      "        0.0000000e+00, 0.0000000e+00],\n",
      "       [1.6654120e-10, 6.4061749e-11, 3.0581555e-11, ..., 0.0000000e+00,\n",
      "        0.0000000e+00, 0.0000000e+00],\n",
      "       [1.4282991e-10, 3.6804469e-11, 2.0828840e-12, ..., 0.0000000e+00,\n",
      "        0.0000000e+00, 0.0000000e+00]], dtype=float32), array([[3.0316592e-03, 6.9702533e-04, 4.1913991e-06, ..., 0.0000000e+00,\n",
      "        0.0000000e+00, 0.0000000e+00],\n",
      "       [4.1956240e-03, 1.2121903e-03, 8.7174667e-05, ..., 0.0000000e+00,\n",
      "        0.0000000e+00, 0.0000000e+00],\n",
      "       [5.7596574e-03, 1.9658220e-03, 2.1257661e-03, ..., 0.0000000e+00,\n",
      "        0.0000000e+00, 0.0000000e+00],\n",
      "       ...,\n",
      "       [6.1953722e-07, 1.5495019e-07, 1.7800326e-10, ..., 0.0000000e+00,\n",
      "        0.0000000e+00, 0.0000000e+00],\n",
      "       [6.8960020e-07, 1.7242428e-07, 3.0261127e-11, ..., 0.0000000e+00,\n",
      "        0.0000000e+00, 0.0000000e+00],\n",
      "       [7.1168688e-07, 1.7792605e-07, 2.2554777e-12, ..., 0.0000000e+00,\n",
      "        0.0000000e+00, 0.0000000e+00]], dtype=float32), array([[1.2849165e-03, 3.7811691e-04, 8.0876525e-06, ..., 0.0000000e+00,\n",
      "        0.0000000e+00, 0.0000000e+00],\n",
      "       [1.3432765e-03, 3.0860817e-04, 2.9277326e-05, ..., 0.0000000e+00,\n",
      "        0.0000000e+00, 0.0000000e+00],\n",
      "       [7.8744383e-04, 7.6944439e-04, 1.2852323e-04, ..., 0.0000000e+00,\n",
      "        0.0000000e+00, 0.0000000e+00],\n",
      "       ...,\n",
      "       [5.6894726e-07, 1.4233095e-07, 1.5701146e-10, ..., 0.0000000e+00,\n",
      "        0.0000000e+00, 0.0000000e+00],\n",
      "       [6.2342627e-07, 1.5587904e-07, 2.1884741e-11, ..., 0.0000000e+00,\n",
      "        0.0000000e+00, 0.0000000e+00],\n",
      "       [6.3936847e-07, 1.5984381e-07, 1.7612756e-12, ..., 0.0000000e+00,\n",
      "        0.0000000e+00, 0.0000000e+00]], dtype=float32), array([[6.8027879e-07, 2.8963319e-07, 7.3360660e-08, ..., 0.0000000e+00,\n",
      "        0.0000000e+00, 0.0000000e+00],\n",
      "       [2.3452296e-05, 1.0654576e-05, 1.4581344e-06, ..., 0.0000000e+00,\n",
      "        0.0000000e+00, 0.0000000e+00],\n",
      "       [7.1406597e-05, 2.6164065e-05, 3.2630742e-06, ..., 0.0000000e+00,\n",
      "        0.0000000e+00, 0.0000000e+00],\n",
      "       ...,\n",
      "       [1.2274119e-08, 3.1900584e-09, 1.8585379e-10, ..., 0.0000000e+00,\n",
      "        0.0000000e+00, 0.0000000e+00],\n",
      "       [1.3639436e-08, 3.4236265e-09, 1.8918075e-11, ..., 0.0000000e+00,\n",
      "        0.0000000e+00, 0.0000000e+00],\n",
      "       [1.3692293e-08, 3.4247938e-09, 2.2027196e-12, ..., 0.0000000e+00,\n",
      "        0.0000000e+00, 0.0000000e+00]], dtype=float32), array([[6.9601483e-05, 2.6440986e-05, 2.1459680e-06, ..., 0.0000000e+00,\n",
      "        0.0000000e+00, 0.0000000e+00],\n",
      "       [8.3259751e-05, 2.4697682e-05, 1.2520694e-05, ..., 0.0000000e+00,\n",
      "        0.0000000e+00, 0.0000000e+00],\n",
      "       [2.3586974e-05, 5.7696638e-05, 9.1751863e-05, ..., 0.0000000e+00,\n",
      "        0.0000000e+00, 0.0000000e+00],\n",
      "       ...,\n",
      "       [2.0733591e-10, 1.7635401e-10, 1.4579170e-10, ..., 0.0000000e+00,\n",
      "        0.0000000e+00, 0.0000000e+00],\n",
      "       [3.5173604e-11, 3.7544655e-11, 3.1854446e-11, ..., 0.0000000e+00,\n",
      "        0.0000000e+00, 0.0000000e+00],\n",
      "       [3.0965835e-12, 2.7369407e-12, 2.3388895e-12, ..., 0.0000000e+00,\n",
      "        0.0000000e+00, 0.0000000e+00]], dtype=float32), array([[1.2797929e-04, 2.8297103e-05, 1.8312621e-06, ..., 0.0000000e+00,\n",
      "        0.0000000e+00, 0.0000000e+00],\n",
      "       [2.0574019e-04, 6.2655672e-05, 2.8251261e-06, ..., 0.0000000e+00,\n",
      "        0.0000000e+00, 0.0000000e+00],\n",
      "       [1.4774206e-04, 8.6307336e-05, 5.1772122e-06, ..., 0.0000000e+00,\n",
      "        0.0000000e+00, 0.0000000e+00],\n",
      "       ...,\n",
      "       [5.9225544e-09, 1.5917339e-09, 6.8901662e-11, ..., 0.0000000e+00,\n",
      "        0.0000000e+00, 0.0000000e+00],\n",
      "       [5.8661196e-09, 1.4847515e-09, 1.3123565e-11, ..., 0.0000000e+00,\n",
      "        0.0000000e+00, 0.0000000e+00],\n",
      "       [5.7263132e-09, 1.4335815e-09, 1.2877232e-12, ..., 0.0000000e+00,\n",
      "        0.0000000e+00, 0.0000000e+00]], dtype=float32), array([[1.6375878e-04, 5.9252357e-05, 3.5095718e-06, ..., 0.0000000e+00,\n",
      "        0.0000000e+00, 0.0000000e+00],\n",
      "       [3.7626649e-04, 1.5963832e-04, 1.2297562e-04, ..., 0.0000000e+00,\n",
      "        0.0000000e+00, 0.0000000e+00],\n",
      "       [5.8666657e-04, 1.3192988e-03, 8.7657693e-04, ..., 0.0000000e+00,\n",
      "        0.0000000e+00, 0.0000000e+00],\n",
      "       ...,\n",
      "       [2.5491353e-09, 7.6609069e-10, 1.1254506e-10, ..., 0.0000000e+00,\n",
      "        0.0000000e+00, 0.0000000e+00],\n",
      "       [2.2965625e-09, 5.9383387e-10, 2.1596398e-11, ..., 0.0000000e+00,\n",
      "        0.0000000e+00, 0.0000000e+00],\n",
      "       [2.2712057e-09, 5.6978267e-10, 3.4507714e-12, ..., 0.0000000e+00,\n",
      "        0.0000000e+00, 0.0000000e+00]], dtype=float32), array([[1.7714236e-05, 4.5769011e-06, 1.3235372e-07, ..., 0.0000000e+00,\n",
      "        0.0000000e+00, 0.0000000e+00],\n",
      "       [2.8916458e-05, 1.1609012e-05, 1.0133083e-05, ..., 0.0000000e+00,\n",
      "        0.0000000e+00, 0.0000000e+00],\n",
      "       [8.8353379e-05, 5.5940403e-05, 8.3250045e-05, ..., 0.0000000e+00,\n",
      "        0.0000000e+00, 0.0000000e+00],\n",
      "       ...,\n",
      "       [3.1060503e-09, 8.6556701e-10, 1.3535278e-10, ..., 0.0000000e+00,\n",
      "        0.0000000e+00, 0.0000000e+00],\n",
      "       [2.9040383e-09, 7.5166168e-10, 2.1542620e-11, ..., 0.0000000e+00,\n",
      "        0.0000000e+00, 0.0000000e+00],\n",
      "       [3.1864087e-09, 7.9849560e-10, 2.0477821e-12, ..., 0.0000000e+00,\n",
      "        0.0000000e+00, 0.0000000e+00]], dtype=float32), array([[3.85694019e-02, 9.87243000e-03, 8.12419574e-04, ...,\n",
      "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
      "       [4.37271297e-02, 1.10710673e-02, 3.05233710e-03, ...,\n",
      "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
      "       [1.03894882e-01, 3.49556692e-02, 6.89273234e-03, ...,\n",
      "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
      "       ...,\n",
      "       [1.08744762e-05, 2.71924364e-06, 8.89786078e-10, ...,\n",
      "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
      "       [1.29989576e-05, 3.25010888e-06, 5.19571830e-10, ...,\n",
      "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
      "       [1.38270725e-05, 3.45725198e-06, 6.75901335e-10, ...,\n",
      "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00]], dtype=float32), array([[0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       ...,\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32), array([[0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       ...,\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)]\n",
      "[[[[1.53833404e-04 5.07819095e-05 1.47654964e-06 ... 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00]\n",
      "   [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00]\n",
      "   [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00]\n",
      "   ...\n",
      "   [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00]\n",
      "   [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00]\n",
      "   [1.96774317e-06 8.00066516e-07 2.94504446e-07 ... 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00]]\n",
      "\n",
      "  [[0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00]\n",
      "   [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00]\n",
      "   [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00]\n",
      "   ...\n",
      "   [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00]\n",
      "   [3.06775246e-06 9.81837388e-07 2.15167290e-07 ... 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00]\n",
      "   [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00]]\n",
      "\n",
      "  [[0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00]\n",
      "   [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00]\n",
      "   [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00]\n",
      "   ...\n",
      "   [3.00560532e-05 1.86631005e-05 1.70885733e-06 ... 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00]\n",
      "   [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00]\n",
      "   [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00]\n",
      "   [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00]\n",
      "   [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00]\n",
      "   ...\n",
      "   [6.57222987e-09 4.17811341e-09 1.75634052e-09 ... 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00]\n",
      "   [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00]\n",
      "   [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00]]\n",
      "\n",
      "  [[0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00]\n",
      "   [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00]\n",
      "   [5.18270804e-09 2.83603452e-09 1.04308029e-09 ... 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00]\n",
      "   ...\n",
      "   [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00]\n",
      "   [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00]\n",
      "   [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00]]\n",
      "\n",
      "  [[0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00]\n",
      "   [1.24308173e-08 3.20630122e-09 8.90091542e-11 ... 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00]\n",
      "   [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00]\n",
      "   ...\n",
      "   [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00]\n",
      "   [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00]\n",
      "   [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00]]]\n",
      "\n",
      "\n",
      " [[[1.23605569e-04 2.98704836e-05 5.84078919e-07 ... 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00]\n",
      "   [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00]\n",
      "   [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00]\n",
      "   ...\n",
      "   [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00]\n",
      "   [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00]\n",
      "   [1.13009207e-03 7.45748344e-04 9.83553473e-04 ... 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00]]\n",
      "\n",
      "  [[0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00]\n",
      "   [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00]\n",
      "   [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00]\n",
      "   ...\n",
      "   [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00]\n",
      "   [6.84377083e-05 1.02536884e-04 1.57730519e-05 ... 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00]\n",
      "   [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00]]\n",
      "\n",
      "  [[0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00]\n",
      "   [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00]\n",
      "   [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00]\n",
      "   ...\n",
      "   [7.62076816e-05 4.52557615e-05 1.28257117e-04 ... 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00]\n",
      "   [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00]\n",
      "   [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00]\n",
      "   [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00]\n",
      "   [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00]\n",
      "   ...\n",
      "   [3.28185390e-09 3.62660391e-09 3.79074194e-09 ... 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00]\n",
      "   [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00]\n",
      "   [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00]]\n",
      "\n",
      "  [[0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00]\n",
      "   [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00]\n",
      "   [7.04436243e-09 3.35728956e-09 2.18966534e-09 ... 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00]\n",
      "   ...\n",
      "   [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00]\n",
      "   [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00]\n",
      "   [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00]]\n",
      "\n",
      "  [[0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00]\n",
      "   [1.67130789e-08 4.27118652e-09 1.24297933e-10 ... 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00]\n",
      "   [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00]\n",
      "   ...\n",
      "   [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00]\n",
      "   [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00]\n",
      "   [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00]]]\n",
      "\n",
      "\n",
      " [[[0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00]\n",
      "   [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00]\n",
      "   [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00]\n",
      "   ...\n",
      "   [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00]\n",
      "   [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00]\n",
      "   [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00]]\n",
      "\n",
      "  [[0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00]\n",
      "   [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00]\n",
      "   [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00]\n",
      "   ...\n",
      "   [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00]\n",
      "   [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00]\n",
      "   [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00]]\n",
      "\n",
      "  [[0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00]\n",
      "   [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00]\n",
      "   [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00]\n",
      "   ...\n",
      "   [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00]\n",
      "   [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00]\n",
      "   [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00]\n",
      "   [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00]\n",
      "   [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00]\n",
      "   ...\n",
      "   [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00]\n",
      "   [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00]\n",
      "   [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00]]\n",
      "\n",
      "  [[0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00]\n",
      "   [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00]\n",
      "   [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00]\n",
      "   ...\n",
      "   [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00]\n",
      "   [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00]\n",
      "   [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00]]\n",
      "\n",
      "  [[0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00]\n",
      "   [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00]\n",
      "   [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00]\n",
      "   ...\n",
      "   [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00]\n",
      "   [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00]\n",
      "   [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00]]]]\n",
      "[[1]\n",
      " [1]\n",
      " [1]]\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "(40, 16, 19)\n",
      "x_train shape: (50, 40, 16, 19)\n",
      "50 train samples\n",
      "47 test samples\n",
      "y_train shape: (50, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\patcas rares\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate:  0.01\n",
      "Model: \"model_122\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_123 (InputLayer)          [(None, 40, 16, 19)] 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3782 (Conv2D)            (None, 40, 16, 16)   2752        input_123[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3416 (Batch (None, 40, 16, 16)   64          conv2d_3782[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_3416 (Activation)    (None, 40, 16, 16)   0           batch_normalization_3416[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3783 (Conv2D)            (None, 40, 16, 16)   272         activation_3416[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3417 (Batch (None, 40, 16, 16)   64          conv2d_3783[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_3417 (Activation)    (None, 40, 16, 16)   0           batch_normalization_3417[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3784 (Conv2D)            (None, 40, 16, 16)   2320        activation_3417[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3418 (Batch (None, 40, 16, 16)   64          conv2d_3784[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_3418 (Activation)    (None, 40, 16, 16)   0           batch_normalization_3418[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3786 (Conv2D)            (None, 40, 16, 64)   1088        activation_3416[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3785 (Conv2D)            (None, 40, 16, 64)   1088        activation_3418[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_1098 (Add)                  (None, 40, 16, 64)   0           conv2d_3786[0][0]                \n",
      "                                                                 conv2d_3785[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3419 (Batch (None, 40, 16, 64)   256         add_1098[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_3419 (Activation)    (None, 40, 16, 64)   0           batch_normalization_3419[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3787 (Conv2D)            (None, 40, 16, 16)   1040        activation_3419[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3420 (Batch (None, 40, 16, 16)   64          conv2d_3787[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_3420 (Activation)    (None, 40, 16, 16)   0           batch_normalization_3420[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3788 (Conv2D)            (None, 40, 16, 16)   2320        activation_3420[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3421 (Batch (None, 40, 16, 16)   64          conv2d_3788[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_3421 (Activation)    (None, 40, 16, 16)   0           batch_normalization_3421[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3789 (Conv2D)            (None, 40, 16, 64)   1088        activation_3421[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_1099 (Add)                  (None, 40, 16, 64)   0           add_1098[0][0]                   \n",
      "                                                                 conv2d_3789[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3422 (Batch (None, 40, 16, 64)   256         add_1099[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_3422 (Activation)    (None, 40, 16, 64)   0           batch_normalization_3422[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3790 (Conv2D)            (None, 40, 16, 16)   1040        activation_3422[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3423 (Batch (None, 40, 16, 16)   64          conv2d_3790[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_3423 (Activation)    (None, 40, 16, 16)   0           batch_normalization_3423[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3791 (Conv2D)            (None, 40, 16, 16)   2320        activation_3423[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3424 (Batch (None, 40, 16, 16)   64          conv2d_3791[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_3424 (Activation)    (None, 40, 16, 16)   0           batch_normalization_3424[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3792 (Conv2D)            (None, 40, 16, 64)   1088        activation_3424[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_1100 (Add)                  (None, 40, 16, 64)   0           add_1099[0][0]                   \n",
      "                                                                 conv2d_3792[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3425 (Batch (None, 40, 16, 64)   256         add_1100[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_3425 (Activation)    (None, 40, 16, 64)   0           batch_normalization_3425[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3793 (Conv2D)            (None, 20, 8, 64)    4160        activation_3425[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3426 (Batch (None, 20, 8, 64)    256         conv2d_3793[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_3426 (Activation)    (None, 20, 8, 64)    0           batch_normalization_3426[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3794 (Conv2D)            (None, 20, 8, 64)    36928       activation_3426[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3427 (Batch (None, 20, 8, 64)    256         conv2d_3794[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_3427 (Activation)    (None, 20, 8, 64)    0           batch_normalization_3427[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3796 (Conv2D)            (None, 20, 8, 128)   8320        add_1100[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3795 (Conv2D)            (None, 20, 8, 128)   8320        activation_3427[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_1101 (Add)                  (None, 20, 8, 128)   0           conv2d_3796[0][0]                \n",
      "                                                                 conv2d_3795[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3428 (Batch (None, 20, 8, 128)   512         add_1101[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_3428 (Activation)    (None, 20, 8, 128)   0           batch_normalization_3428[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3797 (Conv2D)            (None, 20, 8, 64)    8256        activation_3428[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3429 (Batch (None, 20, 8, 64)    256         conv2d_3797[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_3429 (Activation)    (None, 20, 8, 64)    0           batch_normalization_3429[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3798 (Conv2D)            (None, 20, 8, 64)    36928       activation_3429[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3430 (Batch (None, 20, 8, 64)    256         conv2d_3798[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_3430 (Activation)    (None, 20, 8, 64)    0           batch_normalization_3430[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3799 (Conv2D)            (None, 20, 8, 128)   8320        activation_3430[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_1102 (Add)                  (None, 20, 8, 128)   0           add_1101[0][0]                   \n",
      "                                                                 conv2d_3799[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3431 (Batch (None, 20, 8, 128)   512         add_1102[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_3431 (Activation)    (None, 20, 8, 128)   0           batch_normalization_3431[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3800 (Conv2D)            (None, 20, 8, 64)    8256        activation_3431[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3432 (Batch (None, 20, 8, 64)    256         conv2d_3800[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_3432 (Activation)    (None, 20, 8, 64)    0           batch_normalization_3432[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3801 (Conv2D)            (None, 20, 8, 64)    36928       activation_3432[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3433 (Batch (None, 20, 8, 64)    256         conv2d_3801[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_3433 (Activation)    (None, 20, 8, 64)    0           batch_normalization_3433[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3802 (Conv2D)            (None, 20, 8, 128)   8320        activation_3433[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_1103 (Add)                  (None, 20, 8, 128)   0           add_1102[0][0]                   \n",
      "                                                                 conv2d_3802[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3434 (Batch (None, 20, 8, 128)   512         add_1103[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_3434 (Activation)    (None, 20, 8, 128)   0           batch_normalization_3434[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3803 (Conv2D)            (None, 10, 4, 128)   16512       activation_3434[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3435 (Batch (None, 10, 4, 128)   512         conv2d_3803[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_3435 (Activation)    (None, 10, 4, 128)   0           batch_normalization_3435[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3804 (Conv2D)            (None, 10, 4, 128)   147584      activation_3435[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3436 (Batch (None, 10, 4, 128)   512         conv2d_3804[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_3436 (Activation)    (None, 10, 4, 128)   0           batch_normalization_3436[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3806 (Conv2D)            (None, 10, 4, 256)   33024       add_1103[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3805 (Conv2D)            (None, 10, 4, 256)   33024       activation_3436[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_1104 (Add)                  (None, 10, 4, 256)   0           conv2d_3806[0][0]                \n",
      "                                                                 conv2d_3805[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3437 (Batch (None, 10, 4, 256)   1024        add_1104[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_3437 (Activation)    (None, 10, 4, 256)   0           batch_normalization_3437[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3807 (Conv2D)            (None, 10, 4, 128)   32896       activation_3437[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3438 (Batch (None, 10, 4, 128)   512         conv2d_3807[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_3438 (Activation)    (None, 10, 4, 128)   0           batch_normalization_3438[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3808 (Conv2D)            (None, 10, 4, 128)   147584      activation_3438[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3439 (Batch (None, 10, 4, 128)   512         conv2d_3808[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_3439 (Activation)    (None, 10, 4, 128)   0           batch_normalization_3439[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3809 (Conv2D)            (None, 10, 4, 256)   33024       activation_3439[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_1105 (Add)                  (None, 10, 4, 256)   0           add_1104[0][0]                   \n",
      "                                                                 conv2d_3809[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3440 (Batch (None, 10, 4, 256)   1024        add_1105[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_3440 (Activation)    (None, 10, 4, 256)   0           batch_normalization_3440[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3810 (Conv2D)            (None, 10, 4, 128)   32896       activation_3440[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3441 (Batch (None, 10, 4, 128)   512         conv2d_3810[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_3441 (Activation)    (None, 10, 4, 128)   0           batch_normalization_3441[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3811 (Conv2D)            (None, 10, 4, 128)   147584      activation_3441[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3442 (Batch (None, 10, 4, 128)   512         conv2d_3811[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_3442 (Activation)    (None, 10, 4, 128)   0           batch_normalization_3442[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3812 (Conv2D)            (None, 10, 4, 256)   33024       activation_3442[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_1106 (Add)                  (None, 10, 4, 256)   0           add_1105[0][0]                   \n",
      "                                                                 conv2d_3812[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3443 (Batch (None, 10, 4, 256)   1024        add_1106[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_3443 (Activation)    (None, 10, 4, 256)   0           batch_normalization_3443[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_122 (AverageP (None, 5, 2, 256)    0           activation_3443[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_122 (Flatten)           (None, 2560)         0           average_pooling2d_122[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_122 (Dense)               (None, 10)           25610       flatten_122[0][0]                \n",
      "==================================================================================================\n",
      "Total params: 874,346\n",
      "Trainable params: 869,130\n",
      "Non-trainable params: 5,216\n",
      "__________________________________________________________________________________________________\n",
      "ResNet  29v  2\n",
      "Using real-time data augmentation.\n",
      "------------------\n",
      "[[[[-3.32580617e-04 -8.69113937e-05 -1.00089137e-05 ... -1.98650284e-07\n",
      "    -6.64963352e-07 -7.25612722e-07]\n",
      "   [-4.79487198e-07 -4.66331448e-06 -8.89375406e-06 ... -7.50429265e-08\n",
      "    -2.91938456e-08 -3.24993259e-08]\n",
      "   [-5.37498135e-09 -1.41872325e-09 -1.48456403e-09 ... -2.92625533e-08\n",
      "    -9.07102393e-09 -1.29656073e-08]\n",
      "   ...\n",
      "   [-6.44487898e-07 -9.96142603e-07 -8.22959350e-07 ...  0.00000000e+00\n",
      "     0.00000000e+00  0.00000000e+00]\n",
      "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
      "     0.00000000e+00  0.00000000e+00]\n",
      "   [-1.04265881e-03 -1.53786980e-03 -2.58844323e-03 ... -1.41644734e-04\n",
      "    -5.47315227e-04 -9.07485140e-04]]\n",
      "\n",
      "  [[-7.17807736e-04 -3.47352412e-04 -6.92247340e-05 ... -9.60778652e-06\n",
      "    -4.36930986e-06 -9.78022513e-07]\n",
      "   [-5.35814593e-07 -4.61469654e-07 -1.09751602e-06 ... -6.43625845e-06\n",
      "    -7.13541749e-06 -5.04288437e-06]\n",
      "   [-2.22698441e-06 -4.26859333e-06 -1.28046111e-06 ...  0.00000000e+00\n",
      "     0.00000000e+00  0.00000000e+00]\n",
      "   ...\n",
      "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
      "     0.00000000e+00  0.00000000e+00]\n",
      "   [-5.38707525e-03 -8.20153765e-03 -5.59631828e-03 ... -1.15156034e-03\n",
      "    -2.05656211e-03 -2.25965749e-03]\n",
      "   [-3.31821642e-03 -5.75596513e-03 -2.80867377e-03 ... -3.33243574e-04\n",
      "    -6.23081432e-05 -2.21667015e-05]]\n",
      "\n",
      "  [[-9.39335223e-06 -6.27012753e-07 -1.15266744e-06 ... -2.84473092e-04\n",
      "    -1.03545011e-04 -1.10521069e-04]\n",
      "   [-1.87604630e-04 -2.18137880e-04 -7.70949991e-05 ...  0.00000000e+00\n",
      "     0.00000000e+00  0.00000000e+00]\n",
      "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
      "     0.00000000e+00  0.00000000e+00]\n",
      "   ...\n",
      "   [-2.40839762e-03 -4.22892999e-03 -4.11587022e-03 ... -1.06668286e-03\n",
      "    -1.10480944e-02 -1.37990341e-02]\n",
      "   [-3.62203061e-03 -6.09343057e-04 -1.00243848e-03 ... -2.65606446e-04\n",
      "    -2.97850376e-04 -7.05856364e-05]\n",
      "   [-5.51828089e-05 -2.78509378e-05 -8.36958043e-06 ... -1.91950065e-04\n",
      "    -2.22222356e-04 -2.12054161e-04]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[-4.50917428e-12 -3.16191236e-12 -3.77275555e-12 ... -1.45446318e-12\n",
      "    -1.39034715e-12 -1.32162835e-12]\n",
      "   [-1.03613851e-12 -8.84997208e-13 -1.38188040e-12 ...  0.00000000e+00\n",
      "     0.00000000e+00  0.00000000e+00]\n",
      "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
      "     0.00000000e+00  0.00000000e+00]\n",
      "   ...\n",
      "   [-1.59457816e-08 -3.98526234e-09 -3.35562350e-12 ... -5.93906868e-12\n",
      "    -5.29280569e-12 -4.90759039e-12]\n",
      "   [-4.43735803e-12 -4.43562895e-12 -4.37990920e-12 ... -3.02438955e-12\n",
      "    -2.92093823e-12 -3.16592412e-12]\n",
      "   [-2.57593968e-12 -1.89003999e-12 -1.91519305e-12 ... -7.61290499e-13\n",
      "    -6.20845714e-13 -5.80994508e-13]]\n",
      "\n",
      "  [[-4.86314168e-13 -5.78390200e-13 -6.97381118e-13 ...  0.00000000e+00\n",
      "     0.00000000e+00  0.00000000e+00]\n",
      "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
      "     0.00000000e+00  0.00000000e+00]\n",
      "   [-2.67639990e-08 -6.69110900e-09 -2.96213054e-12 ... -3.98308643e-12\n",
      "    -3.91927202e-12 -3.96540873e-12]\n",
      "   ...\n",
      "   [-9.27929717e-13 -8.17696280e-13 -7.32935468e-13 ... -4.54746565e-13\n",
      "    -4.20115548e-13 -4.09356847e-13]\n",
      "   [-3.38677328e-13 -2.57056963e-13 -2.47124261e-13 ... -1.08777726e-13\n",
      "    -1.20264963e-13 -1.00348725e-13]\n",
      "   [-7.94128421e-14 -7.09088143e-14 -7.98647783e-14 ...  0.00000000e+00\n",
      "     0.00000000e+00  0.00000000e+00]]\n",
      "\n",
      "  [[ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
      "     0.00000000e+00  0.00000000e+00]\n",
      "   [-7.16966468e-08 -1.79249877e-08 -3.40234161e-13 ... -3.24382990e-13\n",
      "    -3.25158926e-13 -3.24833666e-13]\n",
      "   [-3.02783054e-13 -2.79770673e-13 -2.37233925e-13 ... -1.27062870e-13\n",
      "    -1.29399827e-13 -1.23260248e-13]\n",
      "   ...\n",
      "   [-3.85566645e-15 -4.03823254e-15 -4.32480877e-15 ... -1.41218604e-15\n",
      "    -1.23482115e-15 -1.54258718e-15]\n",
      "   [-1.01435425e-15 -5.39077708e-16 -3.44277547e-16 ...  0.00000000e+00\n",
      "     0.00000000e+00  0.00000000e+00]\n",
      "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
      "     0.00000000e+00  0.00000000e+00]]]\n",
      "\n",
      "\n",
      " [[[-3.32699157e-04 -8.69934011e-05 -1.00124144e-05 ... -1.98650284e-07\n",
      "    -6.64963352e-07 -7.25612722e-07]\n",
      "   [-4.79487198e-07 -4.66331448e-06 -8.89375406e-06 ... -7.50429265e-08\n",
      "    -2.91938456e-08 -3.24993259e-08]\n",
      "   [-5.37498135e-09 -1.41872325e-09 -1.48456403e-09 ... -2.92625533e-08\n",
      "    -9.07102393e-09 -1.29656073e-08]\n",
      "   ...\n",
      "   [-6.44487898e-07 -9.96142603e-07 -8.22959350e-07 ...  0.00000000e+00\n",
      "     0.00000000e+00  0.00000000e+00]\n",
      "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
      "     0.00000000e+00  0.00000000e+00]\n",
      "   [-1.03823480e-03 -1.53494847e-03 -2.58458732e-03 ... -1.41644734e-04\n",
      "    -5.47315227e-04 -9.07485140e-04]]\n",
      "\n",
      "  [[-7.17807736e-04 -3.47352412e-04 -6.92247340e-05 ... -9.60778652e-06\n",
      "    -4.36930986e-06 -9.78022513e-07]\n",
      "   [-5.35814593e-07 -4.61469654e-07 -1.09751602e-06 ... -6.43625845e-06\n",
      "    -7.13541749e-06 -5.04288437e-06]\n",
      "   [-2.22698441e-06 -4.26859333e-06 -1.28046111e-06 ...  0.00000000e+00\n",
      "     0.00000000e+00  0.00000000e+00]\n",
      "   ...\n",
      "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
      "     0.00000000e+00  0.00000000e+00]\n",
      "   [-5.38681913e-03 -8.20113905e-03 -5.59625728e-03 ... -1.15156034e-03\n",
      "    -2.05656211e-03 -2.25965749e-03]\n",
      "   [-3.31821642e-03 -5.75596513e-03 -2.80867377e-03 ... -3.33243574e-04\n",
      "    -6.23081432e-05 -2.21667015e-05]]\n",
      "\n",
      "  [[-9.39335223e-06 -6.27012753e-07 -1.15266744e-06 ... -2.84473092e-04\n",
      "    -1.03545011e-04 -1.10521069e-04]\n",
      "   [-1.87604630e-04 -2.18137880e-04 -7.70949991e-05 ...  0.00000000e+00\n",
      "     0.00000000e+00  0.00000000e+00]\n",
      "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
      "     0.00000000e+00  0.00000000e+00]\n",
      "   ...\n",
      "   [-2.40821647e-03 -4.22882568e-03 -4.11537383e-03 ... -1.06668286e-03\n",
      "    -1.10480944e-02 -1.37990341e-02]\n",
      "   [-3.62203061e-03 -6.09343057e-04 -1.00243848e-03 ... -2.65606446e-04\n",
      "    -2.97850376e-04 -7.05856364e-05]\n",
      "   [-5.51828089e-05 -2.78509378e-05 -8.36958043e-06 ... -1.91950065e-04\n",
      "    -2.22222356e-04 -2.12054161e-04]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[-4.50917428e-12 -3.16191236e-12 -3.77275555e-12 ... -1.45446318e-12\n",
      "    -1.39034715e-12 -1.32162835e-12]\n",
      "   [-1.03613851e-12 -8.84997208e-13 -1.38188040e-12 ...  0.00000000e+00\n",
      "     0.00000000e+00  0.00000000e+00]\n",
      "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
      "     0.00000000e+00  0.00000000e+00]\n",
      "   ...\n",
      "   [-1.59586850e-08 -3.98742506e-09  4.62242050e-12 ... -5.93906868e-12\n",
      "    -5.29280569e-12 -4.90759039e-12]\n",
      "   [-4.43735803e-12 -4.43562895e-12 -4.37990920e-12 ... -3.02438955e-12\n",
      "    -2.92093823e-12 -3.16592412e-12]\n",
      "   [-2.57593968e-12 -1.89003999e-12 -1.91519305e-12 ... -7.61290499e-13\n",
      "    -6.20845714e-13 -5.80994508e-13]]\n",
      "\n",
      "  [[-4.86314168e-13 -5.78390200e-13 -6.97381118e-13 ...  0.00000000e+00\n",
      "     0.00000000e+00  0.00000000e+00]\n",
      "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
      "     0.00000000e+00  0.00000000e+00]\n",
      "   [-2.67567000e-08 -6.68906486e-09  1.53428138e-12 ... -3.98308643e-12\n",
      "    -3.91927202e-12 -3.96540873e-12]\n",
      "   ...\n",
      "   [-9.27929717e-13 -8.17696280e-13 -7.32935468e-13 ... -4.54746565e-13\n",
      "    -4.20115548e-13 -4.09356847e-13]\n",
      "   [-3.38677328e-13 -2.57056963e-13 -2.47124261e-13 ... -1.08777726e-13\n",
      "    -1.20264963e-13 -1.00348725e-13]\n",
      "   [-7.94128421e-14 -7.09088143e-14 -7.98647783e-14 ...  0.00000000e+00\n",
      "     0.00000000e+00  0.00000000e+00]]\n",
      "\n",
      "  [[ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
      "     0.00000000e+00  0.00000000e+00]\n",
      "   [-7.16798567e-08 -1.79208115e-08 -2.01846786e-13 ... -3.24382990e-13\n",
      "    -3.25158926e-13 -3.24833666e-13]\n",
      "   [-3.02783054e-13 -2.79770673e-13 -2.37233925e-13 ... -1.27062870e-13\n",
      "    -1.29399827e-13 -1.23260248e-13]\n",
      "   ...\n",
      "   [-3.85566645e-15 -4.03823254e-15 -4.32480877e-15 ... -1.41218604e-15\n",
      "    -1.23482115e-15 -1.54258718e-15]\n",
      "   [-1.01435425e-15 -5.39077708e-16 -3.44277547e-16 ...  0.00000000e+00\n",
      "     0.00000000e+00  0.00000000e+00]\n",
      "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
      "     0.00000000e+00  0.00000000e+00]]]\n",
      "\n",
      "\n",
      " [[[-3.33183882e-04 -8.71105367e-05 -1.00147045e-05 ... -1.98650284e-07\n",
      "    -6.64963352e-07 -7.25612722e-07]\n",
      "   [-4.79487198e-07 -4.66331448e-06 -8.89375406e-06 ... -7.50429265e-08\n",
      "    -2.91938456e-08 -3.24993259e-08]\n",
      "   [-5.37498135e-09 -1.41872325e-09 -1.48456403e-09 ... -2.92625533e-08\n",
      "    -9.07102393e-09 -1.29656073e-08]\n",
      "   ...\n",
      "   [-6.44487898e-07 -9.96142603e-07 -8.22959350e-07 ...  0.00000000e+00\n",
      "     0.00000000e+00  0.00000000e+00]\n",
      "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
      "     0.00000000e+00  0.00000000e+00]\n",
      "   [-1.04266650e-03 -1.53787294e-03 -2.58844439e-03 ... -1.41644734e-04\n",
      "    -5.47315227e-04 -9.07485140e-04]]\n",
      "\n",
      "  [[-7.17807736e-04 -3.47352412e-04 -6.92247340e-05 ... -9.60778652e-06\n",
      "    -4.36930986e-06 -9.78022513e-07]\n",
      "   [-5.35814593e-07 -4.61469654e-07 -1.09751602e-06 ... -6.43625845e-06\n",
      "    -7.13541749e-06 -5.04288437e-06]\n",
      "   [-2.22698441e-06 -4.26859333e-06 -1.28046111e-06 ...  0.00000000e+00\n",
      "     0.00000000e+00  0.00000000e+00]\n",
      "   ...\n",
      "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
      "     0.00000000e+00  0.00000000e+00]\n",
      "   [-5.38708735e-03 -8.20154138e-03 -5.59631921e-03 ... -1.15156034e-03\n",
      "    -2.05656211e-03 -2.25965749e-03]\n",
      "   [-3.31821642e-03 -5.75596513e-03 -2.80867377e-03 ... -3.33243574e-04\n",
      "    -6.23081432e-05 -2.21667015e-05]]\n",
      "\n",
      "  [[-9.39335223e-06 -6.27012753e-07 -1.15266744e-06 ... -2.84473092e-04\n",
      "    -1.03545011e-04 -1.10521069e-04]\n",
      "   [-1.87604630e-04 -2.18137880e-04 -7.70949991e-05 ...  0.00000000e+00\n",
      "     0.00000000e+00  0.00000000e+00]\n",
      "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
      "     0.00000000e+00  0.00000000e+00]\n",
      "   ...\n",
      "   [-2.40851543e-03 -4.22900310e-03 -4.11587674e-03 ... -1.06668286e-03\n",
      "    -1.10480944e-02 -1.37990341e-02]\n",
      "   [-3.62203061e-03 -6.09343057e-04 -1.00243848e-03 ... -2.65606446e-04\n",
      "    -2.97850376e-04 -7.05856364e-05]\n",
      "   [-5.51828089e-05 -2.78509378e-05 -8.36958043e-06 ... -1.91950065e-04\n",
      "    -2.22222356e-04 -2.12054161e-04]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[-4.50917428e-12 -3.16191236e-12 -3.77275555e-12 ... -1.45446318e-12\n",
      "    -1.39034715e-12 -1.32162835e-12]\n",
      "   [-1.03613851e-12 -8.84997208e-13 -1.38188040e-12 ...  0.00000000e+00\n",
      "     0.00000000e+00  0.00000000e+00]\n",
      "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
      "     0.00000000e+00  0.00000000e+00]\n",
      "   ...\n",
      "   [-1.59715547e-08 -4.00164701e-09 -1.02432333e-11 ... -5.93906868e-12\n",
      "    -5.29280569e-12 -4.90759039e-12]\n",
      "   [-4.43735803e-12 -4.43562895e-12 -4.37990920e-12 ... -3.02438955e-12\n",
      "    -2.92093823e-12 -3.16592412e-12]\n",
      "   [-2.57593968e-12 -1.89003999e-12 -1.91519305e-12 ... -7.61290499e-13\n",
      "    -6.20845714e-13 -5.80994508e-13]]\n",
      "\n",
      "  [[-4.86314168e-13 -5.78390200e-13 -6.97381118e-13 ...  0.00000000e+00\n",
      "     0.00000000e+00  0.00000000e+00]\n",
      "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
      "     0.00000000e+00  0.00000000e+00]\n",
      "   [-2.67843241e-08 -6.70223077e-09 -7.05264146e-12 ... -3.98308643e-12\n",
      "    -3.91927202e-12 -3.96540873e-12]\n",
      "   ...\n",
      "   [-9.27929717e-13 -8.17696280e-13 -7.32935468e-13 ... -4.54746565e-13\n",
      "    -4.20115548e-13 -4.09356847e-13]\n",
      "   [-3.38677328e-13 -2.57056963e-13 -2.47124261e-13 ... -1.08777726e-13\n",
      "    -1.20264963e-13 -1.00348725e-13]\n",
      "   [-7.94128421e-14 -7.09088143e-14 -7.98647783e-14 ...  0.00000000e+00\n",
      "     0.00000000e+00  0.00000000e+00]]\n",
      "\n",
      "  [[ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
      "     0.00000000e+00  0.00000000e+00]\n",
      "   [-7.17453972e-08 -1.79375608e-08 -6.89289663e-13 ... -3.24382990e-13\n",
      "    -3.25158926e-13 -3.24833666e-13]\n",
      "   [-3.02783054e-13 -2.79770673e-13 -2.37233925e-13 ... -1.27062870e-13\n",
      "    -1.29399827e-13 -1.23260248e-13]\n",
      "   ...\n",
      "   [-3.85566645e-15 -4.03823254e-15 -4.32480877e-15 ... -1.41218604e-15\n",
      "    -1.23482115e-15 -1.54258718e-15]\n",
      "   [-1.01435425e-15 -5.39077708e-16 -3.44277547e-16 ...  0.00000000e+00\n",
      "     0.00000000e+00  0.00000000e+00]\n",
      "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
      "     0.00000000e+00  0.00000000e+00]]]\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      " [[[-3.33043863e-04 -8.70777440e-05 -1.00132074e-05 ... -1.98650284e-07\n",
      "    -6.64963352e-07 -7.25612722e-07]\n",
      "   [-4.79487198e-07 -4.66331448e-06 -8.89375406e-06 ... -7.50429265e-08\n",
      "    -2.91938456e-08 -3.24993259e-08]\n",
      "   [-5.37498135e-09 -1.41872325e-09 -1.48456403e-09 ... -2.92625533e-08\n",
      "    -9.07102393e-09 -1.29656073e-08]\n",
      "   ...\n",
      "   [-6.44487898e-07 -9.96142603e-07 -8.22959350e-07 ...  0.00000000e+00\n",
      "     0.00000000e+00  0.00000000e+00]\n",
      "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
      "     0.00000000e+00  0.00000000e+00]\n",
      "   [-1.04204135e-03 -1.53704907e-03 -2.58745952e-03 ... -1.41644734e-04\n",
      "    -5.47315227e-04 -9.07485140e-04]]\n",
      "\n",
      "  [[-7.17807736e-04 -3.47352412e-04 -6.92247340e-05 ... -9.60778652e-06\n",
      "    -4.36930986e-06 -9.78022513e-07]\n",
      "   [-5.35814593e-07 -4.61469654e-07 -1.09751602e-06 ... -6.43625845e-06\n",
      "    -7.13541749e-06 -5.04288437e-06]\n",
      "   [-2.22698441e-06 -4.26859333e-06 -1.28046111e-06 ...  0.00000000e+00\n",
      "     0.00000000e+00  0.00000000e+00]\n",
      "   ...\n",
      "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
      "     0.00000000e+00  0.00000000e+00]\n",
      "   [-5.38654719e-03 -8.20119027e-03 -5.59589546e-03 ... -1.15156034e-03\n",
      "    -2.05656211e-03 -2.25965749e-03]\n",
      "   [-3.31821642e-03 -5.75596513e-03 -2.80867377e-03 ... -3.33243574e-04\n",
      "    -6.23081432e-05 -2.21667015e-05]]\n",
      "\n",
      "  [[-9.39335223e-06 -6.27012753e-07 -1.15266744e-06 ... -2.84473092e-04\n",
      "    -1.03545011e-04 -1.10521069e-04]\n",
      "   [-1.87604630e-04 -2.18137880e-04 -7.70949991e-05 ...  0.00000000e+00\n",
      "     0.00000000e+00  0.00000000e+00]\n",
      "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
      "     0.00000000e+00  0.00000000e+00]\n",
      "   ...\n",
      "   [-2.39289319e-03 -4.20956034e-03 -4.08313749e-03 ... -1.06668286e-03\n",
      "    -1.10480944e-02 -1.37990341e-02]\n",
      "   [-3.62203061e-03 -6.09343057e-04 -1.00243848e-03 ... -2.65606446e-04\n",
      "    -2.97850376e-04 -7.05856364e-05]\n",
      "   [-5.51828089e-05 -2.78509378e-05 -8.36958043e-06 ... -1.91950065e-04\n",
      "    -2.22222356e-04 -2.12054161e-04]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[-4.50917428e-12 -3.16191236e-12 -3.77275555e-12 ... -1.45446318e-12\n",
      "    -1.39034715e-12 -1.32162835e-12]\n",
      "   [-1.03613851e-12 -8.84997208e-13 -1.38188040e-12 ...  0.00000000e+00\n",
      "     0.00000000e+00  0.00000000e+00]\n",
      "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
      "     0.00000000e+00  0.00000000e+00]\n",
      "   ...\n",
      "   [-1.59443019e-08 -3.98435818e-09  1.37077849e-14 ... -5.93906868e-12\n",
      "    -5.29280569e-12 -4.90759039e-12]\n",
      "   [-4.43735803e-12 -4.43562895e-12 -4.37990920e-12 ... -3.02438955e-12\n",
      "    -2.92093823e-12 -3.16592412e-12]\n",
      "   [-2.57593968e-12 -1.89003999e-12 -1.91519305e-12 ... -7.61290499e-13\n",
      "    -6.20845714e-13 -5.80994508e-13]]\n",
      "\n",
      "  [[-4.86314168e-13 -5.78390200e-13 -6.97381118e-13 ...  0.00000000e+00\n",
      "     0.00000000e+00  0.00000000e+00]\n",
      "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
      "     0.00000000e+00  0.00000000e+00]\n",
      "   [-2.67766236e-08 -6.69516620e-09 -3.82361243e-13 ... -3.98308643e-12\n",
      "    -3.91927202e-12 -3.96540873e-12]\n",
      "   ...\n",
      "   [-9.27929717e-13 -8.17696280e-13 -7.32935468e-13 ... -4.54746565e-13\n",
      "    -4.20115548e-13 -4.09356847e-13]\n",
      "   [-3.38677328e-13 -2.57056963e-13 -2.47124261e-13 ... -1.08777726e-13\n",
      "    -1.20264963e-13 -1.00348725e-13]\n",
      "   [-7.94128421e-14 -7.09088143e-14 -7.98647783e-14 ...  0.00000000e+00\n",
      "     0.00000000e+00  0.00000000e+00]]\n",
      "\n",
      "  [[ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
      "     0.00000000e+00  0.00000000e+00]\n",
      "   [-7.17436919e-08 -1.79366761e-08 -5.57908212e-14 ... -3.24382990e-13\n",
      "    -3.25158926e-13 -3.24833666e-13]\n",
      "   [-3.02783054e-13 -2.79770673e-13 -2.37233925e-13 ... -1.27062870e-13\n",
      "    -1.29399827e-13 -1.23260248e-13]\n",
      "   ...\n",
      "   [-3.85566645e-15 -4.03823254e-15 -4.32480877e-15 ... -1.41218604e-15\n",
      "    -1.23482115e-15 -1.54258718e-15]\n",
      "   [-1.01435425e-15 -5.39077708e-16 -3.44277547e-16 ...  0.00000000e+00\n",
      "     0.00000000e+00  0.00000000e+00]\n",
      "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
      "     0.00000000e+00  0.00000000e+00]]]\n",
      "\n",
      "\n",
      " [[[-3.33144999e-04 -8.70998847e-05 -1.00143370e-05 ... -1.98650284e-07\n",
      "    -6.64963352e-07 -7.25612722e-07]\n",
      "   [-4.79487198e-07 -4.66331448e-06 -8.89375406e-06 ... -7.50429265e-08\n",
      "    -2.91938456e-08 -3.24993259e-08]\n",
      "   [-5.37498135e-09 -1.41872325e-09 -1.48456403e-09 ... -2.92625533e-08\n",
      "    -9.07102393e-09 -1.29656073e-08]\n",
      "   ...\n",
      "   [-6.44487898e-07 -9.96142603e-07 -8.22959350e-07 ...  0.00000000e+00\n",
      "     0.00000000e+00  0.00000000e+00]\n",
      "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
      "     0.00000000e+00  0.00000000e+00]\n",
      "   [-1.04264857e-03 -1.53782382e-03 -2.58819456e-03 ... -1.41644734e-04\n",
      "    -5.47315227e-04 -9.07485140e-04]]\n",
      "\n",
      "  [[-7.17807736e-04 -3.47352412e-04 -6.92247340e-05 ... -9.60778652e-06\n",
      "    -4.36930986e-06 -9.78022513e-07]\n",
      "   [-5.35814593e-07 -4.61469654e-07 -1.09751602e-06 ... -6.43625845e-06\n",
      "    -7.13541749e-06 -5.04288437e-06]\n",
      "   [-2.22698441e-06 -4.26859333e-06 -1.28046111e-06 ...  0.00000000e+00\n",
      "     0.00000000e+00  0.00000000e+00]\n",
      "   ...\n",
      "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
      "     0.00000000e+00  0.00000000e+00]\n",
      "   [-5.38552925e-03 -8.19935184e-03 -5.59423584e-03 ... -1.15156034e-03\n",
      "    -2.05656211e-03 -2.25965749e-03]\n",
      "   [-3.31821642e-03 -5.75596513e-03 -2.80867377e-03 ... -3.33243574e-04\n",
      "    -6.23081432e-05 -2.21667015e-05]]\n",
      "\n",
      "  [[-9.39335223e-06 -6.27012753e-07 -1.15266744e-06 ... -2.84473092e-04\n",
      "    -1.03545011e-04 -1.10521069e-04]\n",
      "   [-1.87604630e-04 -2.18137880e-04 -7.70949991e-05 ...  0.00000000e+00\n",
      "     0.00000000e+00  0.00000000e+00]\n",
      "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
      "     0.00000000e+00  0.00000000e+00]\n",
      "   ...\n",
      "   [-2.40812358e-03 -4.22883593e-03 -4.11582738e-03 ... -1.06668286e-03\n",
      "    -1.10480944e-02 -1.37990341e-02]\n",
      "   [-3.62203061e-03 -6.09343057e-04 -1.00243848e-03 ... -2.65606446e-04\n",
      "    -2.97850376e-04 -7.05856364e-05]\n",
      "   [-5.51828089e-05 -2.78509378e-05 -8.36958043e-06 ... -1.91950065e-04\n",
      "    -2.22222356e-04 -2.12054161e-04]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[-4.50917428e-12 -3.16191236e-12 -3.77275555e-12 ... -1.45446318e-12\n",
      "    -1.39034715e-12 -1.32162835e-12]\n",
      "   [-1.03613851e-12 -8.84997208e-13 -1.38188040e-12 ...  0.00000000e+00\n",
      "     0.00000000e+00  0.00000000e+00]\n",
      "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
      "     0.00000000e+00  0.00000000e+00]\n",
      "   ...\n",
      "   [-1.59501319e-08 -3.98448430e-09  3.28243422e-12 ... -5.93906868e-12\n",
      "    -5.29280569e-12 -4.90759039e-12]\n",
      "   [-4.43735803e-12 -4.43562895e-12 -4.37990920e-12 ... -3.02438955e-12\n",
      "    -2.92093823e-12 -3.16592412e-12]\n",
      "   [-2.57593968e-12 -1.89003999e-12 -1.91519305e-12 ... -7.61290499e-13\n",
      "    -6.20845714e-13 -5.80994508e-13]]\n",
      "\n",
      "  [[-4.86314168e-13 -5.78390200e-13 -6.97381118e-13 ...  0.00000000e+00\n",
      "     0.00000000e+00  0.00000000e+00]\n",
      "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
      "     0.00000000e+00  0.00000000e+00]\n",
      "   [-2.67719482e-08 -6.68883393e-09  8.50548798e-13 ... -3.98308643e-12\n",
      "    -3.91927202e-12 -3.96540873e-12]\n",
      "   ...\n",
      "   [-9.27929717e-13 -8.17696280e-13 -7.32935468e-13 ... -4.54746565e-13\n",
      "    -4.20115548e-13 -4.09356847e-13]\n",
      "   [-3.38677328e-13 -2.57056963e-13 -2.47124261e-13 ... -1.08777726e-13\n",
      "    -1.20264963e-13 -1.00348725e-13]\n",
      "   [-7.94128421e-14 -7.09088143e-14 -7.98647783e-14 ...  0.00000000e+00\n",
      "     0.00000000e+00  0.00000000e+00]]\n",
      "\n",
      "  [[ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
      "     0.00000000e+00  0.00000000e+00]\n",
      "   [-7.17440045e-08 -1.79367756e-08  6.46169316e-14 ... -3.24382990e-13\n",
      "    -3.25158926e-13 -3.24833666e-13]\n",
      "   [-3.02783054e-13 -2.79770673e-13 -2.37233925e-13 ... -1.27062870e-13\n",
      "    -1.29399827e-13 -1.23260248e-13]\n",
      "   ...\n",
      "   [-3.85566645e-15 -4.03823254e-15 -4.32480877e-15 ... -1.41218604e-15\n",
      "    -1.23482115e-15 -1.54258718e-15]\n",
      "   [-1.01435425e-15 -5.39077708e-16 -3.44277547e-16 ...  0.00000000e+00\n",
      "     0.00000000e+00  0.00000000e+00]\n",
      "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
      "     0.00000000e+00  0.00000000e+00]]]\n",
      "\n",
      "\n",
      " [[[ 3.95845564e-05  7.23246922e-06 -7.35097365e-06 ...  1.72099953e-06\n",
      "     1.08795793e-05  1.96020555e-05]\n",
      "   [ 8.60781438e-06  2.05802746e-04  3.99832323e-04 ... -7.50429265e-08\n",
      "    -2.91938456e-08 -3.24993259e-08]\n",
      "   [-5.37498135e-09 -1.41872325e-09 -1.48456403e-09 ... -2.92625533e-08\n",
      "    -9.07102393e-09 -1.29656073e-08]\n",
      "   ...\n",
      "   [-6.44487898e-07 -9.96142603e-07 -8.22959350e-07 ...  0.00000000e+00\n",
      "     0.00000000e+00  0.00000000e+00]\n",
      "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
      "     0.00000000e+00  0.00000000e+00]\n",
      "   [ 5.45838615e-04 -7.82496354e-04 -2.46109394e-03 ...  6.36324054e-03\n",
      "     2.61093695e-02  4.34155315e-02]]\n",
      "\n",
      "  [[ 3.33673097e-02  1.51894335e-02  2.09659268e-03 ... -9.60778652e-06\n",
      "    -4.36930986e-06 -9.78022513e-07]\n",
      "   [-5.35814593e-07 -4.61469654e-07 -1.09751602e-06 ... -6.43625845e-06\n",
      "    -7.13541749e-06 -5.04288437e-06]\n",
      "   [-2.22698441e-06 -4.26859333e-06 -1.28046111e-06 ...  0.00000000e+00\n",
      "     0.00000000e+00  0.00000000e+00]\n",
      "   ...\n",
      "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
      "     0.00000000e+00  0.00000000e+00]\n",
      "   [ 1.47692859e-04 -1.21180294e-03  2.39864737e-03 ...  1.15191042e-02\n",
      "     4.19772603e-03  4.90055233e-03]\n",
      "   [-1.34179019e-03  1.27393054e-03  1.21717062e-03 ... -3.33243574e-04\n",
      "    -6.23081432e-05 -2.21667015e-05]]\n",
      "\n",
      "  [[-9.39335223e-06 -6.27012753e-07 -1.15266744e-06 ... -2.84473092e-04\n",
      "    -1.03545011e-04 -1.10521069e-04]\n",
      "   [-1.87604630e-04 -2.18137880e-04 -7.70949991e-05 ...  0.00000000e+00\n",
      "     0.00000000e+00  0.00000000e+00]\n",
      "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
      "     0.00000000e+00  0.00000000e+00]\n",
      "   ...\n",
      "   [ 5.92858437e-03  9.46539454e-03  1.53805269e-03 ...  4.35814308e-03\n",
      "    -1.04044154e-02  8.72805528e-03]\n",
      "   [ 2.44653597e-02  2.00966327e-03 -8.12101469e-04 ... -2.65606446e-04\n",
      "    -2.97850376e-04 -7.05856364e-05]\n",
      "   [-5.51828089e-05 -2.78509378e-05 -8.36958043e-06 ... -1.91950065e-04\n",
      "    -2.22222356e-04 -2.12054161e-04]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[-4.50917428e-12 -3.16191236e-12 -3.77275555e-12 ... -1.45446318e-12\n",
      "    -1.39034715e-12 -1.32162835e-12]\n",
      "   [-1.03613851e-12 -8.84997208e-13 -1.38188040e-12 ...  0.00000000e+00\n",
      "     0.00000000e+00  0.00000000e+00]\n",
      "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
      "     0.00000000e+00  0.00000000e+00]\n",
      "   ...\n",
      "   [ 4.30500847e-07  1.07648006e-07  9.24870770e-12 ...  4.77914496e-12\n",
      "     8.37484943e-12  8.65877682e-12]\n",
      "   [ 6.60667311e-12  4.53261560e-12  2.44956702e-12 ... -3.02438955e-12\n",
      "    -2.92093823e-12 -3.16592412e-12]\n",
      "   [-2.57593968e-12 -1.89003999e-12 -1.91519305e-12 ... -7.61290499e-13\n",
      "    -6.20845714e-13 -5.80994508e-13]]\n",
      "\n",
      "  [[-4.86314168e-13 -5.78390200e-13 -6.97381118e-13 ...  0.00000000e+00\n",
      "     0.00000000e+00  0.00000000e+00]\n",
      "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
      "     0.00000000e+00  0.00000000e+00]\n",
      "   [ 8.08999914e-07  2.02272957e-07  5.48729985e-12 ...  4.90171792e-12\n",
      "     5.43367348e-12  4.00291605e-12]\n",
      "   ...\n",
      "   [ 2.76073045e-12  2.11470728e-12  1.58059308e-12 ... -4.54746565e-13\n",
      "    -4.20115548e-13 -4.09356847e-13]\n",
      "   [-3.38677328e-13 -2.57056963e-13 -2.47124261e-13 ... -1.08777726e-13\n",
      "    -1.20264963e-13 -1.00348725e-13]\n",
      "   [-7.94128421e-14 -7.09088143e-14 -7.98647783e-14 ...  0.00000000e+00\n",
      "     0.00000000e+00  0.00000000e+00]]\n",
      "\n",
      "  [[ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
      "     0.00000000e+00  0.00000000e+00]\n",
      "   [ 2.34460072e-06  5.86174167e-07  1.32304725e-12 ...  1.75406640e-12\n",
      "     1.35216263e-12  1.02680776e-12]\n",
      "   [ 1.45047418e-12  1.10595376e-12  5.75163073e-13 ... -1.27062870e-13\n",
      "    -1.29399827e-13 -1.23260248e-13]\n",
      "   ...\n",
      "   [-3.85566645e-15 -4.03823254e-15 -4.32480877e-15 ... -1.41218604e-15\n",
      "    -1.23482115e-15 -1.54258718e-15]\n",
      "   [-1.01435425e-15 -5.39077708e-16 -3.44277547e-16 ...  0.00000000e+00\n",
      "     0.00000000e+00  0.00000000e+00]\n",
      "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
      "     0.00000000e+00  0.00000000e+00]]]]\n",
      "Epoch 1/100\n",
      "Learning rate:  0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\patcas rares\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\keras_preprocessing\\image\\image_data_generator.py:938: UserWarning: Expected input to be images (as Numpy array) following the data format convention \"channels_last\" (channels on axis 3), i.e. expected either 1, 3 or 4 channels on axis 3. However, it was passed an array with shape (50, 40, 16, 19) (19 channels).\n",
      "  warnings.warn(\n",
      "c:\\users\\patcas rares\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\keras_preprocessing\\image\\numpy_array_iterator.py:129: UserWarning: NumpyArrayIterator is set to use the data format convention \"channels_last\" (channels on axis 3), i.e. expected either 1, 3, or 4 channels on axis 3. However, it was passed an array with shape (50, 40, 16, 19) (19 channels).\n",
      "  warnings.warn('NumpyArrayIterator is set to use the '\n",
      "c:\\users\\patcas rares\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\keras\\engine\\training.py:1972: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "1/2 [==============>...............] - ETA: 4s - loss: 2.8964 - accuracy: 0.0938"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-111-e1ddb79d7f59>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maccs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m9\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m         \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m     \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mret\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m0.54\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m         \u001b[1;32mcontinue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-110-89c3fd698c25>\u001b[0m in \u001b[0;36mmain\u001b[1;34m(pz)\u001b[0m\n\u001b[0;32m    218\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    219\u001b[0m         \u001b[1;31m# Fit the model on the batches generated by datagen.flow().\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 220\u001b[1;33m         model.fit_generator(datagen.flow(x_train, y_train, batch_size = batch_size),\n\u001b[0m\u001b[0;32m    221\u001b[0m                             \u001b[0mvalidation_data\u001b[0m \u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_valid\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_valid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    222\u001b[0m                             \u001b[0mepochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mworkers\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\patcas rares\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m   1973\u001b[0m                   \u001b[1;34m'will be removed in a future version. '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1974\u001b[0m                   'Please use `Model.fit`, which supports generators.')\n\u001b[1;32m-> 1975\u001b[1;33m     return self.fit(\n\u001b[0m\u001b[0;32m   1976\u001b[0m         \u001b[0mgenerator\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1977\u001b[0m         \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\patcas rares\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1182\u001b[0m                 _r=1):\n\u001b[0;32m   1183\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1184\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1185\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1186\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\patcas rares\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    883\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    884\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 885\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    886\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    887\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\patcas rares\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    915\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    916\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 917\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    918\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    919\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\patcas rares\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3037\u001b[0m       (graph_function,\n\u001b[0;32m   3038\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m-> 3039\u001b[1;33m     return graph_function._call_flat(\n\u001b[0m\u001b[0;32m   3040\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0;32m   3041\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\patcas rares\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1961\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1962\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1963\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1964\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0;32m   1965\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[1;32mc:\\users\\patcas rares\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    589\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    590\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 591\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    592\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    593\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\patcas rares\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     57\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "accs=[]\n",
    "precisions = []\n",
    "recalls = []\n",
    "fmeasures = []\n",
    "while True:\n",
    "    if len(accs) > 9:\n",
    "        break\n",
    "    ret = main(i)\n",
    "    if ret[0] < 0.54:\n",
    "        continue\n",
    "    accs+=[ret[0]]\n",
    "    precisions+=[ret[1]]\n",
    "    recalls+=[ret[2]]\n",
    "    fmeasures+=[ret[3]]\n",
    "print(accs)\n",
    "print(precisions)\n",
    "print(recalls)\n",
    "print(fmeasures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bdf6f58",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(accs))\n",
    "print('accs: ', accs)\n",
    "print('precisions: ', precisions)\n",
    "print('recalls: ', recalls)\n",
    "print('fmeasures: ', fmeasures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6777949f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.4541222062044867, 0.6489080939358943)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import scipy.stats as st\n",
    "\n",
    "#define sample data\n",
    "data = accs\n",
    "\n",
    "#create 95% confidence interval for population mean weight\n",
    "st.t.interval(alpha=0.95, df=len(data)-1, loc=np.mean(data), scale=st.sem(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a7ba3da9",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-23-a556f0421074>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9874d947",
   "metadata": {},
   "outputs": [],
   "source": [
    "accs = [0.26829269528388977, 0.41860464215278625, 0.4651162922382355, 0.5555555820465088, 0.5116279125213623, 0.4285714328289032, 0.44999998807907104, 0.39534884691238403, 0.6666666865348816, 0.5454545617103577]\n",
    "precisions = [0.07198096371207614, 0.1752298539751217, 0.2163331530557058, 0.7575757575757577, 0.7558139534883721, 0.1986062717770035, 0.20249999999999999, 0.15630070308274743, 0.44444444444444436, 0.29752066115702475]\n",
    "recalls = [0.2682926829268293, 0.4186046511627907, 0.46511627906976744, 0.5555555555555556, 0.5116279069767442, 0.42857142857142855, 0.45, 0.3953488372093023, 0.6666666666666666, 0.5454545454545454]\n",
    "fmeasures = [0.11350844277673547, 0.24704536789935186, 0.29531192321889993, 0.4188948306595365, 0.3700707785642063, 0.27142857142857146, 0.2793103448275862, 0.22403100775193796, 0.5333333333333334, 0.38502673796791437]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "0fc86ade",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.6539882966412536, 0.6943988016711244)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import scipy.stats as st\n",
    "\n",
    "#define sample data\n",
    "data = accs\n",
    "\n",
    "#create 95% confidence interval for population mean weight\n",
    "st.t.interval(alpha=0.95, df=len(data)-1, loc=np.mean(data), scale=st.sem(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "ad51f07e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.49031273655309493, 0.6830269359623643)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#define sample data\n",
    "data = precisions\n",
    "\n",
    "#create 95% confidence interval for population mean weight\n",
    "st.t.interval(alpha=0.95, df=len(data)-1, loc=np.mean(data), scale=st.sem(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "8ecd2c99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.6539882917530159, 0.6943988050211779)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#define sample data\n",
    "data = recalls\n",
    "\n",
    "#create 95% confidence interval for population mean weight\n",
    "st.t.interval(alpha=0.95, df=len(data)-1, loc=np.mean(data), scale=st.sem(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "66c4ddf5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.5504964410956525, 0.5997834952867505)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#define sample data\n",
    "data = fmeasures\n",
    "\n",
    "#create 95% confidence interval for population mean weight\n",
    "st.t.interval(alpha=0.95, df=len(data)-1, loc=np.mean(data), scale=st.sem(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6df9ee8a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
